\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}

\setcounter{MaxMatrixCols}{10}


\textwidth=6.9in
\oddsidemargin=-0.3in
\topmargin=-0.5in
\textheight=9.0in
\linespread{1.8}

\input{preamble}
\usepackage{amsfonts}
\usepackage{amsmath}


\setcounter{MaxMatrixCols}{10}


\title{Probabilità\footnote{mariachiara.menicucci@mail.polimi.it per segnalare errori, richiedere il codice LaTeX ecc.}}


\begin{document}

\maketitle
Questi appunti sono stati presi durante le lezioni dell'insegnamento "Probabilità" tenuto dalla prof. Guatteri durante l'A. A. 2022/23. Non sono stati revisionati da alcun docente (potrebbero contenere errori, in forma e in sostanza, di qualsiasi tipo) e non sono in alcun modo sostitutivi della frequentazione delle lezioni. 
\newpage
\tableofcontents

\newpage

\section{Fondamenti}

In genere indicheremo una funzione usando la notazione $X:\Omega \rightarrow
E$, dove $\Omega $ \`{e} il dominio e $E$ \`{e} il codominio; si indicano
con $A$ i sottinsieme di $\Omega $, con $B$ quelli di $E$, con $\omega $ il
generico elemento di $\Omega $, con $x$ l'immagine di $\omega $ attraverso $%
X $ ($X\left( \omega \right) =x\in E$). $\left\{ \omega \right\} \subseteq
\Omega $. Di solito per noi $E$ sar\`{a} $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ o $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, mentre per $\Omega $ abbiamo una vasta scelta.

\textbf{Def} Data $X:\Omega \rightarrow E$, $A\subseteq \Omega $, si dice
immagine di $A$ attraverso $X$, e si indica con $X\left( A\right) $, $%
\left\{ x\in E:\exists \text{ }\omega \in A:X\left( \omega \right)
=x\right\} $.

L'insieme degli $X\left( A\right) $ al variare di $A$, cio\`{e} $\left\{
X\left( A\right) :A\subseteq \Omega \right\} $ \`{e} una famiglia di
sottinsiemi di $E$. $X\left( A\right) \subseteq E$.

\textbf{Def} Data $X:\Omega \rightarrow E$, $B\subseteq E$, si dice
controimmagine di $B$ attraverso $X$, e si indica con $X^{-1}\left( B\right) 
$, $\left\{ \omega \in \Omega :X\left( \omega \right) \in B\right\} $.

Vale $X^{-1}\left( B\right) \subseteq \Omega $. $X^{-1}\left( B\right) $ 
\`{e} un oggetto ben definito per ogni $B\subseteq E$.\ Inoltre \`{e}
possibile che $X\left( \Omega \right) \subset E$, mentre $X^{-1}\left(
E\right) =\Omega $.

L'insieme degli $X^{-1}\left( B\right) $ al variare di $B$, cio\`{e} $%
\left\{ X^{-1}\left( B\right) :B\subseteq E\right\} $ \`{e} una famiglia di
sottinsiemi di $\Omega $.

\begin{enumerate}
\item Sia $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega ^{2}$. $X\left( \Omega \right)
=[0,+\infty )$, che \`{e} un sottinsieme proprio di $E$. Siano $A=\left(
0,1\right) \subseteq \Omega $, $B=\left( 0,1\right) \subseteq E$. $X\left(
A\right) =\left( 0,1\right) ,X^{-1}\left( B\right) =\left( -1,0\right) \cup
\left( 0,1\right) \subseteq \Omega $. $A^{c}=(-\infty ,0]\cup \lbrack
1,+\infty )$: $X\left( A^{c}\right) =[0,+\infty )$, mentre $\left( X\left(
A\right) \right) ^{c}=(-\infty ,0]\cup \lbrack 1,+\infty )$, quindi $X\left(
A^{c}\right) \neq \left( X\left( A\right) \right) ^{c}$: le due operazioni
non commutano.

Sia $\tilde{A}=\left( -1,0\right) $: $\tilde{A}\cap A=\NEG{0}$, cio\`{e} $%
\tilde{A}$ e $A$ sono disgiunti. $X\left( A\right) =\left( 0,1\right) $, $%
X\left( \tilde{A}\right) =\left( 0,1\right) $, quindi $X\left( A\right) \cap
X\left( \tilde{A}\right) =\left( 0,1\right) $, che \`{e} diverso da $X\left(
A\cap \tilde{A}\right) =\NEG{0}$: le operazioni di intersezione e immagine
non commutano.

$X^{-1}\left( E\right) =\Omega $. $X^{-1}\left( B\right) =\NEG{0}$ per ogni $%
B\subseteq \left( -\infty ,0\right) =\left( X\left( \Omega \right) \right)
^{c}$, invece $X^{-1}\left( (-\infty ,0]\right) =\left\{ 0\right\} $.

$B^{c}=(-\infty ,0]\cup \lbrack 1,+\infty )$: $X^{-1}\left( B^{c}\right)
=(-\infty ,-1]\cup \left\{ 0\right\} \cup \lbrack 1,+\infty )$, mentre $%
\left( X^{-1}\left( B\right) \right) ^{c}=\left( \left( -1,0\right) \cup
\left( 0,1\right) \right) ^{c}=(-\infty ,-1]\cup \left\{ 0\right\} \cup
\lbrack 1,+\infty )$: in questo caso le operazioni di controimmagine e
complementazione commutano, cio\`{e} $X^{-1}\left( B^{c}\right) =\left(
X^{-1}\left( B\right) \right) ^{c}$.

Sia $\tilde{B}=\left( -1,0\right) \subseteq E$. $\tilde{B}\cap B=\NEG{0}$ e $%
X^{-1}\left( \tilde{B}\cap B\right) =\NEG{0}$, ma anche $X^{-1}\left(
B\right) \cap X^{-1}\left( \tilde{B}\right) =\left( \left( -1,0\right) \cup
\left( 0,1\right) \right) \cap \NEG{0}=\NEG{0}$: in questo caso le
operazioni di intersezione e controimmagine commutano.
\end{enumerate}

In generale valgono le seguenti propriet\`{a}.

\textbf{Propriet\`{a} (controimmagine di una funzione)}%
\begin{gather*}
\text{Hp: }X:\Omega \rightarrow E,A\subseteq \Omega ,B\subseteq E\text{, }I%
\text{ qualsiasi} \\
\text{Ts: (i) }X\left( X^{-1}\left( B\right) \right) \subseteq E \\
\text{(ii) }X^{-1}\left( X\left( A\right) \right) \supseteq A \\
\text{(iii) }X^{-1}\left( B^{c}\right) =\left( X^{-1}\left( B\right) \right)
^{c} \\
\text{(iv) }\forall \text{ }\left( B_{\alpha }\right) _{\alpha \in
I}:B_{\alpha }\subseteq E\text{ }\forall \text{ }\alpha \in I\text{, }%
X^{-1}\left( \cap _{\alpha }B_{\alpha }\right) =\cap _{\alpha }X^{-1}\left(
B_{\alpha }\right) \\
\text{ e }X^{-1}\left( \cup _{\alpha }B_{\alpha }\right) =\cup _{\alpha
}X^{-1}\left( B_{\alpha }\right)
\end{gather*}

Un esempio di validit\`{a} di (i), (ii) si ha quando $B=E,A=\Omega $: (ii)
vale con l'uguaglianza se $A=\Omega $. In generale, con l'operazione di
immagine \`{e} possibile "perdere" qualcosa, mentre con la controimmagine 
\`{e} possibile "guadagnare" qualcosa. (iv) \`{e} significativa in
particolare quando $I$ \`{e} non numerabile: afferma che la controimmagine
dell'intersezione \`{e} l'intersezione delle controimmagini.

In probabilit\`{a} $X^{-1}\left( B\right) $ si indica con $\left( X\in
B\right) $. Quindi e. g. $X^{-1}\left( B^{c}\right) =\left( X\in
B^{c}\right) =\left( X\not\in B\right) =\left( X^{-1}\left( B\right) \right)
^{c}=\left( X\in B\right) ^{c}$: per le propriet\`{a} della controimmagine,
il simbolo di complementare passa fuori.


Date $X:\Omega \rightarrow E,h:E\rightarrow E^{\prime }$, si ha la funzione
composta $\left( h\circ X\right) \left( \omega \right) =Y\left( \omega
\right) =h\left( X\left( \omega \right) \right) $, funzione da $\Omega $ in $%
E^{\prime }$. Per ogni $C^{\prime }\subseteq E^{\prime }$ $\left( h\circ
X\right) ^{-1}\left( C^{\prime }\right) =X^{-1}\left( h^{-1}\left( C^{\prime
}\right) \right) $.

\textbf{Funzioni a valori in }$%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} chiuso rispetto alle operazioni di addizione, sottrazione,
divisione, moltiplicazione, massimo tra due elementi (indicato con $\vee $)
e minimo tra due elementi (indicato con $\wedge $): forma un reticolo.
Quindi, date $X_{1}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,X_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, \`{e} ben definita e. g. $X_{1}+X_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, cio\`{e} $\left( X_{1}+X_{2}\right) \left( \omega \right) =X_{1}\left(
\omega \right) +X_{2}\left( \omega \right) $.

\begin{enumerate}
\item Sia $\Omega =\left\{ t,c\right\} \times \left\{ t,c\right\} =\left\{
\left( t,t\right) ,\left( t,c\right) ,\left( c,t\right) ,\left( c,c\right)
\right\} =\left\{ \omega =\left( \omega _{1},\omega _{2}\right) :\omega
_{k}\in \left\{ t,c\right\} \text{ }\forall \text{ }k=1,2\right\} $, che
modella i possibili esiti di due lanci consecutivi di una moneta. $%
X_{1}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X_{1}\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se }\omega _{1}=t \\ 
0\text{ altrimenti}%
\end{array}%
\right. $, $X_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X_{2}\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se }\omega _{2}=t \\ 
0\text{ altrimenti}%
\end{array}%
\right. $. $X_{i}$ \`{e} la funzione indicatrice dell'evento "al lancio $i$ 
\`{e} uscita testa". $X_{1}\neq X_{2}$ perch\'{e} ad esempio se $\omega
=\left( t,c\right) $ $X_{1},X_{2}$ hanno valori diversi. $X_{1}$ pu\`{o}
essere rappresentata come $%
\begin{array}{cc}
1 & 0 \\ 
1 & 0%
\end{array}%
$, dove in ogni quadratino \`{e} presente il valore di $X_{1}$ associato a
un certo $\omega \in \Omega $: infatti $\left\vert \Omega \right\vert =4$. $%
a_{11}$ \`{e} il valore di $X_{1}$ per $\omega =\left( c,t\right) $, $a_{12}$
per $\omega =\left( c,c\right) $, $a_{21}$ per $\omega =\left( t,c\right) $, 
$a_{22}$ per $\omega =\left( t,t\right) $. Analogamente si rappresenta $%
X_{2} $ con $%
\begin{array}{cc}
0 & 0 \\ 
1 & 1%
\end{array}%
$. Allora $X_{1}+X_{2}$ \`{e} $%
\begin{array}{cc}
1 & 0 \\ 
2 & 1%
\end{array}%
$: $\left( X_{1}+X_{2}\right) \left( \omega \right) =\left\{ 
\begin{array}{c}
2\text{ se }\omega =\left( t,t\right) \\ 
0\text{ se }\omega =\left( c,c\right) \\ 
1\text{ altrimenti}%
\end{array}%
\right. $: $X_{1}+X_{2}$ conta il numero di teste uscite nei due lanci.

$2X_{1}-X_{2}$ \`{e} rappresentabile come $%
\begin{array}{cc}
2 & 0 \\ 
1 & -1%
\end{array}%
$, $X_{1}\vee X_{2}$ con $%
\begin{array}{cc}
1 & 0 \\ 
1 & 1%
\end{array}%
$, $X_{1}X_{2}$ con $%
\begin{array}{cc}
0 & 0 \\ 
1 & 0%
\end{array}%
$. L'insieme $\left( X_{1}=0\right) $ \`{e} l'insieme delle coppie per cui
il primo elemento non \`{e} $t$, dunque $\left\{ \left\{ c,t\right\}
,\left\{ c,c\right\} \right\} $: $\left( X_{1}=0\right) =X_{1}^{-1}\left(
\left\{ 0\right\} \right) =\left\{ \omega \in \Omega :X_{1}\left( \omega
\right) =0\right\} =\left\{ \omega \in \Omega :\omega _{1}\neq t\right\} $.
\end{enumerate}

\textbf{Spazio di Bernoulli }Considero gli esperimenti che possono avere
solo due esiti: successo o insuccesso. Si definisce $\Omega =\left\{
0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}$ come l'insieme delle successioni per cui ogni elemento \`{e} $0$ o $1$,
cio\`{e} $\Omega =\left\{ 0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}=\left\{ \left( \omega _{n}\right) _{n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
:}:\omega _{n}\in \left\{ 0,1\right\} \forall n\right\} $. $\Omega $ \`{e}
quindi uno spazio di successioni (detto spazio di Bernoulli), cio\`{e} il
generico elemento di $\Omega $ \`{e} e. g. $\bar{\omega}=\left(
0,1,...,0,1,...\right) $. $\Omega $ \`{e} non numerabile, per cui si vedr%
\`{a} che \`{e} ragionevole scegliere $\mathcal{A}=\sigma \left\{ \left(
E_{k}\right) _{k\geq 1}\right\} $, dove $E_{k}$ \`{e} l'evento che
rappresenta il successo al tentativo $k$.

Data una successione $\omega \in \Omega $, si definisce $X_{n}:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,X_{n}\left( \omega \right) =\omega _{n}$: \`{e} una funzione che a ogni
successione associa il suo elemento $n$-esimo, quindi una funzione
proiezione che restituisce l'esito dell'$n$-esimo esperimento.

Se l'$n$-esimo elemento di $\bar{\omega}$ \`{e} $1$, $X_{n}\left( \bar{\omega%
}\right) =\bar{\omega}_{n}=1$; $X_{0}\left( \bar{\omega}\right)
=0,X_{1}\left( \bar{\omega}\right) =1,X_{n-1}\left( \bar{\omega}\right) =0$. 
$\left( X_{n}\right) _{n\geq 0}$ \`{e} una successione di funzioni, ciascuna
delle quali, al variare di $\omega \in \Omega $, ha immagine $X_{n}\left(
\Omega \right) =\left\{ 0,1\right\} $.

\begin{enumerate}
\item $\left( X_{2}=0\right) $ \`{e} $X_{2}^{-1}\left( \left\{ 0\right\}
\right) $, cio\`{e} l'insieme delle successioni di $\Omega $ che hanno il
secondo elemento nullo: $\left\{ \omega \in \Omega :\omega _{2}=0\right\} $.

\item $\bigcap_{n=0}^{+\infty }\left( X_{n}=0\right) $ \`{e} l'insieme delle
successioni di $\Omega $ tali che $X_{i}=0$ $\forall $ $i=1,...,n$, quindi $%
\left\{ \omega _{n}:\omega _{n}=0\text{ }\forall \text{ }n\right\} $, cio%
\`{e} la successione nulla.
\end{enumerate}

\textbf{Funzione indicatrice} Dato $A\subseteq \Omega $, si definisce
funzione indicatrice dell'insieme $A$ la funzione $I_{A}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,I_{A}\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se }\omega \in A \\ 
0\text{ altrimenti}%
\end{array}%
\right. $. Quindi $\left( I_{A}=1\right) =I_{A}^{-1}\left( \left\{ 1\right\}
\right) =A$, mentre $\left( I_{A}=0\right) =A^{c}$. Se $A_{1},...,A_{n}%
\subseteq \Omega $, la funzione indicatrice della loro intersezione \`{e} $%
I_{\cap
_{k=1}^{n}A_{k}}=\prod_{k=1}^{n}I_{A_{k}}=I_{A_{1}}I_{A_{2}}...I_{A_{n}}$.
Inoltre $I_{A_{1}\cup A_{2}}=I_{A_{1}}+I_{A_{2}}-I_{A_{1}}I_{A_{2}}$.

\section{Definizione assiomatica di probabilit\`{a}}

Si dice esperimento aleatorio un esperimento, non necessariamente ripetibile
nel tempo, di cui non \`{e} noto a priori l'esito. E. g., si pu\`{o}
supporre di avere un'urna che contiene palline rosse e bianche e di voler
contare quante palline rosse ci sono: il numero non \`{e} noto a priori. La
probabilit\`{a} studia modelli per questi esperimenti aleatori. Ci interessa
in particolare - come modello di un esperimento aleatorio - la terna di
Kolmogorov $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, che \`{e} alla
base dell'approccio assiomatico alla probabilit\`{a}. L'approccio
assiomatico di Kolmogorov consiste nel fatto che la sua teoria non dice come
calcolare probabilit\`{a}, ma quali propriet\`{a} deve avere un certo
oggetto matematico per poter essere chiamato modello di un esperimento
aleatorio.

\subsection{Spazio campionario}

\textbf{Def} Si dice spazio campionario o spazio degli esiti, e si indica
con $\Omega $, un insieme che contiene tutti i possibili esiti
dell'esperimento aleatorio di cui si vuole costruire il modello. Un generico
elemento di $\Omega $, $\omega \in \Omega $, cio\`{e} un possibile risultato
dell'esperimento, si dice realizzazione dell'esperimento.

E' conveniente che $\Omega $ contenga tutti e soli i risultati
dell'esprimento; in generale per\`{o} la scelta di $\Omega $ dipende dallo
sperimentatore e dalla grandezza di interesse, non \`{e} univocamente
determinata dall'esperimento aleatorio; quando \`{e} possibile, \`{e}
conveniente scegliere $\Omega \subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

$\Omega $ pu\`{o} essere finito, infinito numerabile o infinito pi\`{u} che
numerabile; quando $\Omega $ \`{e} al pi\`{u} numerabile (cio\`{e} \`{e}
finito o infinito numerabile) si dice che $\Omega $ \`{e} discreto.

\begin{enumerate}
\item Se l'esperimento aleatorio \`{e} il lancio di un moneta e il risultato
di interesse \`{e} la faccia che esce, ci sono solo due possibili esiti:
esce testa o esce croce. Posso quindi scegliere uno spazio campionario
categorico $\Omega =\left\{ t,c\right\} $, oppure - se $0$ indica che esce
croce - $\Omega =\left\{ 0,1\right\} $.

\item Se lancio un dado e il risultato di interesse \`{e} il numero che esce
sulla faccia superiore, $\Omega =\left\{ 1,2,3,4,5,6\right\} $.

\item Se lancio $n$ volte una moneta e il risultato di interesse \`{e} il
numero di volte che esce testa, $\Omega =\left\{ 0,1,...,n\right\} $.

\item Se ho un'urna con $M$ palline rosse e bianche, tra cui almeno una
rossa e almeno una bianca, la grandezza di interesse \`{e} il numero di
palline rosse e conto il numero di palline rosse, $\Omega =\left\{
1,...,M-1\right\} $.

\item Se si considera il tempo di vita di una lampadina, $\Omega =\left[ 0,T%
\right] $, o $\Omega =\left[ 0,+\infty \right] $.
\end{enumerate}

Si dice evento una proposizione logica di cui, dopo l'esperimento aleatorio, 
\`{e} noto il valore di verit\`{a} o falsit\`{a}. Ogni realizzazione di $%
\Omega $, $\omega \in \Omega $, corrisponde a un evento $\left\{ \omega
\right\} \subseteq \Omega $, detto evento elementare. Ogni evento \`{e}
definito da un insieme $A\subseteq \Omega $ (quindi un sottinsieme di $%
\Omega $) tale che la proposizione logica che descrive l'evento \`{e} vera
se e solo se il risultato dell'esperimento $\omega $ appartiene a $\Omega $,
e allora si dice che l'evento si \`{e} verificato. Se invece $\omega \not\in
\Omega $, si \`{e} verificato $A^{c}$.

\begin{enumerate}
\item Se lancio un dado, $\Omega =\left\{ 1,2,3,4,5,6\right\} $; la
proposizione "esce il numero $1$" \`{e} un evento, che posso indicare con $A$
e a cui corrisponde un insieme a cui il risultato dell'esperimento
appartiene se e solo se la proposizione \`{e} vera. $A=\left\{ 1\right\}
\subseteq \Omega $. $C=\left\{ 2,4,6\right\} $ \`{e} l'evento "esce un
numero pari"; pur non essendo $C$ un evento elementare, pu\`{o} essere visto
come unione di eventi elementari: $C=\left\{ 2\right\} \cup \left\{
4\right\} \cup \left\{ 6\right\} $.
\end{enumerate}

\subsection{$\protect\sigma $-algebre}

In generale non \`{e} possibile descrivere per elencazione l'insieme di
tutti gli eventi relativi a un esperimento; se ne descrivono le propriet\`{a}%
.

\textbf{Def 1.1} Dato un qualsiasi insieme $\Omega $ e l'insieme delle parti
di $\Omega $ $2^{\Omega }$, dato $\mathcal{A}\subseteq 2^{\Omega }$, si dice
che $\mathcal{A}$ \`{e} una $\sigma $-algebra su $\Omega $ se valgono le
seguenti propriet\`{a}:

\begin{description}
\item[A1] $\Omega \in \mathcal{A},\varnothing \in \mathcal{A}$

\item[A2] $A\in \mathcal{A}\Longrightarrow A^{c}\in \mathcal{A}$

\item[A3] Se $\left( A_{n}\right) _{n\geq 1}$ \`{e} una successione di
eventi con $A_{n}\in \mathcal{A}$ $\forall $ $n$, allora $%
\bigcup_{n=1}^{+\infty }A_{n}\in \mathcal{A}$ e $\bigcap_{n=1}^{+\infty
}A_{n}\in \mathcal{A}$
\end{description}

$\mathcal{A}$ \`{e} "l'insieme degli eventi relativi a un esperimento che ci
possono interessare" (il generico elemento di $\mathcal{A}$ ha il
significato modellistico di evento) e le tre propriet\`{a} richieste sono
ragionevoli per poter avere un insieme abbastanza ricco di eventi: se ci
interessano gli eventi $A_{1},A_{2}$, ci interesseranno anche i loro
complementari, le loro unioni e le loro intersezioni. Una generica $\sigma $%
-algebra \`{e} una famiglia di sottinsiemi di $\Omega $ e non
necessariamente coincide con l'insieme delle parti di $\Omega $: pu\`{o}
esserne anche un sottinsieme proprio.

A2 afferma che $\mathcal{A}$ \`{e} chiusa rispetto all'operazione di
complementare, A3 che \`{e} chiusa rispetto all'intersezione e unione
numerabile. $\left( A_{n}\right) _{n\geq 1}$ con $A_{n}\in \mathcal{A}$ $%
\forall $ $n$ \`{e} una successione di eventi. La coppia $\left( \Omega ,%
\mathcal{A}\right) $ si dice spazio probabilizzabile o spazio misurabile.

Se $\Omega $ \`{e} al pi\`{u} numerabile, classicamente si considera come $%
\sigma $-algebra su $\Omega $ l'insieme delle parti di $\Omega $; se invece $%
\Omega =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ noi, come $\sigma $-algebra su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, non considereremo mai $\mathcal{P}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, perch\'{e} cos\`{\i} facendo non si riesce a definire una misura
di probabilit\`{a} che sia invariante per traslazioni. Questo si far\`{a}
in genere se $\Omega $ non \`{e} discreto.

La definizione pu\`{o} essere raffinata. Infatti, dalle richieste $\Omega
\in \mathcal{A}$ e A2 segue che $\varnothing \in \mathcal{A}$. Inoltre, per
le leggi di De Morgan, $\left( \bigcup_{\alpha }A_{\alpha }\right)
^{c}=\bigcap_{\alpha }A_{\alpha }^{c}$: quindi, se vale A2 e se $\left(
A_{n}\right) _{n\geq 1}$ successione con $A_{n}\in \mathcal{A}$ $\forall $ $%
n\Longrightarrow \bigcup_{n=1}^{+\infty }A_{n}\in \mathcal{A}$, si ha che $%
A_{n}^{c}\in \mathcal{A}$ $\forall $ $n$ e inoltre $\bigcup_{n=1}^{+\infty
}A_{n}^{c}\in \mathcal{A}$. Allora, per A2, $\left( \bigcup_{n=1}^{+\infty
}A_{n}^{c}\right) ^{c}=\bigcap_{n=1}^{+\infty }A_{n}\in \mathcal{A}$. La
definizione ripulita delle ridondanze diventa quindi

\textbf{Def 1.2} Dato un qualsiasi insieme $\Omega $ e l'insieme delle parti
di $\Omega $ $2^{\Omega }$, dato $\mathcal{A}\subseteq 2^{\Omega }$, si dice
che $\mathcal{A}$ \`{e} una $\sigma $-algebra su $\Omega $ se

\begin{description}
\item[A1'] $\Omega \in \mathcal{A}$

\item[A2] $A\in \mathcal{A}\Longrightarrow A^{c}\in \mathcal{A}$

\item[A3'] $\left( A_{n}\right) _{n\geq 1}$ \`{e} una successione di eventi
con $A_{n}\in \mathcal{A}$ $\forall $ $n\Longrightarrow
\bigcup_{n=1}^{+\infty }A_{n}\in \mathcal{A}$
\end{description}

Nella definizione, la chiusura \`{e} rispetto a un'unione numerabile, quindi
infinita: \`{e} per\`{o} naturale chiedere che la chiusura sia anche
rispetto a un'unione finita (si sta affermando che ogni $\sigma $-algebra 
\`{e} un'algebra).

\textbf{Prop 1.3 (chiusura per unione e intersezione finita)}%
\begin{gather*}
\text{Hp: }\mathcal{A}\text{ \`{e} una }\sigma \text{-algebra su }\Omega 
\text{, }n\text{ \`{e} finito, }A_{1},A_{2},...,A_{n}\text{ } \\
\text{sono tali che }A_{k}\in \mathcal{A}\text{ }\forall \text{ }k=1,...,n \\
\text{Ts: }\bigcup_{k=1}^{n}A_{k}\in \mathcal{A},\bigcap_{k=1}^{n}A_{k}\in 
\mathcal{A}
\end{gather*}

La tesi significa che $\mathcal{A}$ \`{e} chiusa anche per unione e
intersezione finita. Questo implica che sia anche chiusa per differenze,
perch\'{e} $A_{1}\backslash A_{2}=A_{1}\cap A_{2}^{c}$.

\textbf{Dim} Sia $n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $A_{1},A_{2},...,A_{n}:A_{k}\in \mathcal{A}$ $\forall $ $k=1,...,n$. Devo
dimostrare che $\bigcup_{k=1}^{n}A_{k}\in \mathcal{A}$: mi devo quindi
inventare una successione di eventi in modo da ottenere $%
\bigcup_{k=1}^{n}A_{k}$ come unione numerabile di eventi, per usare A3.
Definisco allora $\left( B_{k}\right) _{k\geq 1}$, famiglia numerabile di
eventi, in modo che $B_{k}\in \mathcal{A}$ $\forall $ $k$ e $%
\bigcup_{k=1}^{n}A_{k}=\bigcup_{k=1}^{+\infty }B_{k}$. Prendo $B_{k}=\left\{ 
\begin{array}{c}
A_{k}\text{ se }k\leq n \\ 
\varnothing \text{ se }k\geq n+1%
\end{array}%
\right. $: $B_{k}\in \mathcal{A}$ $\forall $ $k$ ($A_{k}$ per ipotesi, $%
\varnothing $ per A1) e $\bigcup_{k=1}^{+\infty
}B_{k}=\bigcup_{k=1}^{n}A_{k}\cup \varnothing .\cup
...=\bigcup_{k=1}^{n}A_{k}$, ma $\bigcup_{k=1}^{+\infty }B_{k}\in \mathcal{A}
$ per A3, dunque anche $\bigcup_{k=1}^{n}A_{k}\in \mathcal{A}$.

Allora $\mathcal{A}$ \`{e} chiusa anche per intersezione finita, perch\'{e} $%
\bigcap_{k=1}^{n}A_{k}=\left( \bigcup_{k=1}^{n}A_{k}^{c}\right) ^{c}$, e $%
\left( \bigcup_{k=1}^{n}A_{k}^{c}\right) ^{c}\in \mathcal{A}$ per quanto
appena mostrato e per A2. $\blacksquare $

Si \`{e} quindi visto come dalla sola richiesta (oltre ad A1 e A2) della
chiusura rispetto all'unione numerabile si siano dedotte anche la chiusura
rispetto all'intersezione numerabile, l'intersezione finita e l'unione
finita.

Data $\left( \mathcal{A}_{\alpha }\right) $ una famiglia di $\sigma $%
-algebre su $\Omega $, $\bigcap_{\alpha }\mathcal{A}_{\alpha }$ \`{e} ancora
una $\sigma $-algebra su $\Omega $, perch\'{e} $\varnothing ,\Omega \in 
\mathcal{A}_{\alpha }$ $\forall $ $\alpha $; dato un generico elemento in $%
\bigcap_{\alpha }\mathcal{A}_{\alpha }$, questo si trova in ciascuna $%
\mathcal{A}_{\alpha }$, dunque il suo complementare si trover\`{a} in
ciascuna $\mathcal{A}_{\alpha }$ e dunque anche in $\bigcap_{\alpha }%
\mathcal{A}_{\alpha }$; dati $n$ elementi di $\bigcap_{\alpha }\mathcal{A}%
_{\alpha }$, questi si trovano in ciascuna $\mathcal{A}_{\alpha }$, dunque
la loro unione si trover\`{a} in ciascuna $\mathcal{A}_{\alpha }$ e dunque
anche in $\bigcap_{\alpha }\mathcal{A}_{\alpha }$. L'unione di $\sigma $%
-algebre non \`{e} invece una $\sigma $-algebra.

\begin{enumerate}
\item Dato $\Omega $, la $\sigma $-algebra $\left\{ \varnothing ,\Omega
\right\} $, per cui sono banalmente veri A1, A2 e A3, \`{e} detta $\sigma $%
-algebra banale.

\item Dato $\Omega $, l'insieme delle parti di $\Omega $ $2^{\Omega }$ \`{e}
la pi\`{u} grande $\sigma $-algebra su $\Omega $, nel senso che qualsiasi $%
\sigma $-algebra su $\Omega $ \`{e} sottinsieme di $2^{\Omega }$.

\item Dato $\Omega $, se $A$ \`{e} un qualsiasi elemento di $2^{\Omega }$
(cio\`{e} un qualsiasi sottinsieme di $\Omega $), $\left\{ \varnothing
,\Omega ,A,A^{c}\right\} $ \`{e} una $\sigma $-algebra.

\item Considero $\Omega =\left\{ 1,2,3,4,5,6\right\} $ e l'evento $A=\left\{
2,4,6\right\} $ ("esce un numero pari"). La pi\`{u} piccola $\sigma $%
-algebra su $\Omega $ che contenga $A$ \`{e} $\left\{ \varnothing ,\Omega
,\left\{ 2,4,6\right\} ,\left\{ 1,3,5\right\} \right\} $.
\end{enumerate}

\textbf{Def} Dato un qualsiasi insieme $\Omega $ e l'insieme delle parti di $%
\Omega $ $2^{\Omega }$, dato $\mathcal{A}\subseteq 2^{\Omega }$, si dice che 
$\mathcal{A}$ \`{e} un'algebra su $\Omega $ se

\begin{description}
\item[A1] $\Omega \in \mathcal{A},\varnothing \in \mathcal{A}$

\item[A2] $A\in \mathcal{A}\Longrightarrow A^{c}\in \mathcal{A}$

\item[A3] $n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $A_{1},...,A_{n}\in \mathcal{A}\Longrightarrow \bigcup_{k=1}^{n}A_{k}\in 
\mathcal{A}$ e $\bigcap_{k=1}^{n}A_{k}\in \mathcal{A}$
\end{description}

Ogni $\sigma $-algebra su $\Omega $ \`{e} quindi un'algebra su $\Omega $.

\textbf{Def 1.4} Dato $\Omega $ e $\mathcal{C}\subseteq 2^{\Omega }$ una
classe di sottinsiemi di $\Omega $, si dice $\sigma $-algebra generata dalla
classe $\mathcal{C}$, e si indica con $\sigma \left( \mathcal{C}\right) $,
la pi\`{u} piccola $\sigma $-algebra su $\Omega $ contenente $\mathcal{C}$.

Con $\mathcal{C}$ in generale si indica un insieme di eventi, quindi un
sottinsieme di $2^{\Omega }$. Con "la pi\`{u} piccola $\sigma $-algebra" si
intende l'intersezione tra tutte le $\sigma $-algebre che contengono $%
\mathcal{C}$. Questa definizione serve perch\'{e} \`{e} possibile che si sia
interessati in particolare ad alcuni eventi (cio\`{e} alcuni elementi di $%
2^{\Omega }$), e si desidera quindi trovare una $\sigma $-algebra adeguata
per costruire un modello probabilistico dell'esperimento; in genere \`{e}
conveniente lavorare con una $\sigma $-algebra piccola.

\textbf{Prop 1.5 (esistenza della }$\sigma $\textbf{-algebra generata da un
insieme di eventi)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\Omega \text{ \`{e} un insieme qualsiasi, }\mathcal{C}%
\subseteq 2^{\Omega }\text{ una classe di sottinsiemi di }\Omega \\
\text{Ts}\text{: } &&\exists \text{ }\sigma \left( \mathcal{C}\right)
\end{eqnarray*}

Questo significa che la definizione 1.4 \`{e} ben posta.

\textbf{Dim*} Essendo $\mathcal{C}\subseteq 2^{\Omega }$, poich\'{e} $%
2^{\Omega }$ \`{e} una $\sigma $-algebra, esiste una $\sigma $-algebra che
contiene $\mathcal{C}$. L'intersezione di $\sigma $-algebre \`{e} ancora una 
$\sigma $-algebra: quindi se considero la famiglia di tutte le $\sigma $%
-algebre su $\Omega $ che contengono $\mathcal{C}$ e la chiamo $\mathcal{F}$%
, vale $\bigcap_{\alpha \in \mathcal{F}}\mathcal{A}_{\alpha }=\sigma \left( 
\mathcal{C}\right) $. $\blacksquare $

\begin{enumerate}
\item Se $\Omega $ \`{e} un insieme e $A\subseteq \Omega $, $\sigma \left(
A\right) =\left\{ \Omega ,\varnothing ,A,A^{c}\right\} $.
\end{enumerate}

\textbf{Def 1.6} Dato $\Omega $, si dice partizione discreta di $\Omega $, e
si indica con $\mathcal{C}$, una famiglia di sottinsiemi di $\Omega $ $%
\left\{ C_{k}\right\} _{k\in I}$ tale che $I$ \`{e} al pi\`{u} numerabile, $%
C_{k}\cap C_{h}=\varnothing $ $\forall $ $h\neq k$, $\bigcup_{k\in
I}C_{k}=\Omega $.

La seconda richiesta significa che i $C_{k}$ sono a due a due disgiunti, la
terza che almeno uno degli eventi $C_{k}$ si verifica sempre (essendo gli
eventi disgiunti, in realt\`{a} se ne verifica sempre esattamente uno).

\textbf{Prop 1.6 (}$\sigma $\textbf{-algebra generata da una partizione
discreta)} 
\begin{eqnarray*}
\text{Hp}\text{: } &&\Omega \text{ \`{e} un insieme qualsiasi, }\mathcal{C}%
\text{ \`{e} una partizione discreta di }\Omega \\
\text{Ts}\text{: } &&\sigma \left( \mathcal{C}\right) =\left\{ A\subseteq
\Omega :A=\bigcup_{k\in J}C_{k}\text{ al variare di }J\subseteq I\right\}
\end{eqnarray*}

Infatti $\left\{ A\subseteq \Omega :A=\bigcup_{k\in J}C_{k},J\subseteq
I\right\} $ \`{e} un insieme costruito in modo da essere chiuso rispetto
all'unione numerabile. Contiene $\varnothing $ (si prende $J=\varnothing $)
e $\Omega $ (si prende $J=I$). Se $\Omega $ \`{e} finito, $\left\vert \sigma
\left( \mathcal{C}\right) \right\vert =2^{\left\vert I\right\vert }$.

\begin{enumerate}
\item Sia $\Omega =\left\{ 1,...,6\right\} $. $C_{1}=\left\{ 1,6\right\}
,C_{2}=\left\{ 2,5\right\} ,C_{3}=\left\{ 3,4\right\} $: $\left\{
C_{k}\right\} $ \`{e} una partizione discreta di $\Omega $, indicizzata su $%
I=\left\{ 1,2,3\right\} $. I $J$ da considerare sono quindi $\varnothing
,\left\{ 1\right\} ,\left\{ 2\right\} ,\left\{ 3\right\} ,\left\{
1,2\right\} ,\left\{ 1,3\right\} ,\left\{ 2,3\right\} ,\left\{ 1,2,3\right\} 
$ e si ottiene $\sigma \left( \mathcal{C}\right) =\left\{ \varnothing
,\left\{ 1,6\right\} ,\left\{ 2,5\right\} ,\left\{ 3,4\right\} ,\left\{
1,2,5,6\right\} ,\left\{ 1,3,4,6\right\} ,\left\{ 2,3,4,5\right\} ,\left\{
1,2,3,4,5,6\right\} \right\} $, che \`{e} effettivamente una $\sigma $%
-algebra.

\item Se $\Omega $ \`{e} al pi\`{u} numerabile, la famiglia $\mathcal{C}%
=\left\{ \left\{ \omega _{i}\right\} \right\} _{i\in I}$ di tutti i
singoletti di $\Omega $ \`{e} una partizione di $\Omega $ e $\sigma \left( 
\mathcal{C}\right) =2^{\Omega }$.
\end{enumerate}

\textbf{Def 1.7} Si definisce insieme dei boreliani di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, e si indica con $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, la $\sigma $-algebra generata dalla classe $\mathcal{C}=\left\{
\left( a,b\right) :-\infty \leq a<b\leq +\infty \right\} $.

Si potrebbe equivalentemente usare $\left[ a,b\right] $ o $(a,b]$ per la
definizione. $\mathcal{C}$ \`{e} l'insieme di tutti gli intervalli aperti di 
$%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, e evidentemente non \`{e} una $\sigma $-algebra perch\'{e} non \`{e}
chiusa per complementazione: $\left( 0,1\right) ^{c}$ non \`{e} un
intervallo aperto. $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ contiene tutti gli intervalli di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ (ad esempio, $(a,b]=\bigcap_{n=1}^{+\infty }\left( a,b+\frac{1}{n}\right)
\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $), le loro unioni e le loro intersezioni, $%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$ e quindi $I$: in generale contiene tutti i sottinsiemi non "patologici" di 
$%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ (non l'insieme di Vitali, ad esempio), quindi $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \varsubsetneq 2^{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}$. In generale, si pu\`{o} mostrare che se 1.7 \`{e} data usando gli
intervalli di un certo tipo, allora la $\sigma $-algebra generata contiene
tutti gli intervalli di qualsiasi altro tipo: essenzialmente, quindi, $%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ \`{e} la pi\`{u} piccola $\sigma $-algebra che contenga tutti gli
intervalli di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

La definizione pu\`{o} essere data equivalentemente dicendo che $\mathcal{B}%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ \`{e} la $\sigma $-algebra generata dalla topologia di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, cio\`{e} gli aperti: l'equivalenza vale per ogni insieme aperto pu\`{o}
essere scritto come unione numerabile di intervalli aperti disgiunti.

\textbf{Prop 1.8 (genesi dei boreliani) }%
\begin{eqnarray*}
\text{Hp}\text{: } &&\mathcal{C}=\left\{ (-\infty ,q]:q\in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right\} \\
\text{Ts}\text{: } &&\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =\sigma \left( \mathcal{C}\right)
\end{eqnarray*}

Quindi la $\sigma $-algebra generata dall'insieme degli intervalli
inferiormente illimitati avente estremo destro razionale \`{e} la stessa
generata dall'insieme degli aperti di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. L'utilit\`{a} della proposizione sta nel fatto che l'insieme delle
semirette \`{e} pi\`{u} semplice rispetto a quello degli aperti.

\subsection{Misure di probabilit\`{a}}

Storicamente ci sono stati tre principali approcci alla probabilit\`{a}:

\begin{enumerate}
\item approccio soggettivista: la probabilit\`{a} di un evento \`{e} il
grado di fiducia dello sperimentatore nel verificarsi di tale evento.
Dipende dal grado di avversione al rischio dello sperimentatore.

\item approccio frequentista: si suppone di poter ripetere pi\`{u} volte
l'esperimento. Se si fanno $n$ prove e l'evento di interesse si \`{e}
verificato $n_{A}$ volte, la frequenza relativa dell'evento $A$ di interesse 
\`{e} $f_{n}\left( A\right) =\frac{n_{A}}{n}$. Allora si definisce la
probabilit\`{a} di $A$ come $\mathbf{P}\left( A\right) =\lim_{n\rightarrow
+\infty }f_{n}\left( A\right) $.

\item approccio classico: per ogni esperimento che abbia un numero finito di
esiti possibili (occorre che la cardinalit\`{a} di $\Omega $ $\left\vert
\Omega \right\vert $ sia finita) si definisce $\mathbf{P}\left( A\right) $
come numero di casi favorevoli fratto numero di casi possibili.
\end{enumerate}

Se ad esempio lancio un dado non truccato, posso usare tutti e tre gli
approcci e ottengo lo stesso risultato; se invece lancio un dado truccato
(e. g. con una faccia di materiale diverso, che renda pi\`{u} probabile
l'uscita della faccia opposta), l'unico approccio sensato \`{e} quello
frequentista, perch\'{e} non si dispone di informazioni sulla situazione.
Per valutare la probabilit\`{a} che ci siano elezioni politiche quest'anno 
\`{e} invece sensato usare l'approccio soggettivista (l'esperimento \`{e}
non ripetibile).

\textbf{Def 2.1} Dato lo spazio misurabile $\left( \Omega ,\mathcal{A}%
\right) $, si dice misura di probabilit\`{a} su $\left( \Omega ,\mathcal{A}%
\right) $ una funzione $\mathbf{P}:\mathcal{A}\rightarrow \left[ 0,1\right] $
tale che

\begin{description}
\item[A1] $\mathbf{P}\left( \Omega \right) =1$

\item[A2] se $\left( A_{n}\right) _{n\geq 1}$ \`{e} una famiglia numerabile tale che $%
A_{n}\in \mathcal{A}$ $\forall $ $n\geq 1$ e $A_{h}\cap A_{k}=\varnothing $ 
$\forall $ $h\neq k$, allora $\mathbf{P}\left( \bigcup_{n=1}^{+\infty }A_{n}\right)
=\sum_{n=1}^{+\infty }\mathbf{P}\left( A_{n}\right) $
\end{description}

A1 \`{e} ben posta perch\'{e} $\Omega \in \mathcal{A}$. $\left( A_{n}\right)
_{n\geq 1}$ \`{e} quindi una famiglia numerabile di eventi. A2 \`{e} ben
posta perch\'{e} $\bigcup_{n=1}^{+\infty }A_{n}$ \`{e} un'unione numerabile
di elementi di $\mathcal{A}$, quindi appartiene a $\mathcal{A}$ e $\mathbf{P}
$ \`{e} ivi definita. $\Omega $ \`{e} detto evento certo, per il quale si ha
il massimo grado di fiducia. A2 permette di calcolare la probabilit\`{a} che
almeno uno degli $A_{n}$ (di fatto, esattamente uno, perch\'{e} sono eventi
disgiunti) si verifichi, se si conosce la probabilit\`{a} di ciascun evento.
A2 \`{e} detta $\sigma $-additivit\`{a}, ed \`{e} fondamentale il fatto che
si richiede che $\mathbf{P}$ sia additiva rispetto a famiglie numerabili di
eventi. Se si richiede l'addivit\`{a} rispetto a una qualsiasi famiglia di
eventi, anche non numerabile - oltre a non sapere se l'unione non numerabile
di eventi appartiene ad $\mathcal{A}$ - si incorre immediatamente in una
contraddizione, perch\'{e} se si considera $\left( \Omega ,\mathcal{A}%
\right) $ con $\Omega =\left[ a,b\right] $, $\mathcal{A}$ una $\sigma $%
-algebra qualsiasi su $\Omega $ e una $\mathbf{P:P}\left( \left\{ x\right\}
\right) =0$ $\forall $ $x\in \left[ a,b\right] $, si ha che $\mathbf{P}%
\left( \bigcup_{n=1}^{+\infty }A_{n}\right) =\mathbf{P}\left( \bigcup_{x\in %
\left[ a,b\right] }\left\{ x\right\} \right) =\mathbf{P}\left( \Omega
\right) =\sum_{x\in \left[ a,b\right] }0$, che contraddice A1.

La probabilit\`{a} assegna a ogni evento, cio\`{e} a degli insiemi, un
numero reale, che fornisce una misura degli eventi, proprio come, misurando
le aree e i volumi, si assegna a un insieme un numero reale.

\textbf{Teo 2.2 (propriet\`{a} della probabilit\`{a})}%
\begin{gather*}
\text{Hp: }\mathbf{P}\text{ \`{e} una misura di probabilit\`{a} su }\left(
\Omega ,\mathcal{A}\right) \\
\text{Ts: (P1) }\mathbf{P}\left( \varnothing \right) =0 \\
\text{(P2) Se }\left\{ A_{1},...,A_{n}\right\} \text{ \`{e} un insieme tale
che }A_{n}\in \mathcal{A}\text{ }\forall \text{ }n\geq 1\text{ } \\
\text{e }A_{h}\cap A_{k}=\varnothing \text{ }\forall \text{ }h\neq k\text{, }%
\mathbf{P}\left( \bigcup_{k=1}^{n}A_{k}\right) =\sum_{k=1}^{n}\mathbf{P}%
\left( A_{k}\right)
\end{gather*}

P2 \`{e} detta finita additivit\`{a}: se $\mathbf{P}$ \`{e} $\sigma $%
-additiva, allora \`{e} anche additiva rispetto a una famiglia finita di
eventi disgiunti. Non vale invece il viceversa.

\textbf{Dim} (P1) E' logico pensare di usare A2. Considero la famiglia
numerabile $\left( A_{n}\right) _{n\geq 1}$ con $A_{n}=\varnothing $ $%
\forall $ $n\geq 1$: vale $A_{n}\in \mathcal{A}$ $\forall $ $n$ e $A_{h}\cap
A_{k}=\varnothing $ $\forall $ $h\neq k$, allora, poich\'{e} $\mathbf{P}$ 
\`{e} una misura di probabilit\`{a}, per A1 $\mathbf{P}\left(
\bigcup_{n=1}^{+\infty }A_{n}\right) =\mathbf{P}\left( \varnothing \right)
=\sum_{n=1}^{+\infty }\mathbf{P}\left( \varnothing \right) $. Quindi, poich%
\'{e} $\mathbf{P}\in \left[ 0,1\right] $, $\mathbf{P}\left( \varnothing
\right) =0$. (Oppure: $\mathbf{P}\left( \Omega \cup \varnothing \right) =1$)

(P2) Considero la famiglia numerabile $\left( B_{k}\right) _{k\geq 1}$
definita come segue: $B_{k}=\left\{ 
\begin{array}{c}
A_{k}\text{ se }k\leq n \\ 
\varnothing \text{ se }k>n%
\end{array}%
\right. $. Vale $B_{k}\in \mathcal{A}$ $\forall $ $k$ e $B_{h}\cap
B_{k}=\varnothing $ $\forall $ $h\neq k$ per le ipotesi e poi si hanno solo
insiemi vuoti; inoltre $\bigcup_{k=1}^{+\infty }B_{k}=\bigcup_{k=1}^{n}A_{k}$%
, ma quindi per A2 $\mathbf{P}\left( \bigcup_{k=1}^{+\infty }B_{k}\right)
=\sum_{k=1}^{+\infty }\mathbf{P}\left( B_{k}\right) =\sum_{k=1}^{n}\mathbf{P}%
\left( A_{k}\right) +\mathbf{P}\left( \varnothing \right) +...+\mathbf{P}%
\left( \varnothing \right) =\sum_{k=1}^{n}\mathbf{P}\left( A_{k}\right) $ e $%
\bigcup_{k=1}^{n}A_{k}=\sum_{k=1}^{n}\mathbf{P}\left( A_{k}\right) $. $%
\blacksquare $

\textbf{Teo 2.3 (propriet\`{a} della probabilit\`{a})}%
\begin{gather*}
\text{Hp: }\mathbf{P}\text{ \`{e} una misura di probabilit\`{a} su }\left(
\Omega ,\mathcal{A}\right) \\
\text{Ts: (P3) (monotonia) se }A,A^{\prime }\in \mathcal{A}\text{ e }%
A\subseteq A^{\prime }\text{, }\mathbf{P}\left( A\right) \leq \mathbf{P}%
\left( A^{\prime }\right) \\
\text{(P4) (complementare) se }A\in \mathcal{A}\text{, }\mathbf{P}\left(
A^{c}\right) =1-\mathbf{P}\left( A\right) \\
\text{(P5) (differenza) se }A,A^{\prime }\in \mathcal{A}\text{, }\mathbf{P}%
\left( A\backslash A^{\prime }\right) =\mathbf{P}\left( A\right) -\mathbf{P}%
\left( A^{\prime }\cap A\right) \\
\text{(P6) (unione) se }A,A^{\prime }\in \mathcal{A}\text{, }\mathbf{P}%
\left( A\cup A^{\prime }\right) =\mathbf{P}\left( A\right) +\mathbf{P}\left(
A^{\prime }\right) -\mathbf{P}\left( A\cap A^{\prime }\right) \\
\text{(P7) se }\left( A_{n}\right) _{n\geq 1}\text{ \`{e} una famiglia
numerabile tale che }A_{n}\in \mathcal{A}\text{ }\forall \text{ }n\text{, }%
\mathbf{P}\left( \bigcup_{n=1}^{+\infty }A_{n}\right) \leq
\sum_{n=1}^{+\infty }\mathbf{P}\left( A_{n}\right) \\
\text{(P8) disuguaglianza di Bonferroni: se }\left\{ A_{1},...,A_{n}\right\} 
\text{ \`{e} un insieme tale che }A_{n}\in \mathcal{A}\text{ } \\
\forall \text{ }n\geq 1\text{, }\mathbf{P}\left( A_{1}\cap ...\cap
A_{n}\right) \geq \mathbf{P}\left( A_{1}\right) +...+\mathbf{P}\left(
A_{n}\right) -\left( n-1\right) \text{ }\forall \text{ }n\geq 2
\end{gather*}

P3 mantiene la relazione d'ordine da $\mathcal{A}$ a $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. p5 generalizza P4. P6 implica $\mathbf{P}\left( A\cup A^{\prime }\right)
\leq \mathbf{P}\left( A\right) +\mathbf{P}\left( A^{\prime }\right) $,
propriet\`{a} che \`{e} detta subadditivit\`{a}. P7 diventa inutile se la
serie al lato destro diverge.

\textbf{Dim} (P3) Sar\`{a} naturale usare ancora P2. Voglio scrivere $%
A^{\prime }$ come unione di insiemi disgiunti: disintegrandolo grazie ad $A$%
, $A^{\prime }=\left( A^{\prime }\cap A\right) \cup \left( A^{\prime }\cap
A^{c}\right) =A\cup \left( A^{\prime }\cap A^{c}\right) =A\cup \left(
A^{\prime }\backslash A\right) $. $A^{\prime }\cap A,A^{\prime }\cap A^{c}$
sono disgiunti e ciascuno dei due appartiene a $\mathcal{A}$ per ipotesi e
A2 e A3. Quindi per P2 $\mathbf{P}\left( A^{\prime }\right) =\mathbf{P}%
\left( A\right) +\mathbf{P}\left( A^{\prime }\backslash A\right) \geq 
\mathbf{P}\left( A\right) $ perch\'{e} $\mathbf{P}\left( A^{\prime
}\backslash A\right) \geq 0$.

(P4) Vale $\Omega =A\cup A^{c}$, quindi $\mathbf{P}\left( A\cup A^{c}\right)
=1=\mathbf{P}\left( A\right) +\mathbf{P}\left( A^{c}\right) $, perch\'{e} $%
A,A^{c}$ sono disgiunti e $A,A^{c}\in \mathcal{A}$, quindi si usa P2.

(P5) Vale $A=\left( A\backslash A^{\prime }\right) \cup \left( A^{\prime
}\cap A\right) $, quindi, essendo $A\backslash A^{\prime },A^{\prime }\cap A$
eventi disgiunti e appartenenti ad $\mathcal{A}$, per P2 $\mathbf{P}\left(
A\backslash A^{\prime }\right) +\mathbf{P}\left( A^{\prime }\cap A\right) =%
\mathbf{P}\left( A\right) $.

(P6) Di nuovo, scrivo $A\cup A^{\prime }$ come unione di insiemi disgiunti: $%
A\cup A^{\prime }=\left( A\backslash A^{\prime }\right) \cup \left( A\cap
A^{\prime }\right) \cup \left( A^{\prime }\backslash A\right) $. Per P5 $%
\mathbf{P}\left( A\backslash A^{\prime }\right) =\mathbf{P}\left( A\right) -%
\mathbf{P}\left( A^{\prime }\cap A\right) $, mentre $\mathbf{P}\left(
A^{\prime }\backslash A\right) =\mathbf{P}\left( A^{\prime }\right) -\mathbf{%
P}\left( A^{\prime }\cap A\right) $, quindi per P2 $\mathbf{P}\left( A\cup
A^{\prime }\right) =\mathbf{P}\left( A\backslash A^{\prime }\right) +\mathbf{%
P}\left( A\cap A^{\prime }\right) +\mathbf{P}\left( A^{\prime }\backslash
A\right) =\mathbf{P}\left( A\right) -\mathbf{P}\left( A^{\prime }\cap
A\right) +\mathbf{P}\left( A\cap A^{\prime }\right) +\mathbf{P}\left(
A^{\prime }\right) -\mathbf{P}\left( A^{\prime }\cap A\right) =\mathbf{P}%
\left( A\right) +\mathbf{P}\left( A^{\prime }\right) -\mathbf{P}\left(
A^{\prime }\cap A\right) $.

(P8) Si procede per induzione. Se $n=2$, per P6 $\mathbf{P}\left( A_{1}\cap
A_{2}\right) =\mathbf{P}\left( A_{1}\right) +\mathbf{P}\left( A_{2}\right) -%
\mathbf{P}\left( A_{1}\cup A_{2}\right) \geq \mathbf{P}\left( A_{1}\right) +%
\mathbf{P}\left( A_{2}\right) \geq \mathbf{P}\left( A_{1}\right) +\mathbf{P}%
\left( A_{2}\right) -1$. Ora suppongo $\mathbf{P}\left( A_{1}\cap ...\cap
A_{n}\right) \geq \mathbf{P}\left( A_{1}\right) +...+\mathbf{P}\left(
A_{n}\right) -\left( n-1\right) $ vera per $n$ generico e mostro che \`{e}
vera anche per $n+1$. Sia $A^{\prime }=A_{1}\cap ...\cap A_{n}$, che
appartiene ad $\mathcal{A}$: $\mathbf{P}\left( A_{1}\cap ...\cap A_{n}\cap
A_{n+1}\right) =\mathbf{P}\left( A^{\prime }\cap A_{n+1}\right) \geq \mathbf{%
P}\left( A^{\prime }\right) +\mathbf{P}\left( A_{n+1}\right) -1$, che per
ipotesi induttiva \`{e} maggiore o uguale di $\mathbf{P}\left( A_{1}\right)
+...+\mathbf{P}\left( A_{n}\right) -\left( n-1\right) +\mathbf{P}\left(
A_{n+1}\right) -1=\mathbf{P}\left( A_{1}\right) +...+\mathbf{P}\left(
A_{n}\right) +\mathbf{P}\left( A_{n+1}\right) -\left( n+1-1\right) $. $%
\blacksquare $

\begin{enumerate}
\item Dimostro che, dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $%
A\in \mathcal{A}:\mathbf{P}\left( A\right) =1$, $\mathbf{P}\left( A\cap
B\right) =\mathbf{P}\left( B\right) $ $\forall $ $B\in \mathcal{A}$. Infatti 
$\mathbf{P}\left( A\cap B\right) =\mathbf{P}\left( A\right) +\mathbf{P}%
\left( B\right) -\mathbf{P}\left( A\cup B\right) $. Ma $\mathbf{P}\left(
A\cup B\right) \mathbf{\geq P}\left( A\right) =1$ per P3, essendo $%
A\subseteq A\cup B$: quindi $\mathbf{P}\left( A\cup B\right) =1$ e $\mathbf{P%
}\left( A\cap B\right) =1+\mathbf{P}\left( B\right) -1=\mathbf{P}\left(
B\right) $.
\end{enumerate}

\textbf{Successioni di insiemi inscatolati }Data una $\sigma $-algebra $%
\mathcal{A}$, data una famiglia numerabile $\left( A_{n}\right) _{n\geq
1}:A_{n}\in \mathcal{A}$ $\forall $ $n$, si dice che $A_{n}$ cresce ad $A$,
e si scrive $A_{n}\uparrow A$, se vale $\left\{ 
\begin{array}{c}
A_{n}\subseteq A_{n+1} \\ 
\bigcup_{n=1}^{+\infty }A_{n}=A%
\end{array}%
\right. $; si dice che $A_{n}$ decresce ad $A$, e si scrive $A_{n}\downarrow
A$, se vale $\left\{ 
\begin{array}{c}
A_{n+1}\subseteq A_{n} \\ 
\bigcap_{n=1}^{+\infty }A_{n}=A%
\end{array}%
\right. $. Il fatto che tra insiemi non sia definita una relazione d'ordine
totale, a differenza di quanto accade in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, non rende possibile estendere la definizione di limite per successioni
alle successioni di insiemi.

$\bigcup_{n=1}^{+\infty }A_{n}$ \`{e} ben definita, senza bisogno di
inventarsi una definizione di limite: $\bigcup_{n=1}^{+\infty }A_{n}=\left\{
a:\exists \text{ }i:a\in A_{i}\right\} $.

\textbf{Def} Dato un insieme $\Omega $ e una successione di insiemi $%
A_{1},A_{2},...:A_{i}\subseteq \Omega $ $\forall $ $i$, si definisce limite
superiore degli $A_{n}$, e si indica con $\lim \sup_{n}A_{n}$, $%
\bigcap_{n=1}^{+\infty }\bigcup_{k=n}^{+\infty }A_{n}$.

\textbf{Def} Dato un insieme $\Omega $ e una successione di insiemi $%
A_{1},A_{2},...:A_{i}\subseteq \Omega $ $\forall $ $i$, si definisce limite
inferiore degli $A_{n}$, e si indica con $\lim \inf_{n}A_{n}$, $%
\bigcup_{n=1}^{+\infty }\bigcap_{k=n}^{+\infty }A_{n}$.

Se $\left( \Omega ,\mathcal{A}\right) $ \`{e} uno spazio misurabile e $%
A_{i}\in \mathcal{A}$ $\forall $ $i$, l'evento $\lim \sup_{n}A_{n}$ pu\`{o}
essere espresso a parole come "$\omega $ appartiene ad $A_{n}$ per infiniti $%
n$"; l'evento $\lim \inf_{n}A_{n}$ pu\`{o} essere espresso a parole come "$%
\omega $ appartiene definitivamente ad $A_{n}$", cio\`{e} $\exists $ $%
k:\omega \in A_{n}$ $\forall $ $n\geq k$. Se e. g. $A_{n}$ rappresenta la
testa in un lancio di moneta, $\lim \sup_{n}A_{n}$ si verifica se e solo se
esce testa infinite volte, $\lim \inf_{n}A_{n}$ si verifica se e solo se
esce sempre testa da un certo punto in poi.

\textbf{Teo 2.4 (continuit\`{a} della probabilit\`{a})}
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( A_{n}\right) _{n\geq 1}:A_{n}\in 
\mathcal{A}\text{ }\forall \text{ }n\text{, }A_{n}\uparrow A \\
\text{Ts}\text{: (P9) }\mathbf{P}\left( \bigcup_{n=1}^{+\infty }A_{n}\right)
=\lim_{n\rightarrow +\infty }\mathbf{P}\left( A_{n}\right) \\
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( A_{n}\right) _{n\geq 1}:A_{n}\in 
\mathcal{A}\text{ }\forall \text{ }n\text{, }A_{n}\downarrow A \\
\text{Ts}\text{: (P10) }\mathbf{P}\left( \bigcap_{n=1}^{+\infty
}A_{n}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}\left( A_{n}\right)
\end{gather*}

La tesi \`{e} ben posta perch\'{e} $\bigcup_{n=1}^{+\infty }A_{n}\in 
\mathcal{A}$: ogni $\sigma $-algebra \`{e} chiusa per limiti crescenti.

\textbf{Dim} (P9) Devo scrivere $A$ come unione di insiemi disgiunti.
Costruisco $\left( B_{n}\right) _{n\geq 1}:B_{1}=A_{1},B_{2}=A_{2}\backslash
A_{1},...,B_{n}=A_{n}\backslash A_{n-1}$ con $n\geq 2$: per $\left(
B_{n}\right) _{n\geq 1}$ vale che $\bigcup_{n=1}^{+\infty }B_{n}=A$, $%
\bigcup_{k=1}^{n}B_{k}=A_{k}$, $B_{h}\cap B_{k}=\varnothing $ $\forall $ $%
h\neq k$. Allora per la $\sigma $-additivit\`{a} sui $B_{n}$, cio\`{e} A2,
vale $\mathbf{P}\left( A\right) =\mathbf{P}\left( \bigcup_{n=1}^{+\infty
}B_{n}\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left( B_{n}\right)
=\lim_{k\rightarrow +\infty }\sum_{n=1}^{k}\mathbf{P}\left( B_{n}\right)
=\lim_{k\rightarrow +\infty }\mathbf{P}\left( A_{k}\right) $\ usando la
successione delle somme parziali, e per P2 su $A_{k}$.

(P10) Uso le leggi di De Morgan. Vale $\bigcap_{n=1}^{+\infty }A_{n}=\left(
\bigcup_{n=1}^{+\infty }A_{n}^{c}\right) ^{c}$, per cui $\mathbf{P}\left(
\bigcap_{n=1}^{+\infty }A_{n}\right) =\mathbf{P}\left(
\bigcup_{n=1}^{+\infty }A_{n}^{c}\right) ^{c}=1-\mathbf{P}\left(
\bigcup_{n=1}^{+\infty }A_{n}^{c}\right) =1-\lim_{n\rightarrow +\infty }%
\mathbf{P}\left( A_{n}^{c}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}%
\left( A_{n}\right) $, usando P4 e P9. $\blacksquare $

\textbf{Teo (lemma di Borel-Cantelli)*}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( A_{n}\right) _{n\geq 1}:A_{n}\in 
\mathcal{A}\text{ }\forall \text{ }n\text{, }\sum_{n=1}^{+\infty }\mathbf{P}%
\left( A_{n}\right) <+\infty \\
\text{Ts}\text{: (P9) }\mathbf{P}\left( \lim \sup_{n}A_{n}\right) =0
\end{gather*}

\textbf{Dim} Per definizione $\lim \sup_{n}A_{n}=\bigcap_{n=1}^{+\infty
}\bigcup_{k=n}^{+\infty }A_{k}$. Ponendo $B_{n}=\bigcup_{k=n}^{+\infty
}A_{n} $, i $B_{n}$ sono una successione decrescente, quindi per continuit%
\`{a} e subadditivit\`{a} della probabilit\`{a} $\mathbf{P}\left(
\bigcap_{n=1}^{+\infty }B_{n}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}%
\left( \bigcup_{k=n}^{+\infty }A_{k}\right) \leq \lim_{n\rightarrow +\infty
}\sum_{k=n}^{+\infty }\mathbf{P}\left( A_{k}\right) =\lim_{n\rightarrow
+\infty }\left( \sum_{k=1}^{+\infty }\mathbf{P}\left( A_{k}\right)
-\sum_{k=n+1}^{+\infty }\mathbf{P}\left( A_{k}\right) \right)
=\lim_{n\rightarrow +\infty }0=0$. $\blacksquare $

\subsubsection{Assegnazione di una probabilit\`{a}}

E' ora naturale chiedersi come si fa, dato uno spazio misurabile $\left(
\Omega ,\mathcal{A}\right) $, ad assegnarvi una probabilit\`{a} $\mathbf{P}$%
.\ Partiamo dal caso semplice di assegnazione di probabilit\`{a}, con $%
\Omega $ discreto.

\textbf{Teo 3.1 (assegnazione di probabilit\`{a} su }$\Omega $ \textbf{%
discreto)}%
\begin{gather*}
\text{Hp: }\Omega \text{ \`{e} al pi\`{u} numerabile} \\
\text{Ts: (i) }\mathbf{P}:2^{\Omega }\rightarrow \left[ 0,1\right] \text{ 
\`{e} caratterizzata da }p:\Omega \rightarrow \left[ 0,1\right] \text{ tale
che }p\left( \omega \right) =\mathbf{P}\left( \left\{ \omega \right\} \right)
\\
\text{(ii) data }p:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }\exists \text{ }!\text{ }\mathbf{P}:2^{\Omega }\rightarrow \left[
0,1\right] :\mathbf{P}\left( \left\{ \omega \right\} \right) =p\left( \omega
\right) \text{ }\forall \text{ }\omega \in \Omega \text{ } \\
\Longleftrightarrow \text{(A) }p\left( \omega \right) \geq 0\text{ }\forall 
\text{ }\omega \in \Omega \text{ e (B)}\sum_{\omega \in \Omega }p\left(
\omega \right) =1
\end{gather*}

$\mathbf{P}$ \`{e} considerata definita su $2^{\Omega }$ a priori perch\'{e}
se $\Omega $ \`{e} numerabile classicamente si sceglie $2^{\Omega }$ come $%
\sigma $-algebra su $\Omega $. (i), cio\`{e} che $\mathbf{P}$ \`{e}
caratterizzata dal suo valore sugli eventi elementari, significa che - data
una certa $p$ - assumendo che $\mathbf{P}$ in corrispondenza degli eventi
elementari (atomi) $\omega $ valga $p\left( \omega \right) $, si pu\`{o}
calcolare $\mathbf{P}\left( A\right) $ $\forall $ $A\in 2^{\Omega }$, cio%
\`{e} $p$ determina univocamente $\mathbf{P}$; \`{e} vero, ma poco
significativo, anche il viceversa. L'utilit\`{a} di (i) sta nel fatto che si
pu\`{o} costruire $\mathbf{P}$ assegnando una probabilit\`{a} a ogni evento
elementare, lavorando quindi con un dominio pi\`{u} semplice.

La funzione $p:\Omega \rightarrow \left[ 0,1\right] $, che soddisfa (A) e
(B), \`{e} detta distribuzione di probabilit\`{a}.

\textbf{Dim} (i) Ogni $A\in 2^{\Omega }$ pu\`{o} essere scritto in modo
unico come unione di eventi elementari, cio\`{e} $A=\bigcup_{\omega \in
A}\left\{ \omega \right\} $, perch\'{e} $A$ \`{e} un sottinsieme di $\Omega $
e quindi unione di elementi di $\Omega $. Essendo $\Omega $ al pi\`{u}
numerabile, anche $A$ \`{e} al pi\`{u} numerabile e $\bigcup_{\omega \in
A}\left\{ \omega \right\} $ \`{e} un'unione finita o infinita numerabile di
eventi disgiunti: allora per A2 e per la finita additivit\`{a} $\mathbf{P}%
\left( A\right) =\mathbf{P}\left( \bigcup_{\omega \in A}\left\{ \omega
\right\} \right) =\sum_{\omega \in A}\mathbf{P}\left( \left\{ \omega
\right\} \right) $, che \`{e} una somma se $A$ ha cardinalit\`{a} finita,
una serie se $A$ ha cardinalit\`{a} infinita. Poich\'{e} si sa come
calcolare $\mathbf{P}\left( A\right) $ $\forall $ $A\in 2^{\Omega }$, $%
\mathbf{P}$ \`{e} univocamente determinata.

(ii) Mostro l'implicazione da sinistra a destra. Se $\mathbf{P}\left(
\left\{ \omega \right\} \right) =p\left( \omega \right) $ $\forall $ $\omega
\in \Omega $, poich\'{e} $\mathbf{P}$ \`{e} una funzione a valori in $\left[
0,1\right] $, dovr\`{a} essere $p\in \left[ 0,1\right] $ e quindi $p\left(
\omega \right) \geq 0$ $\forall $ $\omega $. Inoltre $\sum_{\omega \in \Omega }p\left( \omega
\right) =\sum_{\omega \in \Omega }\mathbf{P}\left( \left\{ \omega \right\}
\right) =P\left( \bigcup_{\omega \in \Omega }\left\{ \omega \right\} \right)
=\mathbf{P}\left( \Omega \right) =1$ perch\'{e} $\Omega $ \`{e} al pi\`{u}
numerabile, quindi si applicano A2, la finita o $\sigma $ additivit\`{a} e
A1.

Mostro l'implicazione da destra a sinistra. Sia $p\left( \omega \right) \geq
0$ $\forall $ $\omega \in \Omega $ e $\sum_{\omega \in \Omega }p\left(
\omega \right) =1$. Dato un qualsiasi sottinsieme di $\Omega $ $A\in
2^{\Omega }$, poich\'{e} pu\`{o} essere scritto come $\bigcup_{\omega \in
A}\left\{ \omega \right\} $, definisco $\mathbf{P}\left( A\right) =\mathbf{P}%
\left( \bigcup_{\omega \in A}\left\{ \omega \right\} \right) :=\sum_{\omega
\in A}p\left( \omega \right) $. Verifico che soddisfa A1 e A2: $\mathbf{P}%
\left( \Omega \right) =\sum_{\omega \in \Omega }p\left( \omega \right) =1$,
quindi va bene A1; A2 si pu\`{o} dimostrare grazie al fatto che si possono
riordinare i termini di una serie senza modificarne la somma. $\blacksquare $

\begin{enumerate}
\item Considero un'urna che contiene $N$ palline numerate da $1$ a $N$, un
infante bendato che ne pesca una pallina e osserva il numero. Definisco il
modello probabilistico dell'esperimento: $\Omega =\left\{ 1,...,N\right\} $, 
$\mathcal{A}=2^{\Omega }$ dato che $\Omega $ \`{e} finito. Ora uso il
teorema (ii): scelgo $p$ tale che $p\left( \omega \right) \geq 0$ $\forall $ 
$\omega \in \Omega $ e $\sum_{n=1}^{N}p\left( \omega _{n}\right) =1$, cos%
\`{\i} da individuare $\mathbf{P}$. Avrei infinite possibili scelte: ma
nelle realt\`{a}, essendo l'infante bendato, \`{e} sensato assumere che
tutte le palline siano equiprobabili, per cui si avr\`{a} la stessa $p\left(
\omega \right) =c$ per ogni $\omega \in \Omega $. Per trovarne il valore si
risolve il sistema $\left\{ 
\begin{array}{c}
p\left( \omega \right) =c\geq 0 \\ 
\sum_{\omega \in \Omega }p\left( \omega \right) =1%
\end{array}%
\right. $, da cui si ricava $Nc=1$, cio\`{e} $c=\frac{1}{N}$: l'ipotesi che
ogni evento elementare sia equiprobabile ha portato a $\mathbf{P}\left(
\left\{ \omega \right\} \right) =\frac{1}{N}$ $\forall $ $\omega \in \Omega $%
. Di conseguenza, se $A$ \`{e} un qualsiasi sottinsieme di $\Omega $ con
cardinalit\`{a} $\left\vert A\right\vert $, $A=\bigcup_{i=1}^{\left\vert
A\right\vert }\left\{ \omega _{i}\right\} $, $\mathbf{P}\left( A\right)
=\sum_{i=1}^{\left\vert A\right\vert }\mathbf{P}\left( \left\{ \omega
_{i}\right\} \right) =\frac{\left\vert A\right\vert }{N}=\frac{\left\vert
A\right\vert }{\left\vert \Omega \right\vert }$: l'approccio assiomatico
alla probabilit\`{a} ci ha riportato alla definizione classica di probabilit%
\`{a} come casi favorevoli fratto casi possibili. Il modello di probabilit%
\`{a} $\left( \Omega ,2^{\Omega },\mathbf{P}\right) $ visto, con $\Omega $
finito e $\mathbf{P}$ tale che $\mathbf{P}\left( \left\{ \omega _{i}\right\}
\right) =c$ $\forall $ $i$, \`{e} detto modello di spazio equiprobabile, e
la $p$ scelta \`{e} detta distribuzione uniforme.
\end{enumerate}

\textbf{Def} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, se $\Omega $ \`{e} finito, $\mathcal{A}=2^{\Omega }$ e $%
\mathbf{P}$ \`{e} tale che $\mathbf{P}\left( \left\{ \omega \right\} \right)
=\frac{1}{\left\vert \Omega \right\vert }$ $\forall $ $\omega \in \Omega $, $%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ si dice spazio probabilistico
discreto e uniforme.

Per 3.1 $\mathbf{P}$ \`{e} ben definita.

\begin{enumerate}
\item Sia $\Omega =\left\{ 0,...,n\right\} $, $\mathcal{A}=2^{\Omega }$. $%
\left\vert \mathcal{A}\right\vert =2^{n+1}$. Scelgo $p:\Omega \rightarrow %
\left[ 0,1\right] $ tale che $p\left( \omega \right) \geq 0$ $\forall $ $%
\omega \in \Omega $ e $\sum_{\omega \in \Omega }p\left( \omega \right) =1$,
cos\`{\i} da individuare $\mathbf{P}$. Dato $p\in \left( 0,1\right) $
assegnato, definisco $p\left( k\right) =\binom{n}{k}p^{k}\left( 1-p\right)
^{n-k}$: \`{e} vero che $p\left( k\right) \geq 0$ $\forall $ $k\in \Omega $,
e inoltre $\sum_{k=0}^{n}\binom{n}{k}p^{k}\left( 1-p\right) ^{n-k}=\left(
p+1-p\right) ^{n}=1$, perch\'{e} questa somma \`{e} lo sviluppo del binomio
di Newton. La $p$ scelta \`{e} detta distribuzione binomiale ($Bi\left(
n,p\right) $).

\item Sia $\Omega =%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\mathcal{A}=2^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}$, $\lambda >0$. Scelgo $p:\Omega \rightarrow \left[ 0,1\right] $ tale che $%
p\left( \omega \right) \geq 0$ $\forall $ $\omega \in \Omega $ e $%
\sum_{\omega \in \Omega }p\left( \omega \right) =1$, cos\`{\i} da
individuare $\mathbf{P}$. Definisco $p\left( k\right) =e^{-\lambda }\frac{%
\lambda ^{k}}{k!}$ $\forall $ $k\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$: \`{e} vero che $p\left( k\right) \geq 0$ $\forall $ $k\in \Omega $, e
inoltre $\sum_{k=0}^{+\infty }e^{-\lambda }\frac{\lambda ^{k}}{k!}%
=e^{-\lambda }e^{\lambda }=1$ perch\'{e} $\sum_{k=0}^{+\infty }\frac{\lambda
^{k}}{k!}$ \`{e} la serie di Taylor di $e^{\lambda }$. Il modello di
probabilit\`{a} $\left( 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
,2^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
},\mathbf{P}\right) $ visto \`{e} detto modello di Poisson e la $p$ scelta 
\`{e} detta distribuzione di Poisson ($poiss(\lambda )$).
\end{enumerate}

Ora si passa all'assegnazione di una probabilit\`{a} con $\Omega $ qualsiasi.

\textbf{Teo 3.2 (assegnazione di probabilit\`{a} su }$\Omega $ \textbf{%
qualsiasi)}%
\begin{gather*}
\text{Hp: }\Omega \text{ \`{e} un insieme qualsiasi, }\left( C_{k}\right)
_{k\in I}\text{ \`{e} una partizione discreta di }\Omega \text{, }\mathcal{A}%
=\sigma \left( \left( C_{k}\right) _{k}:k\in I\right) \\
\text{Ts: (i) }\mathbf{P}:\mathcal{A}\rightarrow \left[ 0,1\right] \text{ 
\`{e} univocamente determinata da }p:I\rightarrow \left[ 0,1\right] \text{
tale che }p\left( n\right) =\mathbf{P}\left( C_{n}\right) \\
\text{(ii) data }p:I\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }\exists \text{ }!\text{ }\mathbf{P}:\mathcal{A}\rightarrow \left[
0,1\right] :\mathbf{P}\left( C_{n}\right) =p\left( n\right) \text{ }\forall 
\text{ }n\in I \\
\Longleftrightarrow \text{(A) }p\left( n\right) \geq 0\text{ }\forall \text{ 
}n\in I\text{ e (B)}\sum_{n\in I}p\left( n\right) =1
\end{gather*}

$\left( C_{k}\right) _{k\in I}$ partizione discreta di $\Omega $ significa
che \`{e} $\left( C_{k}\right) _{k\geq 1}$ \`{e} una famiglia al pi\`{u}
numerabile di insiemi disgiunti la cui unione \`{e} $\Omega $. $\mathcal{A}$
in questo caso non pu\`{o} essere $2^{\Omega }$, che potrebbe essere "troppo
grande", perch\'{e} $\Omega $ \`{e} qualsiasi. Si \`{e} visto che $\sigma
\left( \left( C_{k}\right) _{k}:k\in I\right) =\left\{ A\subseteq \Omega
:A=\bigcup_{k\in J}C_{k},J\subseteq I\right\} $. Gli eventi a cui \`{e}
assegnata una probabilit\`{a} sono dunque solo quelli del tipo $%
A=\bigcup_{k\in J}C_{k},J\subseteq I$. 3.2 diventa 3.1 nel caso particolare
in cui $\Omega $ \`{e} discreto e, se $\Omega $ \`{e} infinito numerabile, $%
I=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ e $C_{k}=\left\{ \omega _{k}\right\} $ $\forall $ $k$.

C'\`{e} un'evidente analogia con il teorema precedente: essendo $\Omega $
qualsiasi e non necessariamente discreto, si definisce la probabilit\`{a}
non sugli atomi ma su ogni elemento di una partizione discreta. Se $\Omega $
non \`{e} discreto si compie dunque un compromesso: si rinuncia a "vedere"
alcuni eventi, limitandosi ad assegnare una probabilit\`{a} agli elementi
della partizione discreta, ma in questo modo ci si riconduce al caso
discreto, riuscendo a scrivere ogni evento come unione al pi\`{u} numerabile
di insiemi e calcolando ogni probabilit\`{a} mediante una funzione definita
su un insieme molto semplice quale $I$.

\textbf{Dim }(i) E' noto che per 1.6 che se $\mathcal{C}$ \`{e} una
partizione discreta di $\Omega $ allora $\sigma \left( \mathcal{C}\right)
=\left\{ A\subseteq \Omega :A=\bigcup_{k\in J}C_{k}\text{ al variare di }%
J\subseteq I\right\} $, cio\`{e} ogni elemento della $\sigma $-algebra
scelta pu\`{o} essere scritto come unione finita o infinita numerabile dei $%
C_{k}$. Quindi $\forall $ $A\in \mathcal{A}$ vale, per $\sigma $-additivit%
\`{a}, $\mathbf{P}\left( A\right) =\mathbf{P}\left( \bigcup_{k\in
J}C_{k}\right) =\sum_{k\in J}\mathbf{P}\left( C_{k}\right) =\sum_{k\in
J}p\left( k\right) $, e $\mathbf{P}$ \`{e} univocamente determinata.

(ii) Mostro l'implicazione da sinistra a destra. Se $\mathbf{P}\left(
C_{n}\right) =p\left( n\right) $ $\forall $ $n\in I$, poich\'{e} $\mathbf{P}$
\`{e} una funzione a valori in $\left[ 0,1\right] $, dovr\`{a} essere $p\in %
\left[ 0,1\right] $ e quindi $p\left( n\right) \geq 0$ $\forall $ $n\in I$.
Inoltre $\sum_{n\in I}p\left( n\right) =\sum_{n\in I}\mathbf{P}\left(
C_{n}\right) =\mathbf{P}\left( \bigcup_{n\in I}C_{n}\right) =\mathbf{P}%
\left( \Omega \right) =1$ per definizione di partizione.

Mostro l'implicazione da destra a sinistra. Sia $p\left( n\right) \geq 0$ $%
\forall $ $n\in I$ e $\sum_{n\in I}p\left( n\right) =1$. Dato un qualsiasi
sottinsieme di $\Omega $ $A\in \mathcal{A}$, poich\'{e} pu\`{o} essere
scritto come $\bigcup_{k\in J}C_{k}$, definisco $\mathbf{P}\left( A\right) =%
\mathbf{P}\left( \bigcup_{k\in J}C_{k}\right) :=\sum_{k\in J}p\left(
k\right) $. Verifico che soddisfa A1 e A2: $\mathbf{P}\left( \Omega \right)
=\sum_{n\in I}p\left( n\right) =1$, quindi va bene A1; A2 si pu\`{o}
dimostrare grazie al fatto che si possono riordinare i termini di una serie
senza modificarne la somma. $\blacksquare $

\section{Probabilit\`{a} condizionata}

\begin{enumerate}
\item Lancio uno dopo l'altro due dadi non truccati e voglio calcolare la
probabilit\`{a} dell'evento $A=$"la somma dei due risultati \`{e} $12$". La
terna di Kolmogorov dell'esperimento \`{e} $\Omega =\left\{ 1,...,6\right\}
\times \left\{ 1,...,6\right\} $, $\mathcal{A}=2^{\Omega }$, e - poich\'{e} 
\`{e} sensato che ogni coppia sia equiprobabile - si pu\`{o} usare la
distribuzione uniforme, per cui $\mathbf{P}\left( A\right) =\frac{\left\vert
A\right\vert }{\left\vert \Omega \right\vert }$: $\left\vert \Omega
\right\vert =36$, $\left\vert A\right\vert =\left\vert \left\{ \left(
h,k\right) :\left( h,k\right) \in \Omega \wedge h+k=12\right\} \right\vert
=\left\vert \left\{ \left( 6,6\right) \right\} \right\vert =1$, per cui $%
\mathbf{P}\left( A\right) =\frac{1}{36}$.

Ora considero l'evento $E=$"il primo lancio d\`{a} $6$": $\mathbf{P}\left(
A\right) $, con questa informazione aggiuntiva, coincide con la probabilit%
\`{a} che il secondo lancio dia $6$, quindi $\frac{1}{6}$: \`{e} aumentata,
perch\'{e} ora i casi possibili sono solo le coppie sulla prima riga.%
\begin{equation*}
\begin{array}{cccccc}
\left( 6,1\right) & \left( 6,2\right) & \left( 6,3\right) & \left( 6,4\right)
& \left( 6,5\right) & \left( 6,6\right) \\ 
\left( 5,1\right) & \left( 5,2\right) & \left( 5,3\right) & \left( 5,4\right)
& \left( 5,5\right) & \left( 5,6\right) \\ 
\left( 4,1\right) & \left( 4,2\right) & \left( 4,3\right) & \left( 4,4\right)
& \left( 4,5\right) & \left( 4,6\right) \\ 
\left( 3,1\right) & \left( 3,2\right) & \left( 3,3\right) & \left( 3,4\right)
& \left( 3,5\right) & \left( 3,6\right) \\ 
\left( 2,1\right) & \left( 2,2\right) & \left( 2,3\right) & \left( 2,4\right)
& \left( 2,5\right) & \left( 2,6\right) \\ 
\left( 1,1\right) & \left( 1,2\right) & \left( 1,3\right) & \left( 1,4\right)
& \left( 1,5\right) & \left( 1,6\right)%
\end{array}%
\end{equation*}

Dunque $\frac{1}{6}=\frac{\left\vert A\right\vert }{\left\vert E\right\vert }
$; dato che $A\subseteq E$, vale $\mathbf{P}\left( A\right) =\mathbf{P}%
\left( A\cap E\right) $, dunque $\frac{1}{6}=\frac{\left\vert A\cap
E\right\vert }{\left\vert E\right\vert }=\frac{\left\vert A\cap E\right\vert 
}{\left\vert \Omega \right\vert }\frac{\left\vert \Omega \right\vert }{%
\left\vert E\right\vert }=\frac{P\left( A\cap E\right) }{P\left( E\right) }$.
\end{enumerate}

Questo esempio rende ragionevole la seguente definizione.

\textbf{Def 3.3} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, $E\in \mathcal{A}$ evento tale che $\mathbf{P}\left(
E\right) >0$ e $A\in \mathcal{A}$ evento qualsiasi, si dice probabilit\`{a}
condizionata di $A$ dato $E$, e si indica con $\mathbf{P}\left( A|E\right) $%
, il numero $\frac{\mathbf{P}\left( A\cap E\right) }{\mathbf{P}\left(
E\right) }$.

Il significato della definizione \`{e} il calcolo della probabilit\`{a} di
un evento quando si \`{e} in possesso di un'informazione aggiuntiva. \\
La
definizione \`{e} ben posta perch\'{e} si richiede \textbf{$P$}$\left(
E\right) >0$ (cio\`{e} che $E$ sia un evento non trascurabile). \\
Evidentemente il ruolo di $A$ e $E$ non pu\`{o} essere scambiato. \\
 Se $E\subseteq A$, l'intuizione dice che $%
\mathbf{P}\left( A|E\right) =1$, perch\'{e} $E$ implica $A$: questo \`{e} in
accordo con la definizione, perch\'{e} $\mathbf{P}\left( A|E\right) =\frac{%
\mathbf{P}\left( A\cap E\right) }{\mathbf{P}\left( E\right) }=\frac{\mathbf{P%
}\left( E\right) }{\mathbf{P}\left( E\right) }=1$. Se invece $A\cap
E=\varnothing $, l'intuizione dice che $\mathbf{P}\left( A|E\right) =0$,
perch\'{e} $A$ e $E$ sono incompatibili: questo \`{e} in accordo con la
definizione, perch\'{e} $\mathbf{P}\left( A|E\right) =\frac{\mathbf{P}\left(
A\cap E\right) }{\mathbf{P}\left( E\right) }=\frac{0}{\mathbf{P}\left(
E\right) }=0$.\\
La
probabilit\`{a} condizionata \`{e} utile in generale quando un esperimento 
\`{e} composto da pi\`{u} fasi:
\begin{enumerate}
\item Se lancio due dadi e $A=$"ad almeno uno dei due lanci esce un numero
pari" e $E=$"al primo lancio esce un numero pari", evidentemente $E\subseteq
A$ e $\mathbf{P}\left( A|E\right) =1$. NB: un evento \`{e} un elemento di $%
\mathcal{A}$, quindi necessariamente una coppia, non pu\`{o} essere relativo
a solo una fase dell'esperimento.

\item Considerando lo stesso esperimento di prima, sia $F=$"uno dei due
lanci ha dato $6$" (si intende almeno uno). In tal caso, essendo sempre in
regime equiprobabile, $\mathbf{P}\left( A|F\right) =\frac{\mathbf{P}\left(
A\cap F\right) }{\mathbf{P}\left( F\right) }=\frac{\left\vert A\cap
F\right\vert }{\left\vert \Omega \right\vert }\cdot \frac{\left\vert \Omega
\right\vert }{\left\vert F\right\vert }=\frac{1}{36}\cdot \frac{36}{11}=%
\frac{1}{11}$. Noto che $\frac{1}{36}<\frac{1}{11}<\frac{1}{6}$: al crescere
della quantit\`{a} di informazioni possedute la probabilit\`{a} aumenta,
infatti nel primo caso non si sa niente, nel secondo si sa cosa \`{e}
successo in uno dei due lanci, nel terzo si sa cosa \`{e} successo nel primo
lancio.
\end{enumerate}

\textbf{Prop 3.4 (la probabilit\`{a} condizionata \`{e} una misura di
probabilit\`{a} nel suo primo argomento)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
spazio di probabilit\`{a}, }E\in \mathcal{A}\text{, }\mathbf{P}\left(
E\right) >0\text{, }A\in \mathcal{A}\text{ fissato} \\
\text{Ts}\text{: } &&\mathbf{P}_{E}:\mathcal{A}\rightarrow \left[ 0,1\right]
,\mathbf{P}_{E}\left( A\right) =\mathbf{P}\left( A|E\right) \text{ \`{e} una
misura di probabilit\`{a} su }\mathcal{A}
\end{eqnarray*}

$\mathbf{P}_{E}$ \`{e} inoltre assolutamente continua rispetto a $\mathbf{P}$%
.

\textbf{Dim} Affinch\'{e} sia vera la tesi $P_{E}$ deve soddisfare A1, A2. $%
\mathbf{P}_{E}\left( \Omega \right) =\mathbf{P}\left( \Omega |A\right) =%
\frac{\mathbf{P}\left( \Omega \cap A\right) }{\mathbf{P}\left( A\right) }=%
\frac{\mathbf{P}\left( A\right) }{\mathbf{P}\left( A\right) }=1$, quindi
vale A1. Se $\left( A_{n}\right) _{n\geq 1}$ \`{e} una famiglia numerabile
di eventi disgiunti, $\mathbf{P}_{E}\left( \bigcup_{n=1}^{+\infty
}A_{n}\right) =\mathbf{P}\left( \bigcup_{n=1}^{+\infty }A_{n}|E\right) =%
\frac{\mathbf{P}\left( \left( \bigcup_{n=1}^{+\infty }A_{n}\right) \cap
E\right) }{\mathbf{P}\left( E\right) }=\frac{\mathbf{P}\left(
\bigcup_{n=1}^{+\infty }\left( A_{n}\cap E\right) \right) }{\mathbf{P}\left(
E\right) }$ per la propriet\`{a} distributiva dell'intersezione rispetto
all'unione; poich\'{e} $\mathbf{P}$ \`{e} una misura di probabilit\`{a} (e,
essendo gli $A_{n}$ disgiunti, anche gli $A_{n}\cap E$ sono disgiunti) si
ottiene $\frac{\sum_{n=1}^{+\infty }\mathbf{P}\left( A_{n}\cap E\right) }{%
\mathbf{P}\left( E\right) }=\sum_{n=1}^{+\infty }\frac{\mathbf{P}\left(
A_{n}\cap E\right) }{\mathbf{P}\left( E\right) }=\sum_{n=1}^{+\infty }%
\mathbf{P}_{E}\left( A_{n}\right) $. $\blacksquare $

Quindi valgono tutte le solite propriet\`{a} della probabilit\`{a}, e. g. $%
\mathbf{P}_{E}\left( A^{c}\right) =\mathbf{P}\left( A^{c}|E\right) =1-%
\mathbf{P}\left( A|E\right) $, $\mathbf{P}_{E}\left( A\cup A^{\prime
}\right) =\mathbf{P}\left( A\cup A^{\prime }|E\right) =\mathbf{P}_{E}\left(
A\right) +\mathbf{P}_{E}\left( A^{\prime }\right) -\mathbf{P}_{E}\left(
A\cap A^{\prime }\right) $. Non \`{e} invece vero che $\mathbf{P}_{A}\left(
E\right) =\mathbf{P}\left( A|E\right) $ \`{e} una misura di probabilit\`{a}:
infatti, dati $A,B$ disgiunti, $\mathbf{P}\left( A|A\cup B\right) =\frac{%
\mathbf{P}\left( A\right) }{\mathbf{P}\left( A\cup B\right) }\neq \mathbf{P}%
\left( A|A\right) +\mathbf{P}\left( A|B\right) =1+\mathbf{P}\left(
A|B\right) $.

\begin{enumerate}
\item Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, $A,B,C\in \mathcal{A}$, $\mathbf{P}\left( A\cap B\right) >0$%
, vale $\mathbf{P}_{A}\left( C|B\right) =\mathbf{P}_{A\cap B}\left( C\right) 
$. Infatti $\mathbf{P}_{A}\left( C|B\right) =\frac{\mathbf{P}_{A}\left(
C\cap B\right) }{\mathbf{P}_{A}\left( B\right) }=\frac{\mathbf{P}\left(
C\cap B|A\right) }{\mathbf{P}\left( B|A\right) }=\frac{\mathbf{P}\left(
C\cap B\cap A\right) }{\mathbf{P}\left( B|A\right) \mathbf{P}\left( A\right) 
}$, mentre $\mathbf{P}_{A\cap B}\left( C\right) =\mathbf{P}\left( C|A\cap
B\right) =\frac{\mathbf{P}\left( C\cap B\cap A\right) }{\mathbf{P}\left(
A\cap B\right) }$.
\end{enumerate}

Nell'ipotesi $\mathbf{P}\left( E\right) >0$, l'uguaglianza $\mathbf{P}\left(
A\cap E\right) =\mathbf{P}\left( A|E\right) \mathbf{P}\left( E\right) $ fa
intuire che il concetto di probabilit\`{a} condizionata pu\`{o} essere usato
anche per assegnare un modello, ad esempio per esperimenti che si svolgono
in pi\`{u} fasi, come \`{e} spiegato nel contesto seguente.

Se ho due partizioni discrete $\left( A_{n}\right) _{n\geq 1},\left(
B_{n}\right) _{n\geq 1}$ di $\Omega $, ciascuna formata da eventi non
trascurabili, allora anche $\left\{ A_{h}\cap B_{k}\text{ al variare di }%
h,k\geq 1\right\} $ \`{e} una partizione discreta di $\Omega $: tutte le
possibili intersezioni tra gli insiemi delle due partizioni determinano una
partizione pi\`{u} fine di $\Omega $. Supponendo che le partizioni siano
finite, vale $A_{i}=\bigcup_{h=1}^{k}\left( A_{i}\cap B_{h}\right)
=A_{i}\cap \left( \bigcup_{h=1}^{k}B_{h}\right) =A_{i}\cap \Omega $.

\textbf{Teo 4.1 (assegnazione di probabilit\`{a} su }$\Omega $ \textbf{%
qualsiasi II})%
\begin{gather*}
\text{Hp: }\Omega \text{ \`{e} un insieme, }\left( A_{n}\right) _{n\geq
1},\left( B_{n}\right) _{n\geq 1}\text{ sono partizioni discrete di }\Omega 
\text{, }\left( A_{n}\right) _{n\geq 1}\text{ eventi} \\
\text{non trascurabili, }\mathcal{A}=\sigma \left( \left( A_{h}\cap
B_{k}\right) :h,k\geq 1\right) \text{, }p:I\rightarrow \left[ 0,1\right]
:p\left( n\right) >0\text{ }\forall \text{ }n\geq 1\text{ e} \\
\sum_{n=1}^{+\infty }p\left( n\right) =1\text{, }\forall \text{ }n\text{
fissato }q\left( k|n\right) :J\rightarrow \left[ 0,1\right] :q\left(
k|n\right) \geq 0\text{ }\forall \text{ }k\text{,}\sum_{k=1}^{+\infty
}q\left( k|n\right) =1 \\
\text{Ts: }\exists \text{ }!\text{ }\mathbf{P}:\mathcal{A}\rightarrow \left[
0,1\right] :\mathbf{P}\left( A_{n}\right) =p\left( n\right) \text{ e }%
\mathbf{P}\left( B_{k}|A_{n}\right) =q\left( k|n\right) \text{ }\forall 
\text{ }k,\forall \text{ }n
\end{gather*}

cosa significa non trascurabili? non vuoti? o di probabilità non nulla? ma rispetto a quale prob?

Il teorema spiega come modellizzare un esperimento a partire dalla probabilit%
\`{a} condizionata. Dalla tesi segue che avendo $p$ e $q$ si pu\`{o}
costruire una probabilit\`{a} sulla $\sigma $-algebra generata dalla
partizione pi\`{u} fine, perch\'{e} $\mathbf{P}\left( B_{k}|A_{n}\right) 
\mathbf{=}\frac{\mathbf{P}\left( A_{n}\cap B_{k}\right) }{\mathbf{P}\left(
A_{n}\right) }$, per cui $\mathbf{P}\left( A_{n}\cap B_{k}\right) =\mathbf{P}%
\left( B_{k}|A_{n}\right) \mathbf{P}\left( A_{n}\right) $: si vedono solo
tutte le possibili unioni dei "quadratini", cio\`{e} degli elementi della
partizione fine. (NB: lei non aveva messo hp $q\left( k|n\right) \geq 0$ $%
\forall $ $k$). La sommatoria \`{e} su tutti i naturali e non su $I$
generico perch\'{e} si stanno considerando partizioni infinite. L'implicazione
opposta \`{e} ovvia.

\textbf{Dim} Voglio usare il teorema 3.2. Se quindi definisco $p\left(
n,k\right) :p\left( n,k\right) \geq 0$ $\forall $ $n,k$ e $\sum_{n,k\geq
1}p\left( n,k\right) =1$, allora $\exists $ $!$ $\mathbf{P}:\sigma \left(
\left( A_{h}\cap B_{k}\right) :h,k\geq 1\right) \rightarrow \left[ 0,1\right]
:\mathbf{P}\left( A_{h}\cap B_{k}\right) =p\left( n,k\right) $ $\forall $ $%
n\in I$. Fisso allora $p\left( n,k\right) =p\left( n\right) q\left(
k|n\right) $: $p\left( n,k\right) \geq 0$ $\forall $ $n$, $\forall $ $k$ 
\`{e} vero per ipotesi, mentre $\sum_{n,k\geq 1}p\left( n,k\right)
=\sum_{n,k\geq 1}p\left( n\right) q\left( k|n\right) =\sum_{n}p\left(
n\right) \sum_{k}q\left( k|n\right) =\sum_{n}p\left( n\right) =1$ perch\'{e}
le serie sono a termini positivi e per le ipotesi. Allora $\exists $ $!$
$\mathbf{P}:\mathcal{A}\rightarrow \left[ 0,1\right] :\mathbf{P}\left(
A_{n}\cap B_{k}\right) =p\left( n,k\right) $. Ne segue che $\mathbf{P}\left(
A_{n}\right) \mathbf{=P}\left( \bigcup_{k=1}^{+\infty }\left( A_{n}\cap
B_{k}\right) \right) =\sum_{k=1}^{+\infty }\mathbf{P}\left( A_{n}\cap
B_{k}\right) =\sum_{k=1}^{+\infty }p\left( n\right) q\left( k|n\right)
=p\left( n\right) \sum_{k=1}^{+\infty }q\left( k|n\right) =p\left( n\right) $
e $\mathbf{P}\left( B_{k}|A_{n}\right) =\frac{\mathbf{P}\left( B_{k}\cap
A_{n}\right) }{\mathbf{P}\left( A_{n}\right) }=\frac{p\left( n\right)
q\left( k|n\right) }{p\left( n\right) }=q\left( k|n\right) $ per definizione
di probabilit\`{a} condizionata e per quanto mostrato sopra. $\blacksquare $

Questo teorema permette quindi di assegnare una probabilit\`{a} che coglie
bene l'aspetto modellistico che ci interessa.

\begin{enumerate}
\item Considero un'urna con $n\geq 2$ palline nere e $b\geq 2$ palline
bianche: faccio due estrazioni senza reimmissione e osservo il colore delle
palline estratte. Lo spazio campionario \`{e} $\Omega =\left\{ \left(
b,b\right) ,\left( b,n\right) ,\left( n,b\right) ,\left( n,n\right) \right\} 
$. Sia $N_{1}$ l'evento "al lancio $1$ \`{e} uscita una pallina nera" ($%
\left\{ \left( n,n\right) ,\left( n,b\right) \right\} $), e analogamente $%
B_{1}=\left\{ \left( b,b\right) ,\left( b,n\right) \right\} ,N_{2},B_{2}$.$%
\left\{ B_{1},N_{1}\right\} $ \`{e} una partizione di $\Omega $ (cio\`{e}
gli $\left( A_{n}\right) $), e $\left\{ B_{2},N_{2}\right\} $ \`{e} un'altra
partizione di $\Omega $ (cio\`{e} i $\left( B_{n}\right) $). Qual \`{e} $%
\mathbf{P}\left( B_{1}\cap B_{2}\right) $? Posso usare il teorema sopra per
risalire a $\mathbf{P}$ definita sulla $\sigma $-algebra generata da $%
\left\{ B_{h}\cap N_{k}:h,k\in \left\{ 1,2\right\} \right\} $: \`{e}
sufficiente definire $p\left( n,k\right) $ in corrispondenza degli elementi
della partizione. Trovandosi in un caso in cui gli esiti sono tutti
equiprobabili, si usa la distribuzione uniforme, per cui $p_{1}=\mathbf{P}%
\left( B_{1}\right) =\frac{b}{n+b}$, $p_{2}=\mathbf{P}\left( N_{1}\right) =%
\frac{n}{n+b}$, $q_{1|1}=\mathbf{P}\left( B_{2}|B_{1}\right) =\frac{b-1}{%
n+b-1}$, $q_{2|1}=\mathbf{P}\left( N_{2}|B_{1}\right) =\frac{n}{n+b-1}$, $%
q_{1|2}=\mathbf{P}\left( B_{2}|N_{1}\right) =\frac{b}{n+b-1}$, $q_{2|2}=%
\mathbf{P}\left( N_{2}|N_{1}\right) =\frac{n-1}{n+b-1}$. Allora $\mathbf{P}%
\left( B_{1}\cap B_{2}\right) =p_{1}q_{1|1}=\frac{b}{n+b}\frac{b-1}{n+b-1}$.
\end{enumerate}

Come fare per calcolare $\mathbf{P}\left( N_{2}\right) $ o $\mathbf{P}\left(
N_{1}|N_{2}\right) $ nell'esempio precedente? Il seguente teorema fornisce
una risposta.

\textbf{Teo 4.2 (disintegrazione e probabilit\`{a} totali)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }\left( E_{n}\right) _{n\geq 1}\text{ \`{e} una
partizione discreta di }\Omega \text{ con }E_{n}\in \mathcal{A}\text{ }%
\forall \text{ }n \\
\text{Ts: (i) (formula di disintegrazione) }\forall \text{ }A\in \mathcal{A}%
\text{ }\mathbf{P}\left( A\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left(
A\cap E_{n}\right) \\
\text{(ii) (formula delle probabilit\`{a} totali) se inoltre }\mathbf{P}%
\left( E_{n}\right) >0\text{ }\forall \text{ }n\text{, }\forall \text{ }A\in 
\mathcal{A}\text{ }\mathbf{P}\left( A\right) =\sum_{n=1}^{+\infty }\mathbf{P}%
\left( A|E_{n}\right) \mathbf{P}\left( E_{n}\right)
\end{gather*}

La (i) \`{e} detta formula di disintegrazione perch\'{e} si sta
disintegrando $A$ con gli $E_{n}$. La (ii) serve quando le condizioni
dell'esperimento sono incerte.

\textbf{Dim} (i) Poich\'{e} $\left( E_{n}\right) _{n\geq 1}$ \`{e} una
partizione discreta di $\Omega $, $A=\bigcup_{n=1}^{+\infty }\left( A\cap
E_{n}\right) $. Gli $A\cap E_{n}$ sono eventi disgiunti perch\'{e} gli $%
E_{n} $ lo sono, quindi per la $\sigma $-additivit\`{a} (A2) $\mathbf{P}%
\left( A\right) =\mathbf{P}\left( \bigcup_{n=1}^{+\infty }\left( A\cap
E_{n}\right) \right) =\sum_{n=1}^{+\infty }\mathbf{P}\left( A\cap
E_{n}\right) $.

(ii) Se $\mathbf{P}\left( E_{n}\right) >0$ $\forall $ $n$, \`{e} ben
definita $\forall $ $n$ $\mathbf{P}\left( A|E_{n}\right) =\frac{\mathbf{P}%
\left( A\cap E_{n}\right) }{\mathbf{P}\left( E_{n}\right) }$, e usando (i)
si ha $\mathbf{P}\left( A\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left(
A\cap E_{n}\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left( A|E_{n}\right) 
\mathbf{P}\left( E_{n}\right) $. $\blacksquare $

\begin{enumerate}
\item Nell'esempio precedente, $\mathbf{P}\left( N_{2}\right) =\sum_{n=1}^{2}%
\mathbf{P}\left( N_{2}|E_{n}\right) \mathbf{P}\left( E_{n}\right) =\mathbf{P}%
\left( N_{2}|N_{1}\right) \mathbf{P}\left( N_{1}\right) +\mathbf{P}\left(
N_{2}|B_{1}\right) \mathbf{P}\left( B_{1}\right) =\frac{n-1}{n+b-1}\frac{n}{%
n+b}+\frac{n}{n+b-1}\frac{b}{n+b}=\frac{n}{n+b-1}\frac{n-1+b}{n+b}=\frac{n}{%
n+b}$: \`{e} la stessa probabilit\`{a} di estrarre una pallina nera alla
prima estrazione. Infatti, se non so cosa \`{e} uscito alla prima
estrazione, \`{e} come se non avessi tolto alcuna pallina (risultato
controintuitivo).
\end{enumerate}

In realt\`{a}, nel teorema le ipotesi possono essere indebolite: non \`{e}
necessario avere una partizione. 
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }\left( E_{n}\right) _{n\geq 1}\text{ \`{e} una
famiglia di sottinsiemi di }\Omega \text{ } \\
\text{ al pi\`{u} numerabile tale che }E_{n}\in \mathcal{A}\text{ }\forall 
\text{ }n\text{, }\mathbf{P}\left( E_{h}\cap E_{k}\right) =0\text{ }\forall 
\text{ }h\neq k\text{, }\mathbf{P}\left( \bigcup_{n=1}^{+\infty
}E_{n}\right) =1 \\
\text{Ts: (i) (formula di disintegrazione) }\forall \text{ }A\in \mathcal{A}%
\text{ }\mathbf{P}\left( A\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left(
A\cap E_{n}\right) \\
\text{(ii) (formula delle probabilit\`{a} totali) se inoltre }\mathbf{P}%
\left( E_{n}\right) >0\text{ }\forall \text{ }n\text{, }\mathbf{P}\left(
A\right) =\sum_{n=1}^{+\infty }\mathbf{P}\left( A|E_{n}\right) \mathbf{P}%
\left( E_{n}\right)
\end{gather*}

Infatti, dato $A$, affinch\'{e} sia $\mathbf{P}\left( A\right) =1$ \`{e}
sufficiente, ma non necessario, che $A=\Omega $, e affinch\'{e} sia $\mathbf{%
P}\left( A\right) =0$ \`{e} sufficiente, ma non necessario, che $%
A=\varnothing $.

\textbf{Dim} (i) Disintegro $A$ usando gli $E_{n}$: $A=\left( A\cap
\bigcup_{n=1}^{+\infty }E_{n}\right) \cup \left( A\cap \left(
\bigcup_{n=1}^{+\infty }E_{n}\right) ^{c}\right) $. Avendo un'unione finita
di eventi disgiunti, vale $\mathbf{P}\left( A\right) =\mathbf{P}\left( A\cap
\bigcup_{n=1}^{+\infty }E_{n}\right) +\mathbf{P}\left( A\cap \left(
\bigcup_{n=1}^{+\infty }E_{n}\right) ^{c}\right) $. Poich\'{e} $\mathbf{P}%
\left( \bigcup_{n=1}^{+\infty }E_{n}\right) =1$, $\mathbf{P}\left( A\cap
\left( \bigcup_{n=1}^{+\infty }E_{n}\right) ^{c}\right) \leq \mathbf{P}%
\left( \left( \bigcup_{n=1}^{+\infty }E_{n}\right) ^{c}\right) =0$, quindi $%
\mathbf{P}\left( A\cap \left( \bigcup_{n=1}^{+\infty }E_{n}\right)
^{c}\right) =0$. Inoltre $\forall $ $N$ $\mathbf{P}\left( A\cap
\bigcup_{n=1}^{N}E_{n}\right) =\mathbf{P}\left( \bigcup_{n=1}^{N}\left(
A\cap E_{n}\right) \right) =$ $\sum_{n=1}^{N}\mathbf{P}\left( A\cap
E_{n}\right) -\sum_{1\leq i<j\leq N}\mathbf{P}\left( \left( A\cap
E_{i}\right) \cap \left( A\cap E_{k}\right) \right) +$ $\sum_{1\leq
i<j<k\leq N}\mathbf{P}\left( \left( A\cap E_{i}\right) \cap \left( A\cap
E_{k}\right) \cap \left( A\cap E_{k}\right) \right) -...+\left( -1\right)
^{N-1}\mathbf{P}\left( \left( A\cap E_{1}\right) \cap ...\cap \left( A\cap
E_{N}\right) \right) $, che \`{e} uguale a $\sum_{n=1}^{+\infty }\mathbf{P}%
\left( A\cap E_{n}\right) $ perch\'{e} $\mathbf{P}\left( E_{h}\cap
E_{k}\right) =0$ $\forall $ $h\neq k$. Dunque $\mathbf{P}\left( A\right)
=\sum_{n=1}^{+\infty }\mathbf{P}\left( A\cap E_{n}\right) $. $\blacksquare $

Si \`{e} visto che, dato $E:\mathbf{P}\left( E\right) >0$, $\mathbf{P}\left(
A|E\right) =\frac{\mathbf{P}\left( A\cap E\right) }{\mathbf{P}\left(
E\right) }$, fissato $E$, \`{e} una misura di probabilit\`{a} su $\mathcal{A}
$ al variare di $A\in \mathcal{A}$. Quindi, se si conosce $\mathbf{P}%
_{E}\left( A\right) $, si ha che $\mathbf{P}_{E}\left( A^{c}\right) =1-%
\mathbf{P}_{E}\left( A\right) =1-\mathbf{P}\left( A|E\right) $. In generale
invece $\mathbf{P}\left( A|E\right) $, fissato $A$, non \`{e} una misura di
probabilit\`{a} al variare di $E$ (infatti in generale $\mathbf{P}\left(
A|E\right) \neq \mathbf{P}\left( E|A\right) $). Tuttavia esiste una
relazione tra le due, espressa dal seguente teorema.

\textbf{Teo 4.3 (Bayes)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( E_{n}\right) _{n\geq 1}\text{ \`{e}
una partizione discreta } \\
\text{di }\Omega \text{ con }E_{n}\in \mathcal{A}\text{ }\forall \text{ }n%
\text{ e }P\left( E_{n}\right) >0\text{ }\forall \text{ }n\text{, }A\in 
\mathcal{A}\text{ \`{e} non trascurabile} \\
\text{Ts}\text{: }\mathbf{P}\left( E_{n}|A\right) =\frac{\mathbf{P}\left(
A|E_{n}\right) \mathbf{P}\left( E_{n}\right) }{\mathbf{P}\left( A\right) }=%
\frac{\mathbf{P}\left( A|E_{n}\right) \mathbf{P}\left( E_{n}\right) }{%
\sum_{n=1}^{+\infty }\mathbf{P}\left( A|E_{n}\right) \mathbf{P}\left(
E_{n}\right) }\text{ }\forall \text{ }h\geq 1
\end{gather*}

Il teorema evidenzia che non c'\`{e} una relazione lineare tra $\mathbf{P}%
\left( E_{n}|A\right) $ e $\mathbf{P}\left( A|E_{n}\right) \mathbf{P}\left(
E_{n}\right) $

\textbf{Dim} Per definizione $\mathbf{P}\left( E_{n}|A\right) =\frac{\mathbf{%
P}\left( E_{n}\cap A\right) }{\mathbf{P}\left( A\right) }$, ben definita
perch\'{e} $\mathbf{P}\left( A\right) >0$. Essendo anche $\mathbf{P}\left(
E_{n}\right) >0$ $\forall $ $h$, \`{e} ben definita $\mathbf{P}\left(
A|E_{n}\right) =\frac{\mathbf{P}\left( E_{n}\cap A\right) }{\mathbf{P}\left(
E_{n}\right) }$: sostituendo nell'uguaglianza precedente si ha $\mathbf{P}%
\left( E_{h}|A\right) =\frac{\mathbf{P}\left( A|E_{n}\right) \mathbf{P}%
\left( E_{n}\right) }{\mathbf{P}\left( A\right) }$. La seconda uguaglianza
della tesi vale perch\'{e} $\mathbf{P}\left( A\right) =\sum_{n=1}^{+\infty }%
\mathbf{P}\left( A|E_{n}\right) \mathbf{P}\left( E_{n}\right) $ per la
formula delle probabilit\`{a} totali. $\blacksquare $

\begin{enumerate}
\item Nell'esempio precedente, $\mathbf{P}\left( N_{1}|N_{2}\right) \mathbf{=%
}\frac{\mathbf{P}\left( N_{2}|N_{1}\right) \mathbf{P}\left( N_{1}\right) }{%
\mathbf{P}\left( N_{2}\right) }=\frac{n-1}{n+b-1}\frac{n}{n+b}\frac{n+b}{n}=%
\frac{n-1}{n+b-1}$, che coincide con $\mathbf{P}\left( N_{2}|N_{1}\right) $.
\end{enumerate}

\textbf{Teo 4.4 (formula di moltiplicazione)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }A_{1},...,A_{n}\in \mathcal{A}\text{, }%
\mathbf{P}\left( A_{1}\cap ...\cap A_{n-1}\right) >0 \\
\text{Ts}\text{: } &&\mathbf{P}\left( A_{1}\cap ...\cap A_{n}\right) =%
\mathbf{P}\left( A_{1}\right) \mathbf{P}\left( A_{2}|A_{1}\right) \mathbf{P}%
\left( A_{3}|A_{2}\cap A_{1}\right) ...\mathbf{P}\left( A_{n}|A_{n-1}\cap
...\cap A_{1}\right)
\end{eqnarray*}

Poich\'{e} $\mathbf{P}\left( A_{1}\cap ...\cap A_{n-1}\right) >0$ e $%
A_{1}\supseteq A_{1}\cap A_{2}\supseteq ...\supseteq A_{1}\cap ...\cap
A_{n-1}$, per P3 $\forall $ $i=1,...,n-1$ $\mathbf{P}\left( A_{1}\cap
...\cap A_{i}\right) \geq \mathbf{P}\left( A_{1}\cap ...\cap A_{i+1}\right) $%
, e questo implica $\mathbf{P}\left( A_{1}\cap ...\cap A_{i}\right) \geq
...\geq \mathbf{P}\left( A_{1}\cap ...\cap A_{n-1}\right) >0$ $\forall $ $%
i=1,...,n-1$, dunque le probabilit\`{a} condizionate nella tesi sono tutte
ben definite.

La formula \`{e} utile quando \`{e} facile calcolare le probabilit\`{a}
condizionate.

\textbf{Dim} Scrivo il lato destro usando la definizione di probabilit\`{a}
condizionata: $\mathbf{P}\left( A_{1}\right) \mathbf{P}\left(
A_{2}|A_{1}\right) \mathbf{P}\left( A_{3}|A_{2}\cap A_{1}\right) ...\mathbf{P%
}\left( A_{n}|A_{n-1}\cap ...\cap A_{1}\right) =\mathbf{P}\left(
A_{1}\right) \frac{\mathbf{P}\left( A_{2}\cap A_{1}\right) }{\mathbf{P}%
\left( A_{1}\right) }\frac{\mathbf{P}\left( A_{3}\cap A_{2}\cap A_{1}\right) 
}{\mathbf{P}\left( A_{2}\cap A_{1}\right) }...\frac{\mathbf{P}\left(
A_{n}\cap A_{n-1}\cap ...\cap A_{1}\right) }{\mathbf{P}\left( A_{n-1}\cap
...\cap A_{1}\right) }=\mathbf{P}\left( A_{n}\cap A_{n-1}\cap ...\cap
A_{1}\right) $. La dimostrazione si potrebbe fare anche per induzione. $%
\blacksquare $

\section{Indipendenza stocastica}

\begin{enumerate}
\item Nell'ultimo esempio visto, con estrazione senza reimmissione, $\mathbf{%
P}\left( N_{2}|N_{1}\right) =\frac{n-1}{n+b-1}\neq \mathbf{P}\left(
N_{2}\right) =\frac{n}{n+b}$. Se invece si estrae con reimmissione, si sta
effettuando un esperimento diverso, descritto da un'altra terna di
Kolmogorov, con misura di probabilit\`{a} $\mathbf{\tilde{P}:\tilde{P}}%
\left( N_{2}|N_{1}\right) =\frac{n}{n+b}=\mathbf{\tilde{P}}\left(
N_{2}\right) $: in assenza di reimmissione $\mathbf{P}\left(
N_{2}|N_{1}\right) \neq \mathbf{P}\left( N_{2}\right) $, cio\`{e} la
probabilit\`{a} \`{e} influenzata dall'essersi verificato $N_{1}$, mentre ci%
\`{o} non accade con reimmissione, perch\'{e} $\mathbf{\tilde{P}}\left(
N_{2}|N_{1}\right) =\frac{\mathbf{\tilde{P}}\left( N_{2}\cap N_{1}\right) }{%
\mathbf{\tilde{P}}\left( N_{1}\right) }=\mathbf{\tilde{P}}\left(
N_{2}\right) $. Questa intuizione modellistica \`{e} formalizzata dalla
definizione di indipendenza.
\end{enumerate}

\textbf{Def 4.5} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, $A,E\in \mathcal{A}$ si dicono indipendenti, e si scrive 
$A\perp E$, se $\mathbf{P}\left( A\cap E\right) =\mathbf{P}\left( A\right) 
\mathbf{P}\left( E\right) $.

La situazione precedentemente descritta, $\frac{\mathbf{\tilde{P}}\left(
N_{2}\cap N_{1}\right) }{\mathbf{\tilde{P}}\left( N_{1}\right) }=\mathbf{%
\tilde{P}}\left( N_{2}\right) $, permette quindi di affermare che con
reimmissione $N_{1}$ e $N_{2}$ sono eventi indipendenti, senza reimmissione
non lo sono. Si noti che, per astrarre la definizione di eventi
indipendenti, nell'ultima uguaglianza si sono moltiplicati entrambi i lati
per $\mathbf{\tilde{P}}\left( N_{1}\right) $, per rimuovere la necessit\`{a}
di $\mathbf{\tilde{P}}\left( N_{1}\right) >0$. La relazione di indipendenza
tra eventi gode della propriet\`{a} di simmetria, ma non della riflessivit%
\`{a} (in generale $\mathbf{P}\left( A\right) \neq \mathbf{P}^{2}\left(
A\right) $, quindi non \`{e} una relazione di equivalenza.

Se inoltre $\mathbf{P}\left( A\right) \mathbf{,P}\left( E\right) >0$, $%
A\perp E\Longleftrightarrow \mathbf{P}\left( A|E\right) =\mathbf{P}\left(
A\right) \Longleftrightarrow \mathbf{P}\left( E|A\right) =\mathbf{P}\left(
E\right) $, come si ricava dalla definizione, dividendo per $\mathbf{P}%
\left( E\right) \mathbf{,P}\left( A\right) $ rispettivamente. In questa
uguaglianza sta il significato modellistico dell'indipendenza tra eventi: il
verificarsi di uno non influenza la probabilit\`{a} del verificarsi
dell'altro.

La definizione di indipendenza aiuta inoltre a costruire i modelli
probabilistici.

\begin{enumerate}
\item Lancio un dado rosso e un dado bianco. Chiamo $R_{k}$ l'evento "esce
la faccia $k$ sul dado rosso", analogamente $B_{k}$; $\Omega =\left\{ \left(
h,k\right) :h,k\in \left\{ 1,...,6\right\} \right\} $; $\left( R_{k}\right)
_{k\in \left\{ 1,...,6\right\} },\left( B_{k}\right) _{k\in \left\{
1,...,6\right\} }$ sono due partizioni di $\Omega $ (gli $A_{n}$ e $B_{n}$
del teorema). $\mathcal{A}=\sigma \left( B_{k}\cap R_{h},h,k\in \left\{
1,...,6\right\} \right); l'evento $B_{k}\cap R_{h}$ \`{e}
identificato dalla coppia $\left( k,h\right) $. Per il teorema 4.1, basta
imporre $p_{k}=\frac{1}{6}$ $\forall $ $k=1,...,6$ e $q_{h|n}=\frac{1}{6}$ $%
\forall $ $h,\forall k=1,...,6$: $p_{k}$ rappresenta $\mathbf{P}\left(
R_{k}\right) $, $q_{h|k}$ \`{e} effettivamente $\mathbf{P}\left(
B_{k}|R_{k}\right) =\mathbf{P}\left( B_{k}\right) $, perch\'{e} i risultati
sui due dadi sono indipendenti. Allora $P\left( R_{h}\cap B_{k}\right)
=P\left( R_{h}\right) P\left( B_{k}\right) =\frac{1}{6}\frac{1}{6}$ $\forall 
$ $h,k=1,...,6$, cio\`{e} $\mathbf{P}\left( \left( h,k\right) \right) =\frac{%
1}{36}$ $\forall $ $h,k=1,...,6$: l'indipendenza dei due dadi induce il
modello uniforme nello spazio misurabile $\left( \Omega ,\mathcal{A}\right) $%
.
\end{enumerate}

\textbf{Prop (indipendenza tra eventi)}%
\begin{gather*}
\text{(i) Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }A\in \mathcal{A}\text{, }\mathbf{P}%
\left( A\right) =0\text{ o }\mathbf{P}\left( A\right) =1 \\
\text{Ts}\text{: }\forall \text{ }E\in \mathcal{A}\text{, }A\perp E \\
\text{(ii) Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }A,B\in \mathcal{A}\text{, }A\subseteq B%
\text{, }\mathbf{P}\left( A\right) >0\text{, }\mathbf{P}\left( B\right) <1 \\
\text{Ts}\text{: }A\not\perp B \\
\text{(iii) Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }A,B\in \mathcal{A}\text{, }A\cap
B=\varnothing \text{, }\mathbf{P}\left( A\right) ,\mathbf{P}\left( B\right)
>0 \\
\text{Ts}\text{: }A\not\perp B \\
\text{(iv) Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }A,E\in \mathcal{A} \\
\text{Ts}\text{: }A\perp E\Longleftrightarrow A\perp
E^{c}\Longleftrightarrow A^{c}\perp E\Longleftrightarrow A^{c}\perp E^{c}
\end{gather*}

(i) significa che un evento certo o un evento impossibile \`{e} indipendente
da qualsiasi evento. (ii) intuitivamente \`{e} dovuta al fatto che $A$
implica $B$, quindi sapere che $A$ si \`{e} verificato modifica il grado di
fiducia nel verificarsi di $B$. (iii) intuitivamente \`{e} dovuta al fatto
che $A$ e $B$ sono mutuamente esclusivi, quindi dall'informazione che uno
dei due si \`{e} verificato si ricava con certezza che l'altro non si \`{e}
verificato, quindi non possono essere indipendenti.

Si noti che le ipotesi di (i) e (iii) sono incompatibili: infatti, se $%
\mathbf{P}\left( A\right) =1$ e $A\cap B=\varnothing $, necessariamente $%
\mathbf{P}\left( B\right) =0$ per $\sigma $-additivit\`{a}.

\textbf{Dim} (i) $A\perp E\Longleftrightarrow \mathbf{P}\left( A\cap
E\right) =\mathbf{P}\left( A\right) \mathbf{P}\left( E\right) $: se $\mathbf{%
P}\left( A\right) =0$, $\mathbf{P}\left( A\cap E\right) \leq \mathbf{P}%
\left( A\right) =0$, quindi effettivamente $\mathbf{P}\left( A\cap E\right)
=0=\mathbf{P}\left( A\right) \mathbf{P}\left( E\right) $. Se $\mathbf{P}%
\left( A\right) =1$, $\mathbf{P}\left( E\right) =\mathbf{P}\left( \left(
A\cap E\right) \cup \left( A^{c}\cap E\right) \right) =\mathbf{P}\left(
A\cap E\right) +\mathbf{P}\left( A^{c}\cap E\right) $. Ma $\mathbf{P}\left(
A^{c}\cap E\right) =0$ perch\'{e} $\mathbf{P}\left( A^{c}\right) =0$, quindi
effettivamente $\mathbf{P}\left( A\cap E\right) =\mathbf{P}\left( A\right) 
\mathbf{P}\left( E\right) =\mathbf{P}\left( E\right) $.

(ii) $\mathbf{P}\left( A\cap B\right) =\mathbf{P}\left( A\right) $, quindi
non \`{e} possibile che $\mathbf{P}\left( A\cap B\right) =\mathbf{P}\left(
A\right) \mathbf{P}\left( B\right) $ a meno che $\mathbf{P}\left( A\right)
=0 $ o $\mathbf{P}\left( B\right) =1$, casi esclusi dalle ipotesi.

(iii) $\mathbf{P}\left( A\cap B\right) =\mathbf{P}\left( \varnothing \right)
=0$, quindi, essendo $\mathbf{P}\left( A\right) \neq 0$ e $\mathbf{P}\left(
B\right) \neq 0$, non \`{e} possibile $\mathbf{P}\left( A\cap B\right) =%
\mathbf{P}\left( A\right) \mathbf{P}\left( B\right) $.

(iv) Se $A\perp E$, $\mathbf{P}\left( A\cap E\right) =\mathbf{P}\left(
A\right) \mathbf{P}\left( E\right) $. Inoltre, essendo $A=\left( A\cap
E\right) \cup \left( A\cap E^{c}\right) $, per A2 $\mathbf{P}\left( A\right)
=\mathbf{P}\left( A\cap E\right) +\mathbf{P}\left( A\cap E^{c}\right) =%
\mathbf{P}\left( A\right) \mathbf{P}\left( E\right) \mathbf{+P}\left( A\cap
E^{c}\right) $, dunque $\mathbf{P}\left( A\cap E^{c}\right) \mathbf{=P}%
\left( A\right) \left( 1-\mathbf{P}\left( E\right) \right) =\mathbf{P}\left(
A\right) \mathbf{P}\left( E^{c}\right) $, cio\`{e} $A,E^{c}$ sono
indipendenti. Se si ripete la stessa dimostrazione a parti invertite per $%
E,A $ si ottiene l'indipendenza di $A^{c},E$, se si ripete di nuovo su $%
A^{c},E$ si ottiene l'indipendenza di $A^{c},E^{c}$. $\blacksquare $

\textbf{Def 5.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $I$ insieme qualsiasi, una famiglia di insiemi $\left(
A_{i}\right) _{i\in I}\subseteq \mathcal{A}$ si dice famiglia di eventi
indipendenti se $\forall $ $J\subseteq I:2\leq \left\vert J\right\vert
<+\infty $ vale $\mathbf{P}\left( \bigcap_{j\in J}A_{j}\right) =\prod_{j\in
J}\mathbf{P}\left( A_{j}\right) $.

$J$ indicizza una sottofamiglia di $\left(
A_{i}\right) _{i\in I}$; $\prod_{j\in J}\mathbf{P}\left( A_{j}\right) $ \`{e}
una produttoria finita. Nella definizione non si richiede che $I$ sia al pi%
\`{u} numerabile. Noto che se $I=\left\{ 1,2\right\} $, si ritrova la
definizione gi\`{a} vista di due eventi indipendenti: infatti l'unico $J$
che soddisfa le richieste \`{e} $J=I$ e si ritrova $\mathbf{P}\left(
A_{1}\cap A_{2}\right) =\mathbf{P}\left( A_{1}\right) \mathbf{P}\left(
A_{2}\right) $.

Se invece $I=\left\{ 1,2,3\right\} $, i $J$ possibili sono $\left\{
1,2\right\} ,\left\{ 1,3\right\} ,\left\{ 2,3\right\} ,\left\{ 1,2,3\right\} 
$: la condizione $\mathbf{P}\left( \bigcap_{j\in J}A_{j}\right) =\prod_{j\in
J}\mathbf{P}\left( A_{j}\right) $ va verificata per ogni $J$, cio\`{e}
occorre controllare le quattro uguaglianze $\mathbf{P}\left( A_{1}\cap
A_{2}\right) =\mathbf{P}\left( A_{1}\right) \mathbf{P}\left( A_{2}\right) $, 
$\mathbf{P}\left( A_{1}\cap A_{3}\right) =\mathbf{P}\left( A_{1}\right) 
\mathbf{P}\left( A_{3}\right) $, $\mathbf{P}\left( A_{2}\cap A_{3}\right) =%
\mathbf{P}\left( A_{2}\right) \mathbf{P}\left( A_{3}\right) $, $\mathbf{P}%
\left( A_{1}\cap A_{2}\cap A_{3}\right) =\mathbf{P}\left( A_{1}\right) 
\mathbf{P}\left( A_{2}\right) \mathbf{P}\left( A_{3}\right) $. Questa \`{e}
quindi una definizione laboriosa, che difficilmente potr\`{a} essere usata
in pratica.

Se una famiglia di eventi \`{e} di eventi indipendenti, allora gli eventi
sono a due a due, a tre a tre,... indipendenti. Se $\left( A_{i}\right)
_{i\in I}\subseteq \mathcal{A}$ \`{e} una famiglia di eventi indipendenti,
ogni sottinsieme della famiglia \`{e} a sua volta una famiglia di eventi
indipendenti.

\begin{enumerate}
\item Se $\left\vert I\right\vert =n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, il numero di $J\subseteq I:\left\vert J\right\vert <+\infty $ e $2\leq
\left\vert J\right\vert <+\infty $ (e quindi il numero di condizioni da
verificare) \`{e} $2^{n}-n-1$: coincide infatti con l'insime delle parti,
meno gli insiemi con un solo elemento (che sono $n$), meno l'insieme vuoto.
\end{enumerate}

Avrei potuto pensare anche a una definizione pi\`{u} semplice, ad esempio
che $\left( A_{i}\right) _{i\in I}\subseteq \mathcal{A}$ si dice famiglia di
eventi indipendenti se vale $\mathbf{P}\left( \bigcap_{i\in I}A_{i}\right)
=\prod_{i\in I}\mathbf{P}\left( A_{i}\right) $. Si dimostra per\`{o} che la
5.1 \`{e} l'unica definizione che permette di dimostrare propriet\`{a} che
sono ragionevoli da un punto di vista modellistico, ad esempio che se $%
A_{1},A_{2},A_{3}$ sono indipendenti, allora $A_{1}$ e $A_{2}\cup A_{3}$
sono indipendenti.

\textbf{Prop}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( A_{i}\right) _{i\in I}\subseteq 
\mathcal{A} \\
\text{ \`{e} una famiglia di eventi indipendenti} \\
\text{Ts}\text{: }\forall \text{ }\bar{\imath}\in I\text{, }\forall \text{ }%
B\in \sigma \left( \left( A_{i}\right) _{i\in I,i\neq \bar{\imath}}\right) 
\text{, }A_{i}\perp B\text{ }
\end{gather*}

La tesi significa che ogni evento \`{e} indipendente da qualsiasi elemento
della $\sigma $-algebra generata da tutti gli altri eventi.

\textbf{Dim} (i) Dimostro che $A_{1}\perp \left( A_{2}\cup A_{3}\right) $.
Per definizione, $\forall $ $J\subseteq \left\{ 1,2,3\right\} :\left\vert
J\right\vert <+\infty $ e $2\leq \left\vert J\right\vert <+\infty $ vale $%
\mathbf{P}\left( \bigcap_{j\in J}A_{j}\right) =$ $\prod_{j\in J}\mathbf{P}%
\left( A_{j}\right) $, cio\`{e} $\mathbf{P}\left( A_{1}\cap A_{2}\right) =%
\mathbf{P}\left( A_{1}\right) \mathbf{P}\left( A_{2}\right) $, $\mathbf{P}%
\left( A_{1}\cap A_{3}\right) =\mathbf{P}\left( A_{1}\right) \mathbf{P}%
\left( A_{3}\right) $, $\mathbf{P}\left( A_{2}\cap A_{3}\right) =\mathbf{P}%
\left( A_{2}\right) \mathbf{P}\left( A_{3}\right) $, $\mathbf{P}\left(
A_{1}\cap A_{2}\cap A_{3}\right) =\mathbf{P}\left( A_{1}\right) \mathbf{P}%
\left( A_{2}\right) \mathbf{P}\left( A_{3}\right) $. Devo mostrare che $%
\mathbf{P}\left( A_{1}\cap \left( A_{2}\cup A_{3}\right) \right) =\mathbf{P}%
\left( A_{1}\right) \mathbf{P}\left( A_{2}\cup A_{3}\right) $. Per la
propriet\`{a} distributiva dell'intersezione rispetto all'unione e per P6 $%
\mathbf{P}\left( A_{1}\cap \left( A_{2}\cup A_{3}\right) \right) =\mathbf{P}%
\left( \left( A_{1}\cap A_{2}\right) \cup \left( A_{1}\cap A_{3}\right)
\right) =\mathbf{P}\left( A_{1}\cap A_{2}\right) +\mathbf{P}\left( A_{1}\cap
A_{3}\right) -\mathbf{P}\left( A_{1}\cap A_{2}\cap A_{3}\right) $: usando
l'ipotesi e di nuovo P6 si ottiene $\mathbf{P}\left( A_{1}\right) \mathbf{P}%
\left( A_{2}\right) +\mathbf{P}\left( A_{1}\right) \mathbf{P}\left(
A_{3}\right) -\mathbf{P}\left( A_{1}\right) \mathbf{P}\left( A_{2}\right) 
\mathbf{P}\left( A_{3}\right) =\mathbf{P}\left( A_{1}\right) \left( \mathbf{P%
}\left( A_{2}\right) +\mathbf{P}\left( A_{3}\right) -\mathbf{P}\left(
A_{2}\right) \mathbf{P}\left( A_{3}\right) \right) =\mathbf{P}\left(
A_{1}\right) \mathbf{P}\left( A_{2}\cup A_{3}\right) $ perch\'{e} $\mathbf{P}%
\left( A_{2}\cap A_{3}\right) =\mathbf{P}\left( A_{2}\right) \mathbf{P}%
\left( A_{3}\right) $. $\blacksquare $

\textbf{Prop }%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e}
uno spazio di probabilit\`{a}, }\left( A_{i}\right) _{i\in I}\subseteq 
\mathcal{A}\text{ \`{e} una famiglia di eventi } \\
\text{indipendenti, }\left( B_{i}\right) _{i\in I}\subseteq \mathcal{A}\text{
\`{e} tale che }B_{i}=A_{i}\text{ o }B_{i}=A_{i}^{c}\text{ }\forall \text{ }%
i\in I\text{ } \\
\text{Ts}\text{: }\left( B_{i}\right) _{i\in I}\subseteq \mathcal{A}\text{ 
\`{e} una famiglia di eventi indipendenti}
\end{gather*}

\textbf{Dim} Per ipotesi $\forall $ $J\subseteq I:2\leq \left\vert
J\right\vert <+\infty $ vale $\mathbf{P}\left( \bigcap_{j\in J}A_{j}\right)
=\prod_{j\in J}\mathbf{P}\left( A_{j}\right) $. Voglio mostrare che $\forall 
$ $J\subseteq I:2\leq \left\vert J\right\vert <+\infty $ vale $\mathbf{P}%
\left( \bigcap_{j\in J}B_{j}\right) =\prod_{j\in J}\mathbf{P}\left(
B_{j}\right) $. Procedo per induzione sulla cardinalit\`{a} $\left\vert
J\right\vert =n$. Se $n=2$ vale che $\mathbf{P}\left( \bigcap_{j\in
J}B_{j}\right) =\prod_{j\in J}\mathbf{P}\left( B_{j}\right) $ perch\'{e} $%
B_{j_{1}},B_{j_{2}}$ sono o $A_{j_{1}},A_{j_{2}}$, che sono indipendenti
perch\'{e} l'indipendenza sulla famiglia implica l'indipendenza a coppie, o $%
A_{j_{1}},A_{j_{2}}^{c}$, o $A_{j_{1}}^{c},A_{j_{2}}^{c}$ che sono due
coppie indipendenti perch\'{e} $A_{j_{1}}\perp A_{j_{2}}\Longleftrightarrow
A_{j_{1}}\perp A_{j_{1}}^{c}\Longleftrightarrow A_{j_{1}}^{c}\perp
A_{j_{1}}^{c}$. Suppongo vera la tesi per $n>2$ e mostro che vale per $n+1$:
suppongo quindi che, dato $J:\left\vert J\right\vert =n$, $\mathbf{P}\left(
\bigcap_{j\in J}B_{j}\right) =\prod_{j\in J}\mathbf{P}\left( B_{j}\right) $.
Allora, dato $J^{\prime }:\left\vert J^{\prime }\right\vert =n+1$, $%
\bigcap_{j\in J^{\prime }}B_{j}=\bigcap_{j\in J}B_{j}\cap B_{n+1}$. Ma
essendo gli $\left( A_{j}\right) _{j\in J}$ e $A_{n+1}$ una famiglia di
eventi indipendenti, vale in particolare che l'evento $\bigcap_{j\in J}A_{j}$
(elemento della $\sigma $-algebra generata da "tutti gli altri eventi") \`{e}
indipendente da $A_{n+1}$, e dunque anche da $A_{n+1}^{c}$, a seconda della
natura di $B_{n+1}$. $\blacksquare $

\section{Assegnazione della probabilit\`{a} su $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $}

$\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ \`{e} un insieme "molto grande": non c'\`{e} speranza di
caratterizzare i suoi elementi in modo semplice (mentre \`{e} facile farlo
e. g. con la $\sigma $-algebra generata da una partizione discreta di $%
\Omega $). E' noto che $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =\sigma \left( \mathcal{C}\right) $; poich\'{e} nel caso di $\Omega $
si riesce a caratterizzare la probabilit\`{a} definendola sugli elementi di $%
\Omega $, avendo come $\sigma $-algebra $2^{\Omega }$ (che \`{e} la $\sigma $
algebra generata dagli atomi), per analogia si potrebbe cercare di vedere se 
\`{e} possibile caratterizzare la probabilit\`{a} definendola sugli elementi
di $\mathcal{C}$, per poi estenderla su tutto $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ (ma l'estensione dev'essere unica). Questo \`{e} confermato dal
seguente risultato.

\textbf{Def} Dato $\Omega $ insieme qualsiasi, una classe di sottinsiemi di $%
\Omega $ $\mathcal{C}$ si dice $\pi $-sistema su $\Omega $ se $%
C_{1},...,C_{n}\in \mathcal{C\Longrightarrow }$ $C_{1}\cap ...\cap C_{n}\in 
\mathcal{C}$.

Un $\pi $-sistema \`{e} quindi una classe di sottinsiemi di $\Omega $ chiusa
per intersezione finita. Ogni collezione di sottinsiemi disgiunti di $\Omega 
$ che contenga anche l'insieme vuoto \`{e} un $\pi $-sistema su $\Omega $.
Ogni $\sigma $-algebra su $\Omega $ \`{e} un $\pi $-sistema su $\Omega $.

[\textbf{Def} Dato $\Omega $, qualsiasi, si dice classe monotona (detta
anche $\lambda $-sistema) un sottinsieme di $2^{\Omega }$ $\mathcal{M}$ tale
che

\begin{description}
\item[M1] $\Omega \in \mathcal{M}$

\item[M2] $A,B\in \mathcal{M}$, $A\subset B\Longrightarrow B\backslash A\in 
\mathcal{M}$

\item[M3] $\left( A_{n}\right) \in \mathcal{M}$, $A_{n}\subset
A_{n+1}\Longrightarrow \bigcup_{n=1}^{+\infty }A_{n}\in \mathcal{M}$
\end{description}

Si dice classe monotona generata da un sottinsieme $\mathcal{F}$ di $%
2^{\Omega }$, e si indica con $\lambda \left( \mathcal{F}\right) $, la pi%
\`{u} piccola classe monotona su $\Omega $ che contenga $C$.

Una classe monotona \`{e} quindi chiusa per differenze e per limiti
crescenti.

Ogni $\sigma $-algebra \`{e} una classe monotona ($B\backslash A=B\cap A^{c}$%
).

\textbf{Lemma di Dynkin (teorema delle classi monotone)}%
\begin{eqnarray*}
\text{Hp} &\text{: }&C\text{ \`{e} un }\pi \text{-sistema su }\Omega \\
\text{Ts} &\text{: }&\sigma \left( C\right) =\lambda \left( C\right)
\end{eqnarray*}

]

\textbf{Teo 5.2} \textbf{(criterio di Caratheodory) }%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A}\right) \text{ \`{e} uno spazio
probabilizzabile, }\mathbf{P,Q}\text{ sono due misure di probabilit\`{a} su }
\\
\left( \Omega ,\mathcal{A}\right) \text{, }\mathcal{C}\subseteq \mathcal{A}%
\text{ \`{e} un }\pi \text{-sistema su }\Omega \text{ tale che }\sigma
\left( \mathcal{C}\right) =\mathcal{A}\text{, }\mathbf{P}\left( C\right) =%
\mathbf{Q}\left( C\right) \text{ }\forall \text{ }C\in \mathcal{C} \\
\text{Ts: }\mathbf{P}\left( A\right) =\mathbf{Q}\left( A\right) \text{ }%
\forall \text{ }A\in \mathcal{A}
\end{gather*}

Il teorema afferma l'unicit\`{a} dell'estensione di una probabilit\`{a} da
un $\pi $-sistema che generi $\mathcal{A}$ ad $\mathcal{A}$; in altre
parole, due probabilit\`{a} che coincidono in corrispondenza degli elementi
di $\mathcal{C}$ sono la stessa probabilit\`{a}, vale a dire che il valore
di una probabilit\`{a} in corrispondenza degli elementi di $\mathcal{C}$ la
identifica univocamente su tutta $\mathcal{A}$. Per assegnare una probabilit%
\`{a} a $\left( \Omega ,\mathcal{A}\right) $ \`{e} dunque sufficiente
assegnare la\ probabilit\`{a} sugli elementi di un $\pi $-sistema.

Se $\Omega $ \`{e} discreto, $\mathcal{A}=2^{\Omega }$ e $\mathcal{C=}%
\left\{ \varnothing ,\left\{ \omega _{1}\right\} ,\left\{ \omega
_{n}\right\} ...\right\} $ \`{e} l'insieme dei singoletti pi\`{u} l'insieme
vuoto, si riottiene il fatto che stabilire una probabilit\`{a} sugli atomi
determina univocamente la probabilit\`{a}.

\begin{enumerate}
\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $, $\mathcal{C=}\left\{ \left( a,b\right) :-\infty \leq
a<b\leq +\infty \right\} $ \`{e} un $\pi $-sistema. Ricordiamo che $\sigma
\left( \mathcal{C}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

$\mathcal{\tilde{C}=}\left\{ (-\infty ,q]:q\in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right\} $ \`{e} un $\pi $-sistema. Ricordiamo che $\sigma \left( \mathcal{%
\tilde{C}}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

$\mathcal{\mathring{C}=}\left\{ (-\infty ,x]:x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right\} $ \`{e} un $\pi $-sistema. Vale inoltre $\sigma \left( \mathcal{%
\mathring{C}}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Dimostro che $\sigma \left( \mathcal{\mathring{C}}\right)
\subseteq \sigma \left( \mathcal{\tilde{C}}\right) $. Infatti, dato $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $\exists $ $\left( q_{n}\right) _{n\geq 1}:q_{n}\in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$ $\forall $ $n,q_{n}\leq x$ $\forall $ $n$ e $\lim_{n\rightarrow +\infty
}q_{n}=x$, perch\'{e} $%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$ \`{e} denso in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Allora posso scrivere $(-\infty ,x]=\bigcup_{n=1}^{+\infty }(-\infty
,q_{n}]$: il lato destro appartiene a $\sigma \left( \mathcal{\tilde{C}}%
\right) $, essendo ogni $\sigma $-algebra chiusa per unione numerabile,
dunque $(-\infty ,x]\in \sigma \left( \mathcal{\tilde{C}}\right) $ e $%
\mathcal{\mathring{C}}\subseteq \sigma \left( \mathcal{\tilde{C}}\right) $,
per cui $\sigma \left( \mathcal{\mathring{C}}\right) \subseteq \sigma \left( 
\mathcal{\tilde{C}}\right) $. L'inclusione $\sigma \left( \mathcal{\tilde{C}}%
\right) \subseteq \sigma \left( \mathcal{\mathring{C}}\right) $ \`{e} ovvia,
perch\'{e} ogni numero razionale \`{e} anche reale, quindi $\sigma \left( 
\mathcal{\mathring{C}}\right) =\sigma \left( \mathcal{\tilde{C}}\right) =%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.
\end{enumerate}

\textbf{Def 5.3} Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ spazio di probabilit\`{a}, si dice funzione di
ripartizione associata a $\mathbf{P}$, e si indica con $F$, la funzione $F:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,1\right] :F\left( x\right) =\mathbf{P}\left( (-\infty
,x]\right) $ $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

Data $\mathbf{P}$, la funzione $F$ \`{e} unica, ed \`{e} l'analoga di $%
p:\Omega \rightarrow \left[ 0,1\right] $ per spazi al pi\`{u} numerabili: 
\`{e} infatti definita su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e non su $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, il che ne riduce la complessit\`{a}, e permette di risalire a $%
\mathbf{P}\left( A\right) $ $\forall $ $A$ intervallo (e anche per altro: si
vede dopo). Gli intervalli del tipo $(-\infty ,x]$ sono i generatori di $%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, proprio come gli $\left\{ \omega \right\} $ sono i generatori di $%
2^{\Omega }$: in questo caso gli atomi non sono gli eventi elementari, perch%
\'{e} non sto generando dai singoletti, ma da $\mathcal{\mathring{C}}$. Per
il criterio di Caratheodory \`{e} quindi ragionevole aspettarsi che $F$
identifichi univocamente $\mathbf{P}$: assegnare $F$ significa definire $%
\mathbf{P}$ su un $\pi $-sistema che genera $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

\textbf{Teo 5.4 (propriet\`{a} della funzione di ripartizione)}

(1) (caratterizzazione della funzione di ripartizione)
\begin{gather*}
\text{Hp: }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{ spazio probabilizzabile} \\
\text{Ts: }F:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,1\right] \text{ \`{e} funzione di ripartizione di una }%
\mathbf{P}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] \text{ }\Longleftrightarrow \text{ (A) 
}F\text{ \`{e} monotona} \\
\text{non decrescente, (B) }F\text{ \`{e} continua da destra, (C) }%
\lim_{x\rightarrow -\infty }F\left( x\right) =0\text{ e }\lim_{x\rightarrow
+\infty }F\left( x\right) =1
\end{gather*}

(2) (misura di intervalli con la funzione di ripartizione)%
\begin{gather*}
\text{Hp: }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) \text{ spazio di probabilit\`{a}, }F\text{ \`{e}
la funzione di ripartizione associata a }\mathbf{P}\text{, }x<y \\
\text{Ts: (i) }\mathbf{P}\left( (x,y]\right) =F\left( y\right) -F\left(
x\right) \text{, (ii) }\mathbf{P}\left( [x,y]\right) =F\left( y\right)
-F\left( x^{-}\right) \text{, (iii) }\mathbf{P}\left( [x,y)\right) =F\left(
y^{-}\right) -F\left( x^{-}\right) \text{,} \\
\text{(iv) }\mathbf{P}\left( (x,y)\right) =F\left( y^{-}\right) -F\left(
x\right) \text{, (v) }\mathbf{P}\left( \left\{ x\right\} \right) =F\left(
x\right) -F\left( x^{-}\right)
\end{gather*}

(3)
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{ spazio probabilizzabile, }F:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,1\right] \text{ \`{e} una funzione di ripartizione di
una }\mathbf{P} \\
\text{Ts}\text{: } &&F\text{ caratterizza }\mathbf{P}\text{, i. e. }%
F_{1}=F_{2}\Longleftrightarrow \mathbf{P}_{1}=\mathbf{P}_{2}
\end{eqnarray*}

$F\left( x^{-}\right) =\lim_{y\rightarrow x^{-}}F\left( y\right) $. In (1)
A, B, C sono propriet\`{a} caratterizzanti di una funzione di ripartizione: 
\`{e} l'analogo continuo delle propriet\`{a} caratterizzanti viste per $%
p:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ nel caso discreto. La situazione \`{e} tuttavia pi\`{u} complessa, nel
senso che avendo $F$ non si riesce a calcolare $\mathbf{P}\left( A\right) $ $%
\forall $ $A\in \mathcal{A}$; perlomeno per\`{o} si riesce a calcolare la probabilit\`{a} di
un qualsiasi intervallo. (2) evidenzia che in generale la probabilit\`{a} di
un singoletto non \`{e} nulla. (3) significa che conoscendo $F$ il valore di 
$\mathbf{P}$ $\forall $ $A\in \mathcal{A}$ \`{e} univocamente determinato.

\textbf{Dim} (1) Mostro l'implicazione da sinistra a destra.

(A) Voglio mostrare che se $x<y$ allora $F\left( x\right) \leq F\left(
y\right) $. Per definizione di funzione di ripartizione $F\left( x\right) =%
\mathbf{P}\left( (-\infty ,x]\right) ,F\left( y\right) =\mathbf{P}\left(
(-\infty ,y]\right) $: ma se $x<y$ $(-\infty ,x]\subseteq (-\infty ,y]$,
quindi per P3 (monotonia) $\mathbf{P}\left( (-\infty ,x]\right) \leq \mathbf{%
P}\left( (-\infty ,y\right) $, cio\`{e} $F\left( x\right) \leq F\left(
y\right) $.

(B) Considero una successione $x_{n}$ che decresce a $x$, cio\`{e} $%
x_{n}:x_{n}\geq x_{n+1}$ $\forall $ $n$ e $\lim_{n\rightarrow +\infty
}x_{n}=x$: mostro che, se $x_{n}\downarrow x$, $\lim_{n\rightarrow +\infty
}F\left( x_{n}\right) =F\left( x\right) $. $F\left( x_{n}\right) =\mathbf{P}\left(
(-\infty ,x_{n}]\right) $; posso porre $A_{n}=(-\infty ,x_{n}]$, e se $%
x_{n}\downarrow x$ $A_{n}\downarrow A$, con $A=\bigcap_{n=1}^{+\infty
}A_{n}=(-\infty ,x]$. Quindi $\lim_{n\rightarrow +\infty }F\left(
x_{n}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}\left( A_{n}\right) =%
\mathbf{P}\left( A\right) =\mathbf{P}\left( (-\infty ,x]\right) =F\left(
x\right) $ per la continuit\`{a} della probabilit\`{a} (2.4).

(C) Considero una successione $x_{n}$ che decresce a $-\infty $, cio\`{e} $%
x_{n}:x_{n}\leq x_{n+1}$ $\forall $ $n$ e $\lim_{n\rightarrow +\infty
}x_{n}=-\infty $: mostro che, se $x_{n}\downarrow -\infty $, $%
\lim_{n\rightarrow +\infty }F\left( x_{n}\right) =0$. $F\left( x_{n}\right) =%
\mathbf{P}\left( (-\infty ,x_{n}]\right) $; posso porre $A_{n}=(-\infty
,x_{n}]$, e se $x_{n}\downarrow -\infty $ $A_{n}\downarrow A$, con $%
A=\bigcap_{n=1}^{+\infty }A_{n}=\varnothing $. Quindi $\lim_{n\rightarrow
+\infty }F\left( x_{n}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}\left(
A_{n}\right) =\mathbf{P}\left( A\right) =\mathbf{P}\left( \varnothing
\right) =0$ per il teorema 2.4.

Analogamente considero una successione $x_{n}$ che cresce a $+\infty $, cio%
\`{e} $x_{n}:x_{n}\leq x_{n+1}$ $\forall $ $n$ e $\lim_{n\rightarrow +\infty
}x_{n}=+\infty $: mostro che, se $x_{n}\uparrow +\infty $, $%
\lim_{n\rightarrow +\infty }F\left( x_{n}\right) =1$. $F\left( x_{n}\right) =%
\mathbf{P}\left( (-\infty ,x_{n}]\right) $; posso porre $A_{n}=(-\infty
,x_{n}]$, e se $x_{n}\uparrow +\infty $ $A_{n}\uparrow A$, con $%
A=\bigcup_{n=1}^{+\infty }A_{n}=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Quindi $\lim_{n\rightarrow +\infty }F\left( x_{n}\right)
=\lim_{n\rightarrow +\infty }\mathbf{P}\left( A_{n}\right) =\mathbf{P}\left(
A\right) =\mathbf{P}\left( \Omega \right) =1$ per 2.4.

(2) Sia $x<y$. (i) $(x,y]=(-\infty ,y]\backslash (-\infty ,x]$, quindi per
P5 vale $\mathbf{P}\left( (x,y]\right) =\mathbf{P}\left( (-\infty
,y]\backslash (-\infty ,x]\right) =\mathbf{P}\left( (-\infty ,y]\right) 
\mathbf{-P}\left( (-\infty ,y]\cap (-\infty ,x]\right) =\mathbf{P}\left(
(-\infty ,y]\right) \mathbf{-P}\left( (-\infty ,x]\right) =F\left( y\right)
-F\left( x\right) $. Oppure, usando pi\`{u} semplicemente la $\sigma $%
-additivit\`{a}: $(-\infty ,y]=(-\infty ,x]\cup (x,y]$, quindi $F\left(
y\right) =F\left( x\right) +\mathbf{P}\left( (x,y]\right) $ e $\mathbf{P}%
\left( (x,y]\right) =F\left( y\right) -F\left( x\right) $.

(iv) $\left( x,y\right) =\bigcup_{n=1}^{+\infty }(x,y-\frac{1}{n}]$:
l'uguaglianza vale anche con $\bigcup_{n=1}^{+\infty }(x,y-\frac{1}{n})$, ma
non si potrebbe usare (i). Ponendo $A_{n}=(x,y-\frac{1}{n}]$, poich\'{e} $%
A_{n}\uparrow A$, per la continuit\`{a} della probabilit\`{a} al contrario
si ha che $\mathbf{P}\left( \bigcup_{n=1}^{+\infty }A_{n}\right)
=\lim_{n\rightarrow +\infty }\mathbf{P}\left( A_{n}\right) $, ed \`{e} noto
che $\mathbf{P}\left( (x,y-\frac{1}{n}]\right) =F\left( y-\frac{1}{n}\right)
-F\left( x\right) $, per cui $\lim_{n\rightarrow +\infty }\mathbf{P}\left(
A_{n}\right) =F\left( y^{-}\right) -F\left( x\right) $.

(ii) $[x,y]=(-\infty ,y]\backslash \left( -\infty ,x\right) $. Posso
scrivere $\mathbf{P}\left( \left( -\infty ,x\right) \right)
=\lim_{n\rightarrow +\infty }\mathbf{P}\left( \left( -n,x-\frac{1}{n}\right)
\right) =\lim_{n\rightarrow +\infty }\left( F\left( x-\frac{1}{n}\right)
^{-}-F\left( -n\right) \right) =F\left( x^{-}\right) $. Quindi $\mathbf{P}%
\left( \left[ x,y\right] \right) =\mathbf{P}\left( (-\infty ,y]\right) 
\mathbf{-P}\left( (-\infty ,y]\cap (-\infty ,x)\right) =F\left( y\right) 
\mathbf{-P}\left( (-\infty ,x)\right) =F\left( y\right) -F\left(
x^{-}\right) $.

(iii) $[x,y)=\left( -\infty ,y\right) \backslash \left( -\infty ,x\right) $,
quindi $\mathbf{P}\left( (-\infty ,y)\backslash (-\infty ,x)\right) =\mathbf{%
P}\left( (-\infty ,y)\right) \mathbf{-P}\left( (-\infty ,x)\right) =F\left(
y^{-}\right) -F\left( x^{-}\right) $.

(v) $\left\{ x\right\} =(-\infty ,x]\backslash \left( -\infty ,x\right) $: $%
\mathbf{P}\left( (-\infty ,x]\right) -\mathbf{P}\left( \left( -\infty
,x\right) \right) =F\left( x\right) -F\left( x^{-}\right) $ per quanto visto
sopra.

(3) L'implicazione da destra a sinistra \`{e} ovvia. Dimostro quella da
sinistra a destra: $F_{1}\left( x\right) =F_{2}\left( x\right) $ $\forall $ $%
x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, quindi $\mathbf{P}_{1}\mathbf{,P}_{2}$ coincidono sugli elementi di $%
\mathcal{\mathring{C}}$; essendo $\mathcal{\mathring{C}}$ un $\pi $-sistema,
per il criterio di Caratheodory $\mathbf{P}_{1}\mathbf{=P}_{2}$ su $\sigma
\left( \mathcal{\mathring{C}}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. $\blacksquare $

\begin{enumerate}
\item Dato $\alpha \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, in $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ definisco la probabilit\`{a} massa di Dirac in $\alpha $
come $\mathbf{P}\left( A\right) =\left\{ 
\begin{array}{c}
1\text{ se }\alpha \in A \\ 
0\text{ se }\alpha \not\in A%
\end{array}%
\right. $ $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Si pu\`{o} quindi ricavare $F\left( x\right) =\mathbf{P}\left(
(-\infty ,x]\right) =\left\{ 
\begin{array}{c}
1\text{ se }\alpha \leq x \\ 
0\text{ se }\alpha >x%
\end{array}%
\right. $, detta funzione gradino di Heaviside. La massa di Dirac
rappresenta la situazione in cui si hanno tutte le informazioni: si \`{e}
certi che l'evento $\left\{ \alpha \right\} $ si verifica.

\item Se $F$ \`{e} una funzione di ripartizione continua in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, allora - per una versione del teorema dei valori intermedi che si applica
perch\'{e} $\lim_{x\rightarrow +\infty }F\left( x\right)
=1,\lim_{x\rightarrow -\infty }F\left( x\right) =0$ - $\forall $ $\lambda
\in \left( 0,1\right) $ $\exists $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:F\left( x\right) =\lambda $.
\end{enumerate}

\textbf{Def} Dato lo spazio probabilizzabile $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e $T\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ discreto, si dice che $\mathbf{P}$ \`{e} una probabilit\`{a} discreta su $%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ se $\exists $ $p:T\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, detta funzione di densit\`{a} discreta, tale che $\left\{ 
\begin{array}{c}
p\left( x\right) \geq 0\text{ }\forall \text{ }x\in T \\ 
\sum_{x\in T}p\left( x\right) =1%
\end{array}%
\right. $, e se $\mathbf{P}$ \`{e} definita come $\mathbf{P}\left( A\right)
=\sum_{x\in A\cap T}p\left( x\right) $ $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.


Quindi $F\left( x\right) =\mathbf{P}\left( (-\infty ,x]\right) =\sum_{y\in
(-\infty ,x]\cap T}p\left( y\right) $. L'assegnazione di una probabilit\`{a}
su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ comprende quindi anche il caso numerabile.

Dato $x\in T$, \`{e} possibile che $p\left( x\right) =0$.

\textbf{Def} Dato $T\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ al pi\`{u} numerabile, dato lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ con funzione di densit\`{a} discreta $%
p:T\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, si dice supporto della densit\`{a} o della probabilit\`{a}, e si indica
con $\mathcal{S}$, $\left\{ x\in T:p\left( x\right) >0\right\} $.

Allora $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $\mathbf{P}\left( A\right) =\sum_{x\in A\cap T}p\left( x\right)
=\sum_{x\in A\cap \mathcal{S}}p\left( x\right) $, e in particolare $\mathbf{P%
}\left( (-\infty ,x]\right) =\sum_{y\in (-\infty ,x]\cap \mathcal{S}}p\left(
y\right) $.

\begin{enumerate}
\item Le distribuzioni di probabilit\`{a} bernoulli, binomiale, poisson
introdotte nel caso di $\Omega $ discreti ($\left\{ 0,1\right\} $, $\left\{
0,...,n\right\} $, $%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, rispettivamente), tutti immersi in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, hanno delle $p$ che sono funzioni di densit\`{a} discrete.
\end{enumerate}

Ci si potrebbe chiedere perch\'{e}
si prende $T$ e non direttamente $\mathcal{S}$. $Bi\left( n,p\right) $ al
variare di $n$ ha come supporto $T$$\mathcal{=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}$. Se invece fisso $n$ $Bi\left( n,p\right) $ ha come supporto $\mathcal{S=}%
\left\{ 0,...,n\right\} \varsubsetneq T$.

\textbf{Def} Una funzione di ripartizione $F$ associata a $\mathbf{P}$ si
dice di puro salto se, detto $O=\left\{ \text{punti di salto}\right\} $, $%
\sum_{x\in O}\left( F\left( x\right) -F\left( x^{-}\right) \right) =1$.

\textsc{S} coincide con l'insieme dei punti di discontinuit\`{a} di $F$,
perch\'{e} una funzione monotona definita su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ pu\`{o} avere solo punti di discontinuit\`{a} a salto. Inoltre \textsc{S} 
\`{e} discreto, perch\'{e} l'insieme dei punti di discontinuit\`{a} di una
funzione monotona definita su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} al pi\`{u} numerabile.

\textbf{Prop 5.5 (caratterizzazione delle probabilit\`{a} discrete)}%
\begin{gather*}
\text{Hp: }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{, }\mathbf{P}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] \text{ con funzione di ripartizione }F
\\
\text{Ts: }\mathbf{P}\text{ \`{e} una probabilit\`{a} discreta con densit%
\`{a} }p\text{ e supporto }\mathcal{S}\Longleftrightarrow F\text{ \`{e} di
puro salto e} \\
\sum_{x\in \mathcal{S}}F\left( x\right) -F\left( x^{-}\right) =1\text{; in
tal caso }\mathcal{S}=\left\{ \text{punti di discontinuit\`{a} di }F\right\} 
\text{ e }p\left( x\right) =F\left( x\right) -F\left( x^{-}\right)
\end{gather*}

Questo significa che posso caratterizzare $p$ e ricavarne il valore a
partire dalle propriet\`{a} analitiche di $F$.

\begin{enumerate}
\item Se $F$ \`{e} di puro salto ed \`{e} discontinua in $\left\{
x_{1},x_{2},x_{3}\right\} $, allora $\mathcal{S}=\left\{
x_{1},x_{2},x_{3}\right\} $ e $p\left( x_{k}\right) =F\left( x_{k}\right)
-F\left( x_{k}^{-}\right) $. Analogamente posso ricavare $F$ da $p$, dato
che $\mathbf{P}\left( (-\infty ,x]\right) =\sum_{y\in (-\infty ,x]\cap
T}p\left( y\right) $ $\forall $ $x$.
\end{enumerate}

\textbf{Def} Data $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, se $f$ \`{e} Riemann integrabile, $f\left( x\right) \geq 0$ $\forall $ $%
x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e $\int_{-\infty }^{+\infty }f\left( x\right) dx=1$, $f$ si dice funzione
di densit\`{a} continua.

E' allora ben definita \ la funzione di $x$ $\int_{-\infty }^{x}f\left(
t\right) dt$, e si pu\`{o} dimostrare che $F\left( x\right) =\int_{-\infty
}^{x}f\left( t\right) dt$ \`{e} una funzione di ripartizione, cio\`{e}
soddisfa A (perch\'{e} $f$ \`{e} non negativa), B (perch\'{e} una funzione
integrale \`{e} continua per il teorema fondamentale del calcolo integrale),
C e identifica dunque un'unica probabilit\`{a} $\mathbf{P}$ su $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $. Poich\'{e} in tal caso $F$ \`{e} continua, $\mathbf{P}%
\left( \left\{ x\right\} \right) =0=F\left( x\right) -F\left( x^{-}\right) $ 
$\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Le richieste su $f$ sono la versione continua delle richieste sulla densit%
\`{a} discreta. Se quindi $F$ non \`{e} continua, non ammette una densit\`{a}%
, cio\`{e} $\NEG{\exists}$ $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:F\left( x\right) =\int_{-\infty }^{x}f\left( t\right) dt$.

Se inoltre $f$ \`{e} continua a tratti, $F$ \`{e} $C^{1}$ a tratti per il
teorema fondamentale e $F^{\prime }\left( x\right) =f\left( x\right) $.
Quindi, se mi viene assegnata $F$ $C^{1}$ a tratti, allora so che $F$ \`{e}
"di questo tipo qua"?? perch\'{e} la sua derivata "fa il gioco della densit%
\`{a}".

Si pu\`{o} quindi costruire un modello di probabilit\`{a} su $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ a partire da una funzione di densit\`{a}, perch\'{e} essa
definisce $F\left( x\right) =\int_{-\infty }^{x}f\left( t\right) dt$ e
quindi $\mathbf{P}$. In base al tipo di probabilit\`{a} che voglio costruire
sceglier\`{o} una funzione di ripartizione di un tipo o di un altro. Si noti
che non \`{e} per ora spiegato come sono fatte le $\mathbf{P}$ per cui
esista una densit\`{a} continua.

\begin{enumerate}
\item Sia $f\left( t\right) =\frac{1}{b-a}I_{(a,b]}\left( t\right) $: $f$
soddisfa le richieste sopra. Allora $F\left( x\right) =\int_{-\infty
}^{x}f\left( t\right) dt=\left\{ 
\begin{array}{c}
0\text{ se }x<a \\ 
\frac{1}{b-a}\left( x-a\right) \text{ se }x\in \left[ a,b\right] \\ 
1\text{ se }x>b%
\end{array}%
\right. $ \`{e} una funzione di ripartizione, che dota $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ della cosiddetta probabilit\`{a} uniforme su $(a,b]$, $%
\mathcal{U}\left( (a,b]\right) $.

\item Sia $f\left( t\right) =\lambda e^{-\lambda t}I_{\left( 0,+\infty
\right) }\left( t\right) $: $f$ soddisfa le richieste sopra. Allora $F\left(
x\right) =\int_{-\infty }^{x}f\left( t\right) dt=\left\{ 
\begin{array}{c}
0\text{ se }x\leq 0 \\ 
1-e^{-\lambda x}\text{ se }x\in \left( 0,+\infty \right)%
\end{array}%
\right. $ \`{e} una funzione di ripartizione, che dota $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ del modello esponenziale $\varepsilon \left( \lambda
\right) $.

\item Sia $f\left( t\right) =\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}t^{2}}$: $%
f $ soddisfa le richieste sopra. Allora $F\left( x\right) =\int_{-\infty
}^{x}f\left( t\right) dt$ \`{e} una funzione di ripartizione, che dota $%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ del modello normale $\mathcal{N}\left( 0,1\right) $.

\item Se $F$ non \`{e} continua, non ammette una densit\`{a} di probabilit%
\`{a} continua; se non \`{e} di puro salto, non ammette una densit\`{a} di
probabilit\`{a} discreta. Se quindi $F$ \`{e} discontinua e non \`{e} di
puro salto, non ammette densit\`{a} di probabilit\`{a}.
\end{enumerate}

\section{Variabili aleatorie}

Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ modello di un
esperimento aleatorio, \`{e} utile introdurre una funzione $X:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, che restituisca un numero che riassuma ci\`{o} che mi interessa
dell'esperimento.

\begin{enumerate}
\item Se lancio due dadi distinti, $\Omega =\left\{ \omega =\left( \omega
_{1},\omega _{2}\right) :\omega _{i}\in \left\{ 1,...,6\right\} \text{ }%
\forall \text{ }i=1,2\right\} $. Se sono interessata alla somma dei
risultati, posso introdurre $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega _{1}+\omega _{2}$.
\end{enumerate}

E' normale allora che per ogni $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ mi interessi la probabilit\`{a} che la funzione che descrive il
risultato di mio interesse assuma valori in $B$, dunque la probabilit\`{a}
che $X$ cada in $B$, cio\`{e} $\mathbf{P}\left( \left( X\in B\right) \right) 
$ $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Affinch\'{e} possa calcolare tale probabilit\`{a} \`{e}
necessario che $\left( X\in B\right) \in \mathcal{A}$ $\forall $ $B\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $: questa condizione prende il nome di misurabilit\`{a}.

\textbf{Def 6.2} Dato $E$ insieme qualsiasi ed $\mathcal{E}$ $\sigma $%
-algebra su $E$, si dice spazio misurabile la coppia $\left( E,\mathcal{E}%
\right) $.

$\mathcal{E}$ \`{e} ovviamente una famiglia di sottinsiemi di $E$. Se in
particolare $E=\Omega $, che ha il significato modellistico di spazio
campionario, $\left( E,\mathcal{E}\right) $ si dice spazio probabilizzabile.

\textbf{Def 6.3} Dati gli spazi misurabili $\left( E,\mathcal{E}\right)
,\left( F,\mathcal{F}\right) $, una funzione $f:E\rightarrow F$ si dice
funzione misurabile se $\forall $ $B\in \mathcal{F}$ $f^{-1}\left( B\right)
\in \mathcal{E}$.

$f^{-1}\left( B\right) $ \`{e} ben definita perch\'{e} il generico elemento
di $\mathcal{F}$ \`{e} un sottinsieme di $F$. La definizione formalizza il
ragionamento fatto prima nel caso di $\left( E,\mathcal{E}\right) =\left(
\Omega ,\mathcal{A}\right) ,\left( F,\mathcal{F}\right) =\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $. In generale una funzione misurabile si indica con $%
f:\left( E,\mathcal{E}\right) \rightarrow \left( F,\mathcal{F}\right) $.

Si vedr\`{a} in seguito che la misurabilit\`{a} \`{e} una richiesta di
regolarit\`{a} di $f$ molto debole.

\textbf{Def 6.4} Dato $\left( \Omega ,\mathcal{A}\right) $ spazio
probabilizzabile e $\left( E,\mathcal{E}\right) $ spazio misurabile, $%
X:\Omega \rightarrow E$ si dice variabile aleatoria se $X$ \`{e} una
funzione misurabile.

A livello strettamente matematico non c'\`{e} quindi differenza tra una v.a.
e una funzione misurabile. La definizione di v.a. significa che $\forall $ $%
B\in \mathcal{E}$ $\left( X\in B\right) =X^{-1}\left( B\right) \in \mathcal{A%
}$, cio\`{e} $X^{-1}\left( B\right) $ \`{e} un evento e dunque - se ho
fissato anche $\mathbf{P}$ su $\left( \Omega ,\mathcal{A}\right) $ - ne
posso calcolare la probabilit\`{a}: cio\`{e}, dato $\left( \Omega ,\mathcal{A%
},\mathbf{P}\right) $ spazio di probabilit\`{a}, se $X:\Omega \rightarrow E$ 
\`{e} una variabile aleatoria allora $\mathbf{P}\left( X\in B\right) $ \`{e}
ben definita $\forall $ $B\in \mathcal{E}$ $\sigma $-algebra su $E$. Questo 
\`{e} fondamentale per poter calcolare la probabilit\`{a} di eventi
rappresentabili attraverso i valori che assume $X$ (cio\`{e} eventi generati
da $X$), che \`{e} quello che ci interessa.

Per noi sar\`{a} sempre $E=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, dotato della $\sigma $-algebra $\mathcal{E=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, o $E=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ (nel qual caso $\mathbf{X}$ sar\`{a} detto vettore aleatorio), dotato
della $\sigma $-algebra $\mathcal{E=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =\mathcal{B}^{n}$, che indica $\sigma \left( \left(
a_{1},b_{1}\right) \times \left( a_{2},b_{2}\right) \times ...\times \left(
a_{n},b_{n}\right) :-\infty \leq a_{i}<b_{i}\leq +\infty \text{ }\forall 
\text{ }i=1,...,n\right) $, cio\`{e} la $\sigma $-algebra generata dai
rettangoli aperti di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$.

\begin{enumerate}
\item Se lancio due dadi distinti, $\Omega =\left\{ 1,...,6\right\} ^{2}$, $%
\mathcal{A}=2^{\Omega }$. Sia $E=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $\mathcal{E=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $: data $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega _{1}+\omega _{2}$, $X$ \`{e} una
variabile aleatoria? E' vero che $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $X^{-1}\left( B\right) \in 2^{\Omega }$? Sicuramente $f^{-1}\left(
B\right) \subseteq \Omega $, ma allora $f^{-1}\left( B\right) \in 2^{\Omega
} $ e $f$ \`{e} una variabile aleatoria.

Quindi, \textit{ogni volta che si hanno }$\left( \Omega ,2^{\Omega }\right)
,\left( E,\mathcal{E}\right) $\textit{, }$X:\Omega \rightarrow E$\textit{\ 
\`{e} una variabile aleatoria}.

\item Considero come spazi misurabili $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\lceil \omega \rceil $. $X\left( \Omega \right) =%
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$. $X$ \`{e} una variabile aleatoria? E' vero che $\forall $ $B\in \mathcal{B%
}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $X^{-1}\left( B\right) \in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $? Se $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, $X^{-1}\left( B\right) =\left( X\in B\right) =\left( X\in
B\right) \cap \Omega =\left( X\in B\right) \cap \left( X\in 
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
\right) $, per quanto osservato sopra. Ma per la propriet\`{a} 4 delle
controimmagini $\left( X\in B\right) \cap \left( X\in 
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
\right) =\left( X\in \left( B\cap \mathbb{Z}\right) \right) =\bigcup_{k\in
\left( B\cap \mathbb{Z}\right) }\left( X=k\right) =\bigcup_{k\in \left(
B\cap \mathbb{Z}\right) }(k-1,k]$, che \`{e} un'unione al pi\`{u} numerabile
di intervalli. Poich\'{e} $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ contiene tutti gli intervalli di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e anche tutte le loro unioni numerabili, essendo una $\sigma $-algebra, $%
\bigcup_{k\in \left( B\cap \mathbb{Z}\right) }(k-1,k]\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ e $X$ \`{e} una variabile aleatoria.

\item Considero come spazi misurabili $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega ^{2}$. $X\left( \Omega \right)
=[0,+\infty )$. E' vero che $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $X^{-1}\left( B\right) \in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $? Non riusciamo ancora a stabilirlo analiticamente, ma i criteri
che seguono permettono di farlo.
\end{enumerate}

\textbf{Teo 6.5 (misurabilit\`{a} della composta di due misurabili)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A}\right) \text{ spazio
probabilizzabile, }\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}\right) 
\text{ spazi misurabili, } \\
X:\Omega \rightarrow E\text{ variabile aleatoria, }h:E\rightarrow F\text{
funzione misurabile} \\
\text{Ts}\text{: }Y=h\circ X:\Omega \rightarrow F\text{ \`{e} una variabile
aleatoria}
\end{gather*}

\textbf{Dim} Devo mostrare che $\forall $ $\mathrm{C}\in \mathcal{F}$ $%
Y^{-1}\left( \mathrm{C}\right) =\left( Y\in \mathrm{C}\right) \in \mathcal{A}
$. Ma $Y^{-1}\left( \mathrm{C}\right) =\left( X^{-1}\left( h^{-1}\left( 
\mathrm{C}\right) \right) \right) =\left( X\in h^{-1}\left( \mathrm{C}%
\right) \right) $: $h^{-1}\left( \mathrm{C}\right) \in \mathcal{E}$ $\forall 
$ $\mathrm{C}\in \mathcal{F}$ perch\'{e} $h$ \`{e} misurabile, quindi,
essendo $h^{-1}\left( \mathrm{C}\right) $ un generico sottinsieme di $%
\mathcal{E}$, si ha che $X^{-1}\left( h^{-1}\left( \mathrm{C}\right) \right)
\in \mathcal{A}$ perch\'{e} $X$ \`{e} una variabile aleatoria, dunque $Y$ 
\`{e} una variabile aleatoria. $\blacksquare $

\textbf{Teo (caratterizzazione della misurabilit\`{a}) }%
\begin{gather*}
\text{Hp}\text{: }\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}\right) 
\text{ spazi misurabili, }h:E\rightarrow F\text{, }\mathcal{C}\subseteq 
\mathcal{F}:\sigma \left( \mathcal{C}\right) =\mathcal{F} \\
\text{Ts}\text{: }h\text{ \`{e} misurabile }\Longleftrightarrow h^{-1}\left(
B\right) \in \mathcal{E}\text{ }\forall \text{ }B\in \mathcal{C}
\end{gather*}

Si pu\`{o} verificare la misurabilit\`{a} di $h$ controllando quindi solo le
controimmagini di insiemi che formano un insieme che genera la $\sigma $%
-algebra di arrivo. 6.6 (i) esibisce un caso particolare di questo teorema.

\textbf{Dim*} L'implicazione da sinistra a destra \`{e} ovvia perch\'{e} $%
h^{-1}\left( B\right) \in \mathcal{E}$ $\forall $ $B\in \mathcal{F}$.

Se invece $h^{-1}\left( B\right) \in \mathcal{E}$ $\forall $ $B\in \mathcal{C%
}$, allora $\mathcal{C}$ \`{e} contenuto nell'insieme dei $B\in \mathcal{F}%
:h^{-1}\left( B\right) \in \mathcal{E}$, indicato con $\mathcal{D}$. Quindi $%
\mathcal{C\subseteq D\subseteq F}$, per cui $\sigma \left( \mathcal{C}%
\right) \mathcal{\subseteq \sigma }\left( \mathcal{D}\right) \mathcal{%
\subseteq \sigma }\left( \mathcal{F}\right) $, cio\`{e} $\mathcal{F\subseteq
\sigma }\left( \mathcal{D}\right) \mathcal{\subseteq F}$, vale a dire $%
\mathcal{\sigma }\left( \mathcal{D}\right) =\mathcal{F}$. Ma $\mathcal{D}$ 
\`{e} una $\sigma $-algebra su $\mathcal{F}$ perch\'{e} se $B\in \mathcal{F}$
\`{e} tale che $h^{-1}\left( B\right) \in \mathcal{E}$, allora anche $%
B^{c}\in \mathcal{F}$ \`{e} tale che $h^{-1}\left( B^{c}\right) =\left(
h^{-1}\left( B\right) \right) ^{c}\in \mathcal{E}$, e sempre per le propriet%
\`{a} della controimmagine anche l'unione di $B$ siffatti \`{e} in $\mathcal{%
E}$. Da questo si deduce che $\mathcal{\sigma }\left( \mathcal{D}\right) =%
\mathcal{D}=\mathcal{F}$, cio\`{e} per ogni $B\in \mathcal{F}$ $h^{-1}\left(
B\right) \in \mathcal{E}$, vale a dire che $h$ \`{e} misurabile. $%
\blacksquare $

\textbf{Teo 6.6 (criteri di misurabilit\`{a})}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A}\right) \text{ spazio probabilizzabile, 
}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \\
\text{(i) }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una variabile aleatoria }\Longleftrightarrow \left( X\leq
x\right) \in \mathcal{A}\text{ }\forall \text{ }x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{(ii) }X=I_{A}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una variabile aleatoria }\Longleftrightarrow A\in \mathcal{A} \\
\text{(iii) }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{, }\mathbf{X}=\left( X_{1},...,X_{n}\right) \text{ \`{e} un
vettore aleatorio }\Longleftrightarrow \text{ }X_{k}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\text{\`{e} una variabile aleatoria }\forall \text{ }k=1,...,n
\end{gather*}

\begin{gather*}
\text{(iv) Hp: }\left( \Omega ,\mathcal{A}\right) \text{ spazio
probabilizzabile, }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{, }X_{k}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una} \\
\text{variabile aleatoria }\forall \text{ }k=1,...,n\text{ e }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} misurabile} \\
\text{Ts: }h\circ \left( X_{1},...,X_{n}\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una variabile aleatoria}
\end{gather*}

\begin{eqnarray*}
\text{(v) Hp}\text{: } &&\left( \Omega ,\mathcal{A}\right) \text{ spazio
probabilizzabile, }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{, }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ sono v. a.} \\
\text{Ts}\text{: } &&X+Y,X-Y,XY,X\vee Y,X\wedge Y,\frac{X}{Y}I_{\left( Y\neq
0\right) }\text{ sono misurabili}
\end{eqnarray*}

\begin{eqnarray*}
\text{(vi) Hp}\text{: } &&\left( \Omega ,\mathcal{A}\right) \text{ spazio
probabilizzabile, }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{, }X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ successione di v. a.} \\
\text{Ts} &\text{:}&\text{ }\sup_{n}X_{n},\inf_{n}X_{n},\lim_{n\rightarrow
+\infty }X_{n}\text{, se esiste, sono misurabili}
\end{eqnarray*}

(i) afferma che per valutare la misurabilit\`{a} di $X$ non occorre
controllare che la controimmagine di ogni sottinsieme di $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ stia in $\mathcal{A}$: \`{e} sufficiente controllare le
controimmagini di un $\pi $-sistema: delle semirette, cio\`{e} gli insiemi $%
(-\infty ,x]$. (iii) afferma che \`{e} possibile controllare la misurabilit%
\`{a} componente per componente. (iv) \`{e} una generalizzazione di 6.5. (v) 
\`{e} ben definita perch\'{e} in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ sono ben definite tutte le operazioni della tesi. $\sup_{n}X_{n}$ \`{e}, $%
\forall $ $\omega \in \Omega $, $\sup \left\{ X_{n}\left( \omega \right)
:n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\right\} $, ed \`{e} quindi una funzione di $\omega $.

\textbf{Dim*} (i) \`{e} il teorema sopra nel caso particolare di $F=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $\mathcal{F=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, dato che $\sigma \left( \left\{ (-\infty ,x]:x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right\} \right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

(ii) $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $I_{A}^{-1}\left( B\right) =\left( I_{A}\in B\right) \in \mathcal{A%
}\Longleftrightarrow A\in \mathcal{A}$ perch\'{e} $I_{A}^{-1}\left( B\right) 
$ pu\`{o} essere solo $A,A^{c}$ o $\Omega $ per definizione di funzione
indicatrice.

(iii) Se $\mathbf{X}=\left( X_{1},...,X_{n}\right) $ \`{e} un vettore
aleatorio, allora $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ $\mathbf{X}^{-1}\left( B\right) \in \mathcal{A}$. Voglio
mostrare che $\forall $ $C\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $X_{1}^{-1}\left( C\right) \in \mathcal{A}$. Ma $X_{1}^{-1}\left(
C\right) =\mathbf{X}^{-1}\left( C\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\times ...\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, che appartiene a $\mathcal{A}$ per ipotesi, per cui $X_{1}$ (e
ogni altra componente) \`{e} misurabile.

Dimostro l'implicazione da destra a sinistra. $\forall $ $k=1,...,n$, $%
\forall $ $C\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $X_{k}^{-1}\left( C\right) \in \mathcal{A}$. Mostro che $\forall $ 
$B$ del tipo $(-\infty ,k_{1}]\times ...\times (-\infty ,k_{n}]$, insieme
generatore di $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $, vale $\mathbf{X}^{-1}\left( B\right) \in \mathcal{A}$. Ma $%
\mathbf{X}^{-1}\left( B\right) =\bigcap_{i=1}^{n}X_{i}^{-1}\left( (-\infty
,k_{i}]\right) $, che quindi appartiene ad $\mathcal{A}$. Allora, per il
teorema sopra, $\mathbf{X}$ \`{e} misurabile.

(v) deriva da (iv) nel caso particolare di $n=2$, con $h\left( x,y\right)
=x+y,x-y,xy,x\vee y,x\wedge y,\frac{x}{y}I_{\left( y\neq 0\right) }$.

(vi) Sappiamo che $\lim_{n\rightarrow +\infty }X_{n}\left( \omega \right)
=X\left( \omega \right) $ $\forall $ $\omega \in \Omega $: mostro che allora 
$X$ \`{e} una variabile aleatoria. Dimostro, usando (i), che $\left( X\leq
x\right) ^{c}\in \mathcal{A}$ $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. $\left( X\leq x\right) ^{c}=\left\{ \omega :X\left( \omega \right)
>x\right\} $ $=\left\{ \omega :\lim_{n\rightarrow +\infty }X_{n}\left(
\omega \right) >x\right\} =\bigcup_{r=1}^{+\infty }\left\{ \omega
:X_{n}\left( \omega \right) >x+\frac{1}{r}\text{ definitivamente per }%
n\rightarrow +\infty \right\} =\bigcup_{r=1}^{+\infty }\lim \inf_{n}\left\{
\omega :X_{n}\left( \omega \right) >x+\frac{1}{r}\right\} $ $%
=\bigcup_{r=1}^{+\infty }\bigcup_{n=1}^{+\infty }\bigcap_{k=n}^{+\infty
}\left\{ \omega :X_{n}\left( \omega \right) >x+\frac{1}{r}\right\} $, che 
\`{e} in $\mathcal{A}$ perch\'{e} ogni $X_{n}$ \`{e} misurabile. $%
\blacksquare $

\textbf{Def 6.7} Dati gli spazi $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}\right) \right) $, una funzione $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}$ misurabile si dice boreliana.

\textbf{Teo 6.8 (continua implica boreliana)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}\right) \right) ,h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}\text{ \`{e} una funzione continua} \\
\text{Ts}\text{: } &&h\text{ \`{e} boreliana}
\end{eqnarray*}

\textbf{Dim*} Mostro che $h$ \`{e} misurabile mostrando che $h^{-1}\left(
B\right) \in \mathcal{E}$ $\forall $ $B\in \mathcal{C}$, con $\mathcal{C}$
insieme degli intervalli aperti di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}$, che genera $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{m}\right) $. Infatti, se $h$ \`{e} continua, la controimmagine di ogni
aperto \`{e} aperta e appartiene quindi a $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $, cui appartengono tutti gli insiemi aperti (che si possono
scrivere a partire da intervalli aperti). $\blacksquare $

\begin{enumerate}
\item Nell'esempio in cui $X\left( \omega \right) =\omega ^{2}$, $X$ \`{e}
una variabile aleatoria perch\'{e} \`{e} continua, per 6.8.

\item $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\mathcal{\rightarrow }%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2},X\left( \omega \right) =\left( 
\begin{array}{c}
\lceil \omega \rceil \\ 
\omega ^{2}%
\end{array}%
\right) $ \`{e} un vettore aleatorio perch\'{e} ogni componente \`{e} una v.
a., per 6.6 (iii).

\item Se $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} una variabile aleatoria, $Y=X^{2}+\lceil X\rceil :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} una variabile aleatoria perch\'{e} somma di variabili aleatorie perch%
\'{e} composizione di variabili aleatorie (6.5).
\end{enumerate}

Dato $\left( \Omega ,\mathcal{A}\emph{,}\mathbf{P}\right) $ spazio di
probabilit\`{a} e $\left( E,\mathcal{E}\right) $ spazio misurabile, se $%
X:\Omega \rightarrow E$ \`{e} una variabile aleatoria, $\mathbf{P}\left(
X\in B\right) $ al variare di $B$ definisce una funzione.

\textbf{Def 7.1} $\left( \Omega ,\mathcal{A}\emph{,}\mathbf{P}\right) $
spazio di probabilit\`{a} e $\left( E,\mathcal{E}\right) $ spazio
misurabile, data $X:\Omega \rightarrow E$ variabile aleatoria, si dice legge
di $X$ la funzione $P^{X}:\mathcal{E}\rightarrow \left[ 0,1\right]
,P^{X}\left( B\right) =\mathbf{P}\left( X\in B\right) $.

La legge di $X$ dunque associa a ogni elemento $B$ della $\sigma $-algebra
dello spazio di arrivo la probabilit\`{a} che la variabile aleatoria
appartenga a quell'elemento (che \`{e} un sottinsieme di $E$), cio\`{e} la
controimmagine di $B$ attraverso $X$. $\mathbf{P}\left( X\in B\right) $ \`{e}
ben definita perch\'{e} $X$ \`{e} una variabile aleatoria, dunque $%
X^{-1}\left( B\right) \in \mathcal{A}$ per ogni $B$.

E' naturale sperare che $P^{X}$ sia una misura di probabilit\`{a} su $%
\mathcal{E}$.

\textbf{Prop 7.2 (la legge di una v.a. \`{e} una probabilit\`{a})}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A}\emph{,}\mathbf{P}\right) \text{ 
\`{e} uno spazio di probabilit\`{a}, }\left( E,\mathcal{E}\right) \text{ 
\`{e} uno spazio misurabile, } \\
X:\Omega \rightarrow E\text{ \`{e} una variabile aleatoria con legge }P^{X}:%
\mathcal{E}\rightarrow \left[ 0,1\right] \\
\text{Ts}\text{: }P^{X}\text{ \`{e} una misura di probabilit\`{a} su }\left(
E,\mathcal{E}\right)
\end{gather*}

La tesi significa che, dato uno spazio di probabilit\`{a}, una variabile
aleatoria tra tale spazio e un altro spazio misurabile induce su
quest'ultimo un misura di probabilit\`{a}, per cui lo spazio misurabile $%
\left( E,\mathcal{E}\right) $ diventa uno spazio di probabilit\`{a} $\left(
E,\mathcal{E},P^{X}\right) $: ho costruito un nuovo modello probabilistico,
che tiene conto solo degli eventi generati da $X$, cio\`{e} solo degli
elementi di $\mathcal{A}$ che si possono costruire come controimmagine
attraverso $X$. Se tale spazio \`{e} noto, si pu\`{o} quindi lavorare su
quello e ignorare lo spazio di partenza.

\textbf{Dim} Devo mostrare che $P^{X}$ soddisfa gli assiomi A1, A2. E' vero
che $P^{X}\left( E\right) =1$? $P^{X}\left( E\right) =\mathbf{P}\left( X\in
E\right) =\mathbf{P}\left( X^{-1}\left( E\right) \right) =\mathbf{P}\left(
\Omega \right) =1$ perch\'{e} $\mathbf{P}$ \`{e} una misura di probabilit%
\`{a} su $\left( \Omega ,\mathcal{A}\right) $. E' vero che, data $\left(
B_{n}\right) _{n\geq 1}$ con $B_{n}\in \mathcal{E}$ $\forall $ $n$, $%
B_{h}\cap B_{k}=\varnothing $ $\forall $ $h\neq k$, vale $P^{X}\left(
\bigcup_{n=1}^{+\infty }B_{n}\right) =\sum_{n=1}^{+\infty }P^{X}\left(
B_{n}\right) $? L'idea \`{e} sfruttare la definizione di $P^{X}$ e poi il
fatto che $\mathbf{P}$ \`{e} una misura di probabilit\`{a}. $P^{X}\left(
\bigcup_{n=1}^{+\infty }B_{n}\right) =\mathbf{P}\left( X\in
\bigcup_{n=1}^{+\infty }B_{n}\right) =\mathbf{P}\left( X^{-1}\left(
\bigcup_{n=1}^{+\infty }B_{n}\right) \right) =\mathbf{P}\left(
\bigcup_{n=1}^{+\infty }X^{-1}\left( B_{n}\right) \right) $ per le propriet%
\`{a} della controimmagine; dato che $\mathbf{P}$ \`{e} una misura di
probabilit\`{a}, essendo $\left( X^{-1}\left( B_{n}\right) \right) _{n\geq
1} $ una famiglia numerabile di elementi disgiunti (per la propriet\`{a} 4
della controimmagine, perch\'{e} i $B_{n}$ sono disgiunti) di $\mathcal{A}$, 
$\mathbf{P}\left( \bigcup_{n=1}^{+\infty }X^{-1}\left( B_{n}\right) \right)
=\sum_{n=1}^{+\infty }\mathbf{P}\left( X^{-1}\left( B_{n}\right) \right)
=\sum_{n=1}^{+\infty }P^{X}\left( B_{n}\right) $, quindi vale A2. $%
\blacksquare $

\begin{enumerate}
\item L'insieme $\left\{ \left( X\in B\right) :B\in \mathcal{E}\right\}
\subseteq \mathcal{A}$, detto insieme degli eventi generati da $X$ e
indicato con $\sigma \left( X\right) $, \`{e} una $\sigma $-algebra
sull'insieme $\Omega $. Infatti contiene $\Omega $ (si ottiene per $B=E$); 
\`{e} chiuso per complementazione, perch\'{e} dato $B\in \mathcal{E}$ e $%
X^{-1}\left( B\right) $, $\left( X^{-1}\left( B\right) \right) ^{c}$
appartiene ancora a $\left\{ \left( X\in B\right) :B\in \mathcal{E}\right\} $
perch\'{e} $\left( X^{-1}\left( B\right) \right) ^{c}=\left( X^{-1}\left(
B^{c}\right) \right) $ per la propriet\`{a} 3 della controimmagine e perch%
\'{e} $B^{c}\in \mathcal{E}$, essendo $\mathcal{E}$ una $\sigma $-algebra.
Inoltre, data $\left( B_{n}\right) _{n\geq 1}\in \mathcal{E}$ e $\left(
X^{-1}\left( B_{n}\right) \right) _{n\geq 1}$, $\bigcup_{n=1}^{+\infty
}\left( X^{-1}\left( B_{n}\right) \right) $ appartiene ancora a $\left\{
\left( X\in B\right) :B\in \mathcal{E}\right\} $ perch\'{e} $%
\bigcup_{n=1}^{+\infty }\left( X^{-1}\left( B_{n}\right) \right)
=X^{-1}\left( \bigcup_{n=1}^{+\infty }B_{n}\right) $ per la propriet\`{a} 4
della controimmagine e perch\'{e} $\bigcup_{n=1}^{+\infty }B_{n}\in \mathcal{%
E}$, essendo $\mathcal{E}$ una $\sigma $-algebra.
\end{enumerate}

Se come spazi di partenza e di arrivo si considerano $\left( \Omega ,%
\mathcal{A}\emph{,}\mathbf{P}\right) $, $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e una variabile aleatoria $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con legge $P^{X}$, $P^{X}$ \`{e} una misura di probabilit\`{a} su $%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, dunque \`{e} caratterizzata dalla sua funzione di ripartizione.

\textbf{Def 7.3} Dato $\left( \Omega ,\mathcal{A}\emph{,}\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ spazio misurabile e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con legge $P^{X}$, si dice funzione di ripartizione di 
$X$ la funzione di ripartizione di $P^{X}$ $F_{X}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,1\right] $, $F_{X}\left( t\right) =P^{X}\left( (-\infty
,t]\right) $.

Vale per definizione $F_{X}\left( t\right) =P^{X}\left( (-\infty ,t]\right) =%
\mathbf{P}\left( X\in (-\infty ,t]\right) =\mathbf{P}\left( X\leq t\right) $.

Dicendo "funzione di ripartizione di $X$" si commette un abuso di notazione
perch\'{e} in realt\`{a} la funzione di ripartizione \`{e} associata a una
probabilit\`{a}: in questo caso, a $P^{X}$. Qualora esista la densit\`{a} di
probabilit\`{a} discreta o continua associata a $P^{X}$ (indicata
rispettivamente con $p_{X}$ o $f_{X}$), conoscerla \`{e} equivalente a
conoscere la legge $P^{X}$: si intender\`{a} con legge, quindi, sia $P^{X}$
che $F^{X}$ che $p_{X}/f_{X}$ (qualora esistano).

E' dunque possibile assegnare una misura di probabilit\`{a} a $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ specificando la funzione di ripartizione $F_{X}$ di una
variabile aleatoria a valori reali.

\textbf{Def} Dato $\left( \Omega ,\mathcal{A}\emph{,}\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ spazio misurabile e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con legge $P^{X}$ e funzione di ripartizione $F_{X}$,
dato $\alpha \in \left[ 0,1\right] $, si dice quantile di $X$ di ordine $%
\alpha $, e si indica con $q_{\alpha }$, ogni numero $q_{\alpha }:\mathbf{P}%
\left( X\leq q_{\alpha }\right) \geq \alpha $ e $\mathbf{P}\left(
X<q_{\alpha }\right) \leq \alpha $. Se $\alpha =\frac{1}{2}$, $q_{\alpha }$
si dice mediana.

\begin{enumerate}
\item Lancio due dadi equi e osservo gli esiti. $\Omega =\left\{
1,...,6\right\} ^{2}$, $\mathcal{A}=2^{\Omega }$, $\mathbf{P}$ \`{e} la
probabilit\`{a} uniforme. Definisco la variabile aleatoria (si \`{e} gi\`{a}
dimostrato che lo \`{e}) $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,X\left( \omega \right) =\omega _{1}+\omega _{2}$ $\forall $ $\omega =\left(
\omega _{1},\omega _{2}\right) \in \Omega $. Qual \`{e} la legge di $X$? $%
P^{X}=\mathbf{P}\left( X\in B\right) =\mathbf{P}\left( X^{-1}\left( B\right)
\right) $. Dato che $X\left( \Omega \right) =\left\{ 2,...,12\right\}
\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} discreto, $P^{X}$ \`{e} una probabilit\`{a} discreta (vedi pi\`{u}
avanti le definizioni equivalenti) e conoscerla \`{e} equivalente a
conoscere $p_{X}$ densit\`{a} discreta, $p_{X}:T\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con $T=X\left( \Omega \right) $ e $p_{X}\left( k\right) =P^{X}\left(
\left\{ k\right\} \right) =\mathbf{P}\left( X=k\right) $: ma quest'ultima 
\`{e} nota, perch\'{e} $\mathbf{P}\left( X=k\right) =\frac{\left\vert
\left\{ \left( \omega _{1},\omega _{2}\right) :\omega _{1}+\omega
_{2}=k\right\} \right\vert }{36}$: $\left( X=k\right) $ \`{e} un elemento di 
$2^{\Omega }$, e dato che $\mathbf{P}$ \`{e} la probabilit\`{a} uniforme si
calcola come cardinalit\`{a} di $X^{-1}\left( \left\{ k\right\} \right) $
fratto $\left\vert \Omega \right\vert $. Si ricava che $p_{X}\left( k\right)
=\left\{ 
\begin{array}{c}
\frac{k-1}{36}\text{ se }k=2,...,6 \\ 
\frac{13-k}{36}\text{ se }k=7,...,12%
\end{array}%
\right. $. Dunque $P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $ \`{e} in realt\`{a} una probabilit%
\`{a} discreta con densit\`{a} discreta $p_{X}:T\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e $P^{X}\left( B\right) =\sum_{k\in B\cap T}p_{X}\left( k\right) $. In
questo caso il supporto della densit\`{a} $p_{X}$ (si pu\`{o} anche dire
supporto di $X$) \`{e} $S_{X}=T=\left\{ k\in T:p_{X}\left( k\right)
>0\right\} $. E' interessante notare che, nonostante $p$ sullo spazio di
partenza sia uniforme, la probabilit\`{a} indotta da $X$ su $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ non \`{e} uniforme; e che $p_{X}$ \`{e} individuata
univocamente dallo spazio di probabilit\`{a} $\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $ e dalla definizione di variabile aleatoria.

\item Sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ uno spazio di probabilit\`{a} con $\mathbf{P}%
=\varepsilon \left( \lambda \right) $, sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ uno spazio misurabile, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\lceil \omega \rceil $ (si \`{e} gi\`{a}
dimostrato che \`{e} una v. a.). Qual \`{e} la legge di $X$? In questo caso $%
X\left( \Omega \right) =%
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$, quindi $P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $ \`{e} una probabilit\`{a} discreta
con $p_{X}:T\rightarrow \left[ 0,1\right] $, $T=%
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$. Dato $k\in 
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$, $p_{X}\left( k\right) =P^{X}\left( \left\{ k\right\} \right) =\mathbf{P}%
\left( X=k\right) =\mathbf{P}\left( (k-1,k]\right) $ per quanto gi\`{a}
visto su $X\left( \omega \right) =\lceil \omega \rceil $. Ora ricordo che $%
\mathbf{P}\left( (k-1,k]\right) =F\left( k\right) -F\left( k-1\right)
=\int_{-\infty }^{k}f\left( t\right) dt-\int_{-\infty }^{k-1}f\left(
t\right) dt=\int_{k-1}^{k}\lambda e^{-\lambda t}I_{\left( 0,+\infty \right)
}\left( t\right) dt=\left\{ 
\begin{array}{c}
0\text{ se }k\leq 0 \\ 
e^{-\lambda \left( k-1\right) }-e^{-\lambda k}\text{ se }k\geq 1%
\end{array}%
\right. $. Dunque $p_{X}\left( k\right) =\left\{ 
\begin{array}{c}
0\text{ se }k\leq 0 \\ 
e^{-\lambda \left( k-1\right) }\left( 1-e^{-\lambda }\right) \text{ se }%
k\geq 1%
\end{array}%
\right. $. $S_{X}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\backslash \left\{ 0\right\} $: in questo caso $S_{X}\varsubsetneq T$. Noto
che si pu\`{o} scrivere $p_{X}\left( k\right) =\left( 1-p\right) ^{k-1}p$ se 
$k\geq 1$: si scrive che $P^{X}\sim geom\left( 1-e^{-\lambda }\right) $.

\item Sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ uno spazio di probabilit\`{a} con $\mathbf{P}$
qualsiasi, sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ uno spazio misurabile, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega $ (si \`{e} gi\`{a} dimostrato che \`{e}
una v. a.). Qual \`{e} la legge di $X$? In questo caso $X\left( \Omega
\right) =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, quindi non posso usare la densit\`{a} discreta per $X$. $F_{X}\left(
t\right) =P^{X}\left( (-\infty ,t]\right) =\mathbf{P}\left( X\in (-\infty
,t]\right) =\mathbf{P}\left( \omega \in (-\infty ,t]\right) =\mathbf{P}%
\left( (-\infty ,t]\right) $ perch\'{e} $X^{-1}\left( (-\infty ,t]\right)
=(-\infty ,t]$. $\mathbf{P}\left( (-\infty ,t]\right) =F\left( t\right) $:
la legge di $X$ ha come funzione di ripartizione la stessa di quella
associata a $\mathbf{P}$ sullo spazio di partenza, perch\'{e} $X$ \`{e} la
funzione identit\`{a}. In generale, prendendo come $X$ l'identit\`{a}, si
replica sullo spazio di arrivo la probabilit\`{a} dello spazio di partenza.

\item Sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ uno spazio di probabilit\`{a} con $\mathbf{P}%
=\varepsilon \left( \lambda \right) $, sia $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ uno spazio misurabile, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega ^{2}$ (si \`{e} gi\`{a} dimostrato che 
\`{e} una variabile aleatoria). Qual \`{e} la legge di $X$? In questo caso $%
X\left( \Omega \right) =[0,+\infty )$, quindi devo di nuovo usare la
funzione di ripartizione di $X$. $F_{X}\left( t\right) =P^{X}\left( (-\infty
,t]\right) =\mathbf{P}\left( X^{-1}\left( (-\infty ,t]\right) \right)
=\left\{ 
\begin{array}{c}
\mathbf{P}\left( \varnothing \right) \text{ se }t<0 \\ 
\mathbf{P}\left( \left[ -\sqrt{t},\sqrt{t}\right] \right) \text{ se }t\geq 0%
\end{array}%
\right. $. Se $t\geq 0$, $F_{X}\left( t\right) =\int_{-\sqrt{t}}^{\sqrt{t}%
}\lambda e^{-\lambda r}I_{\left( 0,+\infty \right) }dr=1-e^{-\lambda \sqrt{t}%
}$, se $t<0$ $F_{X}\left( t\right) =0$. $F_{X}$ \`{e} derivabile eccetto in $%
0$, quindi esiste una densit\`{a} continua di probabilit\`{a}: $f_{X}\left(
t\right) =\frac{\lambda }{2\sqrt{t}}e^{-\lambda \sqrt{t}}I_{\left( 0,+\infty
\right) }\left( t\right) $, che non \`{e} la densit\`{a} esponenziale. Ora
so tutto della legge di $X$: so calcolare ad esempio $P^{X}\left( \left(
a,b\right) \right) =\mathbf{P}\left( X\in \left( a,b\right) \right)
=\int_{a}^{b}f_{X}\left( t\right) dt$.

\item Se $X$ ha funzione di ripartizione $F$ strettamente monotona, allora
la variabile aleatoria $F\left( X\right) $ ha distribuzione uniforme in $%
\left( 0,1\right) $. Infatti $\mathbf{P}\left( F\left( X\right) \leq
t\right) $ vale $0$ se $t<0$, $1$ se $t>1$; se $t\in \left( 0,1\right) $ $%
\mathbf{P}\left( F\left( X\right) \leq t\right) =\mathbf{P}\left( X\leq
F^{-1}\left( t\right) \right) =F\left( F^{-1}\left( t\right) \right) =t$,
per cui $F\left( X\right) \sim \mathcal{U}\left( \left( 0,1\right) \right) $.
\end{enumerate}

\subsection{Relazione tra variabili aleatorie}

\textbf{Def} Dati $\left( \Omega ,\mathcal{A}\right) ,\left( E,\mathcal{E}%
\right) $ spazi misurabili e due variabili aleatorie $X,Y:\Omega \rightarrow
E$, si dice che $X=Y$ certamente se $\forall $ $\omega \in \Omega $ $X\left(
\omega \right) =Y\left( \omega \right) $.

Due v. a. sono uguali certamente se sono la stessa funzione: questa
definizione non aggiunge niente alla definizione gi\`{a} vista in analisi di
uguaglianza tra funzioni; non \`{e} influenzata dal fatto che $X,Y$ sono
v.a. Dal punto di vista probabilistico, significa che si effettua un unico
esperimento con due osservatori.

Per\`{o}, dato che $X,Y$ sono variabili aleatorie, a noi interessa anche la
loro legge: si introduce allora una definizione di uguaglianza pi\`{u}
debole, tra le leggi.

\textbf{Def} Dati $\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right)
,\left( \Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) $ spazi di
probabilit\`{a} e $\left( E,\mathcal{E}\right) $ spazio misurabile, date due
variabili aleatorie $X:\Omega _{1}\rightarrow E,Y:\Omega _{2}\rightarrow E$
con leggi $P^{X},P^{Y}$, si dice che $X$ e $Y$ hanno la stessa legge, e si
scrive $P^{X}=P^{Y}$ ($X\sim Y$) se $\forall $ $B\in \mathcal{E}$ $%
P^{X}\left( B\right) =P^{Y}\left( B\right) $.

(Quando si parla di leggi devo specificare le $\mathbf{P}$ nelle hp della
def!) Due v. a. possono quindi avere la stessa legge anche se definite su
spazi misurabili diversi, perch\'{e} la definizione richiede che $P^{X}:%
\mathcal{E}\rightarrow \left[ 0,1\right] ,P^{Y}:\mathcal{E\rightarrow }\left[
0,1\right] $ siano la stessa funzione: per confrontare le due leggi \`{e}
sufficiente che entrambe siano definite sulla stesse $\sigma $-algebra.

Se $X=Y$ certamente ovviamente $P^{X}=P^{Y}$: il viceversa non \`{e} vero,
com'\`{e} ovvio dal fatto che \`{e} possibile che $X,Y$ siano definite su
dominii diversi, pur avendo la stessa legge.

\begin{enumerate}
\item Lancio un dado rosso e un dado blu. $\Omega =\left\{ 1,...,6\right\}
^{2},\mathcal{A}=2^{\Omega }$, $\mathbf{P}$ \`{e} la probabilit\`{a}
uniforme, lo spazio misurabile di arrivo \`{e} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $. $X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ descrivono l'esito del lancio rispettivamente sul dado rosso e su quello
blu, cio\`{e} $X\left( \omega \right) =\omega _{1},Y\left( \omega \right)
=\omega _{2}$. $X$ e $Y$ non sono uguali certamente: se $\omega =\left(
1,2\right) $, $X\left( \omega \right) \neq Y\left( \omega \right) $.
Tuttavia, poich\'{e} $X\left( \Omega \right) =Y\left( \Omega \right)
=\left\{ 1,...,6\right\} =T$, $P^{X},P^{Y}$ sono probabilit\`{a} discrete, e
sono la stessa funzione perch\'{e} coincidono sugli atomi: $P^{X}\left(
\left\{ k\right\} \right) =p_{X}\left( k\right) =\frac{1}{6}=P^{Y}\left(
\left\{ k\right\} \right) =p_{Y}\left( k\right) $ $\forall $ $k\in T$.
Quindi $X$ e $Y$ hanno la stessa legge.
\end{enumerate}

\textbf{Def 7.4} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, $\left( E,\mathcal{E}\right) $ spazio misurabile e $%
X:\Omega \rightarrow E,Y:\Omega \rightarrow E$ variabili aleatorie, si dice
che $X$ e $Y$ sono uguali quasi certamente, e si scrive $X=Y$ q. c., se $%
\exists $ $A\in \mathcal{A}:\mathbf{P}\left( A\right) =1$ e $\forall $ $%
\omega \in A$ $X\left( \omega \right) =Y\left( \omega \right) $.

Due v. a. si dicono quindi uguali quasi certamente se, ristrette a un evento
di probabilit\`{a} $1$, sono la stessa funzione, cio\`{e} se coincidono su
un evento quasi certo: una volta assegnato $\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $, si sa quindi che alcuni eventi sono trascurabili, cio%
\`{e} hanno probabilit\`{a} nulla. La definizione dipende dalla misura di
probabilit\`{a} scelta per $\left( \Omega ,\mathcal{A}\right) $.

Se $E=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ o $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, $X-Y=Z$ \`{e} ancora una v. a. per 6.6 (v), quindi $\forall $ $B\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $Z^{-1}\left( B\right) \in \mathcal{A}$, e in particolare $%
Z^{-1}\left( \left\{ 0\right\} \right) =\left( X-Y=0\right) \in \mathcal{A}$%
. $X=Y$ q. c. $\Longleftrightarrow \mathbf{P}\left( X-Y=0\right) =1$.
Infatti se $X=Y$ q. c., $\exists $ $A\in \mathcal{A}:\mathbf{P}\left(
A\right) =1$ e $\forall $ $\omega \in A$ $X\left( \omega \right) =Y\left(
\omega \right) $: allora $A\subseteq Z^{-1}\left( \left\{ 0\right\} \right) $%
, per cui $\mathbf{P}\left( Z^{-1}\left( \left\{ 0\right\} \right) \right) =%
\mathbf{P}\left( X=Y\right) \geq \mathbf{P}\left( A\right) =1$, cio\`{e} $%
\mathbf{P}\left( X=Y\right) =1$. Se invece so che $\mathbf{P}\left(
Z^{-1}\left( \left\{ 0\right\} \right) \right) =1$, allora $X,Y$ sono uguali
q. c. con $A=Z^{-1}\left( \left\{ 0\right\} \right) $.

In generale, per capire se due v. a. sono uguali quasi certamente \`{e}
sufficiente calcolare la probabilit\`{a} del pi\`{u} grande sottinsieme di $%
\Omega $ su cui esse coincidono: \`{e} $1$ se e solo se sono uguali quasi
certamente.

La relazione di uguaglianza quasi certa gode della propriet\`{a} riflessiva
e simmetrica. Inoltre, date tre v. a. $X,Y,Z:\Omega \rightarrow E$, se $X$ e 
$Y$ sono uguali quasi certamente $\exists $ $A\in \mathcal{A}:\mathbf{P}%
\left( A\right) =1$ e $\forall $ $\omega \in A$ $X\left( \omega \right)
=Y\left( \omega \right) $; se $Y$ e $Z$ sono uguali quasi certamente $%
\exists $ $B\in \mathcal{A}:\mathbf{P}\left( B\right) =1$ e $\forall $ $%
\omega \in B$ $Y\left( \omega \right) =Z\left( \omega \right) $. Allora $%
\mathbf{P}\left( A\cap B\right) =\mathbf{P}\left( A\right) \mathbf{+P}\left(
B\right) \mathbf{-P}\left( A\cup B\right) =2-\mathbf{P}\left( A\cup B\right) 
$; poich\'{e} $\mathbf{P}\left( A\cup B\right) \geq \mathbf{P}\left(
A\right) $, $\mathbf{P}\left( A\cup B\right) =1$, dunque $\mathbf{P}\left(
A\cap B\right) =1$. Allora $\mathbf{P}\left( A\cap B\right) =1$ e $X\left(
\omega \right) =Z\left( \omega \right) $ $\forall $ $\omega \in \left( A\cap
B\right) $, cio\`{e} anche $X$ e $Z$ sono uguali quasi certamente:
l'uguaglianza quasi certa gode della propriet\`{a} transitiva.

\begin{enumerate}
\item Considero i due spazi $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\varepsilon \left( \lambda \right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $. Considero $X_{1},X_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X_{1}\left( \omega \right) =\omega $, $X_{2}\left( \omega \right)
=\left\vert \omega \right\vert $, $X_{3}\left( \omega \right) =\omega I_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
}\left( \omega \right) =\left\{ 
\begin{array}{c}
\omega \text{ se }\omega \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\\ 
0\text{ se }\omega \in 
%TCIMACRO{\U{211a}}%
%BeginExpansion
\mathbb{Q}%
%EndExpansion
\end{array}%
\right. $. $X_{1}\neq X_{2}$ $\forall $ $\omega \in \left( -\infty ,0\right) 
$. Tuttavia, $X_{1}=X_{2}$ q. c., perch\'{e} $X_{1}\left( \omega \right)
=X_{2}\left( \omega \right) $ $\forall $ $\omega \in \lbrack 0,+\infty )$, e
se $A=[0,+\infty )$, $\mathbf{P}\left( A\right) =1-F\left( 0\right)
=\int_{0}^{+\infty }\lambda e^{\lambda t}dt=1$. Anche se $X_{1}$ e $X_{2}$
come funzioni non coincidono, la probabilit\`{a} assegnata allo spazio
misurabile fa s\`{\i} che coincidano su un evento quasi certo.

Analogamente, $X_{1}\neq X_{3}$ $\forall $ $\omega \in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\backslash \left\{ 0\right\} $. Tuttavia, $X_{1}=X_{3}$ q. c., perch\'{e} $%
X_{1}\left( \omega \right) =X_{2}\left( \omega \right) $ $\forall $ $\omega
\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$, e se $A=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$, $\mathbf{P}\left( A\right) =\mathbf{P}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) -\mathbf{P}\left( 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right) =1-\mathbf{P}\left( 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right) =1-\sum_{q\in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
}\mathbf{P}\left( \left\{ q\right\} \right) =1$ per la $\sigma $-additivit%
\`{a}, essendo $%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$ discreto, e perch\'{e} la probabilit\`{a} di qualsiasi singoletto \`{e}
nulla per probabilit\`{a} che ammettano una densit\`{a} continua. Anche se $%
X_{1}$ e $X_{3}$ come funzioni non coincidono, la probabilit\`{a} assegnata
allo spazio misurabile fa s\`{\i} che coincidano su un evento quasi certo.

\item Considero i due spazi $\left( \left( 0,1\right) ,\mathcal{B}\left(
\left( 0,1\right) \right) ,\mathcal{U}\left( [0,1)\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $, e $X,Y:\left( 0,1\right) \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,X\left( \omega \right) =\omega ,Y\left( \omega \right) =1-\omega $. $%
P^{X}\left( B\right) =\mathbf{P}\left( X\in B\right) $, $P^{Y}\left(
B\right) =\mathbf{P}\left( Y\in B\right) $. Usando la f. d. r. delle
variabili aleatorie, $F_{X}\left( t\right) =P^{X}\left( (-\infty ,t]\right) =%
\mathbf{P}\left( X^{-1}(-\infty ,t]\right) =\left\{ 
\begin{array}{c}
0\text{ se }t\leq 0 \\ 
\mathbf{P}\left( (0,t]\right) =t\text{ se }t\in \left( 0,1\right) \\ 
\mathbf{P}\left( \left( 0,1\right) \right) =1\text{ se }t\geq 1%
\end{array}%
\right. =F\left( t\right) $ (anche $P^{X}$ \`{e} uniforme). Invece $%
F_{Y}\left( t\right) =P^{Y}\left( (-\infty ,t]\right) =\mathbf{P}\left(
Y^{-1}(-\infty ,t]\right) =\left\{ 
\begin{array}{c}
0\text{ se }t\leq 0 \\ 
\mathbf{P}\left( [1-t,1)\right) =t\text{ se }t\in \left( 0,1\right) \\ 
\mathbf{P}\left( \left( 0,1\right) \right) =1\text{ se }t\geq 1%
\end{array}%
\right. $. Quindi $F_{Y}\left( t\right) =F_{X}\left( t\right) $ $\forall $ $%
t $ e $P^{X}\left( B\right) =P^{Y}\left( B\right) $ $\forall $ $B$, ma $%
\mathbf{P}\left( X=Y\right) =\mathbf{P}\left( \left\{ \frac{1}{2}\right\}
\right) =0$ perch\'{e} ogni singoletto \`{e} un evento di probabilit\`{a}
nulla se la probabilit\`{a} \`{e} continua. Quindi $X$ e $Y$ non sono uguali
q. c., pur avendo la stessa legge.
\end{enumerate}

\textbf{Prop 7.5 (uguaglianza certa, quasi certa, in legge)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }\left( E,\mathcal{E}\right) \text{ \`{e} uno
spazio } \\
\text{misurabile, }X,Y:\Omega \rightarrow E\text{ sono due variabili
aleatorie} \\
\text{Ts: (i) }X=Y\Longrightarrow \text{(ii) }X=Y\text{ q. c. }%
\Longrightarrow \text{(iii) }P^{X}=P^{Y}
\end{gather*}

Il fatto che (ii)$\nRightarrow $(i) \`{e} mostrato dall'esempio 1 sopra con $%
X_{1},X_{2}$ o $X_{1},X_{3}$. Il fatto che (iii)$\nRightarrow $(ii) \`{e}
mostrato dall'esempio 2 sopra con $X_{1},X_{2}$. La proposizione mostra che
l'uguaglianza quasi certa \`{e} una relazione di "forza intermedia" tra
l'uguaglianza certa e l'uguaglianza tra le leggi.

\textbf{Dim} (i)$\Longrightarrow $(ii) Se $X=Y$, significa che $X\left(
\omega \right) =Y\left( \omega \right) $ $\forall $ $\omega \in \Omega $. Se
si prende $A=\Omega $, \`{e} evidente che $\exists $ $A\in \mathcal{A}:%
\mathbf{P}\left( A\right) =1$, perch\'{e} $\mathbf{P}\left( \Omega \right)
=1 $.

(ii)$\Longrightarrow $(iii) Se $X=Y$ q. c., significa che $\exists $ $A\in 
\mathcal{A}:\mathbf{P}\left( A\right) =1$ e $X\left( \omega \right) =Y\left(
\omega \right) $ $\forall $ $\omega \in A$. Dato $B\in \mathcal{E}$, $%
P^{X}\left( B\right) =\mathbf{P}\left( X^{-1}\left( B\right) \right) $, $%
P^{Y}\left( B\right) =\mathbf{P}\left( Y^{-1}\left( B\right) \right) $. $%
\mathbf{P}\left( X\in B\right) =$*$\mathbf{P}\left( \left( X\in B\right)
\cap A\right) =\mathbf{P}\left( \left( Y\in B\right) \cap A\right) =\mathbf{P%
}\left( Y\in B\right) $. La penultima uguaglianza \`{e} dovuta al fatto che $%
\left( X^{.-1}\left( B\right) )\cap A\right) =\left\{ \omega \in \Omega
:\omega \in A\wedge X\left( \omega \right) \in B\right\} $: ogni elemento di
questo insieme \`{e} anche in $Y^{.-1}\left( B\right) )\cap A$, perch\'{e} $%
X\left( \omega \right) =Y\left( \omega \right) $ $\forall $ $\omega \in A$,
e viceversa, dunque $Y^{.-1}\left( B\right) \cap A=X^{.-1}\left( B\right)
\cap A$.

[*In generale infatti, se $\mathbf{P}\left( A\right) =1$, $C=\left( C\cap
A\right) \cup \left( C\cap A^{c}\right) $, unione finita di eventi
disgiunti: $\mathbf{P}\left( C\right) =\mathbf{P}\left( C\cap A\right) +%
\mathbf{P(}C\cap A^{c})=\mathbf{P}\left( C\cap A\right) $ perch\'{e} $%
\mathbf{P(}C\cap A^{c})\leq \mathbf{P(}A^{c})=1-\mathbf{P}\left( A\right) =0$%
] $\blacksquare $

\textbf{Def} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, si dice che una propriet\`{a} $P\left( \omega \right) $ che
dipende da $\omega \in \Omega $ vale quasi certamente se $\exists $ $%
A\subseteq \mathcal{A}:\mathbf{P}\left( A\right) =1$ e $P\left( \omega
\right) $ vale $\forall $ $\omega \in \Omega $.

Alternativamente, si dice che $P\left( \omega \right) $ vale quasi
certamente se $\mathbf{P}\left( \left\{ \omega :-P\left( \omega \right)
\right\} \right) =0$.

Se si considera il pi\`{u} grande sottinsieme di $\Omega $, che chiamo $%
A_{\max }$, in cui vale la propriet\`{a} $p$ e si trova che $\mathbf{P}%
\left( A_{\max }\right) =0$, allora si pu\`{o} concludere che $p$ non vale
quasi certamente, per monotonia della probabilit\`{a}: su ogni $A\subseteq
A_{\max }$, in cui varr\`{a} $p$, sar\`{a} ancora $\mathbf{P}\left( A\right)
=0$. Se invece si trova $\mathbf{P}\left( A_{\max }\right) =1$, \`{e}
possibile che esistano $A\subset A_{\max }:\mathbf{P}\left( A\right) =1$.

\begin{enumerate}
\item Considero i due spazi $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathcal{U}\left( 0,1\right) \right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e la variabile aleatoria $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\omega $. $X\left( \Omega \right) =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Dimostro che tuttavia $X\in \left[ 0,1\right] $ quasi certamente, cio\`{e}
che $\exists $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) :\mathbf{P}\left( A\right) =1$ e $X\left( \omega \right) \in \left[
0,1\right] $ $\forall $ $\omega \in A$. Se considero $A=\left( 0,1\right) $, 
\`{e} ovvio che $X\left( \omega \right) \in \left[ 0,1\right] $ $\forall $ $%
\omega \in A$, ma soprattutto $\mathbf{P}\left( A\right) =\int_{0}^{1}1dt=1$%
. Infatti $\mathbf{P}\left( X\in \left[ 0,1\right] \right) =\mathbf{P}\left(
\omega \in \left[ 0,1\right] \right) =1$: nonostante l'immagine di $X$ sia $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, i valori che $X$ assume sono governati da $\mathbf{P}$ perch\'{e} questa
determina la probabilit\`{a} dei sottinsiemi di $\Omega $, cio\`{e} degli
input della $X$.
\end{enumerate}

\subsection{Integrazione rispetto a una misura di probabilit\`{a}}

Considero $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria reale. E' naturale voler dire qualcosa sui valori di $%
X $ prima di effettuare l'esperimento, e. g. voler trovare "il centro" di $X$%
, che rispetti l'idea di valore "centrale" rispetto ai possibili valori di $%
X\left( \omega \right) $ al variare di $\omega \in \Omega $.

Tale valore centrale, di cui si dar\`{a} una definizione rigorosa nel
seguito, si indica in vari modi: $\mathbf{E}\left( X\right) $, $\mu $, $%
\int_{\Omega }X\left( \omega \right) d\mathbf{P}\left( \omega \right) $, $%
\int_{\Omega }X\left( \omega \right) \mathbf{P}\left( d\omega \right) $, $%
\int_{\Omega }Xd\mathbf{P}$. Si costruisce ora un oggetto matematico che
rispetti l'intuizione modellistica di $\mathbf{E}\left( X\right) $.

PASSO 1

\textbf{Def 8.1} Dato $\left( \Omega ,\mathcal{A}\right) $ spazio
probabilizzabile e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria reale, $X$ si dice semplice se assume un numero finito
di valori, cio\`{e} se $\left\vert \func{Im}\left( X\right) \right\vert
=n<+\infty $.

Questo \`{e} equivalente a dire che si pu\`{o} scrivere, data $\left\{
A_{1},A_{2},...,A_{n}\right\} $ partizione finita di $\Omega $ e $%
x_{1},...,x_{n}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\sum_{k=1}^{n}x_{k}I_{A_{k}}\left( \omega
\right) =x_{1}I_{A_{1}}\left( \omega \right) +...+x_{n}I_{A_{n}}\left(
\omega \right) $. Se $\omega \in A_{1}$, $X\left( \omega \right) =x_{1}$,
eccetera. $X^{-1}\left( \left\{ x_{k}\right\} \right) =\left( X=x_{k}\right)
=A_{k}$, $X\left( \Omega \right) =\left\{ x_{1},...,x_{n}\right\} $.

Nelle ipotesi della definizione non occorre specificare la probabilit\`{a}
dello spazio.

\textbf{Def 8.2} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria reale semplice, si dice valore atteso di $X$, e si
indica con $\mathbf{E}\left( X\right) $, $\sum_{k=1}^{n}x_{k}\mathbf{P}%
\left( X=x_{k}\right) $.

La definizione \`{e} ben posta perch\'{e} $\left( X=x_{k}\right) \in 
\mathcal{A}$, essendo $X$ una v.a. $\sum_{k=1}^{n}x_{k}\mathbf{P}\left(
X=x_{k}\right) $ \`{e} proprio come calcolare l'integrale di Riemann di una
funzione a scala (in quel caso si considera una successione di funzioni a
scala), ma nell'integrale di Riemann si calcola $\sum_{k=1}^{n}f\left(
I_{k}\right) \mu \left( I_{k}\right) $ dove $\mu \left( I_{k}\right)
=x_{k+1}-x_{k}$.

Il valore atteso di una v. a. r. semplice \`{e} quindi una media dei valori
che essa assume, \textit{pesata sulle probabilit\`{a} dei valori}: dati i
valori $x_{1},...,x_{n}$ sull'asse reale, $\mathbf{E}\left( X\right) $
individua il centro di tale distribuzione in base alla misura di probabilit%
\`{a} dello spazio. $\mathbf{E}\left( X\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$; \`{e} possibile che $\mathbf{E}\left( X\right) \not\in \func{Im}\left(
X\right) $.

\begin{enumerate}
\item Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e $A\in \mathcal{A}$, $X\left( \omega \right) =I_{A}\left(
\omega \right) $ \`{e} una v. a. semplice tale che $\mathbf{E}\left(
X\right) =\mathbf{P}\left( A\right) $.
\end{enumerate}

\textbf{Prop (propriet\`{a} del valore atteso di v. a. semplici)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\text{variabili aleatorie reali semplici, }\alpha ,\beta \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (i) }\alpha X+\beta Y\text{ \`{e} una v. a. reale semplice } \\
\text{(ii) (linearit\`{a}) }\mathbf{E}\left( \alpha X+\beta Y\right) =\alpha 
\mathbf{E}\left( X\right) +\beta \mathbf{E}\left( Y\right) \\
\text{(iii) (monotonia) se }X\left( \omega \right) \leq Y\left( \omega
\right) \text{ }\forall \text{ }\omega \in \Omega \text{, }\mathbf{E}\left(
X\right) \leq \mathbf{E}\left( Y\right)
\end{gather*}

\begin{enumerate}
\item Se $Y:\Omega \rightarrow \left[ 0,+\infty \right] $ \`{e} una
variabile aleatoria semplice e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =0\leq Y\left( \omega \right) $, allora $X$ \`{e}
una v. a. r. semplice con $\mathbf{E}\left( X\right) =0$, per cui $\mathbf{E}%
\left( Y\right) \geq 0$.
\end{enumerate}

PASSO 2

\textbf{Prop (approssimazione di una funzione)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A}\right) \text{ spazio misurabile, }%
X:\Omega \rightarrow \lbrack 0,+\infty ]\text{ v. a. reale} \\
\text{Ts: }\exists \text{ }\left( X_{n}\right) _{n\geq 1}:\text{(1) }%
X_{n}:\Omega \rightarrow \lbrack 0,+\infty )\text{ \`{e} semplice }\forall 
\text{ }n\geq 1\text{,} \\
\text{(2) }\forall \text{ }\omega \in \Omega \text{ }\lim_{n\rightarrow
+\infty }X_{n}\left( \omega \right) =X\left( \omega \right) \text{ e }\left(
X_{n}\right) _{n\geq 1}\text{ \`{e} monotona non decrescente}
\end{gather*}

$X:\Omega \rightarrow \lbrack 0,+\infty ]$ ha come $\sigma $-algebra sullo
spazio di arrivo quella generata dagli aperti contenuti in $[0,+\infty ]$. $%
\left( X_{n}\right) $ monotona non decrescente significa che $X_{n}\left(
\omega \right) \leq X_{n+1}\left( \omega \right) $ $\forall $ $n$, $\forall $
$\omega $: (2) afferma quindi che $\left( X_{n}\right) _{n\geq 1}$ converge
puntualmente a $X$ (pi\`{u} avanti questa verr\`{a} chiamata convergenza
certa) in maniera monotona: si scrive $X_{n}\nearrow X$.

Il senso della proposizione \`{e} che qualsiasi variabile aleatoria reale
non negativa pu\`{o} essere scritta come limite di una successione di
variabili aleatorie reali semplici. Come costruisco tale successione? Una
possibilit\`{a} \`{e}%
\begin{equation*}
\text{fissato }n\geq 1\text{, al variare di }k=0,...,n2^{n}-1\text{, }%
X_{n}\left( \omega \right) =\left\{ 
\begin{array}{c}
\frac{k}{2^{n}}\text{ se }X\left( \omega \right) \in \lbrack \frac{k}{2^{n}},%
\frac{k+1}{2^{n}}) \\ 
n\text{ se }X\left( \omega \right) \geq n%
\end{array}%
\right.
\end{equation*}

Quindi, fissato $n$, $X_{n}\left( \omega \right) =\left\{ 
\begin{array}{c}
0\text{ se }X\left( \omega \right) \in \lbrack 0,\frac{1}{2^{n}}) \\ 
\frac{1}{2^{n}}\text{ se }X\left( \omega \right) \in \lbrack \frac{1}{2^{n}},%
\frac{1}{2^{n-1}}) \\ 
\frac{1}{2^{n-1}}\text{ se }X\left( \omega \right) \in \lbrack \frac{1}{%
2^{n-1}},\frac{3}{2^{n}}) \\ 
... \\ 
\frac{n2^{n}-1}{2^{n}}\text{ se }X\left( \omega \right) \in \lbrack \frac{%
n2^{n}-1}{2^{n}},n) \\ 
n\text{ se }X\left( \omega \right) \geq n%
\end{array}%
\right. $ \`{e} un'approssimazione per difetto di $X$: quando $X$ assume
valori in $\left[ a,b\right] $, $X_{n}$ assume valore $a$. Al crescere di $n$%
, $X_{n}$ approssima $X$ sempre pi\`{u} finemente, perch\'{e} la partizione
dell'asse $y$ \`{e} pi\`{u} fitta. Chiaramente $X_{n}$ \`{e} una v. a.
semplice: $\func{Im}\left( X_{n}\right) =\left\{ 0,\frac{1}{2^{n}}%
,...,n\right\} $, con cardinalit\`{a} $n2^{n}+1$; per definizione $\mathbf{E}%
\left( X_{n}\right) =\sum_{k=0}^{n2^{n}-1}\frac{k}{2^{n}}\mathbf{P}\left(
X\in \lbrack \frac{k}{2^{n}},\frac{k+1}{2^{n}})\right) +n\mathbf{P}\left(
X\geq n\right) $. La definizione data fornisce di fatto una definizione di $%
X_{n}$ su tutto $\Omega $, ma ottenuta partizionando il codominio di $X$ (cio%
\`{e} $\left[ 0,+\infty \right] $), dato che $X^{-1}\left( X\left( \Omega
\right) \right) =\Omega $. Questa \`{e} l'idea alla base dell'integrale di
Lebesgue.

\begin{enumerate}
\item Se $n=1$, $k=0$ o $k=1$, quindi si avranno tre tratti: $X_{1}\left(
\omega \right) =\left\{ 
\begin{array}{c}
0\text{ se }X\left( \omega \right) \in \lbrack 0,\frac{1}{2}) \\ 
\frac{1}{2}\text{ se }X\left( \omega \right) \in \lbrack \frac{1}{2},1) \\ 
1\text{ se }X\left( \omega \right) \geq 1%
\end{array}%
\right. $
\end{enumerate}

Si dimostra che $X_{n+1}\left( \omega \right) \geq X_{n}\left( \omega
\right) $ $\forall $ $\omega \in \Omega ,\forall $ $n$, quindi $\mathbf{E}%
\left( X_{n+1}\right) \geq \mathbf{E}\left( X_{n}\right) \geq 0$ per
monotonia del valore atteso: allora $\left( \mathbf{E}\left( X_{n}\right)
\right) _{n\geq 1}$ \`{e} una successione a valori reali non negativi
monotona non decrescente, che pu\`{o} tendere a $L\geq 0$ o $+\infty $ per $%
n\rightarrow +\infty $.

\textbf{Def 8.3 }Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $X:\Omega \rightarrow \left[ 0,+\infty \right] $
variabile aleatoria reale non negativa, si dice valore atteso di $X$, e si
indica con $\mathbf{E}\left( X\right) $, $\lim_{n\rightarrow +\infty }%
\mathbf{E}\left( X_{n}\right) $.

Il valore atteso pu\`{o} essere $+\infty $. Per come sono stati costruite le 
$X_{n}$, vale anche $\mathbf{E}\left( X\right) =\lim_{n\rightarrow +\infty
}\left( \sum_{k=0}^{n2^{n}-1}\frac{k}{2^{n}}\mathbf{P}\left( X\in \left[ 
\frac{k}{2^{n}},\frac{k+1}{2^{n}}\right] \right) +n\mathbf{P}\left( X\geq
n\right) \right) $. In realt\`{a} la definizione di valore atteso non
dipende dalla scelta di $\left( X_{n}\right) _{n\geq 1}$, purch\'{e} sia una
successione di v. a. semplici che cresce a $X$.

Se $X$ \`{e} una v.a.r. semplice non negativa, la 8.3 e la 8.2 sono coerenti.

Se $\mathbf{P}\left( X=+\infty \right) >0$, $\mathbf{E}\left( X\right)
=+\infty $. Infatti $\mathbf{E}\left( X\right) \geq \lim_{n\rightarrow
+\infty }n\mathbf{P}\left( X\geq n\right) $, ma $X^{-1}\left( [n,+\infty
)\right) \supseteq \left( X=+\infty \right) =\bigcap_{n=1}^{+\infty }\left(
X\geq n\right) $, quindi $\mathbf{P}\left( X\geq n\right) \geq \mathbf{P}%
\left( X=+\infty \right) $ e $\lim_{n\rightarrow +\infty }n\mathbf{P}\left(
X\geq n\right) \geq \lim_{n\rightarrow +\infty }n\mathbf{P}\left( X=+\infty
\right) =+\infty $,quindi $\mathbf{E}\left( X\right) =+\infty $.

PASSO 3

\textbf{Def 8.4 }Data $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, si definisce parte positiva di $X$, e si indica con $X_{+}$, la funzione $%
X_{+}:\Omega \rightarrow \lbrack 0,+\infty ),X_{+}\left( \omega \right)
=\max \left\{ X\left( \omega \right) ,0\right\} =X\left( \omega \right) \vee
0$; si definisce parte negativa di $X$, e si indica con $X_{-}$, la funzione 
$X_{-}:\Omega \rightarrow \lbrack 0,+\infty ),X_{-}\left( \omega \right)
=-\min \left\{ X\left( \omega \right) ,0\right\} =-X\left( \omega \right)
\wedge 0$.

Vale quindi $X\left( \omega \right) =X_{+}\left( \omega \right) -X_{-}\left(
\omega \right) $, mentre $\left\vert X\left( \omega \right) \right\vert
=X_{+}\left( \omega \right) +X_{-}\left( \omega \right) $. Questa
definizione permette di generalizzare ulteriormente la definizione di valore
atteso: infatti $X_{+},X_{-}$ sono v.a.r. non negative (infatti si possono
scrivere come prodotto di $X$ per $I_{A}$ dove $A=\left\{ \omega \in \Omega
:X\left( \omega \right) >0\right\} $ e $A=\left\{ \omega \in \Omega :X\left(
\omega \right) <0\right\} $ rispettivamente, e $A\in \mathcal{A}$ perch\'{e} 
$A=\left( X\in \left( 0,+\infty \right) \right) $ e $X$ \`{e} una variabile
aleatoria, quindi $X_{+}$ \`{e} il prodotto di due variabili aleatorie), e
per definire $\mathbf{E}\left( X\right) $ ci si pu\`{o} ricondurre alla
definizione precedente.

\textbf{Def 8.5 }Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con parte positiva $X_{+}$ e parte negativa $X_{-}$,
si dice che $X$ ammette valore atteso se almeno uno tra $\mathbf{E}\left(
X_{+}\right) $ e $\mathbf{E}\left( X_{-}\right) $ \`{e} finito. In tal caso
si dice valore atteso di $X$, e si indica con $\mathbf{E}\left( X\right) $, $%
\mathbf{E}\left( X_{+}\right) -\mathbf{E}\left( X_{-}\right) $. Se $\mathbf{E%
}\left( X_{+}\right) =\mathbf{E}\left( X_{-}\right) =+\infty $, si dice che $%
X$ non ammette valore atteso.

Il valore atteso cos\`{\i} definito appartiene a $\left[ -\infty ,+\infty %
\right] =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{\ast }$. Se $X$ \`{e} una v.a.r. semplice non negativa, la 8.5, 8.3 e 8.2
sono coerenti. Se $X$ \`{e} una v.a.r. non negativa, la 8.3 e 8.5 sono
coerenti perch\'{e} $X_{-}\left( \omega \right) =0$.

\textbf{Def 8.6 }Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con parte positiva $X_{+}$ e parte negativa $X_{-}$,
si dice che $X$ \`{e} integrabile, o che ammette valore atteso finito, se $%
\mathbf{E}\left( X_{+}\right) $ e $\mathbf{E}\left( X_{-}\right) $ sono
finiti.

In tal caso il valore atteso di $X$ \`{e} $\mathbf{E}\left( X\right) =%
\mathbf{E}\left( X_{+}\right) -\mathbf{E}\left( X_{-}\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

\textbf{Def 8.7} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, si indica con $\mathcal{L}^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $ lo spazio delle variabili aleatorie reali integrabili,
cio\`{e} $\mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
=\left\{ X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ variabili aleatorie}:X\text{ ammette valore atteso finito}\right\} $.

Il vantaggio dell'astrazione nella definizione di $\mathbf{E}\left( X\right) 
$ \`{e} che \`{e} possibile ricavare facilmente propriet\`{a} generali del
valore atteso, senza ipotesi su $\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $.

\textbf{Teo 8.8 (propriet\`{a} del valore atteso)}

Sia $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ uno spazio di probabilit%
\`{a}. 
\begin{gather*}
\text{1) }\mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
\`{e} uno spazio vettoriale} \\
\text{2) Hp: }\mathbf{E}:\mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }X,Y\in \mathcal{L}^{1},\alpha ,\beta \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (i) (linearit\`{a}) }\mathbf{E}\left( \alpha X+\beta Y\right)
=\alpha \mathbf{E}\left( X\right) +\beta \mathbf{E}\left( Y\right) \\
\text{(ii) (positivit\`{a}) se }X\geq 0\text{, }\mathbf{E}\left( X\right)
\geq 0
\end{gather*}

1) significa che se $X,Y\in \mathcal{L}^{1}$ e $\alpha ,\beta \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $\alpha X+\beta Y\in \mathcal{L}^{1}$, cio\`{e} se $\mathbf{E}\left(
X\right) ,\mathbf{E}\left( Y\right) $ sono finiti, allora anche $\mathbf{E}%
\left( \alpha X+\beta Y\right) $ \`{e} finito (proprio come l'insieme delle
funzioni Riemann integrabili \`{e} uno spazio vettoriale). Questo fa s\`{\i}
che l'uguaglianza $\mathbf{E}\left( \alpha X+\beta Y\right) =\alpha \mathbf{E%
}\left( X\right) +\beta \mathbf{E}\left( Y\right) $ in 2) (i) sia ben posta:
si pu\`{o} effettivamente calcolare $\mathbf{E}\left( \alpha X+\beta
Y\right) $; in 2) (i) sono coinvolti solo numeri reali, e la propriet\`{a} 
\`{e} analoga alla linearit\`{a} dell'integrale di Riemann. 2) (i),(ii) si
sono dimostrate sopra per v.a. semplici.

\begin{gather*}
\text{3) Hp: }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ sono v. a., }Y\in \mathcal{L}^{1}\text{, }Y\geq X\geq 0 \\
\text{Ts: }X\in \mathcal{L}^{1}\text{, (monotonia) }\mathbf{E}\left(
Y\right) \geq \mathbf{E}\left( X\right) \\
\text{4) Hp: }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v. a., }X\geq 0\text{, }\mathbf{E}\left( X\right) =0 \\
\text{Ts: }X=0\text{ quasi certamente} \\
\text{5) Hp: }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ sono v. a. che ammettono valore atteso, }X=Y\text{ q. c.} \\
\text{Ts: }\mathbf{E}\left( X\right) =\mathbf{E}\left( Y\right)
\end{gather*}

3) implica che una v. a. non negativa e limitata \`{e}
integrabile, quindi per funzioni limitate nonnegative integrabilit\`{a} e
misurabilit\`{a} sono equivalenti; con 7) si rimuover\`{a} l'ipotesi di
positivit\`{a}.

(4) non vale se si rimuove l'ipotesi $X\geq 0$: il "centro" pu\`{o} essere
in $0$ anche se $X$ assume sia valori positivi che negativi con probabilit%
\`{a} non nulla.

5) significa che, essendo $\mathbf{P}\left( X=Y\right) =1$, $X,Y$ hanno lo
stesso valore atteso, eventualmente infinito, perch\'{e} differiscono su un
insieme di probabilit\`{a} nulla, per cui l'integrale "non lo vede". (5)
implica anche che vale l'implicazione opposta in (4). Facendo la regola del
valore atteso questa propriet\`{a} sar\`{a} ulteriormente generalizzata.

\textbf{Dim*} (4) Per la disuguaglianza di Markov $\mathbf{P}\left(
\left\vert X\right\vert \geq a\right) \leq 0$ $\forall $ $a>0$: essendo $%
X\geq 0$, $\mathbf{P}\left( X\geq a\right) =0$ $\forall $ $a>0$. La
successione di eventi $\left( X\geq \frac{1}{n}\right) =X^{-1}\left( [\frac{1%
}{n},+\infty )\right) $ cresce a $X^{-1}\left( \left( 0,+\infty \right)
\right) $, per cui, per continuit\`{a} della probabilit\`{a} $\mathbf{P}%
\left( X>0\right) =\lim_{n\rightarrow +\infty }\mathbf{P}\left( X\geq \frac{1%
}{n}\right) =0$, cio\`{e} $X=0$ q. c., essendo $X\geq 0$. $\blacksquare $

\begin{gather*}
\text{6) Hp: }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ sono v. a., }X,Y\geq 0,\alpha ,\beta \geq 0 \\
\text{Ts: }\mathbf{E}\left( \alpha X+\beta Y\right) =\alpha \mathbf{E}\left(
X\right) +\beta \mathbf{E}\left( Y\right) \\
\text{7) }X\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\Longleftrightarrow \left\vert X\right\vert \in \mathcal{L}^{1}\left( \Omega
,\mathcal{A},\mathbf{P}\right) \text{, e in tal caso} \\
\left\vert \mathbf{E}\left( X\right) \right\vert \leq \mathbf{E}\left(
\left\vert X\right\vert \right)
\end{gather*}

6) \`{e} la 2), ma per l'altra categoria di v. a. per quali sappiamo che
esiste il valore atteso; \`{e} possibile che qualche valore atteso sia $%
+\infty $. Si chiede $X,Y\geq 0,\alpha ,\beta \geq 0$ per evitare di avere a
che fare con forme di indeterminazione, di modo che $\mathbf{E}\left( \alpha
X+\beta Y\right) $ sotto tali ipotesi pu\`{o} essere solo non negativo\ o $%
+\infty $. Comunque tutti i valori attesi certamente esistono perch\'{e} $%
X,Y $ sono non negative.

7) evidenzia la differenza tra l'integrale con cui \`{e} stato definito il
valore atteso e l'integrale di Riemann: se $f$ \`{e} Riemann integrabile, $%
\left\vert f\right\vert $ \`{e} Riemann integrabile, ma non vale il
viceversa. Vale una disuguaglianza analoga a $\left\vert \mathbf{E}\left(
X\right) \right\vert \leq \mathbf{E}\left( \left\vert X\right\vert \right) $
per l'integrale di Riemann. $\left\vert X\right\vert $ \`{e} una variabile
aleatoria perch\'{e} composizione della funzione continua e quindi
misurabile $\left\vert x\right\vert $ con $X$.

\textbf{Dim*} 7) Se $X\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P%
}\right) $, per definizione $\mathbf{E}\left( X_{+}\right) ,\mathbf{E}\left(
X_{-}\right) <+\infty $: allora $\mathbf{E}\left( \left\vert X\right\vert
\right) =\mathbf{E}\left( X_{+}+X_{-}\right) =\mathbf{E}\left( X_{+}\right) +%
\mathbf{E}\left( X_{-}\right) <+\infty $. Se invece $\left\vert X\right\vert
\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $\mathbf{E%
}\left( X_{+}\right) +\mathbf{E}\left( X_{-}\right) <+\infty $, ma dato che $%
\mathbf{E}\left( X_{+}\right) ,\mathbf{E}\left( X_{-}\right) $ sono entrambi
positivi non \`{e} possibile che almeno uno dei due sia infinito, cio\`{e} $%
\mathbf{E}\left( X_{+}\right) ,\mathbf{E}\left( X_{-}\right) <+\infty $.
Allora $X$ \`{e} integrabile.

$\left\vert \mathbf{E}\left( X\right) \right\vert =\left\vert \mathbf{E}%
\left( X_{+}\right) -\mathbf{E}\left( X_{-}\right) \right\vert \leq
\left\vert \mathbf{E}\left( X_{+}\right) \right\vert +\left\vert \mathbf{E}%
\left( X_{-}\right) \right\vert =\mathbf{E}\left( X_{+}\right) +\mathbf{E}%
\left( X_{-}\right) =\mathbf{E}\left( \left\vert X\right\vert \right) $ per
definizione, linearit\`{a}, disuguaglianza triangolare e positivit\`{a} del
valore atteso. $\blacksquare $

Si enunciano due teoremi che permettono di scambiare limite e valore atteso
per successioni di v. a. r. nonnegative e integrabili, rispettivamente.

\textbf{Teorema di Beppo Levi (convergenza monotona) 8.8 (8)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ \`{e} una successione
di v.a.r., } \\
X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v. a. tale che (}X\geq \text{)}X_{n}\geq 0\text{ q. c. }%
\forall \text{ }n\text{ e }X_{n}\nearrow X\text{ q. c.} \\
\text{Ts: }\mathbf{E}\left( X\right) =\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( X_{n}\right)
\end{gather*}

$X_{n}\leq X$ superfluo. $X_{n}\nearrow X$ significa che $X_{n}$ converge
puntualmente in modo monotono ($X_{n}\leq X_{n+1}$ $\forall $ $n$, $\forall $
$\omega $) a $X$ quasi certamente, cio\`{e} che $\exists $ $A\in \mathcal{A}:%
\mathbf{P}\left( A\right) =1$ e $\lim_{n\rightarrow +\infty }X_{n}\left(
\omega \right) =X\left( \omega \right) $ $\forall $ $\omega \in A$ in modo
monotono. Questo insieme di $\omega $ appartiene a $\mathcal{A}$ perch\'{e} $%
\lim_{n\rightarrow +\infty }X_{n}=:Y$ \`{e} una variabile aleatoria, per cui 
$\lim_{n\rightarrow +\infty }X_{n}\left( \omega \right) =X\left( \omega
\right) \Longleftrightarrow Y-X=0$.

Il teorema afferma che per una successione di v.a.r. non negative che cresca
a $X$ \`{e} possibile scambiare limite e integrale.

\textbf{Teorema di convergenza dominata 8.8 (9)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ \`{e} una successione di
v.a.r., }Y\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \\
\forall \text{ }n\geq 1\text{ vale }\left\vert X_{n}\right\vert \leq Y\text{
q. c. e }X_{n}\rightarrow X\text{ q. c.} \\
\text{Ts: }X_{n}\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) \text{ }\forall \text{ }n\geq 1\text{, }X\in \mathcal{L}^{1}\text{, }%
\mathbf{E}\left( X\right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left(
X_{n}\right)
\end{gather*}

Le ipotesi implicano $Y\geq 0$. Una v. a. certamente limitata \`{e} quindi
in $\mathcal{L}^{1}$, perch\'{e} se $\exists $ $c:\left\vert X\left( \omega
\right) \right\vert \leq c$ $\forall $ $\omega \in \Omega $, $Y\left( \omega
\right) =c$ \`{e} integrabile (prendendo $X_{n}=X$ $\forall $ $n$), allora $%
\left\vert X\right\vert \in \mathcal{L}^{1}$ e $X\in \mathcal{L}^{1}$.

\textbf{Corollario 9.1 (ulteriori propriet\`{a} del valore atteso})%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v.a.} \\
\text{Ts: (i) se }\exists \text{ }c\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:X=c\text{ q. c., }X\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) \text{ e }\mathbf{E}\left( X\right) =c \\
\text{(ii) se }\mathbf{E}\left( X\right) >0\text{, }\mathbf{P}\left(
X>0\right) >0 \\
\text{(iii) }\mathbf{E}\left( \left\vert X\right\vert \right) =\mathbf{E}%
\left( X_{+}\right) +\mathbf{E}\left( X_{-}\right) \\
\text{(iv) se }X\in \left[ a,b\right] \text{ q. c. con }a,b\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }X\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) 
\text{ e }\mathbf{E}\left( X\right) \in \left[ a,b\right]
\end{gather*}

(iv) implica che $X$ limitata \`{e} integrabile (in generale in ogni $L^{p}$)

Non
vale il viceversa n\'{e} per (i) n\'{e} per (ii) n\'{e} per (iv). (iv)
rafforza l'intuizione di $\mathbf{E}\left( X\right) $ come "centro" dei
valori assunti da $X$: se $X\in \left[ a,b\right] $ q. c., \`{e} ragionevole
che anche il centro vi appartenga.

\textbf{Dim} (i) Se $X=c$ q. c., allora $\left\vert X\right\vert =\left\vert
c\right\vert $ q. c. (posso prendere lo stesso $A$). Allora, essendo $%
\left\vert X\right\vert $ e $\left\vert c\right\vert $ v. a. nonnegative, il
loro valore atteso esiste, e per 8.8 (5) vale $\mathbf{E}\left( \left\vert
X\right\vert \right) =\mathbf{E}\left( \left\vert c\right\vert \right) $. Ma 
$\left\vert c\right\vert $ \`{e} una variabile aleatoria semplice, quindi $%
\mathbf{E}\left( \left\vert c\right\vert \right) =\left\vert c\right\vert
\cdot \mathbf{P}\left( \Omega \right) =\left\vert c\right\vert $: allora $%
\mathbf{E}\left( \left\vert X\right\vert \right) <+\infty $, cio\`{e} $%
\left\vert X\right\vert \in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $, quindi per 8.8 (7) anche $X\in \mathcal{L}^{1}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $. Ora che so che esiste $\mathbf{E}%
\left( X\right) $, posso applicare 8.8 (5) a $X,c$, per cui $\mathbf{E}%
\left( X\right) =c\cdot 1=c$.

(ii) Per definizione $\mathbf{E}\left( X\right) =\mathbf{E}\left(
X_{+}\right) \mathbf{-E}\left( X_{-}\right) >0$: allora $\mathbf{E}\left(
X_{+}\right) >\mathbf{E}\left( X_{-}\right) \geq 0$, dunque $\mathbf{E}%
\left( X_{+}\right) >0$ e $\mathbf{P}\left( X_{+}>0\right) >0$ (se per
assurdo fosse $\mathbf{P}\left( X_{+}>0\right) =0$, si avrebbe $\mathbf{P}%
\left( X_{+}=0\right) =1$ perch\'{e} $X_{+}$ \`{e} non negativa, ma questo
significa che $X_{+}=0$ q. c., perci\`{o} si avrebbe $\mathbf{E}\left(
X_{+}\right) =0$, che \`{e} assurdo), quindi $\mathbf{P}\left( X>0\right) >0$
perch\'{e} $X^{-1}\left( 0,+\infty \right) =X_{+}^{-1}\left( 0,+\infty
\right) $.

(iii) E' noto che $\left\vert X\right\vert =X_{+}+X_{-}$. Essendo entrambe
v. a. r. nonnegative, per la linearit\`{a} in 8.8 (6) si ha $\mathbf{E}%
\left( \left\vert X\right\vert \right) =\mathbf{E}\left( X_{+}\right) +%
\mathbf{E}\left( X_{-}\right) $.

(iv) Poich\'{e} $X\in \left[ a,b\right] $ q. c., si ha che $\left\vert
X\right\vert \leq \max \left\{ \left\vert a\right\vert ,\left\vert
b\right\vert \right\} $. Pongo $c=\max \left\{ \left\vert a\right\vert
,\left\vert b\right\vert \right\} $: per monotonia (8.8 (3)) si ha che $%
\left\vert X\right\vert \in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $ e $\mathbf{E}\left( \left\vert X\right\vert \right) \leq 
\mathbf{E}\left( \max \left\{ \left\vert a\right\vert ,\left\vert
b\right\vert \right\} \right) =\max \left\{ \left\vert a\right\vert
,\left\vert b\right\vert \right\} $. Allora per 8.8 (7) $X\in \mathcal{L}%
^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e per 8.8 (3) applicato
al fatto che $X-a\geq 0$, $b-X\geq 0$, si ha che $\mathbf{E}\left(
X-a\right) \geq 0,\mathbf{E}\left( b-X\right) \geq 0$, cio\`{e}, per linearit%
\`{a} (8.8 (1)), si ha che $\mathbf{E}\left( X\right) \in \left[ a,b\right] $%
. $\blacksquare $

La definizione di valore atteso ha una gran quantit\`{a} di applicazioni.

\textbf{Teo (A1: valore atteso in spazi discreti)}%
\begin{gather*}
\text{Hp: }\Omega \text{ discreto, }\left( \Omega ,2^{\Omega },\mathbf{P}%
\right) \text{ \`{e} uno spazio di probabilit\`{a}, }\mathbf{P}\text{ ha
densit\`{a} } \\
p:\Omega \rightarrow \left[ 0,1\right] \text{, }X:\Omega \rightarrow \left[
0,+\infty \right] \text{ \`{e} una v.a. o }X\in \mathcal{L}^{1}\left( \Omega
,2^{\Omega },\mathbf{P}\right) \\
\text{Ts: }\mathbf{E}\left( X\right) =\sum_{\omega \in \Omega }X\left(
\omega \right) p\left( \omega \right)
\end{gather*}

Nelle ipotesi figurano le due tipologie di variabili aleatorie per le quali
sappiamo per certo che esiste il valore atteso: quelle non negative e quelle
integrabili. La somma nella tesi \`{e} effettivamente una somma se $\Omega $ 
\`{e} finito, \`{e} una serie se $\Omega $ \`{e} infinito numerabile. La
tesi fornisce uno strumento per calcolare agevolmente il valore atteso.

\textbf{Dim} Considero il caso di $\Omega $ finito, $X:\Omega \rightarrow %
\left[ 0,+\infty \right] $. Allora $\left\vert \func{Im}X\right\vert =n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\func{Im}X=\left\{ x_{1},...,x_{n}\right\} $, e $X$ \`{e} semplice,
quindi si pu\`{o} scrivere $X\left( \omega \right)
=\sum_{k=1}^{n}x_{k}I_{A_{k}}\left( \omega \right) =\left\{ 
\begin{array}{c}
x_{1}\text{ se }\omega \in A_{1} \\ 
... \\ 
x_{n}\text{ se }\omega \in A_{n}%
\end{array}%
\right. $, con $\left\{ A_{1},...,A_{n}\right\} $ partizione discreta di $%
\Omega $. $A_{k}=X^{-1}\left( \left\{ x_{k}\right\} \right) =\left(
X=x_{k}\right) $. Allora so scrivere $\mathbf{E}\left( X\right)
=\sum_{k=1}^{n}x_{k}\mathbf{P}\left( A_{k}\right) $: poich\'{e} $\Omega $ 
\`{e} discreto e anche $A_{k}$ \`{e} discreto, $A_{k}$ pu\`{o} essere
scritto come unione al pi\`{u} numerabile di singoletti, per cui $\mathbf{E}%
\left( X\right) =\sum_{k=1}^{n}x_{k}\mathbf{P}\left( A_{k}\right) =$ $%
\sum_{k=1}^{n}x_{k}\sum_{\omega \in A_{k}}p\left( \omega \right)
=\sum_{k=1}^{n}\sum_{\omega \in A_{k}}x_{k}p\left( \omega \right)
=\sum_{k=1}^{n}\sum_{\omega \in A_{k}}X\left( \omega \right) p\left( \omega
\right) =\sum_{\omega \in \bigcup_{k=1}^{n}A_{k}}X\left( \omega \right)
p\left( \omega \right) =\sum_{\omega \in \Omega }X\left( \omega \right)
p\left( \omega \right) $. Il riordinamento non altera la somma perch\'{e} le
serie sono a termini positivi. Il caso di $X\in \mathcal{L}^{1}$ si tratta
analogamente.

Considero ora $\Omega $ infinito numerabile: numero $\Omega $ scrivendo $%
\Omega =\left\{ \omega _{n}:n\geq 1\right\} $. Devo in qualche modo
ricondurmi al caso precedente: allora introduco $\forall $ $n\geq 1$ $%
X_{n}\left( \omega \right) =X\left( \omega \right) I_{\left\{ \omega
_{1},...,\omega _{n}\right\} }\left( \omega \right) =\left\{ 
\begin{array}{c}
X\left( \omega _{1}\right) \text{ se }\omega =\omega _{1} \\ 
... \\ 
X\left( \omega _{n}\right) \text{ se }\omega =\omega _{n} \\ 
0\text{ se }\omega \not\in \left\{ \omega _{1},...,\omega _{n}\right\}%
\end{array}%
\right. $: $X_{n}$ \`{e} una variabile aleatoria semplice, quindi per il
punto precedente $\mathbf{E}\left( X_{n}\right) =\sum_{\omega \in \left\{
\omega _{1},...,\omega _{n}\right\} }X\left( \omega \right) p\left( \omega
\right) =\sum_{k=1}^{n}X\left( \omega _{k}\right) p\left( \omega _{k}\right) 
$. Inoltre $X_{n}\geq 0$ $\forall $ $n$ perch\'{e} $X$ \`{e} nonnegativa per
ipotesi e $X\geq X_{n+1}\geq X_{n}\geq 0$ $\forall $ $n$, $\forall $ $\omega 
$: quindi $X_{n}\nearrow X$ e si pu\`{o} applicare il teorema di convergenza
monotona, per cui $\mathbf{E}\left( X\right) =\lim_{n\rightarrow +\infty }%
\mathbf{E}\left( X_{n}\right) =\lim_{n\rightarrow +\infty
}\sum_{k=1}^{n}X\left( \omega _{k}\right) p\left( \omega _{k}\right) $, che 
\`{e} per definizione $\sum_{n=1}^{+\infty }X\left( \omega _{n}\right)
p\left( \omega _{n}\right) =\sum_{\omega \in \Omega }X\left( \omega \right)
p\left( \omega \right) $. Se $X\in \mathcal{L}^{1}$ la dimostrazione \`{e}
analoga, ma termina con il teorema di convergenza dominata. $\blacksquare $

\begin{enumerate}
\item Considero lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
,2^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
},\mathbf{P}\right) $ con $\mathbf{P}$ caratterizzata dalla densit\`{a} di
Poisson $p\left( k\right) =e^{-\lambda }\frac{\lambda ^{k}}{k!}$ $\forall $ $%
k\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, con $\lambda >1$. Considero la v. a. $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( k\right) =k!$. $\mathbf{P}\left( X=+\infty \right) =0=1-\mathbf{P%
}\left( X\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\right) $. $X$ \`{e} non negativa e $\mathbf{P}$ \`{e} una densit\`{a}
discreta: per il teorema sopra, $\mathbf{E}\left( X\right) =\sum_{\omega \in
\Omega }X\left( \omega \right) p\left( \omega \right) =\sum_{k=0}^{+\infty
}X\left( k\right) p\left( k\right) =\sum_{k=0}^{+\infty }e^{-\lambda
}\lambda ^{k}=+\infty $: la serie diverge perch\'{e} $\lambda >1$, quindi $%
\mathbf{E}\left( X\right) =+\infty $ nonostante $X$ sia q. c. finita. Non 
\`{e} quindi vero che se $\mathbf{P}\left( X=+\infty \right) =0$, allora, se 
$\mathbf{E}\left( X\right) $ esiste, $\mathbf{E}\left( X\right) <+\infty $.
Si \`{e} gi\`{a} dimostrato che invece vale il viceversa.
\end{enumerate}

La seconda applicazione (A2) \`{e} la seguente. Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ spazio di probabilit\`{a} con $\mathbf{P}$
discreta, avente densit\`{a} $p$ e supporto $\mathcal{S}\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, se $X:\Omega \rightarrow \left[ 0,+\infty \right] $ o $X\in \mathcal{L}%
^{1}$, allora $\mathbf{E}\left( X\right) =\sum_{\omega \in S}X\left( \omega
\right) p\left( \omega \right) $. $\mathbf{P}$ discreta rende quindi
equivalente lavorare su $\Omega $ continuo o discreto.

Questo implica che se ci si trova in uno dei due casi precedenti (A1 o A2),
poich\'{e} $X\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\Longleftrightarrow \left\vert X\right\vert \in \mathcal{L}^{1}\left( \Omega
,\mathcal{A},\mathbf{P}\right) $, $\mathbf{E}\left( X\right) $ esiste finito 
$\Longleftrightarrow \mathbf{E}\left( \left\vert X\right\vert \right)
=\sum_{\omega \in \Omega /S}\left\vert X\left( \omega \right) \right\vert
p\left( \omega \right) $ \`{e} finito.

\textbf{Def 9.3} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, dato $A\in \mathcal{A}$, si definisce valore atteso di $%
X $ ristretta ad $A$, e si indica con $\int_{A}Xd\mathbf{P}$ o $\int_{\Omega
}XI_{A}d\mathbf{P}$, il valore atteso di $XI_{A}$ $\mathbf{E}\left(
XI_{A}\right) $, qualora esso esista.

Esiste certamente se $XI_{A}$ \`{e} una v. a. non negativa (sappiamo che 
\`{e} una v.a. per 6.6 (5)), oppure se $XI_{A}\in \mathcal{L}^{1}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $.

Si noti che, essendo $I_{A}$ una v. a. semplice, $\mathbf{E}\left(
I_{A}\right) =\mathbf{P}\left( A\right) =\int_{A}1d\mathbf{P}$:
l'integrazione della v. a. costante $1$ rispetto a una misura di probabilit%
\`{a} restituisce la misura dell'insieme su cui si integra, cio\`{e} $%
\mathbf{P}\left( A\right) $.

\textbf{Teo 9.4 (linearit\`{a} del valore atteso rispetto a somme infinite)}%
\begin{gather*}
\text{(1) Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ \`{e} una }
\\
\text{successione di v.a. tali che }X_{n}:\Omega \rightarrow \left[
0,+\infty \right] \text{ }\forall \text{ }n\geq 1 \\
\text{Ts: }\mathbf{E}\left( \sum_{n=1}^{+\infty }X_{n}\right)
=\sum_{n=1}^{+\infty }\mathbf{E}\left( X_{n}\right)
\end{gather*}%
\begin{gather*}
\text{(2) Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ \`{e} una
successione } \\
\text{di v.a. tali che }X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ }\forall \text{ }n\geq 1\text{, }\sum_{n=1}^{+\infty }\mathbf{E}%
\left( \left\vert X_{n}\right\vert \right) <+\infty \\
\text{Ts: }\sum_{n=1}^{+\infty }X_{n}\left( \omega \right) <+\infty \text{
q. c., }\sum_{n=1}^{+\infty }X_{n}\left( \omega \right) \in \tciLaplace
^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ e }\mathbf{E}\left(
\sum_{n=1}^{+\infty }X_{n}\right) =\sum_{n=1}^{+\infty }\mathbf{E}\left(
X_{n}\right)
\end{gather*}

Acquisir\`{a} senso quando faremo la media campionaria.

\textbf{Dim} Dimostro 1. L'idea \`{e} applicare la convergenza monotona alla
successione delle somme parziali dei valori assoluti. Chiamo $%
T_{n}=\sum_{k=1}^{n}\left\vert X_{k}\right\vert $. Se $T=\sum_{k=1}^{+\infty
}\left\vert X_{k}\right\vert $, allora $T_{n}\nearrow T$, per definizione di 
$\sum_{k=1}^{+\infty }$ e perch\'{e} la serie \`{e} a termini positivi ($%
T_{n+1}=\sum_{k=1}^{n+1}\left\vert X_{k}\right\vert \geq T_{n}\geq 0$ $%
\forall $ $n$). Allora, per il teorema di convergenza monotona e per linearit%
\`{a}, $\mathbf{E}\left( T\right) =\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( T_{n}\right) =\sum_{n=1}^{+\infty }\mathbf{E}\left( \left\vert
X_{n}\right\vert \right) $: il lato destro \`{e} ben definito, quindi $T$
ammette valore atteso, ma essendo $X_{n}\geq 0$ $\forall $ $n$ vale $%
T=\sum_{k=1}^{+\infty }X_{k}$, per cui $\mathbf{E}\left( \sum_{k=1}^{+\infty
}X_{k}\right) =\sum_{k=1}^{+\infty }\mathbf{E}\left( X_{k}\right) $. Cos%
\`{\i} si \`{e} dimostrata (1).

Dimostro 2. Applicando (1), $\mathbf{E}\left( \sum_{n=1}^{+\infty
}\left\vert X_{n}\right\vert \right) =\sum_{n=1}^{+\infty }\mathbf{E}\left(
\left\vert X_{n}\right\vert \right) <+\infty $, quindi $\sum_{n=1}^{+\infty
}\left\vert X_{n}\right\vert <+\infty $ q. c. (si \`{e} dimostrato definendo
il valore atteso che se $\mathbf{P}\left( X=+\infty \right) >0$, allora $%
\mathbf{E}\left( X\right) =+\infty $). Per il criterio della convergenza
assoluta anche $\sum_{n=1}^{+\infty }X_{n}<+\infty $ q. c. Cos\`{\i} si \`{e}
dimostrata (2).1. Chiamo $S_{n}=\sum_{k=1}^{n}X_{k}$ la successione delle
somme parziali delle $X_{k}$.

Per le osservazioni sopra, vale $\forall $ $n$ $0\leq \left\vert
S_{n}\right\vert \leq T_{n}\leq T$. Poich\'{e} per ipotesi $T\in \tciLaplace
^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $S_{n}\rightarrow
S=\sum_{k=1}^{+\infty }X_{k}$, allora, per convergenza dominata, $S_{n},S\in
\tciLaplace ^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ ((2).2) e $%
\mathbf{E}\left( S\right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left(
\sum_{k=1}^{n}X_{k}\right) =\lim_{n\rightarrow +\infty }\sum_{k=1}^{n}%
\mathbf{E}\left( X_{k}\right) =\sum_{k=1}^{+\infty }\mathbf{E}\left(
X_{k}\right) $ ((2).3). Uso la linearit\`{a} di $\mathbf{E}$ perch\'{e} le $%
X_{k}$ sono integrabili per convergenza dominata.

[Ripetendo le stesse osservazioni sopra con le ipotesi di (2), si ha che $%
\mathbf{E}\left( T\right) =\sum_{n=1}^{+\infty }\mathbf{E}\left( \left\vert
X_{n}\right\vert \right) <+\infty $, per cui $T=\sum_{k=1}^{+\infty
}\left\vert X_{k}\right\vert $ \`{e} integrabile. Ma $0\leq \left\vert
\sum_{k=1}^{+\infty }X_{k}\right\vert \leq \sum_{k=1}^{+\infty }\left\vert
X_{k}\right\vert $, quindi per monotonia (8.8 (3)) anche $\left\vert
\sum_{k=1}^{+\infty }X_{k}\right\vert \in \tciLaplace ^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $ e di conseguenza $\sum_{k=1}^{+\infty
}X_{k}\in \tciLaplace ^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $. ] $%
\blacksquare $

\textbf{Teo 9.5 (disuguaglianza di Markov)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v.a.} \\
\text{Ts: }\forall \text{ }a>0\text{ }\mathbf{P}\left( \left\vert
X\right\vert \geq a\right) \leq \frac{\mathbf{E}\left( \left\vert
X\right\vert \right) }{a}
\end{gather*}

La tesi illustra il significato del valore atteso come centro dei valori
assunti da $X$. $\mathbf{E}\left( \left\vert X\right\vert \right) $ si pu%
\`{o} calcolare perch\'{e} $\left\vert X\right\vert $ \`{e} non negativa. La
tesi afferma che una v. a. integrabile prende la "maggior parte dei suoi
valori" in un insieme compatto. Se $a\leq \mathbf{E}\left( \left\vert
X\right\vert \right) $, la disuguaglianza \`{e} inutile, perch\'{e} potrebbe
essere $\left\vert X\right\vert =\mathbf{E}\left( \left\vert X\right\vert
\right) $ q. c., nel qual caso $\mathbf{P}\left( \left\vert X\right\vert
\geq a\right) $ sarebbe $1$.

\textbf{Dim} Se $X\not\in \tciLaplace ^{1}$, allora $\left\vert X\right\vert
\not\in \tciLaplace ^{1}$ e $\mathbf{E}\left( \left\vert X\right\vert
\right) =+\infty $. In tal caso $\mathbf{P}\left( \left\vert X\right\vert
\geq a\right) \leq 1\leq +\infty $, quindi vale la disuguaglianza. Suppongo
ora $X\in \tciLaplace ^{1}$, quindi $\left\vert X\right\vert \in \tciLaplace
^{1}$. L'idea \`{e} scrivere il lato sinistro della disuguaglianza come
valore atteso di qualche v. a. e sfruttare la monotonia. Noto che $\omega
\in \left( \left\vert X\right\vert \geq a\right) \Longleftrightarrow
I_{\left( \left\vert X\right\vert \geq a\right) }\left( \omega \right) =1$,
e vale la disuguaglianza $I_{\left( \left\vert X\right\vert \geq a\right)
}\left( \omega \right) \leq \frac{\left\vert X\left( \omega \right)
\right\vert }{a}I_{\left( \left\vert X\right\vert \geq a\right) }\left(
\omega \right) $ (si ha $0\leq 0$, o $1\leq \frac{\left\vert X\left( \omega
\right) \right\vert }{a}$ quando $\left\vert X\left( \omega \right)
\right\vert \geq a$). Essendo $\left( \left\vert X\right\vert \geq a\right)
\in \mathcal{A}$ perch\'{e} $\left\vert X\right\vert $ \`{e} una v. a., si
ha che entrambi i lati della disuguaglianza sono v. a. Vorrei dire che il
lato destro \`{e} una v. a. in $\tciLaplace ^{1}$ per poter usare la
monotonia: ma $\frac{\left\vert X\left( \omega \right) \right\vert }{a}%
I_{\left( \left\vert X\right\vert \geq a\right) }\left( \omega \right) \leq 
\frac{\left\vert X\left( \omega \right) \right\vert }{a}I_{\Omega }\left(
\omega \right) =\frac{\left\vert X\left( \omega \right) \right\vert }{a}$,
che \`{e} una v. a. non negativa in $\tciLaplace ^{1}$, quindi $\frac{%
\left\vert X\left( \omega \right) \right\vert }{a}I_{\left( \left\vert
X\right\vert \geq a\right) }\left( \omega \right) \in \tciLaplace ^{1}$ e
per 8.8 (3) vale $\mathbf{E}\left( I_{\left( \left\vert X\right\vert \geq
a\right) }\left( \omega \right) \right) \leq \mathbf{E}\left( \frac{%
\left\vert X\left( \omega \right) \right\vert }{a}\right) =\frac{1}{a}%
\mathbf{E}\left( \left\vert X\left( \omega \right) \right\vert \right) $. Ma 
$\mathbf{E}\left( I_{\left( \left\vert X\right\vert \geq a\right) }\left(
\omega \right) \right) =1\cdot \mathbf{P}\left( \left\vert X\right\vert \geq
a\right) $ per la definizione di valore atteso per le v. a. semplici, quindi
si ha la tesi. $\blacksquare $

(Assolutamente inutile: $\mathbf{E}\left( I_{\left( \left\vert X\right\vert
\geq a\right) }\left( \omega \right) \right) =\mathbf{P}\left( \left\vert
X\right\vert \geq a\right) $ si vede con la definizione di valore atteso per
v. a. non negative. Fissato $n$, $X_{1}\left( \omega \right) =\left\{ 
\begin{array}{c}
0\text{ se }I_{\left( \left\vert X\right\vert \geq a\right) }\left( \omega
\right) =0 \\ 
\frac{1}{2}\text{ se }I_{\left( \left\vert X\right\vert \geq a\right)
}\left( \omega \right) =1%
\end{array}%
\right. =\left\{ 
\begin{array}{c}
0\text{ se }\left\vert X\left( \omega \right) \right\vert <a \\ 
\frac{1}{2}\text{ se }\left\vert X\left( \omega \right) \right\vert \geq a%
\end{array}%
\right. $,...., $X_{n}\left( \omega \right) =\left\{ 
\begin{array}{c}
0\text{ se }I_{\left( \left\vert X\right\vert \geq a\right) }\left( \omega
\right) =0 \\ 
\frac{2^{n}-1}{2^{n}}\text{ se }I_{\left( \left\vert X\right\vert \geq
a\right) }\left( \omega \right) =1%
\end{array}%
\right. $ (perch\'{e}, per come sono descritti gli intervallini, quello in
cui \`{e} previsto che la funzione assuma valore $1$ \`{e} quello con $%
k=2^{n}-1$). $\mathbf{E}\left( X_{n}\right) =0\cdot \mathbf{P}\left(
\left\vert X\right\vert <a\right) +\frac{2^{n}-1}{2^{n}}\mathbf{P}\left(
\left\vert X\right\vert \geq a\right) =\left( 1-\frac{1}{2^{n}}\right) 
\mathbf{P}\left( \left\vert X\right\vert \geq a\right) $. Quindi $\mathbf{E}%
\left( I_{\left( \left\vert X\right\vert \geq a\right) }\left( \omega
\right) \right) =\lim_{n\rightarrow +\infty }\left( 1-\frac{1}{2^{n}}\right) 
\mathbf{P}\left( \left\vert X\right\vert \geq a\right) =\mathbf{P}\left(
\left\vert X\right\vert \geq a\right) $. )

\subsubsection{Spazi $L^{p}$ e varianza}

Si \`{e} gi\`{a} dimostrato che la relazione di uguaglianza quasi certa tra
due v. a. \`{e} una relazione di equivalenza: si pu\`{o} scrivere in tal
caso $X\mathfrak{R}Y$. Se si considerano $X,Y\in \mathcal{L}^{1}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $, tale relazione di equivalenza
induce una partizione di $\mathcal{L}^{1}$ in classi di equivalenza; la
classe di equivalenza di $X\in \mathcal{L}^{1}$ si indica con $\left[ X%
\right] $: $\left[ X\right] =\left\{ Y\in \mathcal{L}^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) :Y=X\text{ q. c.}\right\} $. Se $X=Y$ q. c., $%
P^{X}=P^{Y}$ e $\mathbf{E}\left( X\right) =\mathbf{E}\left( Y\right) $,
quindi il valore atteso e la legge sono gli stessi per ogni v. a. nella
stessa classe di equivalenza.

E' quindi ben definito l'insieme quoziente di $\mathcal{L}^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $ rispetto alla relazione $\mathcal{R}$,
indicato con $\mathcal{L}^{1}/\mathcal{R}$: \`{e} l'insieme delle classi di
equivalenza $\left[ X\right] $ indotte da $\mathcal{R}$ in $\mathcal{L}%
^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, al variare di $X\in 
\mathcal{L}^{1}$, e si indica con $L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $.

$L^{1}$ \`{e} uno spazio vettoriale su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con la somma $\left[ X_{1}\right] +\left[ X_{2}\right] =\left[ X_{1}+X_{2}%
\right] $: $+:L^{1}\times L^{1}\rightarrow L^{1}$ \`{e} la funzione che,
date due classi di equivalenza $\left[ X\right] ,\left[ Y\right] $, prende
un qualsiasi $X_{1}\in \left[ X\right] $, un qualsiasi $Y_{1}\in \left[ Y%
\right] $ e associa a esse la classe di equivalenza cui appartiene $%
X_{1}+Y_{1}$ (che appartiene a $L^{1}$ per linearit\`{a} del valore atteso).
Questa non dipende dalla scelta di $X_{1}$ e $Y_{1}$ perch\'{e} se $%
X_{1}=X_{2}$ q. c. (su $A$) e $Y_{1}=Y_{2}$ q. c. (su $B$), $\alpha
X_{1}+\beta Y_{1}=\alpha X_{2}+\beta Y_{2}$ q. c. (su $A\cap B$: $\mathbf{P}%
\left( A\cap B\right) =\mathbf{P}\left( A\right) \mathbf{+P}\left( B\right) 
\mathbf{-P}\left( A\cup B\right) =2-\mathbf{P}\left( A\cup B\right) =1$).
L'elemento neutro \`{e} $\left[ 0\right] $. $\alpha \left[ X_{1}\right] =%
\left[ \alpha X_{1}\right] $.

Noi, commettendo un abuso di notazione, scriveremo $L^{1}$ invece di $%
\mathcal{L}^{1}$ e $X\in L^{1}$, invece che $\left[ X\right] \in L^{1}$.

\textbf{Def 9.6} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $p\in \lbrack 1,+\infty )$, si indica con $\mathcal{L}%
^{p}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ lo spazio delle variabili
aleatorie reali con $p$-esima potenza assoluta sommabile, cio\`{e} $\mathcal{%
L}^{p}\left( \Omega ,\mathcal{A},\mathbf{P}\right) =\left\{ \text{variabili
aleatorie }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:\left\vert X\right\vert ^{p}\text{ ammette valore atteso finito}\right\} $.

Il valore assoluto serve a far s\`{\i} che $\left\vert X\right\vert ^{p}$
sia ben definito $\forall $ $p\geq 1$. In tal caso $\mathbf{E}\left(
\left\vert X\right\vert ^{p}\right) <+\infty $ \`{e} detto momento assoluto $%
p$-esimo associato a $X$ (vedi es). Se $X\in \mathcal{L}^{p}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $, allora $\mathbf{E}\left( \left\vert
X\right\vert ^{p}\right) <+\infty $, cio\`{e} $\left\vert X\right\vert
^{p}\in \mathcal{L}^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $. In
generale, l'insieme delle v. a. semplici \`{e} denso nell'insieme $L^{p}$.

\textbf{Def 9.7} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} e $\mathcal{L}^{p}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $, si indica con $L^{p}$ l'insieme delle classi di equivalenza $%
\left[ X\right] $ indotte da $\mathcal{R}$ in $\mathcal{L}^{p}\left( \Omega
,2^{\Omega },\mathbf{P}\right) $, al variare di $X\in \mathcal{L}^{p}$.

Se $X=c$ q. c., allora $X\in L^{p}$ $\forall $ $p\in \lbrack 1,+\infty )$ e $%
\mathbf{E}\left( \left\vert X\right\vert ^{p}\right) =\left\vert
c\right\vert ^{p}$ (si estende banalmente 9.1 (8)).

Si vedr\`{a} che $\forall $ $p$ $L^{p}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $ \`{e} uno spazio vettoriale (nel seguito si dimostra che $L^{2}$
lo \`{e}), che diventa normato con la norma $\left( \mathbf{E}\left(
\left\vert X\right\vert ^{p}\right) \right) ^{\frac{1}{p}}$ e anche
completo, dunque di Banach. La norma induce quindi la metrica $d\left(
X,Y\right) =\left( \mathbf{E}\left( \left\vert X-Y\right\vert ^{p}\right)
\right) ^{\frac{1}{p}}$; $L^{1}$ con tale distanza \`{e} uno spazio metrico
completo.

Se $p=2$ si pu\`{o} definire il prodotto scalare $\left\langle
\_,\_\right\rangle :L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \times
L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\left\langle X,Y\right\rangle =\mathbf{E}\left( XY\right) =\int_{\Omega }XYd%
\mathbf{P}$, in analogia a $\left\langle f,g\right\rangle
=\int_{a}^{b}f\left( x\right) g\left( x\right) dx$ (ma stavolta si integra
rispetto a una misura). E' ben definito perch\'{e}, come si vedr\`{a} ora,
il prodotto di v. a. in $L^{2}$ \`{e} in $L^{1}$. Effettivamente \`{e}
positivo, bilineare e commutativo per le propriet\`{a} del valore atteso, e $%
\left\langle X,X\right\rangle =0\Longleftrightarrow \mathbf{E}\left(
X^{2}\right) =0\Longleftrightarrow \left[ X\right] =\left[ 0\right] $.
Allora tale prodotto scalare induce la norma $\sqrt{\mathbf{E}\left(
\left\vert X\right\vert ^{2}\right) }$, e $L^{2}$ \`{e} completo rispetto a
tale norma: questo rende $L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $%
, l'unico tra tutti gli $L^{p}$, uno spazio di Hilbert oltre che di Banach.

\textbf{Teo 9.8 (propriet\`{a} degli spazi }$L^{p}$)%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}} \\
\text{Ts: (1) se }1\leq p<q\text{, }L^{q}\subseteq L^{p}\subseteq L^{1} \\
\text{(2) }L^{2}\text{ \`{e} uno spazio vettoriale } \\
\text{(3) (disuguaglianza di Cauchy-Schwarz) se }X,Y\in L^{2}\text{, } \\
XY\in L^{1}\text{ e }\left\vert \mathbf{E}\left( XY\right) \right\vert \leq 
\sqrt{\mathbf{E}\left( X^{2}\right) \mathbf{E}\left( Y^{2}\right) }
\end{gather*}

(1) vale sostanzialmente perch\'{e} $\mathbf{P}$ \`{e} una misura finita, cio%
\`{e} $\mathbf{P}\left( \Omega \right) <+\infty $. (3) vale perch\'{e} $%
\mathbf{E}\left( XY\right) $ \`{e} un prodotto scalare in $L^{2}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $, quindi vale la disuguaglianza
solita $\left\vert \left\langle X,Y\right\rangle \right\vert \leq \left\vert
\left\vert X\right\vert \right\vert \left\vert \left\vert Y\right\vert
\right\vert $.

\textbf{Dim} (1) Vediamo che $L^{2}\subseteq L^{1}$. Se $X\in L^{2}$, allora 
$\mathbf{E}\left( X^{2}\right) <+\infty $: mostro che $\mathbf{E}\left(
X\right) <+\infty $ usando il fatto che $\mathbf{E}\left( \left\vert
X\right\vert \right) <+\infty $, con la monotonia applicata a un'opportuna
disuguaglianza. Infatti $\left\vert X\left( \omega \right) \right\vert
<X^{2}\left( \omega \right) +1$ $\forall $ $\omega \in \Omega $: essendo $%
X^{2}+1\in L^{1}$ per linearit\`{a} ($\mathbf{E}\left( X^{2}+1\right) =%
\mathbf{E}\left( X^{2}\right) +1$), per 8.8 (3) anche $\left\vert
X\right\vert \in L^{1}$, dato che $\mathbf{E}\left( \left\vert X\right\vert
\right) \leq \mathbf{E}\left( X^{2}+1\right) <+\infty $. Si usa $\mathbf{P}%
\left( \Omega \right) <+\infty $ per affermare che $\mathbf{E}\left(
1\right) =1$: infatti, essendo $1$ una v. a. semplice, $\mathbf{E}\left(
1\right) =1\cdot \mathbf{P}\left( \Omega \right) =\mathbf{P}\left( \Omega
\right) =1$.

(3) E' una conseguenza dello struttura di spazio euclideo; in ogni caso, si
ridimostra. E' noto che $\left\vert ab\right\vert \leq \frac{1}{2}a^{2}+%
\frac{1}{2}b^{2}$: quindi $\left\vert XY\right\vert \leq \frac{1}{2}X^{2}+%
\frac{1}{2}Y^{2}$. Entrambi i lati sono nonnegativi e $\frac{1}{2}X^{2}+%
\frac{1}{2}Y^{2}\in L^{1}$ perch\'{e} $L^{1}$ \`{e} uno spazio vettoriale,
quindi per monotonia (8.8 (3)) anche $\left\vert XY\right\vert \in L^{1}$ e $%
XY\in L^{1}$.

La seconda parte \`{e} una conseguenza dello struttura di spazio euclideo;
in ogni caso, si ridimostra. $\mathbf{E}\left( \left( aX+Y\right)
^{2}\right) =a^{2}\mathbf{E}\left( X^{2}\right) +\mathbf{E}\left(
Y^{2}\right) +2a\mathbf{E}\left( X,Y\right) \geq 0$ per positivit\`{a} del
valore atteso, quindi, vedendo la disuguaglianza nell'incognita $a$, il $%
\Delta $ dev'essere non positivo, per cui $4\mathbf{E}^{2}\left( X,Y\right)
-4\mathbf{E}\left( X^{2}\right) \mathbf{E}\left( Y^{2}\right) \leq 0$, cio%
\`{e} $\left\vert \mathbf{E}\left( XY\right) \right\vert \leq \sqrt{\mathbf{E%
}\left( X^{2}\right) \mathbf{E}\left( Y^{2}\right) }$.

(2) Date $X,Y\in L^{2}$, $X+Y\in L^{2}$ perch\'{e} $\mathbf{E}\left( \left(
X+Y\right) ^{2}\right) =\mathbf{E}\left( X^{2}+Y^{2}\mathbf{+}2XY\right) $,
ma la funzione integranda \`{e} in $L^{1}$ perch\'{e} somma di v. a. $L^{1}$%
, per ipotesi e per 3, quindi anche $\mathbf{E}\left( \left( X+Y\right)
^{2}\right) $ \`{e} un numero reale. $\blacksquare $

\textbf{Def 9.9} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a}, data $X\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $, si definisce varianza di $X$, e si indica con $var\left( X\right) 
$ o $\sigma _{X}^{2}$, $\mathbf{E}\left( \left( X-\mathbf{E}\left( X\right)
\right) ^{2}\right) $.

$\sigma ^{2}$ misura quanto i valori assunti da $X$ sono dispersi attorno a $%
\mathbf{E}\left( X\right) $. La definizione \`{e} ben posta, perch\'{e} $%
L^{2}\subseteq L^{1}$ e si pu\`{o} calcolare $\mathbf{E}\left( X\right) $, e
perch\'{e} $X-\mathbf{E}\left( X\right) \in L^{2}$, essendo $L^{2}$ uno
spazio vettoriale, per cui $\sigma ^{2}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

\textbf{Prop 9.10 (propriet\`{a} della varianza)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }X\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \\
\text{Ts: (1) }var\left( X\right) \geq 0 \\
\text{(2) }var\left( X\right) =0\Longleftrightarrow \exists \text{ }c\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:X=c\text{ q. c. }\Longleftrightarrow \exists \text{ }c:P^{X}\sim \delta _{c}
\\
\text{(3) (disuguaglianza di Chebyschev) }\mathbf{P}\left( \left\vert X-%
\mathbf{E}\left( X\right) \right\vert \geq a\right) \leq \frac{\sigma ^{2}}{%
a^{2}}\text{ }\forall \text{ }a>0 \\
\text{(4) }var\left( X\right) =\mathbf{E}\left( X^{2}\right) -\mathbf{E}%
^{2}\left( X\right) \\
\text{(5*) se }Y=aX+b\text{, }var\left( Y\right) =a^{2}var\left( X\right)
\end{gather*}

(1) \`{e} intuitivamente ovvia per il fatto che un indice di dispersione con
valore negativo non ha significato. (2) intuitivamente \`{e} dovuta al fatto
che dispersione nulla di $X$ significa che $X$ assume lo stesso valore quasi
ovunque. (3) illustra il significato di $\sigma ^{2}$ come indice di
dispersione, come fa la disuguaglianza di Markov per il valore atteso: la
varianza controlla la probabilit\`{a} che $X$ si allontani dal suo valore
atteso.

\textbf{Dim} (1) Per definizione $var\left( X\right) =\mathbf{E}\left(
\left( X-\mathbf{E}\left( X\right) \right) ^{2}\right) $. Essendo $\left( X-%
\mathbf{E}\left( X\right) \right) ^{2}\geq 0$, per 8.8 (2) (ii) vale $%
\mathbf{E}\left( \left( X-\mathbf{E}\left( X\right) \right) ^{2}\right) \geq
0$.

(2) La seconda e la terza proposizione sono chiaramente equivalenti perch%
\'{e} $\exists $ $c:P^{X}\sim \delta _{c}$ se e solo se la legge di $X$ $%
P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $ \`{e} tale che $P^{X}\left( A\right)
=\mathbf{P}\left( X^{-1}\left( A\right) \right) =\left\{ 
\begin{array}{c}
1\text{ se }c\in A \\ 
0\text{ se }c\not\in A%
\end{array}%
\right. $ $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Se quindi scelgo $A=\left\{ c\right\} $, $\mathbf{P}\left(
X=c\right) =1$, vale a dire che $X=c$ q. c., e se $X=c$ q. c. la legge \`{e}
necessariamente quella sopra.

Dimostro che la seconda proposizione implica la prima: se $X=c$ q. c., $%
\mathbf{E}\left( X\right) =c$, per cui $X-\mathbf{E}\left( X\right) =0$ q.
c. e $\left( X-\mathbf{E}\left( X\right) \right) ^{2}=0$ q. c., per cui $%
\mathbf{E}\left( \left( X-\mathbf{E}\left( X\right) \right) ^{2}\right)
=0=var\left( X\right) $.

Inoltre la prima proposizione implica la seconda perch\'{e}, vedendo la
varianza come norma al quadrato, si ha $var\left( X\right) =\mathbf{E}\left(
\left( X-\mathbf{E}\left( X\right) \right) \left( X-\mathbf{E}\left(
X\right) \right) \right) =\left\langle X-\mathbf{E}\left( X\right) ,X-%
\mathbf{E}\left( X\right) \right\rangle =\left\vert \left\vert X-\mathbf{E}%
\left( X\right) \right\vert \right\vert ^{2}=0$ se e solo se $X=\mathbf{E}%
\left( X\right) $ q. c., cio\`{e} $X\in \left[ \mathbf{E}\left( X\right) %
\right] $.

(3) Per la disuguaglianza di Markov applicata a $Y=\left( X-\mathbf{E}\left(
X\right) \right) ^{2}=\left\vert Y\right\vert $ con valore di soglia $a^{2}$%
, $\mathbf{P}\left( \left\vert X-\mathbf{E}\left( X\right) \right\vert \geq
a\right) =\mathbf{P}\left( \left\vert X-\mathbf{E}\left( X\right)
\right\vert ^{2}\geq a^{2}\right) \leq \frac{\mathbf{E}\left( \left\vert X-%
\mathbf{E}\left( X\right) \right\vert ^{2}\right) }{a^{2}}=\frac{\sigma ^{2}%
}{a^{2}}$.

[Devo dimostrare che $\mathbf{P}\left( \left\vert X-\mathbf{E}\left(
X\right) \right\vert \geq a\right) \leq \frac{\mathbf{E}\left( \left( X-%
\mathbf{E}\left( X\right) \right) ^{2}\right) }{a^{2}}$. Noto che $%
\left\vert X-\mathbf{E}\left( X\right) \right\vert \geq a\Longleftrightarrow
\left( X-\mathbf{E}\left( X\right) \right) ^{2}\geq a^{2}$: questo significa
che $I_{\left( \left\vert X-\mathbf{E}\left( X\right) \right\vert \geq
a\right) }\left( \omega \right) \leq \frac{\left( X-\mathbf{E}\left(
X\right) \right) ^{2}}{a^{2}}$, perch\'{e} quando $\left\vert X-\mathbf{E}%
\left( X\right) \right\vert <a$ vale ovviamente $\frac{\left( X-\mathbf{E}%
\left( X\right) \right) ^{2}}{a^{2}}\geq 0$, mentre quando $\left\vert X-%
\mathbf{E}\left( X\right) \right\vert \geq a$ vale anche $\left( X-\mathbf{E}%
\left( X\right) \right) ^{2}\geq a^{2}$, cio\`{e} $\frac{\left( X-\mathbf{E}%
\left( X\right) \right) ^{2}}{a^{2}}\geq 1$, per cui la disuguaglianza \`{e}
verificata. Allora $\mathbf{E}\left( I_{\left( \left\vert X-\mathbf{E}\left(
X\right) \right\vert \geq a\right) }\left( \omega \right) \right) \leq 
\mathbf{E}\left( \frac{\left( X-\mathbf{E}\left( X\right) \right) ^{2}}{a^{2}%
}\right) $, cio\`{e} $\mathbf{P}\left( \left\vert X-\mathbf{E}\left(
X\right) \right\vert \geq a\right) \leq \frac{\mathbf{E}\left( \left( X-%
\mathbf{E}\left( X\right) \right) ^{2}\right) }{a^{2}}$.]

(4) Per definizione $Var\left( X\right) =\mathbf{E}\left( \left( X-\mathbf{E}%
\left( X\right) \right) ^{2}\right) =\mathbf{E}\left( X^{2}+\mathbf{E}%
^{2}\left( X\right) -2X\mathbf{E}\left( X\right) \right) $, che \`{e}, per
linearit\`{a} e per idempotenza, $\mathbf{E}\left( X^{2}\right) +\mathbf{E}%
^{2}\left( X\right) -2\mathbf{E}\left( X\right) \mathbf{E}\left( X\right) =%
\mathbf{E}\left( X^{2}\right) -\mathbf{E}^{2}\left( X\right) $.

(5) $var\left( aX+b\right) =\mathbf{E}\left( \left( aX+b-\mathbf{E}\left(
aX+b\right) \right) ^{2}\right) =\mathbf{E}\left( \left( aX-a\mathbf{E}%
\left( X\right) \right) ^{2}\right) =a^{2}\mathbf{E}\left( \left( X-\mathbf{E%
}\left( X\right) \right) ^{2}\right) =a^{2}var\left( X\right) $. $%
\blacksquare $

\subsubsection{Calcolo del valore atteso di una variabile aleatoria}

Sappiamo che dati gli spazi $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, 
$\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con legge $P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $, $P^{X}\left( B\right) =\mathbf{P}%
\left( X^{-1}\left( B\right) \right) $, allora $P^{X}$ \`{e} una misura di
probabilit\`{a} su $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, cio\`{e} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) $ \`{e} uno spazio di probabilit\`{a}. Posso vedere la
funzione $Id:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ come una nuova variabile aleatoria, definita su $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) $, per cui se ne pu\`{o} calcolare il valore atteso
secondo $P^{X}$ $E^{X}\left( Id\right) $.

\textbf{Teo 10.1 (regola del valore atteso)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( E,\mathcal{E}\right) \text{ spazio misurabile, } \\
X:\Omega \rightarrow E\text{ \`{e} una v. a., }h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una funzione misurabile} \\
\text{Ts: (1) }h\left( X\right) \in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P%
}\right) \Longleftrightarrow h\in L^{1}\left( E,\mathcal{E},P^{X}\right) \\
\text{(2) se }h:E\rightarrow \left[ 0,+\infty \right] \text{ o }h\in
L^{1}\left( E,\mathcal{E},P^{X}\right) \text{, }\mathbf{E}\left( h\left(
X\right) \right) =E^{X}\left( h\right)
\end{gather*}

$h:E\rightarrow \left[ 0,+\infty \right] $ o $h\in L^{1}\left( E,\mathcal{E}%
,P^{X}\right) $ fa s\`{\i} che $E^{X}\left( h\right) $ sia ben definito. $%
h\left( X\right) $ \`{e} non negativa se $h$ \`{e} non negativa, oppure \`{e}
integrabile per (1) se $h$ \`{e} integrabile, quindi comunque $\mathbf{E}%
\left( h\left( X\right) \right) $ \`{e} ben definito. (2) significa%
\begin{equation*}
\mathbf{E}\left( h\left( X\right) \right) =\int_{\Omega }h\left( X\left(
\omega \right) \right) d\mathbf{P}\left( \omega \right) =\int_{E}h\left(
x\right) dP^{X}\left( x\right) =E^{X}\left( h\right)
\end{equation*}

E' quindi una formula di cambio di variabile per gli integrali rispetto a
una misura di probabilit\`{a} (analogamente al teorema di sostituzione per
gli integrali di Riemann): la sostituzione \`{e} $X\left( \omega \right) =x$%
, per cui $\omega =X^{-1}\left( x\right) $ e $d\mathbf{P}\left( \omega
\right) =d\mathbf{P}\left( X=x\right) =dP^{X}\left( x\right) $. Si pu\`{o}
quindi calcolare il valore atteso di una v.a. con due diversi integrali,
rispetto a due diverse misure di probabilit\`{a}. La formula rende inoltre
evidente che $\mathbf{E}\left( h\left( X\right) \right) $ non dipende dai
valori che assume $X$ al variare di $\omega $, ma solo da $h$ e dalla legge
di $X$: due v. a. con la stessa legge hanno lo stesso valore atteso, anche
se sono definite su spazi di probabilit\`{a} diversi. Cio\`{e}, in generale,
se $X:\Omega _{1}\rightarrow E,Y:\Omega _{2}\rightarrow E$ sono tali che $%
P^{X}=P^{Y}$, allora $\mathbf{E}\left( X\right) =E^{X}\left( Id\right)
=E^{Y}\left( Id\right) =\mathbf{E}\left( Y\right) $: questa \`{e} una
generalizzazione di 8.8 (5), perch\'{e} se $X=Y$ q. c. allora $P^{X}=P^{Y}$.

Un modo naturale di applicare il teorema, se $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, \`{e} prendere $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $h\left( x\right) =Id=x$, per cui si
pu\`{o} calcolare $\mathbf{E}\left( X\right) $ integrando $x$ rispetto alla
legge di $X$: 
\begin{equation*}
\mathbf{E}\left( X\right) =\int_{\Omega }X\left( \omega \right) d\mathbf{P}%
\left( \omega \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}xdP^{X}\left( x\right) =E^{X}\left( Id\right)
\end{equation*}

\textbf{Dim} (Passo 1) Dato $B\in \mathcal{E}$, definisco $h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $h\left( x\right) =I_{B}\left( x\right) $, che \`{e} ovviamente
misurabile. $\func{Im}h=\left\{ 0,1\right\} $. Essendo $I_{B}\left( X\left(
\omega \right) \right) $ una v. a. semplice, $\mathbf{E}\left( I_{B}\left(
X\right) \right) =\int_{\Omega }I_{\left( X\in B\right) }\left( \omega
\right) d\mathbf{P}\left( \omega \right) =\mathbf{P}\left( X\in B\right)
=P^{X}\left( B\right) =\int_{E}I_{B}\left( x\right) dP^{X}\left( x\right)
=E^{X}\left( I_{B}\right) $. Si \`{e} dimostrata (2) per $h\left( x\right)
=I_{B}\left( x\right) $, con $h$ non negativa.

(Passo 2) Considero $h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a. semplice, per cui $h\left( x\right)
=\sum_{k=1}^{n}h_{k}I_{B_{k}}\left( x\right) $, dove $\left\{
B_{1},...,B_{n}\right\} $ \`{e} una partizione di $E$, $h_{1},...,h_{n}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Allora anche $h\left( X\right) $ \`{e} una v. a. semplice e per
definizione $\mathbf{E}\left( h\left( X\right) \right) =\sum_{k=1}^{n}h_{k}%
\mathbf{P}\left( X\in B_{k}\right) =\sum_{k=1}^{n}h_{k}P^{X}\left(
B_{k}\right) =E^{X}\left( h\right) $ (si mostra direttamente con il passo 1
e la linearit\`{a} di $\mathbf{E}$).

(Passo 3) Considero $h:E\rightarrow \left[ 0,+\infty \right] $: so che
esiste una successione $\left( h_{n}\right) _{n\geq 1}$ di v. a. semplici
non negative che cresce a $h$, cio\`{e} $h_{n}\nearrow h$ ($%
\lim_{n\rightarrow +\infty }h_{n}\left( x\right) =h\left( x\right) $ $%
\forall $ $x$, $0\leq h_{n}\leq h_{n+1}\leq h$ $\forall $ $x$). Per ogni $n$%
, per il passo $2$, vale $\mathbf{E}\left( h_{n}\left( X\right) \right)
=E^{X}\left( h_{n}\right) $. Ho una successione di v. a. non negative che
cresce a $h$: allora anche $h_{n}\left( X\left( \omega \right) \right) $
cresce a $h\left( X\left( \omega \right) \right) $ $\forall $ $\omega $ e
per il teorema di convergenza monotona su $\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $ $\mathbf{E}\left( h\left( X\right) \right)
=\lim_{n\rightarrow +\infty }\mathbf{E}\left( h_{n}\left( X\right) \right)
=\lim_{n\rightarrow +\infty }E^{X}\left( h_{n}\right) $. Sempre per
convergenza monotona applicata a $h_{n}\nearrow h$ in $\left( E,\mathcal{E}%
,P^{X}\right) $, vale $E^{X}\left( h\right) =\lim_{n\rightarrow +\infty
}E^{X}\left( h_{n}\right) $, per cui $\mathbf{E}\left( h\left( X\right)
\right) =E^{X}\left( h\right) $. Cos\`{\i} ho dimostrato che per $%
h:E\rightarrow \left[ 0,+\infty \right] $ vale $\mathbf{E}\left( h\left(
X\right) \right) =E^{X}\left( h\right) $.

E' noto che $h\left( X\right) \in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) \Longleftrightarrow \left\vert h\left( X\right) \right\vert \in
L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $: ma $\left\vert h\left(
X\right) \right\vert $ \`{e} una v. a. non negativa, quindi - essendo per il
passo 3 $\mathbf{E}\left( \left\vert h\left( X\right) \right\vert \right)
=E^{X}\left( \left\vert h\right\vert \right) $ - $\left\vert h\left(
X\right) \right\vert \in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\Longleftrightarrow \left\vert h\right\vert \in L^{1}\left( E,\mathcal{E}%
,P^{X}\right) $, e di nuovo vale $\left\vert h\right\vert \in L^{1}\left( E,%
\mathcal{E},P^{X}\right) \Longleftrightarrow h\in L^{1}\left( E,\mathcal{E}%
,P^{X}\right) $: la catena di equivalenze scritte d\`{a} quindi $h\left(
X\right) \in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\Longleftrightarrow h\in L^{1}\left( E,\mathcal{E},P^{X}\right) $, e cos%
\`{\i} si \`{e} dimostrata (1).

(Passo 4) Devo dimostrare che per $h\in L^{1}\left( E,\mathcal{E}%
,P^{X}\right) $ vale $\mathbf{E}\left( h\left( X\right) \right) =E^{X}\left(
h\right) $. Considero $h\in L^{1}\left( E,\mathcal{E},P^{X}\right) $: $%
h\left( x\right) =h_{+}\left( x\right) -h_{-}\left( x\right) $. Allora $%
h\left( X\right) =\left( h\left( X\right) \right) _{+}-\left( h\left(
X\right) \right) _{-}=h_{+}\left( X\right) -h_{-}\left( X\right) _{-}$, e
per $h_{+},h_{-}$, essendo v. a. non negative, per il passo 3 vale $\mathbf{E%
}\left( h_{+}\left( X\right) \right) =E^{X}\left( h_{+}\right) $, $\mathbf{E}%
\left( h_{-}\left( X\right) \right) =E^{X}\left( h_{-}\right) $, quindi per
linearit\`{a} (8.8 (6)) vale $\mathbf{E}\left( h\left( X\right) \right) =%
\mathbf{E}\left( h_{+}\left( X\right) -h_{-}\left( X\right) \right) =\mathbf{%
E}\left( h_{+}\left( X\right) \right) -\mathbf{E}\left( h_{-}\left( X\right)
\right) =E^{X}\left( h_{+}\right) -E^{X}\left( h_{-}\right) =E^{X}\left(
h\right) $. $\blacksquare $

Teo%
\begin{gather*}
\text{Hp: }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v.a. con legge }P^{X}\text{, }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \lbrack 0,+\infty )\text{ } \\
\text{\`{e} misurabile, }h\left( X\right) \in L^{1}\text{, }\lambda \left(
B\right) :=\int_{B}h\left( x\right) dP^{X}\left( x\right) \\
\text{Ts: }\lambda \text{ \`{e} una misura}
\end{gather*}

\section{Variabili aleatorie discrete}

\textbf{Def 10.2} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a} e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con legge $P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $, $X$ si dice discreta se $P^{X}$ 
\`{e} una probabilit\`{a} discreta, cio\`{e} se $\exists $ $T\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ discreto e $p_{X}:T\rightarrow \left[ 0,1\right] $, detta densit\`{a}
discreta, tali che $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $P^{X}\left( B\right) =\sum_{x\in T\cap B}p_{X}\left( x\right) $.
Si dice supporto della densit\`{a} $p_{X}$ o supporto di $X$, e si indica
con $\mathcal{S}_{X}$, $\left\{ x\in T:p_{X}\left( x\right) >0\right\} $.

(Questo implica $\sum_{x\in T}p_{X}\left( x\right) =1$) $\mathcal{S}%
_{X}\subseteq T$ \`{e} ovviamente discreto. La definizione 
\`{e} poco utilizzabile in pratica: per questo si usano alcune definizioni
equivalenti.

\textbf{Teo (definizioni equivalenti di v. a. discreta)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. con legge }P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] \text{ } \\
\text{e funzione di ripartizione }F^{X} \\
\text{Ts: }X\text{ \`{e} discreta con }p_{X}:T\rightarrow \left[ 0,1\right] 
\text{ avente supporto }\mathcal{S}_{X}\Longleftrightarrow \text{(1) }%
\sum_{x\in \mathcal{S}_{X}}F\left( x\right) -F\left( x^{-}\right) =1\text{ }
\\
\text{e }p_{X}\left( x\right) =F\left( x\right) -F\left( x^{-}\right) \text{ 
}\forall \text{ }x\in T\Longleftrightarrow \text{ (2) }\exists \text{ }%
T^{\prime }\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ discreto }:\mathbf{P}\left( X\in T^{\prime }\right) =1 \\
\Longleftrightarrow \text{(3) }\exists \text{ }\tilde{X}\text{ con }\func{Im}%
\left( \tilde{X}\right) \subseteq T:X=\tilde{X}\text{ q. c.}
\end{gather*}

$S_{X}$ \`{e} anche l'insieme dei punti di discontinuit\`{a} di $F$. (2)
significa che \`{e} possibile che $\exists $ $\omega \in \Omega :X\left(
\omega \right) \not\in T^{\prime }$, ma comunque $X$ ha quasi certamente
immagine discreta.

Come applico la regola del valore atteso per una v. a. discreta?

\textbf{Prop 10.3: regola del valore atteso nel caso discreto}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. discreta con legge } \\
P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] \text{, densit\`{a} }%
p_{X}:T\rightarrow \left[ 0,1\right] \text{ e supporto }\mathcal{S}_{X}\text{%
, }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,+\infty \right] \text{ } \\
\text{misurabile o }h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) \\
\text{Ts: }\mathbf{E}\left( h\left( X\right) \right) =E^{X}\left( h\right)
=\sum_{x\in \mathcal{S}_{X}}h\left( x\right) p_{X}\left( x\right)
\end{gather*}

\textbf{Dim} Per la regola del valore atteso $\mathbf{E}\left( h\left(
X\right) \right) =\int_{\Omega }h\left( X\left( \omega \right) \right) d%
\mathbf{P}\left( \omega \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{x}\left( x\right) $. Per l'applicazione A2, essendo $%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) $ uno spazio di probabilit\`{a} con $P^{X}$ discreta e 
$h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,+\infty \right] $ misurabile o $h\in L^{1}$, allora $%
E^{X}\left( h\right) =\sum_{x\in S_{X}}h\left( x\right) p_{X}\left( x\right) 
$, da cui la tesi. $\blacksquare $

Nelle ipotesi della proposizione, essa ha varie conseguenze.

Nel caso in cui $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ sia una funzione misurabile qualsiasi, dato che $h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) \Longleftrightarrow \left\vert h\right\vert \in
L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) $, la proposizione permette di dedurre che $h\in
L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) \Longleftrightarrow \sum_{x\in \mathcal{S}%
_{X}}\left\vert h\left( x\right) \right\vert p_{X}\left( x\right) <+\infty $%
, cio\`{e} se e solo se $\sum_{x\in \mathcal{S}}h\left( x\right) p_{X}\left(
x\right) $ converge assolutamente: sto convertendo integrabilit\`{a} in
convergenza assoluta di una serie.

Se in particolare $h\left( x\right) =Id\left( x\right) =x$, $\mathbf{E}%
\left( X\right) =\sum_{x\in \mathcal{S}_{X}}xp_{X}\left( x\right) $: quindi $%
X\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \Longleftrightarrow
\sum_{x\in \mathcal{S}_{X}}xp_{X}\left( x\right) <+\infty $. Questo implica
che, se $\mathcal{S}_{X}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\mathbf{E}\left( X\right) =\sum_{k=1}^{+\infty }kp_{X}\left( k\right)
=\sum_{k=1}^{+\infty }k\mathbf{P}\left( X=k\right) $ $=\mathbf{P}\left(
X=1\right) +2\mathbf{P}\left( X=2\right) +3\mathbf{P}\left( X=3\right) +...=$
$\mathbf{P}\left( X=1\right) +\mathbf{P}\left( X=2\right) +\mathbf{P}\left(
X=3\right) +...+\mathbf{P}\left( X=2\right) +\mathbf{P}\left( X=3\right)
+...+\mathbf{P}\left( X=3\right) +...=$ $\mathbf{P}\left( X\geq 1\right) +%
\mathbf{P}\left( X\geq 2\right) +\mathbf{P}\left( X\geq 3\right) +...$. Vale
quindi%
\begin{equation*}
\mathbf{E}\left( X\right) =\sum_{k=1}^{+\infty }kp_{X}\left( k\right)
=\sum_{k=1}^{+\infty }\mathbf{P}\left( X\geq k\right)
\end{equation*}

La proposizione pu\`{o} inoltre essere sfruttata per il calcolo della
varianza, ponendo $h\left( X\right) =\left( X-\mathbf{E}\left( X\right)
\right) ^{2}$: $Var\left( X\right) =\mathbf{E}\left( \left( X-\mathbf{E}%
\left( X\right) \right) ^{2}\right) =E^{X}\left( h\right) =\sum_{x\in 
\mathcal{S}_{X}}\left( x-\mu \right) ^{2}p_{X}\left( x\right) $.

Si pu\`{o} inoltre valutare se $X\in L^{p}$, ponendo $h\left( X\right)
=\left\vert X\right\vert ^{p}$: $X\in L^{p}\Longleftrightarrow \sum_{x\in 
\mathcal{S}_{X}}\left\vert x\right\vert ^{p}p_{X}\left( x\right) <+\infty $.

\begin{description}
\item[E1] Considero lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ di partenza con $\mathbf{P}$ esponenziale di
parametro $\lambda >0$, e lo spazio misurabile $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $. Considero $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $X\left( \omega \right) =\lceil \omega \rceil $: voglio calcolare $%
\mathbf{E}\left( X\right) $. $\func{Im}X=%
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$ \`{e} discreta, quindi per la definizione equivalente $P^{X}$ \`{e} una
probabilit\`{a} discreta. Si \`{e} gi\`{a} dimostrato che $P^{X}$ ha densit%
\`{a} geometrica di parametro $1-e^{-\lambda }$, con supporto $S_{X}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\backslash \left\{ 0\right\} $. Per la regola sopra con $h=Id$ $\mathbf{E}%
\left( X\right) =\sum_{k\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\backslash \left\{ 0\right\} }kp_{X}\left( k\right) =\sum_{k=1}^{+\infty
}k\left( 1-e^{-\lambda }\right) \left( e^{-\lambda }\right) ^{k-1}$. Si pu%
\`{o} calcolare $\sum_{k=1}^{+\infty }k\left( e^{-\lambda }\right) ^{k-1}$
vedendolo come $\sum_{k=1}^{+\infty }kq^{k-1}=\sum_{k=1}^{+\infty }\frac{d}{%
dq}\left( q^{k}\right) =\frac{d}{dq}\left( \frac{1}{1-q}-1\right) =\frac{1}{%
\left( 1-q\right) ^{2}}$, quindi $\sum_{k=1}^{+\infty }k\left( 1-e^{-\lambda
}\right) \left( e^{-\lambda }\right) ^{k-1}=\frac{1}{1-e^{-\lambda }}$, cio%
\`{e} il valore atteso di $X$ con distribuzione geometrica di parametro $p$ 
\`{e} $\frac{1}{p}$.

\item Avrei anche potuto calcolare $\mathbf{E}\left( X\right) =\int_{\Omega
}X\left( \omega \right) d\mathbf{P}\left( \omega \right) =\int_{\Omega
}\left( XI_{\left( 0,+\infty \right) }\right) \left( \omega \right) d\mathbf{%
P}\left( \omega \right) $, per il fatto che $\mathbf{P}\left( X>0\right) =1$%
, cio\`{e} $\mathbf{P}\left( X=X_{\left( 0,+\infty \right) }\right) =1$, che 
\`{e} uguale, in base a com'\`{e} fatta $X$, $\int_{\Omega
}\sum_{k=1}^{+\infty }kI_{(k-1,k]}\left( \omega \right) d\mathbf{P}\left(
\omega \right) =\mathbf{E}\left( \sum_{k=1}^{+\infty }kI_{(k-1,k]}\left(
\omega \right) \right) =\sum_{k=1}^{+\infty }\mathbf{E}\left(
kI_{(k-1,k]}\left( \omega \right) \right) $ per 9.4, che \`{e} uguale a $%
\sum_{k=1}^{+\infty }\int_{\Omega }kI_{(k-1,k]}\left( \omega \right) d%
\mathbf{P}\left( \omega \right) =\sum_{k=1}^{+\infty }k\mathbf{P}\left(
(k-1,k]\right) =\sum_{k=1}^{+\infty }k\int_{k-1}^{k}\lambda e^{-\lambda
\omega }d\omega =\sum_{k=1}^{+\infty }ke^{-\lambda k}\left( e^{\lambda
}-1\right) =\frac{1}{1-e^{-\lambda }}$, dato che $kI_{(k-1,k]}\left( \omega
\right) $, fissato $k$, \`{e} una v. a. semplice, e utilizzando la densit%
\`{a} associata a $\mathbf{P}$. Il calcolo \`{e} molto pi\`{u} laborioso nel
secondo modo, perch\'{e} non si \`{e} sfruttato il fatto che $X$ \`{e}
discreta.

\item $Var\left( X\right) =E^{X}\left( \left( X-\mu \right) ^{2}\right)
=\sum_{k\in \mathcal{S}_{X}}\left( k-\mu \right) ^{2}p_{X}\left( k\right)
=\sum_{k=1}^{+\infty }\left( k-\mu \right) ^{2}p\left( 1-p\right) ^{k-1}$:
la calcolo usando la somma di una serie di una derivata.

\item[E2] Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e $T=\left\{ a_{1},...,a_{n}\right\} $ insieme finito con $%
a_{i}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,a_{i}\neq a_{j}$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria uniforme discreta, e si scrive \ $X\sim 
\mathcal{U}\left( \left\{ a_{1},...,a_{n}\right\} \right) $ se la sua legge
ha densit\`{a} discreta $p_{X}:T\rightarrow \left[ 0,1\right] $, $%
p_{X}\left( a_{k}\right) =\frac{1}{n}$ $\forall $ $k=1,...,n$. Vale quindi $%
S_{X}=\left\{ a_{1},...,a_{n}\right\} $. Se in particolare $T=\left\{
1,...n\right\} $, si scrive $X\sim \mathcal{U}\left\{ 1,...,n\right\} $ e
vale $\mathbf{E}\left( X\right) =E^{X}\left( Id\right) =\sum_{k\in
S_{X}}kp_{X}\left( k\right) =\sum_{k=1}^{n}\frac{k}{n}=\frac{1}{n}\frac{%
n\left( n+1\right) }{2}=\frac{n+1}{2}$.

\item $var\left( X\right) =\sum_{k\in S_{X}}\left( k-\mu \right)
^{2}p_{X}\left( k\right) =$ $\sum_{k=1}^{n}\left( k-\mu \right) ^{2}\frac{1}{%
n}=\frac{1}{n}\left( \sum_{k=1}^{n}k^{2}+\mu ^{2}n-2\mu
\sum_{k=1}^{n}k\right) $ $=\frac{1}{n}\left( \frac{n\left( n+1\right) \left(
2n+1\right) }{6}+\left( \frac{n+1}{2}\right) ^{2}n-\left( n+1\right) \frac{%
n\left( n+1\right) }{2}\right) =\frac{\left( n+1\right) \left( 2n+1\right) }{%
6}-\frac{\left( n+1\right) ^{2}}{4}=\frac{n^{2}-1}{12}$.

\item[E3] Considero $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio
di probabilit\`{a} qualsiasi e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a. con legge $P^{X}$ discreta, avente densit\`{a} $p_{X}\left( k\right)
=\frac{6}{\pi ^{2}}\frac{1}{k^{2}}$ e $\mathcal{S}_{X}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }$ ($\frac{6}{\pi ^{2}}$ \`{e} la costante di normalizzazione
necessaria affinch\'{e} $\sum_{k=1}^{+\infty }p_{X}\left( k\right) =1$). $X$ 
\`{e} non negativa e q. c. finita: $\mathbf{P}\left( X<+\infty \right) =%
\mathbf{P}\left( X\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }\right) =\sum_{k=1}^{+\infty }p_{X}\left( k\right) =1$, ma $\mathbf{E%
}\left( X\right) =E^{X}\left( Id\right) =\sum_{k=1}^{+\infty }k\frac{6}{\pi
^{2}}\frac{1}{k^{2}}=+\infty $, quindi $X$ non \`{e} integrabile, come gi%
\`{a} visto per $X\left( k\right) =k!$.

\item[E4] Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e $A\in \mathcal{A}:\mathbf{P}\left( A\right) =p$, $X:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria di Bernoulli di parametro $p$, e si scrive $%
X\sim B\left( p\right) $, se $X\left( \omega \right) =I_{A}\left( \omega
\right) $. $X$ esprime quindi l'essersi realizzato o meno dell'evento $A$.
E' una v. a. semplice, quindi discreta su $\func{Im}X=T=\left\{ 0,1\right\} $%
, con densit\`{a} discreta $p_{X}\left( 1\right) =p,p_{X}\left( 0\right)
=1-p $. $\mathbf{E}\left( X\right) =p$, $var\left( X\right) =p^{2}\left(
1-p\right) +\left( 1-p\right) ^{2}p=p\left( 1-p\right) $.

\item[E5] Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e una successione finita di eventi indipendenti $\left\{
A_{1},...,A_{n}\right\} \subseteq \mathcal{A}$ tali che $\mathbf{P}\left(
A_{i}\right) =p$ $\forall $ $i=1,...,n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria binomiale di parametri $n,p$, e si scrive $%
X\sim bin\left( n,p\right) $, se $X\left( \omega \right) =I_{A_{1}}\left(
\omega \right) +...+I_{A_{n}}\left( \omega \right) $. $X$ conta quindi
quanti eventi si sono realizzati tra $A_{1},...,A_{n}$. Si pu\`{o} pensare
che $\forall $ $i$ $A_{i}$ rappresenti un evento relativo alla $i$-esima di $%
n$ prove realizzate in sequenza. Se $n=1$, si ottiene una v. a. di
Bernoulli. $X$ \`{e} una una v. a. semplice, quindi discreta su $\func{Im}%
X=T=\left\{ 0,1,...,n\right\} $. La densit\`{a} discreta di $X$ \`{e}, dato $%
I\subseteq \left\{ 1,...,n\right\} :\left\vert I\right\vert =k$, $%
p_{X}\left( k\right) =\mathbf{P}\left( X=k\right) =\sum_{I:\left\vert
I\right\vert =k}\mathbf{P}\left( \bigcap_{i\in I}A_{i}\cap \bigcap_{k\in
I^{c}}A_{k}^{c}\right) =\binom{n}{k}p^{k}\left( 1-p\right) ^{k}$. $\mathbf{E}%
\left( X\right) =np$. Poich\'{e} $\left\{ A_{1},...,A_{n}\right\} $ sono una
famiglia di eventi indipendenti, le. v. a. $X_{i}\left( \omega \right)
=I_{A_{i}}\left( \omega \right) $ sono tutte indipendenti, perch\'{e}
generano solo gli eventi $A_{i},\Omega ,\varnothing $. Ne segue che $%
var\left( \sum_{i=1}^{n}X_{i}\left( \omega \right) \right)
=\sum_{i=1}^{n}var\left( X_{i}\right) =np\left( 1-p\right) $.

\item[E6] Dato $\left( \left\{ 0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
},2^{\Omega },\mathbf{P}\right) $ spazio di probabilit\`{a} e una
successione finita di eventi indipendenti $\left\{ A_{1},...,A_{n}\right\}
\subseteq \mathcal{A}:\mathbf{P}\left( A_{n}\right) =p$ $\forall $ $n$, data 
$X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ binomiale di parametri $n,p$ con $X\left( \omega \right) =X_{1}\left(
\omega \right) +...+X_{n}\left( \omega \right) =I_{A_{1}}\left( \omega
\right) +...+I_{A_{n}}\left( \omega \right) $, $Z\left( \omega \right) =\min
\left\{ n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
:X_{n}\left( \omega \right) =1\right\} $ si dice variabile aleatoria
geometrica di parametro $p$, e si scrive $Z\sim geom\left( p\right) $. Vige
la convenzione $\min \varnothing =-\infty $. $Z$ conta il numero di prove di
Bernoulli necessarie per il primo successo, ed \`{e} discreta su $\func{Im}%
Z=T=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\backslash \left\{ 0\right\} $, con densit\`{a} discreta $\mathbf{P}\left(
Z=k\right) =P\left( \bigcap_{i=1}^{k-1}A_{i}^{c}\cap A_{k}\right) =\left(
1-p\right) ^{k-1}p=p_{Z}\left( k\right) $, per ipotesi di indipendenza. $%
\mathbf{E}\left( Z\right) =\sum_{k=1}^{+\infty }k\left( 1-p\right)
^{k-1}p=p\sum_{k=1}^{+\infty }\frac{d}{dq}q^{k}=p\frac{d}{dq}\left( \frac{q}{%
1-q}\right) =p\frac{1}{\left( 1-q\right) ^{2}}=\frac{1}{p}$. $var\left(
Z\right) =\mathbf{E}\left( Z^{2}\right) -\mathbf{E}^{2}\left( Z\right) $: $%
\mathbf{E}\left( Z^{2}\right) =\sum_{k=1}^{+\infty }k^{2}\left( 1-p\right)
^{k-1}p=p\sum_{k=1}^{+\infty }k^{2}q^{k-1}=p\sum_{k=1}^{+\infty }\frac{d}{dq}%
\left( kq^{k}\right) =p\frac{d}{dq}\sum_{k=1}^{+\infty }kq^{k}$. Ora $%
\sum_{k=1}^{+\infty }kq^{k}=q\sum_{k=1}^{+\infty }\frac{d}{dq}\left(
q^{k}\right) =q\frac{d}{dq}\left( \frac{q}{1-q}\right) =\frac{q}{\left(
1-q\right) ^{2}}$. Quindi $\mathbf{E}\left( Z^{2}\right) =p\left( \frac{%
\left( 1-q\right) ^{2}+2q\left( 1-q\right) }{\left( 1-q\right) ^{4}}\right)
=p\left( \frac{p^{2}+2p\left( 1-p\right) }{p^{4}}\right) =\frac{2-p}{p^{2}}$
e $var\left( Z\right) =\frac{2-p}{p^{2}}-\frac{1}{p^{2}}=\allowbreak \frac{%
1-p}{p^{2}}$.

\item Le mode di $P^{X}$ sono $k=\arg \max_{k\in T}\mathbf{P}\left(
X=k\right) =1$.

\item La funzione di ripartizione della legge di $Z$ \`{e} $F_{Z}\left(
t\right) =P\left( Z\leq t\right) =\sum_{\substack{ k\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }  \\ k\leq t}}\mathbf{P}\left( Z=k\right) =\left\{ 
\begin{array}{c}
0\text{ se }t<1 \\ 
\sum_{k=1}^{\lfloor t\rfloor }\mathbf{P}\left( Z=k\right) \text{ se }t\geq 1%
\end{array}%
\right. $ $p\sum_{k=1}^{\lfloor t\rfloor }\left( 1-p\right) ^{k-1}=p\frac{%
1-\left( 1-p\right) ^{\lfloor t\rfloor }}{1-\left( 1-p\right) }=1-\left(
1-p\right) ^{\lfloor t\rfloor }$, per cui $F_{Z}\left( t\right) =\left(
1-\left( 1-p\right) ^{\lfloor t\rfloor }\right) I_{[1,+\infty )}\left(
t\right) $.

\item La geometrica gode della propriet\`{a} di assenza di memoria: $\forall 
$ $i,j\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\mathbf{P}\left( Z>i+j|Z>i\right) =\mathbf{P}\left( Z>j\right) $.
Infatti $\mathbf{P}\left( Z>i+j|Z>i\right) =\frac{\mathbf{P}\left(
Z>i+j,Z>i\right) }{\mathbf{P}\left( Z>i\right) }=\frac{\mathbf{P}\left(
Z>i+j\right) }{\mathbf{P}\left( Z>i\right) }=\frac{\left( 1-p\right) ^{i+j}}{%
\left( 1-p\right) ^{i}}=\left( 1-p\right) ^{j}=\mathbf{P}\left( Z>j\right) $%
. Vale anche il viceversa: se $Z$ \`{e} una v. a. con densit\`{a} discreta
su $T=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }$ tale che $\forall $ $i,j\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\mathbf{P}\left( Z>i+j|Z>i\right) =\mathbf{P}\left( Z>j\right) $, allora 
$Z\sim geom\left( p\right) $, con $p=\mathbf{P}\left( Z=1\right) $. Infatti,
l'assenza di memoria significa che $\mathbf{P}\left( Z>i+j|Z>i\right) =\frac{%
\mathbf{P}\left( Z>i+j\right) }{\mathbf{P}\left( Z>i\right) }=\mathbf{P}%
\left( Z>j\right) $. Questo \`{e} equivalente a dire che $\mathbf{P}\left(
Z>2\right) =\mathbf{P}\left( Z>1\right) \mathbf{P}\left( Z>1\right) =\left[ 
\mathbf{P}\left( Z>1\right) \right] ^{2}$, mentre $\mathbf{P}\left(
Z>3\right) =\mathbf{P}\left( Z>2+1\right) =\mathbf{P}\left( Z>2\right) 
\mathbf{P}\left( Z>1\right) =\left[ \mathbf{P}\left( Z>1\right) \right] ^{3}$%
, per cui in generale $\forall $ $s\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }$ $\mathbf{P}\left( Z>s\right) =\left[ \mathbf{P}\left( Z>1\right) %
\right] ^{s}$. Avendo $Z$ supporto $%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }$, $\mathbf{P}\left( Z>1\right) =1-\mathbf{P}\left( Z=1\right) =:1-p$%
, cio\`{e} $\mathbf{P}\left( Z>s\right) =\left( 1-p\right) ^{s}$, e la $%
F_{Z}\left( s\right) =1-\left( 1-p\right) ^{s}$, che caratterizza la legge
di una v. a. geometrica.

\item[E7] Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, una successione infinita di eventi indipendenti $\left\{
A_{1},...,\right\} \subseteq \mathcal{A}$ tali che $\mathbf{P}\left(
A_{i}\right) =p$ $\forall $ $i$ e $X_{i}\left( \omega \right)
=I_{A_{i}}\left( \omega \right) $ $\forall $ $i$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria binomiale negativa di parametri $n,p$, e si
scrive $X\sim NB\left( n,p\right) $, se $X\left( \omega \right) =\min
\left\{ k\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
:\sum_{i=1}^{k}X_{i}\left( \omega \right) =n\right\} $: $X$ rappresenta il
numero di prove necessarie per osservare $n$ successi. $X$ \`{e} discreta
con $\func{Im}X=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }$. $\mathbf{P}\left( X=k\right) =\binom{k-1}{n-1}p^{n}\left(
1-p\right) ^{k-n}$. $X$ pu\`{o} anche essere vista come somma di $n$
geometriche indipendenti.

\item[E7] Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a} e $\lambda >0$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria di Poisson di parametro $\lambda $, e si
scrive $X\sim poiss\left( \lambda \right) $, se, dato $T=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, la legge di $X$ \`{e} $p_{X}:T\rightarrow \left[ 0,1\right] ,$ $%
p_{X}\left( k\right) =e^{-\lambda }\frac{\lambda ^{k}}{k!}$. $\mathbf{E}%
\left( X\right) =\sum_{k=0}^{n}k\cdot e^{-\lambda }\frac{\lambda ^{k}}{k!}%
=\sum_{k=1}^{n}ke^{-\lambda }\frac{\lambda ^{k}}{k!}=\lambda e^{-\lambda
}\sum_{k=1}^{n}\frac{\lambda ^{k-1}}{\left( k-1\right) !}=\lambda $, nota la
serie di Taylor di $e^{\lambda }$. $var\left( X\right) =\mathbf{E}\left(
X^{2}\right) -\lambda ^{2}$. $\mathbf{E}\left( X^{2}\right)
=\sum_{k=0}^{n}k^{2}\cdot e^{-\lambda }\frac{\lambda ^{k}}{k!}=e^{-\lambda
}\left( \sum_{k=0}^{n}k\left( k-1\right) \frac{\lambda ^{k}}{k!}%
+\sum_{k=0}^{n}k\frac{\lambda ^{k}}{k!}\right) =e^{-\lambda }\left( \lambda
^{2}\sum_{k=2}^{n}\frac{\lambda ^{k-2}}{\left( k-2\right) !}+\lambda
\sum_{k=1}^{n}\frac{\lambda ^{k-1}}{\left( k-1\right) !}\right) =\lambda
^{2}+\lambda $, per cui $var\left( X\right) =\lambda $.

\item Per massimizzare $\mathbf{P}\left( X=k\right) $ in $\lambda $, si
calcola $\frac{d}{d\lambda }\left( e^{-\lambda }\frac{\lambda ^{k}}{k!}%
\right) =e^{-\lambda }\left( \frac{\lambda ^{k-1}}{\left( k-1\right) !}-%
\frac{\lambda ^{k}}{k!}\right) =e^{-\lambda }\lambda ^{k-1}\left( \frac{1}{%
\left( k-1\right) !}-\frac{\lambda }{k!}\right) $, che \`{e} nulla se e solo
se $\lambda =k$.

\item Se $X\sim poiss\left( \lambda _{1}\right) ,Y\sim poiss\left( \lambda
_{2}\right) $ e $X\perp Y$, allora $X+Y\sim poiss\left( \lambda _{1}+\lambda
_{2}\right) $. Infatti $\mathbf{P}\left( X+Y=k\right) =\sum_{i=0}^{k}\mathbf{%
P}\left( X=i,Y=k-i\right) =\sum_{i=0}^{k}e^{-\lambda _{1}}\frac{\lambda
_{1}^{i}}{i!}e^{-\lambda _{2}}\frac{\lambda _{2}^{k-i}}{\left( k-i\right) !}%
=e^{-\left( \lambda _{1}+\lambda _{2}\right) }\frac{1}{k!}\sum_{i=0}^{k}%
\binom{k}{i}\lambda _{1}^{i}\lambda _{2}^{k-i}=e^{-\left( \lambda
_{1}+\lambda _{2}\right) }\frac{\left( \lambda _{1}+\lambda _{2}\right) ^{k}%
}{k!}$.
\end{description}

\section{Variabili aleatorie assolutamente continue}

Si \`{e} visto che esistono misure di probabilit\`{a} $\mathbf{P}$ su $%
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) :\exists $ $f\geq 0:\int_{-\infty }^{+\infty }f\left( x\right) dx=1$
e $F\left( x\right) =\int_{-\infty }^{x}f\left( x\right) dx$, per cui $F$ 
\`{e} continua e $\mathbf{P}\left( \left\{ x\right\} \right) =0$. Voglio
caratterizzare la classe delle $f$ cos\`{\i} fatte e trovare una formula per
calcolare $\mathbf{E}\left( h\left( X\right) \right) =E^{X}\left( h\right) $
quando la legge di $X$ ammette una tale $f$.

\textbf{Def 11.1} Si dice misura di Lebesgue su $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ una funzione $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ con le seguenti propriet\`{a}:

\begin{description}
\item[M1] $m\left( (a,b]\right) =b-a$ $\forall $ $a,b:-\infty <a<b<+\infty $

\item[M2] $\sigma $-additivit\`{a}: $\forall $ $\left( B_{n}\right) _{n\geq
1}:B_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $\forall $ $n$ e $B_{k}\cap B_{h}=\varnothing $ $\forall $ $k\neq
h $, vale $m\left( \bigcup_{n=1}^{+\infty }B_{n}\right) =\sum_{n=1}^{+\infty
}m\left( B_{n}\right) $
\end{description}

M1 \`{e} ben posta perch\'{e} ogni intervallo appartiene a $\mathcal{B}%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $; M2 \`{e} ben posta perch\'{e} $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ \`{e} chiusa rispetto all'unione numerabile. Si noti che $m$ ha lo
stesso dominio di $\mathbf{P}$, ma pu\`{o} valere anche $+\infty $; ha le
stesse propriet\`{a} di $\mathbf{P}$, eccetto quelle legate al fatto che $%
\mathbf{P}\left( \Omega \right) =1$. M2 differenzia la misura di Lebesgue
dalla misura di Peano-Jordan: ad esempio la funzione di Dirichlet avrebbe
misura nulla se Peano-Jordan avesse M2.

$\mathbf{P}$ \`{e} una misura finita e positiva: studiamo i casi in cui \`{e}
assolutamente continua rispetto alla misura di Lebesgue.

\begin{enumerate}
\item Dato l'intervallo $\left( a,b\right) :b-a=1$, $m:\mathcal{B}\left(
\left( a,b\right) \right) \rightarrow \left[ 0,+\infty \right] $ con le
propriet\`{a} M1 e M2 \`{e} una misura di probabilit\`{a} sullo spazio
misurabile $\left( \left( a,b\right) ,\mathcal{B}\left( \left( a,b\right)
\right) \right) $, perch\'{e} $m\left( \left( a,b\right) \right) =1$. Tale
misura di probabilit\`{a} \`{e} detta uniforme sull'intervallo $\left(
a,b\right) $.
\end{enumerate}

\textbf{Teo 11.2 (esistenza e unicit\`{a} della misura di Lebesgue)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue} \\
\text{Ts}\text{: } &&m\text{ esiste ed \`{e} unica}
\end{eqnarray*}

Enunciamo alcune proprietà della misura di Lebesgue, la cui dimostrazione è identica a quella già vista per le analoghe proprietà di una misura di probabilità.

\textbf{Teo (propriet\`{a} della misura di Lebesgue)}%
\begin{gather*}
\text{Hp: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue} \\
\text{Ts: (P1) }m\left( \varnothing \right) =0 \\
\text{(P2) }\forall \text{ }\left\{ B_{1},...,B_{n}\right\} :B_{n}\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ }\forall \text{ }n\text{ e }B_{k}\cap B_{h}\text{ }\forall 
\text{ }k\neq h\text{, vale }m\left( \bigcup_{n=1}^{+\infty }B_{n}\right)
=\sum_{n=1}^{+\infty }m\left( B_{n}\right)
\end{gather*}

\textbf{Teo (propriet\`{a} della misura di Lebesgue)}%
\begin{gather*}
\text{Hp: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue} \\
\text{Ts: (P3) (monotonia) se }A,A^{\prime }\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ e }A\subseteq A^{\prime }\text{, }m\left( A\right) \leq
m\left( A^{\prime }\right) \\
\text{(P4) (differenza) se }A,A^{\prime }\in \mathcal{A}\text{, }m\left(
A\backslash A^{\prime }\right) =m\left( A\right) -m\left( A^{\prime }\cap
A\right) \\
\text{(P5) (unione) se }A,A^{\prime }\in \mathcal{A}\text{, }m\left( A\cup
A^{\prime }\right) =m\left( A\right) +m\left( A^{\prime }\right) -m\left(
A\cap A^{\prime }\right) \\
\text{(P6) se }\left( A_{n}\right) _{n\geq 1}\text{ \`{e} tale che }A_{n}\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ }\forall \text{ }n\text{, }m\left( \bigcup_{n=1}^{+\infty
}A_{n}\right) \leq \sum_{n=1}^{+\infty }m\left( A_{n}\right) \\
\text{(P7) disuguaglianza di Bonferroni: se }\left\{ A_{1},...,A_{n}\right\} 
\text{ \`{e} tale che }A_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \\
\forall \text{ }n\geq 1\text{, }m\left( A_{1}\cap ...\cap A_{n}\right) \geq
m\left( A_{1}\right) +...+m\left( A_{n}\right) -\left( n-1\right) \text{ }%
\forall \text{ }n\geq 2
\end{gather*}

\textbf{Teo 2.4 (continuit\`{a} della misura)}
\begin{gather*}
\text{Hp}\text{: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue, }\left( A_{n}\right) _{n\geq 1}:A_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ }\forall \text{ }n\text{, }A_{n}\uparrow A \\
\text{Ts}\text{: (P9) }m\left( \bigcup_{n=1}^{+\infty }A_{n}\right)
=\lim_{n\rightarrow +\infty }m\left( A_{n}\right) \\
\text{Hp}\text{: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue, }\left( A_{n}\right) _{n\geq 1}:A_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ }\forall \text{ }n\text{, }A_{n}\downarrow A \\
\text{Ts}\text{: (P10) }m\left( \bigcap_{n=1}^{+\infty }A_{n}\right)
=\lim_{n\rightarrow +\infty }m\left( A_{n}\right)
\end{gather*}

\textbf{Propriet\`{a} ulteriori}%
\begin{gather*}
\text{Hp}\text{: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue, }a,b\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts}\text{: (i) }m\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =+\infty \\
\text{(ii) }m\left( (-\infty ,a]\right) =+\infty =m\left( [b,+\infty )\right)
\\
\text{(iii) }m\left( \left\{ a\right\} \right) =0 \\
\text{(iv) }m\left( 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right) =0 \\
\text{(v) }m\left( (a,b]\right) =m\left( (a,b)\right) =m\left( [a,b)\right)
=m\left( [a,b]\right)
\end{gather*}

(i) rende evidente che la misura di Lebesgue non \`{e} una probabilit\`{a}: $%
\mathbf{P}$ e $m$ sono due diverse misure sullo spazio misurabile $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $.

\textbf{Dim} (i) $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
=\bigcup_{n=1}^{+\infty }(1-n,1+n]$. Per la continuit\`{a} della probabilit%
\`{a} (i) $m\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =m\left( \bigcup_{n=1}^{+\infty }(1-n,1+n]\right)
=\lim_{n\rightarrow +\infty }m\left( (1-n,1+n]\right) =\lim_{n\rightarrow
+\infty }2n=+\infty $.

(ii) $(-\infty ,a]=\bigcup_{n=1}^{+\infty }(a-n,a]$, quindi per la continuit%
\`{a} della probabilit\`{a} $m\left( (-\infty ,a]\right) =\lim_{n\rightarrow
+\infty }m\left( (a-n,a]\right) =+\infty $.

(iii) $\left\{ a\right\} =\bigcap_{n=1}^{+\infty }(a-\frac{1}{n},a+\frac{1}{n%
}]$, perci\`{o} $m\left( \left\{ a\right\} \right) =\lim_{n\rightarrow
+\infty }m\left( (a-\frac{1}{n},a+\frac{1}{n}]\right) =\lim_{n\rightarrow
+\infty }\frac{2}{n}=0$.

(iv) $%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
=\bigcup_{n=1}^{+\infty }\left\{ q_{n}\right\} $, dove $q_{n}\in 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$ (si pu\`{o} prendere e. g. la successione di Cantor per numerare $%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
$): allora per $\sigma $-additivit\`{a}, per (iii) $m\left( 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right) =\sum_{n=1}^{+\infty }m\left( \left\{ q_{n}\right\} \right) =0$.

(v) Ciascun intervallo pu\`{o} essere scritto a partire da $(a,b]$
aggiungendo o togliendo uno o pi\`{u} estremi: dalla $\sigma $-additivit\`{a}
e da (iii) segue la tesi. $\blacksquare $

\textbf{Def} Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $, si dice che una propriet\`{a}
dipendente da $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ vale quasi ovunque se vale $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ tranne al pi\`{u} in un insieme $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ tale che $m\left( A\right) =0$. In particolare, si dice che $f,g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ misurabili sono uguali quasi ovunque se $A=\left\{ x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:f\left( x\right) \neq g\left( x\right) \right\} $ \`{e} tale che $m\left(
A\right) =0$.

\subsection{Integrazione rispetto a una misura}

La teoria dell'integrazione per funzioni $h:\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,m\right) \rightarrow \left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $ \`{e} analoga a quella gi\`{a} vista per variabili
aleatorie: si definisce l'integrale rispetto alla misura di Lebesgue, detto integrale di Lebesgue, in maniera identica a quella già vista per l'integrale rispetto a una misura di probabilità. 

Considero la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e la funzione $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. Si indica l'integrale di $f$ rispetto alla misura di
Lebesgue con $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) m\left( dx\right) $ o $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) dm\left( x\right) $ o$\ \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) dm$. Si definisce come segue.

[PASSO 1

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e la funzione $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ misurabile, $f$ si dice semplice se assume un numero finito di valori, cio%
\`{e} se $\left\vert \func{Im}f\right\vert =n<+\infty $.

Questo \`{e} equivalente a dire che si pu\`{o} scrivere, data $\left\{
A_{1},A_{2},...,A_{n}\right\} $ partizione finita di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e $a_{1},...,a_{n}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $f\left( x\right) =\sum_{k=1}^{n}a_{k}I_{A_{k}}\left( x\right)
=a_{1}I_{A_{1}}\left( x\right) +...+a_{n}I_{A_{n}}\left( x\right) $. Se $%
x\in A_{1}$, $f\left( x\right) =a_{1}$, eccetera. $f^{-1}\left( \left\{
a_{k}\right\} \right) =A_{k}$, $f\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =\func{Im}f=\left\{ a_{1},...,a_{n}\right\} $.

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ funzione misurabile semplice, si dice integrale di $f$ secondo la misura $%
m $, e si indica con $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) dm$, $\sum_{k=1}^{n}a_{k}m\left( A_{k}\right) $.

Serve che $f$ sia misurabile affinch\'{e} $A_{k}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

\textbf{Prop}%
\begin{gather*}
\text{Hp: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue, }f,g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{sono funzioni semplici misurabili, }\alpha ,\beta \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (i) }\alpha f+\beta g\text{ \`{e} una funzione semplice } \\
\text{(ii) (linearit\`{a}) }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( \alpha f+\beta g\right) dm=\alpha \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm+\beta \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm \\
\text{(iii) (monotonia) se }f\left( x\right) \leq g\left( x\right) \text{ }%
\forall \text{ }x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm\leq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm
\end{gather*}

PASSO 2

\textbf{Prop (approssimazione di una funzione)}%
\begin{gather*}
\text{Hp: }m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue, }f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \lbrack 0,+\infty ] \\
\text{\`{e} misurabile} \\
\text{Ts: }\exists \text{ }\left( f_{n}\right) _{n\geq 1}:\text{(1) }f_{n}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \lbrack 0,+\infty )\text{ \`{e} semplice }\forall \text{ }n\geq 1%
\text{,} \\
\text{(2) }\forall \text{ }x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ }\lim_{n\rightarrow +\infty }f_{n}\left( x\right) =f\left( x\right) 
\text{ e }f_{n}\text{ \`{e} monotona non decrescente}
\end{gather*}

$f_{n}$ monotona non decrescente significa che $f_{n}\left( x\right) \leq
f_{n+1}\left( x\right) $ $\forall $ $n$, $\forall $ $x$: (2) afferma quindi
che $\left( f_{n}\right) _{n\geq 1}$ converge puntualmente a $f$ in maniera
monotona: si scrive $f_{n}\nearrow f$.

Come costruisco tale successione? Una possibilit\`{a} \`{e}%
\begin{equation*}
\text{fissato }n\geq 1\text{, al variare di }k=0,...,n2^{n}-1\text{, }%
f_{n}\left( x\right) =\left\{ 
\begin{array}{c}
\frac{k}{2^{n}}\text{ se }f\left( x\right) \in \left[ \frac{k}{2^{n}},\frac{%
k+1}{2^{n}}\right] \\ 
n\text{ se }f\left( x\right) \geq n%
\end{array}%
\right.
\end{equation*}

Quindi, fissato $n$, $f_{n}\left( x\right) $ \`{e} un'approssimazione per
difetto di $f$: quando $f$ assume valori in $\left[ a,b\right] $, $f_{n}$
assume valore $a$. Al crescere di $n$, $f_{n}$ approssima $f$ sempre pi\`{u}
finemente, perch\'{e} la partizione dell'asse $y$ \`{e} pi\`{u} fitta.
Chiaramente $f_{n}$ \`{e} semplice: $\func{Im}\left( f_{n}\right) =\left\{ 0,%
\frac{1}{2^{n}},...,n\right\} $, con cardinalit\`{a} $n2^{n}$; $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm=\sum_{k=0}^{n2^{n}-1}\frac{k}{2^{n}}m\left( f^{-1}\left( \left[ 
\frac{k}{2^{n}},\frac{k+1}{2^{n}}\right] \right) \right) +nm\left(
f^{-1}[n,+\infty )\right) $.

Si dimostra che $f_{n+1}\left( x\right) \geq f_{n}\left( x\right) $ $\forall 
$ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\forall $ $n$, quindi $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n+1}dm\geq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm\geq 0$: allora $\left( \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm\right) _{n\geq 1}$ \`{e} una successione a valori reali non
negativi monotona non decrescente, che pu\`{o} tendere a $L\geq 0$ o $%
+\infty $ per $n\rightarrow +\infty $.

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \lbrack 0,+\infty ]$, si dice integrale di $f$ rispetto alla
misura di Lebesgue, e si indica con $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm$, $\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm$.

L'integrale pu\`{o} essere $+\infty $. La definizione non dipende dalla
scelta di $\left( X_{n}\right) _{n\geq 1}$, purch\'{e} sia una successione
di funzioni semplici che cresce a $f$.

PASSO 3

E' noto che $f\left( x\right) =f_{+}\left( x\right) -f_{-}\left( x\right) $.

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con parte positiva $f_{+}$ e parte negativa $f_{-}$, si dice che $f$
ammette integrale di Lebesgue se almeno uno tra $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{+}dm$ e $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm$ \`{e} finito. In tal caso si dice integrale di Lebesgue di $f$, e
si indica con $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm$, $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{+}dm-\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm$. Se $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{+}dm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm=+\infty $, si dice che $f$ non ammette valore atteso.

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con parte positiva $f_{+}$ e parte negativa $f_{-}$, si dice che $f$ \`{e}
integrabile secondo Lebesgue se $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{+}dm$ e $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm$ sono finiti.

In tal caso l'integrale di Lebesgue di $f$ \`{e} $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm-\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{+}dm-\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{-}dm\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

Non servono ulteriori definizioni per trattare quelli che per Riemann erano
integrali impropri.

\textbf{Def} Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $, si indica con $\mathcal{L}%
^{1}\left( m\right) $ lo spazio delle funzioni $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ integrabili secondo Lebesgue, cio\`{e} $\mathcal{L}^{1}\left( m\right)
=\left\{ h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ boreliane tali che }h\text{ ammette integrale di Lebesgue finito}%
\right\} $.

\textbf{Teo (propriet\`{a} dell'integrale di Lebesgue)} 
\begin{gather*}
\text{1) }\mathcal{L}^{1}\left( m\right) \text{ \`{e} uno spazio vettoriale}
\\
\text{2) Hp: }f,g\in \mathcal{L}^{1},\alpha ,\beta \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (i) (linearit\`{a}) }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( \alpha f+\beta g\right) dm=\alpha \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm+\beta \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm \\
\text{(ii) (positivit\`{a}) se }f\geq 0\text{, }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm\geq 0
\end{gather*}

\begin{gather*}
\text{3) Hp: }f,g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }g\in \mathcal{L}^{1}\left( m\right) \text{, }g\geq f\geq 0 \\
\text{Ts: }f\in \mathcal{L}^{1}\text{, (monotonia) }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm\geq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm \\
\text{4) Hp: }f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }f\geq 0\text{, }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=0 \\
\text{Ts: }f=0\text{ quasi ovunque} \\
\text{5) Hp: }f,g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ ammettono integrale di Lebesgue, }f=g\text{ q. o.} \\
\text{Ts: }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm
\end{gather*}

\begin{enumerate}
\item La funzione di Dirichlet \`{e} una funzione semplice e $I_{%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
}=0$ q. o. perch\'{e} $m\left( 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
\right) =0$, dunque $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}I_{%
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
}dm=0$.
\end{enumerate}

\begin{gather*}
\text{6) Hp: }f,g:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }f,g\geq 0,\alpha ,\beta \geq 0 \\
\text{Ts: }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( \alpha f+\beta g\right) dm=\alpha \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm+\beta \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm \\
\text{7) }f\in \mathcal{L}^{1}\left( m\right) \Longleftrightarrow \left\vert
f\right\vert \in \mathcal{L}^{1}\left( m\right) \text{, e in tal caso} \\
\left\vert \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\right\vert \leq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert f\right\vert dm
\end{gather*}

7) evidenzia la differenza tra l'integrale di Lebesgue e l'integrale di
Riemann: se $f$ \`{e} Riemann integrabile, $\left\vert f\right\vert $ \`{e}
Riemann integrabile, ma non vale il viceversa. Vale una disuguaglianza
analoga a $\left\vert \mathbf{E}\left( X\right) \right\vert \leq \mathbf{E}%
\left( \left\vert X\right\vert \right) $ per l'integrale di Riemann.

\textbf{Teorema di Beppo Levi (convergenza monotona)}%
\begin{gather*}
\text{Hp: }\left( f_{n}\right) _{n\geq 1}\text{ \`{e} una successione di
funzioni misurabili, }f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\text{\`{e} una funzione misurabile t. c. }f_{n}\nearrow f\text{ q. c.} \\
\text{Ts: }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm
\end{gather*}

Il teorema afferma che per una successione di funzioni misurabili non
negative che cresca a $f$ \`{e} possibile scambiare limite e integrale.

\textbf{Teorema di convergenza dominata}%
\begin{gather*}
\text{Hp: }\left( f_{n}\right) _{n\geq 1}\text{ \`{e} una successione di
funzioni misurabili, }g\in \mathcal{L}^{1}\left( m\right) \\
\forall \text{ }n\geq 1\text{ vale }\left\vert f_{n}\right\vert \leq g\text{
q. o. e }\lim_{n\rightarrow +\infty }f_{n}\left( x\right) =f\left( x\right) 
\text{ q. o.} \\
\text{Ts:}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm
\end{gather*}

Se $\exists $ $c\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:f=c$ q. o., non \`{e} vero che $f\in \mathcal{L}^{1}\left( m\right) $, perch%
\'{e} $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}cdm=c\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}dm=cm\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =+\infty $, essendo $1$ una funzione semplice.]

In generale non \`{e} vero se $f$ \`{e} limitata, allora ha integrale di
Lebesgue finito.

Inoltre $1\leq p<q$ non implica $L^{q}\subseteq L^{p}\subseteq L^{1}$, perch%
\'{e} $m\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ non \`{e} un numero reale.

\textbf{Def }Data la misura di Lebesgue $m:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,+\infty \right] $ e $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, dato $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, si definisce $\int_{A}hdm$ come $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hI_{A}dm$.

Si pu\`{o} inoltre notare $\int_{a}^{b}1dx=b-a$: l'integrale di Riemann su
un certo intervallo limitato coincide con la misura di Lebesgue di tale
intervallo.

\textbf{Prop 11.3 (confronto tra Riemann e Lebesgue)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&h:\left[ a,b\right] \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} limitata e Riemann-integrabile} \\
\text{Ts}\text{: } &&h\text{ \`{e} Lebesgue-integrabile e }%
\int_{a}^{b}h\left( x\right) dx=\int_{\left[ a,b\right] }hdm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hI_{\left[ a,b\right] }dm
\end{eqnarray*}

Questo significa che l'insieme delle funzioni Riemann integrabili su un
intervallo compatto sono un sottinsieme delle funzioni Lebesgue integrabili
sullo stesso intervallo. E' quindi molto utile sfruttare l'uguaglianza con
l'integrale di Lebesgue perch\'{e} per esso valgono i teoremi di passaggio
al limite sotto il segno di integrale.

\begin{enumerate}
\item $h\left( x\right) =\frac{1}{x^{2}}I_{[1,+\infty )}\left( x\right) $: $%
h\geq 0$, quindi $\exists $ $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdm$. Voglio sapere se \`{e} finito. Uso il teorema di convergenza monotona
mediante le funzioni troncate: $h_{n}\left( x\right) =\frac{1}{x^{2}}I_{%
\left[ 1,n\right] }\left( x\right) $, $n\geq 1$. $h_{n}\geq 0$ $\forall $ $n$%
, $h\left( x\right) \geq h_{n+1}\left( x\right) \geq h_{n}\left( x\right) $ $%
\forall $ $x$ e $\lim_{n\rightarrow +\infty }h_{n}\left( x\right) =h\left(
x\right) $ $\forall $ $x$. Allora $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h_{n}dm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\frac{1}{x^{2}}I_{\left[ 1,n\right] }\left( x\right) dm=\lim_{n\rightarrow
+\infty }\int_{\left[ 1,n\right] }\frac{1}{x^{2}}dm$. Ma su $\left[ 1,n%
\right] $ l'integrale di Lebesgue coincide con quello di Riemann, quindi
quanto scritto coincide con $\lim_{n\rightarrow +\infty }\int_{1}^{n}\frac{1%
}{x^{2}}dx=1$.

Il ragionamento pu\`{o} essere generalizzato a $h\left( x\right) =f\left(
x\right) I_{[a,+\infty )}\left( x\right) $ con $f\geq 0$: $h\geq 0$, quindi $%
\exists $ $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdm$. Voglio sapere se \`{e} finito. Uso il teorema di convergenza monotona
mediante le funzioni troncate: $h_{n}\left( x\right) =f\left( x\right) I_{%
\left[ a,n\right] }\left( x\right) $, $n\geq \lceil a\rceil $. $h_{n}\geq 0$ 
$\forall $ $n$, $h\left( x\right) \geq h_{n+1}\left( x\right) \geq
h_{n}\left( x\right) $ $\forall $ $x$ e $\lim_{n\rightarrow +\infty
}h_{n}\left( x\right) =h\left( x\right) $ $\forall $ $x$. Allora $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h_{n}dm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) I_{\left[ a,n\right] }\left( x\right)
dm=\lim_{n\rightarrow +\infty }\int_{\left[ 1,n\right] }f\left( x\right) dm$%
. Ma su $\left[ 1,n\right] $ l'integrale di Lebesgue coincide con quello di
Riemann, quindi quanto scritto coincide con $\lim_{n\rightarrow +\infty
}\int_{1}^{n}f\left( x\right) dx$.
\end{enumerate}

Si pu\`{o} dire che $f\sim g$ se $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}gdm$: \`{e} una relazione di equivalenza che induce una partizione di $%
\mathcal{L}^{1}\left( m\right) $ in classi di equivalenza $\left[ f\right] $%
. 

\textbf{Def 11.4} Dato lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, con $F$ funzione di ripartizione di $\mathbf{P}
$, $\mathbf{P}$ \`{e} detta misura di probabilit\`{a} assolutamente continua
se $\exists $ $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ boreliana tale che $f\left( x\right) \geq 0$ $\forall $ $x$ e $F\left(
x\right) =\int_{(-\infty ,x]}fdm$ $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. In tal caso $f$ si dice densit\`{a} continua di $F$ o di $\mathbf{P}$ e $%
F $ si dice assolutamente continua.

Esiste anche una definizione epsilon-delta per definire l'assoluta continuit%
\`{a} di una funzione $F$. Nel seguito si scriver\`{a} $\int_{-\infty
}^{x}f\left( x\right) dx$, integrale di Riemann. Il nome di densit\`{a}
continua per $f$ non fa riferimento a propriet\`{a} analitiche di $f$, cio%
\`{e} non significa che $f$ sia continua, ma solo che $\mathbf{P}$ \`{e}
assolutamente continua. Se $\mathbf{P}$ \`{e} assolutamente continua, \`{e}
continua $F$, per il teorema fondamentale, per cui $\mathbf{P}\left( \left\{
x\right\} \right) =F\left( x\right) -F\left( x^{-}\right) =0$.

Se $\mathbf{P}$ \`{e} assolutamente continua con densit\`{a} $f$, $f$ \`{e}
integrabile secondo Lebesgue perch%
\'{e} misurabile e nonnegativa. Appartiene a $L^{1}\left( m\right) $? Data $%
f_{n}\left( x\right) =f\left( x\right) I_{(-\infty ,n]}\left( x\right) $,
per convergenza monotona ($f_{n}\nearrow f$) vale $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{n}dm=\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f\left( x\right) I_{(-\infty ,n]}\left( x\right) dm=\lim_{n\rightarrow
+\infty }\int_{(-\infty ,n]}f\left( x\right) dm=\lim_{n\rightarrow
+\infty }\int_{-\infty }^{n}f\left( x\right) dx=\lim_{n\rightarrow +\infty
}F\left( n\right) =1$ per le propriet\`{a} di $F$ in quanto funzione di
ripartizione.

\textbf{Teo 11.5 (caratterizzazione della densit\`{a})}%
\begin{gather*}
\text{Hp: }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) \text{ \`{e} uno spazio di probabilit\`{a}, }f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (i) }\mathbf{P}\text{ \`{e} assolutamente continua con densit\`{a} 
}f\Longleftrightarrow f\text{ \`{e} boreliana,} \\
f\left( x\right) \geq 0\text{ }\forall \text{ }x\text{ e }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}fdm=1 \\
\text{(ii) se }\mathbf{P}\text{ \`{e} assolutamente continua con densit\`{a} 
}f\text{, }\mathbf{P}\left( A\right) =\int_{A}fdm\text{ }\forall \text{ }%
A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \\
\text{(iii) se }f_{1},f_{2}\text{ sono densit\`{a} per }\mathbf{P}\text{
assolutamente continua, allora }f_{1}=f_{2}\text{ q.o.}
\end{gather*}

In (ii) vale anche l'implicazione inversa. (iii) significa che $\mathbf{P}$ assolutamente
continua caratterizza $\left[ f\right] $, che \`{e} un insieme di funzioni
uguali a meno di insiemi di misura nulla. Si scrive $f=\frac{d\mathbf{P}}{dm}
$, con la derivata di Radon-Nikodym.

\textbf{Dim*}
(ii) Definisco $\mathbf{\tilde{P}}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] ,$ $\mathbf{\tilde{P}}\left( A\right)
=\int_{A}fdm$ $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. $\mathbf{\tilde{P}}$ \`{e} una misura di probabilit\`{a} perch%
\'{e} $\mathbf{\tilde{P}}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =1$ e si pu\`{o} dimostrare la $\sigma $-additivit\`{a}. Allora la
funzione di ripartizione di $\mathbf{\tilde{P}}$ \`{e} $\tilde{F}\left(
x\right) =\mathbf{\tilde{P}}\left( (-\infty ,x]\right) =\int_{-\infty
}^{x}f\left( t\right) dt$, che coincide con $F\left( x\right) $ per
definizione di probabilit\`{a} assolutamente continua. Poich\'{e} la
funzione di ripartizione caratterizza la $\mathbf{P}$, vale $\mathbf{\tilde{P%
}=P}$, ed effettivamente $\mathbf{P}\left( A\right) =\int_{A}fdm$ $\forall $ 
$A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

(iii) Considero $f_{1},f_{2}$ densit\`{a} per $\mathbf{P}$ assolutamente
continua. Dimostro che $m\left( f_{1}\neq f_{2}\right) =0$, mostrando che $%
m\left( f_{1}>f_{2}\right) =0$ e $m\left( f_{1}<f_{2}\right) =0$. Dato $%
\varepsilon >0$, definisco $A=\left\{ x:f_{1}\left( x\right) +\varepsilon
<f_{2}\left( x\right) \right\} \subseteq \left\{ x:f_{1}\left( x\right)
<f_{2}\left( x\right) \right\} $ (dato $\varepsilon $, in $A$ prendo gli $x$
che permettono di tenere una distanza di almeno $\varepsilon $ da $f_{2}$).
Se $\varepsilon \rightarrow 0$, $A\uparrow \left\{ x:f_{1}\left( x\right)
<f_{2}\left( x\right) \right\} $. Allora, integrando in $dm$ $%
f_{1}+\varepsilon $ e $f_{2}$, si ottiene $\int_{A}\left( f_{1}+\varepsilon
\right) dm\leq \int_{A}f_{2}dm$, cio\`{e}, per linearit\`{a}, $\mathbf{P}%
\left( A\right) +\varepsilon m\left( A\right) \leq \mathbf{P}\left( A\right) 
$. Essendo $\varepsilon >0$, questo implica $m\left( A\right) =0$ e quindi $%
m\left( \left\{ x:f_{1}\left( x\right) <f_{2}\left( x\right) \right\}
\right) =0$. Analogamente, se $A=\left\{ x:f_{1}\left( x\right) <f_{2}\left(
x\right) +\varepsilon \right\} $, si mostra che $m\left( A\right) =0$ e che $%
m\left( \left\{ x:f_{1}\left( x\right) >f_{2}\left( x\right) \right\}
\right) =0$, per cui $m\left( f_{1}\neq f_{2}\right) =m\left( \left\{
x:f_{1}\left( x\right) <f_{2}\left( x\right) \right\} \right) +m\left(
\left\{ x:f_{1}\left( x\right) >f_{2}\left( x\right) \right\} \right) =0$. $%
\blacksquare $

Data $F$, come capisco se esiste una densit\`{a}? Se $F$ \`{e} di puro
salto, \`{e} la funzione di ripartizione di una $\mathbf{P}$ discreta. Se $F$
\`{e} continua e $C^{1}$ a tratti, allora si pu\`{o} dimostrare che la
probabilit\`{a} che essa caratterizza \`{e} assolutamente continua: una sua
densit\`{a} \`{e} $f\left( t\right) =\left\{ 
\begin{array}{c}
F^{\prime }\left( x\right) \text{ se esiste} \\ 
0\text{ altrimenti}%
\end{array}%
\right. $: $C^{\left( 0\right) }$ a tratti, \`{e} nonnegativa perch\'{e} $F$ 
\`{e} monotona non decrescente, ha integrale $1$ per il teorema
fondamentale; inoltre \`{e} misurabile perch\'{e} continua a tratti (quindi
ogni controimmagine pu\`{o} essere scritta come unione di controimmagini,
ciascuna relativa a un tratto in cui $f$ \`{e} continua e quindi misurabile,
ed eventualmente l'insieme dei punti di discontinuit\`{a}), ed \`{e} una
densit\`{a} di $\mathbf{P}$.

Quanto detto sulla densit\`{a} implica anche che se $\mathbf{P}$ \`{e}
assolutamente continua con densit\`{a} $f$, non \`{e} possibile che $\exists 
$ $\alpha >0:\lim_{x\rightarrow +\infty }f\left( x\right) =a$. Infatti, se
cos\`{\i} fosse, preso $\varepsilon =\frac{a}{2}$, esisterebbe $\nu :x>\nu $
implica $\frac{a}{2}<f\left( x\right) <\frac{3}{2}a$. In tal caso si avrebbe
quindi $\int_{-\infty }^{+\infty }f\left( x\right) dx=1\geq \int_{\nu
}^{+\infty }f\left( x\right) dx\geq \int_{\nu }^{+\infty }\frac{a}{2}%
dx=+\infty $, che \`{e} assurdo. In generale, se esiste $\lim_{x\rightarrow
+\infty }f\left( x\right) $, allora dev'essere $\lim_{x\rightarrow +\infty
}f\left( x\right) =0$.

\textbf{Def 11.6} Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ spazio di probabilit\`{a} e $X:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria, $X$ si dice assolutamente continua se la sua legge $%
P^{X}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] $ \`{e} assolutamente continua; in tal
caso la densit\`{a} continua di $P^{X}$ si indica con $f_{X}$.

$f_{X}$ \`{e} spesso detta, con abuso, densit\`{a} di $X$. L'essere
assolutamente continua di $X$ non dice niente sulla sua regolarit\`{a}.

$X$ \`{e} assolutamente continua e $X\in \left[ a,b\right] $ q. c. $%
\Longleftrightarrow $ $\exists $ $f_{X}:f_{X}\left( x\right) =0$ q. o. su $%
\left[ a,b\right] ^{c}$.

Infatti, se $X\in \left[ a,b\right] $ q. c. e $X$ \`{e} assolutamente
continua, $\mathbf{P}\left( X\in A\right) =\mathbf{P}\left( X\in A\cap \left[
a,b\right] \right) $ (perch\'{e} la probabilit\`{a} dell'intersezione tra un
evento qualsiasi e uno quasi certo \`{e} uguale alla probabilit\`{a}
dell'evento qualsiasi) e si ottiene $\int_{A\cap \left[ a,b\right]
}f_{X}dm=\int_{A\cap \left[ a,b\right] }f_{X}\left( t\right)
dt=\int_{A}f_{X}\left( t\right) I_{\left[ a,b\right] }\left( t\right) dt$:
se quindi $A=\left[ a,b\right] ^{c}$ $\mathbf{P}\left( X\in A\right)
=\int_{A}f_{X}dm=0$, cio\`{e} $f_{X}\geq 0$ \`{e} nulla quasi ovunque in $%
\left[ a,b\right] ^{c}$.

Se invece $\exists $ $f_{X}:f_{X}\left( x\right) =0$ q. o. su $\left[ a,b%
\right] ^{c}$, $X$ \`{e} assolutamente continua, e $\mathbf{P}\left( X\in %
\left[ a,b\right] \right) =\int_{\left[ a,b\right] }f_{X}\left( t\right)
dt=1 $ perch\'{e} $\int_{\left[ a,b\right] ^{c}}f_{X}\left( t\right) dt=0$ e 
$\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X}\left( t\right) dt=\int_{\left[ a,b\right] }f_{X}\left( t\right)
dt+\int_{\left[ a,b\right] ^{c}}f_{X}\left( t\right) dt=1$.

Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ e $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a. assolutamente continua con $f_{X},F_{X}$, considero $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $C^{1}$ con $h^{\prime }\left( x\right) \neq 0$ $\forall $ $x$ e mi chiedo
quale sia $F_{Y}$, con $Y=h\left( X\right) $, se $Y$ sia assolutamente
continua, e, se s\`{\i}, quale sia $f_{Y}$.

$F_{Y}\left( t\right) =\mathbf{P}\left( h\left( X\right) \leq t\right) =%
\mathbf{P}\left( X\leq h^{-1}\left( t\right) \right) =F_{X}\left(
h^{-1}\left( t\right) \right) $, che \`{e} $C^{1}$ grazie alle ipotesi
poste. Vale quindi $f_{Y}\left( t\right) =F_{Y}^{\prime }\left( t\right)
=\left\vert g^{\prime }\left( t\right) \right\vert f_{X}\left( g\left(
t\right) \right) $, posto $h^{-1}\left( t\right) =g\left( t\right) $.

\begin{enumerate}
\item Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $X:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a. assolutamente continua con densit\`{a} $f_{X}$, se $\exists $ $\mu
:f_{X}\left( \mu +x\right) =f_{X}\left( \mu -x\right) $ $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, cio\`{e} simmetrica rispetto a $x=\mu $, allora $\mu $ \`{e} una mediana,
cio\`{e} $P\left( X\leq \mu \right) \geq \frac{1}{2}$ e $P\left( X<\mu
\right) \leq \frac{1}{2}$.

Infatti $P\left( X\leq \mu \right) =\int_{-\infty }^{\mu }f_{X}\left(
t\right) dt$, ma per 11.5 $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X}\left( t\right) dt=1=\int_{-\infty }^{\mu }f_{X}\left( t\right)
dt+\int_{\mu }^{+\infty }f_{X}\left( t\right) dt$. Con il cambio di
variabile $z=t-\mu $ $\int_{-\infty }^{\mu }f_{X}\left( t\right)
dt=\int_{-\infty }^{0}f_{X}\left( z+\mu \right) dz$, con quello $t=\mu -w$ $%
\int_{\mu }^{+\infty }f_{X}\left( t\right) dt=-\int_{0}^{-\infty
}f_{X}\left( \mu -w\right) dw=\int_{-\infty }^{0}f_{X}\left( \mu -w\right)
dw=\int_{-\infty }^{0}f_{X}\left( \mu -z\right) dz$. Dato che $f_{X}\left(
z+\mu \right) =f_{X}\left( \mu -z\right) $ $\forall $ $z\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $1=2\int_{-\infty }^{0}f_{X}\left( z+\mu \right) dz$, cio\`{e} $%
\int_{-\infty }^{\mu }f_{X}\left( t\right) dt=\frac{1}{2}=\mathbf{P}\left(
X\leq \mu \right) $.

Se inoltre $X\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $%
\mathbf{E}\left( X\right) =\mu $. Infatti $X-\mu $ e $\mu -X$ hanno la
stessa legge, perch\'{e} $\mathbf{P}\left( X-\mu \leq t\right) =\mathbf{P}%
\left( X\leq t+\mu \right) =\int_{-\infty }^{t+\mu }f_{X}\left( z\right) dz$%
, mentre $\mathbf{P}\left( \mu -X\leq t\right) =\mathbf{P}\left( X\geq \mu
-t\right) =\int_{\mu -t}^{+\infty }f_{X}\left( z\right) dz$, che coincide
con $\mathbf{P}\left( X-\mu \leq t\right) $, come si pu\`{o} verificare con
un cambio di variabile analogo a quello sopra. Poich\'{e} due v. a. con
stessa legge hanno lo stesso valore atteso, vale $\mathbf{E}\left( X-\mu
\right) =\mathbf{E}\left( \mu -X\right) $, cio\`{e}, per linearit\`{a}, $%
\mathbf{E}\left( X\right) =\mu $.
\end{enumerate}

Come calcolo $\mathbf{E}\left( X\right) $ quando $X$ \`{e} assolutamente
continua?

\textbf{Teo 11.7 (regola del valore atteso nel caso assolutamente continuo)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una v.a. assolutamente } \\
\text{continua, con legge }P^{X}\text{ di densit\`{a} }f_{X}\text{; }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} una funzione boreliana } \\
\text{Ts: (1) }h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) \Longleftrightarrow hf_{X}\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,m\right) \\
\text{(2) se }h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,P^{X}\right) \text{ o }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow \left[ 0,+\infty \right] \text{, }\mathbf{E}\left( h\left(
X\right) \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hf_{X}dm
\end{gather*}

Pur somigliando alla regola gi\`{a} vista, questo teorema richiederebbe una
nuova dimostrazione, perch\'{e} $m$ non \`{e} una misura di probabilit\`{a}.
La regola gi\`{a} vista permetteva di calcolare il valore atteso non con un
integrale in $d\mathbf{P}$ ma con uno in $dP^{X}$; questa permette di
calcolarlo non in $dP^{X}$ ma in $dm$, mediante il cambio di variabile $%
dP^{X}=f_{X}dm$ (gi\`{a} visto con l'uguaglianza $\int_{A}d\mathbf{P}%
=\int_{A}fdm$).

(1) significa che $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert h\right\vert f_{X}dm<+\infty $, poich\'{e} $hf_{X}\in
L^{1}\left( m\right) \Longleftrightarrow \left\vert hf_{X}\right\vert \in
L^{1}\left( m\right) $, ma $f_{X}\geq 0$. In (2), per definizione $\mathbf{E}%
\left( h\left( X\right) \right) =\int_{\Omega }h\left( X\left( \omega
\right) \right) d\mathbf{P}\left( \omega \right) $; per la regola del valore
atteso $\mathbf{E}\left( h\left( X\right) \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{X}\left( x\right) $. Inoltre $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hf_{X}dm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) f_{X}\left( x\right) dx$.

Il teorema con $h\left( x\right) =x$ implica che se $X$ \`{e} una v.a.
assolutamente continua, allora $\mathbf{E}\left( X\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}xf_{X}dm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}X\left( \omega \right) f\left( \omega \right) d\omega $ e $X\in L^{1}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) \Longleftrightarrow \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert x\right\vert f_{X}\left( x\right) dx<+\infty $, mentre $%
var\left( X\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( x-\mu \right) ^{2}f_{X}\left( x\right) dx$.

\textbf{Prop (calcolo del valore atteso con la funzione di ripartizione)}%
\begin{gather*}
\text{Hp: }X\text{ \`{e} una v. a. quasi certamente non negativa e
assolutamente} \\
\text{continua con densit\`{a} }f\text{ e funzione di ripartizione }F \\
\text{Ts: }\mathbf{E}\left( X\right) =\int_{0}^{+\infty }\left( 1-F\left(
x\right) \right) dx
\end{gather*}

\textbf{Dim} $\int_{0}^{+\infty }\left( 1-F\left( x\right) \right)
dx=\int_{0}^{+\infty }\mathbf{P}\left( X\geq x\right) dx=\int_{0}^{+\infty
}\left( \int_{x}^{+\infty }f\left( t\right) dt\right) dx$. Questo integrale
doppio \`{e} fatto su un dominio normale rispetto all'asse $x$ (la sezione
del primo quadrante che sta sopra la bisettrice) che pu\`{o} essere visto
come normale rispetto all'asse $t$: per cui $\int_{0}^{+\infty }\left(
\int_{x}^{+\infty }f\left( t\right) dt\right) dx=\int_{0}^{+\infty }\left(
\int_{0}^{t}f\left( t\right) dx\right) dt=\int_{0}^{+\infty }tf\left(
t\right) dt=\mathbf{E}\left( X\right) $. $\blacksquare $

Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ con $\mathbf{P}$ assolutamente continua con
densit\`{a} $f$, dato $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) :m\left( A\right) =0$, allora $\mathbf{P}\left( A\right) =0$.
Infatti $\mathbf{P}\left( A\right) =\mathbf{E}\left( I_{A}\right)
=\int_{\Omega }I_{A}\left( \omega \right) d\mathbf{P}\left( \omega \right)
=\int_{\Omega }I_{A}\left( \omega \right) f\left( \omega \right) dm=0$ perch%
\'{e} $I_{A}\left( \omega \right) f\left( \omega \right) $ \`{e} $0$ quasi
ovunque (in realt\`{a} questa \`{e} proprio la def di misura assolutamente
continua).

\begin{enumerate}
\item $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ con $\mathbf{P}$ che segue la distribuzione
esponenziale $\varepsilon \left( \lambda \right) $, $\lambda >0$. $X\left(
\omega \right) =\omega ^{2}$: calcolo $\mathbf{E}\left( X\right) $. Abbiamo
gi\`{a} visto che in tal caso $P^{X}$ ha densit\`{a} $f_{X}\left( x\right) =%
\frac{\lambda e^{-\lambda \sqrt{x}}}{2\sqrt{x}}I_{\left( 0,+\infty \right)
}\left( x\right) $. Dunque per 11.7 applicata a $P^{X}$ assolutamente
continua $\mathbf{E}\left( X\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}xf_{X}\left( x\right) dx=\int_{0}^{+\infty }\sqrt{x}\frac{\lambda
e^{-\lambda \sqrt{x}}}{2}dx=\lambda \int_{0}^{+\infty }t^{2}e^{-\lambda t}dt=%
\frac{2}{\lambda ^{2}}$. Posso anche utilizzare $\mathbf{E}\left( X\right)
=\int_{\Omega }X\left( \omega \right) d\mathbf{P}\left( \omega \right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}X\left( \omega \right) f\left( \omega \right) d\omega $ perch\'{e} anche $%
\mathbf{P}$ \`{e} assolutamente continua con densit\`{a} $f$: si ottiene
allora $\int_{0}^{+\infty }\omega ^{2}\lambda e^{-\lambda \omega }d\omega =%
\frac{2}{\lambda ^{2}}$.

\item $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $. Data $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., $X$ si dice variabile aleatoria uniforme in $\left( a,b\right) $, e
si scrive $X\sim unif\left( \left( a,b\right) \right) $, se ha densit\`{a} $%
f_{X}\left( x\right) =\frac{1}{b-a}I_{\left[ a,b\right] }\left( t\right) $:
calcolo $\mathbf{E}\left( X\right) =\int_{a}^{b}\frac{x}{b-a}dx=\frac{b+a}{2}
$, mentre $var\left( X\right) =\mathbf{E}\left( \left( X-\mu \right)
^{2}\right) =\int_{a}^{b}\left( x-\mu \right) ^{2}\frac{1}{b-a}dx=\frac{%
\left( b-a\right) ^{2}}{12}$, usando 11.7 con $h\left( x\right) =\left( x-%
\frac{b+a}{2}\right) ^{2}$.

\item $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $. Data $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., $X$ si dice variabile aleatoria di Cauchy di parametro $\alpha $, e
si scrive $X\sim cauchy\left( \alpha \right) $, se ha densit\`{a} $%
f_{X}\left( x\right) =\frac{1}{\pi \left( 1+\left( x-\alpha \right)
^{2}\right) }$ (simmetrica rispetto alla retta verticale $x=\alpha $), dove $%
\frac{1}{\pi }$ \`{e} una costante di normalizzazione. $X\sim cauchy\left(
0\right) $ \`{e} detta t di Student a un grado di libert\`{a}. La funzione
di ripartizione di $X$ \`{e} $F_{X}\left( x\right) =\int_{-\infty }^{x}\frac{%
1}{\pi \left( 1+\left( t-\alpha \right) ^{2}\right) }dt=\frac{1}{\pi }\left[
\arctan \left( t-\alpha \right) \right] _{-\infty }^{x}=\frac{1}{\pi }%
\arctan \left( x-\alpha \right) +\frac{1}{2}$. Per quanto dimostrato in
precedenza sulla simmetria (se $\mathbf{E}\left( X\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ e $f_{X}$ \`{e} simmetrica rispetto a $x=\alpha $, $\mathbf{E}\left(
X\right) =\alpha $ e coincide con la mediana), $\alpha $ \`{e} la mediana
della legge di $X$, cio\`{e} tale che $\mathbf{P}\left( X\leq \alpha \right)
=\frac{1}{2}$; \`{e} evidente anche dal fatto che $P^{X}\left( (-\infty
,\alpha ]\right) =F_{X}\left( \alpha \right) =\frac{1}{2}$. $\mathbf{E}%
\left( X\right) =\frac{1}{\pi }\int_{-\infty }^{+\infty }x\frac{1}{1+\left(
x-\alpha \right) ^{2}}dx$: $\int \frac{x}{1+\left( x-\alpha \right) ^{2}}dx=%
\frac{1}{2}\int \frac{2x-2\alpha }{1+\left( x-\alpha \right) ^{2}}dx+\int 
\frac{\alpha }{1+\left( x-\alpha \right) ^{2}}dx=\frac{1}{2}\ln \left(
1+\left( x-\alpha \right) ^{2}\right) +\alpha \arctan \left( x-\alpha
\right) $, quindi $\mathbf{E}\left( X\right) $ non esiste.

! Per verificarlo con $\alpha =0$, posso alternativamente calcolare $\mathbf{%
E}\left( \left\vert X\right\vert \right) =\int_{-\infty }^{+\infty }\frac{%
\left\vert x\right\vert }{\pi \left( x^{2}+1\right) }dx=\int_{-\infty }^{0}%
\frac{-x}{\pi \left( x^{2}+1\right) }dx+\int_{0}^{+\infty }\frac{x}{\pi
\left( x^{2}+1\right) }dx=+\infty $: $X\not\in L^{1}$, ma potrebbe essere $%
\mathbf{E}\left( X\right) =+\infty $. Uso la definizione di valore atteso: $%
\mathbf{E}\left( X_{+}\right) =\mathbf{E}\left( XI_{\left( 0,+\infty \right)
}\left( X\right) \right) $, cio\`{e}, con $h\left( x\right) =xI_{\left(
0,+\infty \right) }\left( x\right) $, $\int_{-\infty }^{+\infty }xI_{\left(
0,+\infty \right) }\left( x\right) \frac{1}{\pi \left( x^{2}+1\right) }%
dx=\int_{0}^{+\infty }\frac{x}{\pi \left( x^{2}+1\right) }dx=+\infty $ e per
simmetria $\mathbf{E}\left( X_{-}\right) =+\infty $, dunque $X$ non ammette
valore atteso, pur essendo quasi certamente finita.

Dato che $X\not\in L^{1}$, sicuramente $X\not\in L^{2}$. $\mathbf{E}\left(
X^{2}\right) =\int_{-\infty }^{+\infty }x^{2}\frac{1}{\pi \left( 1+\left(
x-\alpha \right) ^{2}\right) }dx=+\infty $ perch\'{e} per $x\rightarrow
+\infty $ la funzione integranda \`{e} asintotica a $k$, quindi non \`{e}
integrabile in senso improprio per $x\rightarrow +\infty $, e per simmetria
neanche per $x\rightarrow -\infty $. (Oppure: integrale di una funzione
nonnegativa, se non \`{e} finito \`{e} $+\infty $).

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria esponenziale di parametro $\lambda >0$, e si
scrive $X\sim \varepsilon \left( \lambda \right) $, se $X$ \`{e}
assolutamente continua con densit\`{a} $f_{X}\left( x\right) =\lambda
e^{-\lambda x}I_{[0,+\infty )}\left( x\right) $. La sua funzione di
ripartizione \`{e} $F_{X}\left( t\right) =\left( 1-e^{-\lambda t}\right)
I_{[0,+\infty )}\left( t\right) $. $\mathbf{E}\left( X\right)
=\int_{0}^{+\infty }\lambda xe^{-\lambda x}dx=\allowbreak \left[
-xe^{-\lambda x}\right] _{0}^{+\infty }+\int_{0}^{+\infty }e^{-\lambda x}dx=%
\frac{1}{\lambda }$. $\mathbf{E}\left( X^{2}\right) =\int_{0}^{+\infty
}\lambda x^{2}e^{-\lambda x}dx=\left[ -x^{2}e^{-\lambda x}\right]
_{0}^{+\infty }+\int_{0}^{+\infty }2xe^{-\lambda x}=\frac{2}{\lambda ^{2}}$,
quindi $var\left( X\right) =\frac{2}{\lambda ^{2}}-\frac{1}{\lambda ^{2}}=%
\frac{1}{\lambda ^{2}}$.

Il quantile inferiore di ordine $\alpha $, cio\`{e} $t_{\alpha }:P^{X}\left(
(-\infty ,t_{\alpha }]\right) =F^{X}\left( t_{\alpha }\right) =\alpha $, si
trova imponendo che $1-e^{-\lambda t_{\alpha }}=\alpha \Longleftrightarrow
t_{\alpha }=\frac{\ln \left( \alpha -1\right) }{\lambda }$. La moda di $X$ 
\`{e} $\arg \max_{[0,+\infty )}f_{X}\left( x\right) =0$.

Ogni v. a. esponenziale gode di una propriet\`{a} detta assenza di memoria:
significa che $\mathbf{P}\left( X>s+t|X>t\right) =\mathbf{P}\left(
X>s\right) $, cio\`{e}, se e. g. $X$ descrive la vita di un oggetto, non
tiene conto dell'usura. Infatti $\mathbf{P}\left( X>s+t|X>t\right) =\frac{%
\mathbf{P}\left( X>s+t,X>t\right) }{\mathbf{P}\left( X>t\right) }=\frac{%
\mathbf{P}\left( X>s+t\right) }{\mathbf{P}\left( X>t\right) }=\frac{%
1-F_{X}\left( s+t\right) }{1-F_{X}\left( t\right) }=\frac{e^{-\lambda
s}e^{-\lambda t}}{e^{-\lambda t}}=e^{-\lambda s}=\mathbf{P}\left( X>s\right) 
$.

Viceversa, se $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ \`{e} uno spazio di probabilit\`{a} e $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} una v. a. assolutamente continua con supporto in $\left( 0,+\infty
\right) $ e tale che $\mathbf{P}\left( X>s+t|X>t\right) =\mathbf{P}\left(
X>s\right) $ $\forall $ $s,t>0$, allora $X\sim \varepsilon \left( \lambda
\right) $, con $\lambda =-\ln \left( \mathbf{P}\left( X>1\right) \right) $.
Si richiede infatti che $\frac{\mathbf{P}\left( X>s+t\right) }{\mathbf{P}%
\left( X>t\right) }=\mathbf{P}\left( X>s\right) $, cio\`{e}, posto $G\left(
x\right) =\mathbf{P}\left( X>x\right) $, che $G\left( s+t\right) =G\left(
s\right) G\left( t\right) $. Vale evidentemente $G\left( 2t\right)
=G^{2}\left( t\right) $, $G\left( 3t\right) =G^{3}\left( t\right) $,..., $%
G\left( nt\right) =G^{n}\left( t\right) $. Analogamente per numeri razionali 
$G\left( \frac{m}{n}t\right) =G^{\frac{m}{n}}\left( t\right) $, e
quindi per i numeri reali $G\left( xt\right) =G^{x}\left( t\right) $ $%
\forall $ $x$. Nel caso particolare di $t=1$ si ha $G\left( x\right)
=G^{x}\left( 1\right) $: vale $G\left( x\right) =\left( G\left( 1\right)
\right) ^{x}=e^{x\ln G\left( 1\right) }$. Si pu\`{o} allora porre, dato che $%
G\left( 1\right) =\mathbf{P}\left( X>1\right) \in \left[ 0,1\right] $, $\ln
G\left( 1\right) =-\lambda $.

\item $\int_{0}^{+\infty }x^{z-1}e^{-x}dx$ \`{e} un numero reale se $1-z<1$,
cio\`{e} $z>0$: \`{e} in tal caso ben definita la funzione $\Gamma :\left(
0,+\infty \right) \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\Gamma \left( z\right) =\int_{0}^{+\infty }x^{z-1}e^{-x}dx$.

Vale $\Gamma \left( z+1\right) =\int_{0}^{+\infty }x^{z}e^{-x}dx=\left[
-x^{z}e^{-x}\right] _{0}^{+\infty }+\int_{0}^{+\infty
}zx^{z-1}e^{-x}dx=z\int_{0}^{+\infty }x^{z-1}e^{-x}dx=z\Gamma \left(
z\right) $. Inoltre $\Gamma \left( 1\right) =1$: da questo si deduce che se $%
z\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ $\Gamma \left( z\right) =\int_{0}^{+\infty }x^{z-1}e^{-x}dx=\left(
z-1\right) !$. [Si pu\`{o} verificare direttamente integrando per parti: $%
\int x^{z-1}e^{-x}dx=-x^{z-1}e^{-x}+\int \left( z-1\right) x^{z-2}e^{-x}dx$;
analogamente $\int x^{z-2}e^{-x}dx=-x^{z-2}e^{-x}+\int \left( z-2\right)
x^{z-3}e^{-x}dx$. Iterando il procedimento si ottiene che, se $z$ \`{e}
naturale, $\int x^{z-1}e^{-x}dx=-x^{z-1}e^{-x}-\left( z-1\right)
x^{z-2}e^{-x}-\left( z-1\right) \left( z-2\right) x^{z-3}e^{-x}-...-\left(
z-1\right) \left( z-2\right) ...1e^{-x}$, con $z$ addendi. Quindi $\Gamma
\left( z\right) =\int_{0}^{+\infty }x^{z-1}e^{-x}dx=\left( z-1\right) !$,
perch\'{e} tutti gli altri termini si annullano.] Si pu\`{o} anche
dimostrare che $\Gamma \left( \frac{1}{2}\right) =\sqrt{\pi }$. La somma
di gamma di parametri $\alpha ,\lambda $ \`{e} una gamma (dim con la f
caratteristica)

Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria gamma, e si scrive $X\sim \Gamma \left( \alpha
,\lambda \right) $, se $X$ \`{e} assolutamente continua con densit\`{a} $%
f_{X}\left( x\right) =cx^{\alpha -1}e^{-\lambda x}I_{\left( 0,+\infty
\right) }\left( x\right) $, con costante di normalizzazione $c=\frac{\lambda
^{\alpha }}{\Gamma \left( \alpha \right) }$ e $\alpha ,\lambda >0$. $X\sim
\Gamma \left( 1,\lambda \right) $ \`{e} una v. a. esponenziale di parametro $%
\lambda $, $X\sim \Gamma \left( \frac{n}{2},\frac{1}{2}\right) $ \`{e} detta
variabile aleatoria chi-quadro a $n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ gradi di libert\`{a}. $f_{X}\left( x\right) =cx^{\alpha -1}e^{-\lambda
x}I_{\left( 0,+\infty \right) }\left( x\right) $ \`{e} effettivamente una
densit\`{a} perch\'{e} \`{e} nonnegativa e $\int_{0}^{+\infty }x^{\alpha
-1}e^{-\lambda x}dx=\frac{\Gamma \left( \alpha \right) }{\lambda ^{\alpha }}$
$\forall $ $\alpha $.

Per trovare la moda di $f$, se $\alpha \geq 1$, si calcola $\frac{%
df_{X}\left( x\right) }{dx}=\left( \alpha -1\right) x^{\alpha -2}e^{-\lambda
x}-\lambda x^{\alpha -1}e^{-\lambda x}=x^{\alpha -2}e^{-\lambda x}\left(
\alpha -1-\lambda x\right) =0\Longleftrightarrow x=\frac{\alpha -1}{\lambda }
$: la moda \`{e} $\arg \max_{\left( 0,+\infty \right) }f_{X}\left( x\right) =%
\frac{\alpha -1}{\lambda }$. Se invece $\alpha <1$ $f_{X}$ \`{e} decrescente
in $\left( 0,+\infty \right) $ e ha massimo in $0$, che non costituisce una
moda.

In generale $\mathbf{E}\left( X\right) =\int_{0}^{+\infty }\frac{\lambda
^{\alpha }}{\Gamma \left( \alpha \right) }x^{\alpha }e^{-\lambda x}dx$: lo
riscrivo per far saltare fuori la densit\`{a} di una v. a. $X\sim \Gamma
\left( \alpha +1,\lambda \right) $, ottenendo quindi $\frac{\Gamma \left(
\alpha +1\right) }{\Gamma \left( \alpha \right) }\frac{1}{\lambda }%
\int_{0}^{+\infty }\frac{\lambda ^{\alpha +1}}{\Gamma \left( \alpha
+1\right) }x^{\alpha }e^{-\lambda x}dx=\frac{\Gamma \left( \alpha +1\right) 
}{\lambda \Gamma \left( \alpha \right) }=\frac{\alpha }{\lambda }$. In
generale, dato $\beta :\alpha +\beta >0$ (per poter calcolare $\Gamma \left(
\alpha +\beta \right) $), $\mathbf{E}\left( X^{\beta }\right)
=\int_{0}^{+\infty }\frac{\lambda ^{\alpha }}{\Gamma \left( \alpha \right) }%
x^{\alpha -1+\beta }e^{-\lambda x}dx=\frac{\Gamma \left( \alpha +\beta
\right) }{\Gamma \left( \alpha \right) }\frac{1}{\lambda ^{\beta }}%
\int_{0}^{+\infty }\frac{\lambda ^{\alpha +\beta }}{\Gamma \left( \alpha
+\beta \right) }x^{\alpha +\beta -1}e^{-\lambda x}dx=\frac{\Gamma \left(
\alpha +\beta \right) }{\lambda ^{\beta }\Gamma \left( \alpha \right) }$.

Invece, posto $\mu =\frac{\alpha }{\lambda }$, $var\left( X\right) =\mathbf{E%
}\left( X^{2}\right) -\mu ^{2}$. Per quanto visto sopra $\mathbf{E}\left(
X^{2}\right) =\frac{\Gamma \left( \alpha +2\right) }{\lambda ^{2}\Gamma
\left( \alpha \right) }=\frac{\alpha \left( \alpha +1\right) }{\lambda ^{2}}$%
, quindi $var\left( X\right) =\frac{\alpha \left( \alpha +1\right) }{\lambda
^{2}}-\frac{\alpha ^{2}}{\lambda ^{2}}=\frac{\alpha }{\lambda ^{2}}$. Per $%
\alpha =1$ si ottengono valore atteso e varianza dell'esponenziale.

Se $c>0$, $Y=cX\sim \Gamma \left( \alpha ,\frac{\lambda }{c}\right) $.
Infatti $\mathbf{P}\left( Y\leq t\right) =\mathbf{P}\left( X\leq \frac{t}{c}%
\right) =F_{X}\left( \frac{t}{c}\right) =\int_{0}^{\frac{t}{c}}\frac{\lambda
^{\alpha }}{\Gamma \left( \alpha \right) }x^{\alpha -1}e^{-\lambda x}dx$.
Con il cambio di variabile $w=xc$ si ottiene $\int_{0}^{\frac{t}{c}}\frac{%
\lambda ^{\alpha }}{\Gamma \left( \alpha \right) }x^{\alpha -1}e^{-\lambda
x}dx=\int_{0}^{t}\frac{1}{\Gamma \left( \alpha \right) }\left( \frac{\lambda 
}{c}\right) ^{\alpha }w^{\alpha -1}e^{-\frac{\lambda }{c}w}dw$, cio\`{e} $%
F_{Y}\left( t\right) =\int_{0}^{t}f_{Y}\left( x\right) dx$ con $f_{Y}\left(
x\right) =\frac{1}{\Gamma \left( \alpha \right) }\left( \frac{\lambda }{c}%
\right) ^{\alpha }x^{\alpha -1}e^{-\frac{\lambda }{c}x}$: $Y$ \`{e} una
gamma di parametri $\alpha $ e $\frac{\lambda }{c}$.

Se $\alpha =n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, la funzione di ripartizione \`{e} $F\left( t\right) =\left(
1-\sum_{k=0}^{n-1}e^{-\lambda t}\frac{\left( \lambda t\right) ^{k}}{k!}%
\right) I_{\left( 0,+\infty \right) }\left( t\right) $. Infatti $\mathbf{P}%
\left( X\leq t\right) =\int_{-\infty }^{t}\frac{\lambda ^{\alpha }}{\Gamma
\left( \alpha \right) }x^{\alpha -1}e^{-\lambda x}dx=\frac{\lambda ^{\alpha }%
}{\left( \alpha -1\right) !}\int_{-\infty }^{t}x^{\alpha -1}e^{-\lambda x}dx$%
. $\int x^{\alpha -1}e^{-\lambda x}dx=-\frac{1}{\lambda }x^{\alpha
-1}e^{-\lambda x}+\frac{1}{\lambda }\int \left( \alpha -1\right) x^{\alpha
-2}e^{-\lambda x}dx$; analogamente $\int x^{\alpha -2}e^{-\lambda x}dx=-%
\frac{1}{\lambda }x^{\alpha -2}e^{-\lambda x}+\frac{1}{\lambda }\int \left(
\alpha -2\right) x^{\alpha -3}e^{-x}dx$. Iterando il procedimento si ottiene
che, dato che $\alpha \in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, $\int x^{\alpha -1}e^{-\lambda x}dx=-\frac{1}{\lambda }x^{\alpha
-1}e^{-\lambda x}-\frac{\alpha -1}{\lambda ^{2}}x^{\alpha -2}e^{-\lambda x}-%
\frac{\left( \alpha -1\right) \left( \alpha -2\right) }{\lambda ^{3}}%
x^{\alpha -3}e^{-\lambda x}-...-\frac{\left( \alpha -1\right) \left( \alpha
-2\right) ...1}{\lambda ^{\alpha }}e^{-\lambda x}$, con $\alpha $ addendi.
Quindi $\mathbf{P}\left( X\geq t\right) =\frac{\lambda ^{\alpha }}{\left(
\alpha -1\right) !}\int_{t}^{+\infty }x^{\alpha -1}e^{-\lambda x}dx=\frac{%
\lambda ^{\alpha }}{\left( \alpha -1\right) !}\left[ \sum_{k=0}^{\alpha
-1}e^{-\lambda t}\frac{\frac{\left( \alpha -1\right) !}{k!}t^{k}}{\lambda
^{\alpha -k}}\right] =\sum_{k=0}^{\alpha -1}e^{-\lambda t}\frac{\left(
\lambda t\right) ^{k}}{k!}$ e $\mathbf{P}\left( X\leq t\right) =\left(
1-\sum_{k=0}^{\alpha -1}e^{-\lambda t}\frac{\left( \lambda t\right) ^{k}}{k!}%
\right) I_{\left( 0,+\infty \right) }\left( t\right) $.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria normale di media $\mu $ e varianza $\sigma
^{2} $, e si scrive $X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) $, se $%
X $ \`{e} assolutamente continua con densit\`{a} $f_{X}\left( x\right) =%
\frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{-\frac{1}{2\sigma ^{2}}\left( x-\mu
\right) ^{2}}$.

Con la sostituzione $t=x-\mu $, $\mathbf{E}\left( X\right) =\int_{-\infty
}^{+\infty }x\frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{-\frac{1}{2\sigma ^{2}}%
\left( x-\mu \right) ^{2}}dx=\frac{1}{\sqrt{2\pi \sigma ^{2}}}\int_{-\infty
}^{+\infty }\left( t+\mu \right) e^{-\frac{t^{2}}{2\sigma ^{2}}}dt$: $%
\int_{-\infty }^{+\infty }te^{-\frac{t^{2}}{2\sigma ^{2}}}dt=0$ perch\'{e} $%
te^{-\frac{t^{2}}{2\sigma ^{2}}}$ \`{e} una funzione dispari integrabile in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, mentre $\int_{-\infty }^{+\infty }\frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{-%
\frac{t^{2}}{2\sigma ^{2}}}dt=1$ perch\'{e} \`{e} l'integrale in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ di una densit\`{a} di probabilit\`{a} con $\mu =0$. Dunque $\mathbf{E}%
\left( X\right) =\mu $. Con la sostituzione $x-\mu =t$ $var\left( X\right)
=\int_{-\infty }^{+\infty }\left( x-\mu \right) ^{2}\frac{1}{\sqrt{2\pi
\sigma ^{2}}}e^{-\frac{1}{2\sigma ^{2}}\left( x-\mu \right) ^{2}}dx=\frac{1}{%
\sqrt{2\pi \sigma ^{2}}}\int_{-\infty }^{+\infty }t^{2}e^{-\frac{1}{2\sigma
^{2}}t^{2}}dt$. $var\left( X\right) =\frac{2}{\sqrt{2\pi \sigma ^{2}}}%
\int_{0}^{+\infty }t^{2}e^{-\frac{1}{2\sigma ^{2}}t^{2}}dt$.

Con la sostituzione $t^{2}=z$ si ha $\int_{0}^{+\infty }t^{2}e^{-\frac{1}{%
2\sigma ^{2}}t^{2}}dt=\int_{0}^{+\infty }\frac{1}{2}\sqrt{z}e^{-\frac{1}{%
2\sigma ^{2}}z}dz$. Usando la densit\`{a} gamma, $\int_{0}^{+\infty }\sqrt{z}%
e^{-\frac{1}{2\sigma ^{2}}z}dz=\Gamma \left( \frac{3}{2}\right) \left(
2\sigma ^{2}\right) ^{\frac{3}{2}}\int_{0}^{+\infty }\frac{\left( \frac{1}{%
2\sigma ^{2}}\right) ^{\frac{3}{2}}}{\Gamma \left( \frac{3}{2}\right) }\sqrt{%
z}e^{-\frac{1}{2\sigma ^{2}}z}dz=\Gamma \left( \frac{3}{2}\right) \left(
2\sigma ^{2}\right) ^{\frac{3}{2}}$. Quindi $var\left( X\right) =\frac{2}{%
\sqrt{2\pi \sigma ^{2}}}\frac{1}{2}\Gamma \left( \frac{3}{2}\right) \left(
2\sigma ^{2}\right) ^{\frac{3}{2}}=\frac{1}{\sqrt{2\pi }}\frac{\sqrt{\pi }}{2%
}2\sqrt{2}\sigma ^{2}=\sigma ^{2}$.

Considero $Y=\left\vert X\right\vert $. Poich\'{e} $F_{X}$, se $X\sim 
\mathcal{N}\left( \mu ,\sigma ^{2}\right) $, \`{e} $C^{\infty }$, anche $Y$ 
\`{e} assolutamente continua, avendo funzione di ripartizione $F_{Y}\left(
t\right) =\left( F_{X}\left( t\right) -F_{X}\left( -t\right) \right)
I_{\left( 0,+\infty \right) }\left( t\right) $, e quindi $f_{Y}\left(
t\right) =\left( f_{X}\left( t\right) +f_{X}\left( -t\right) \right)
I_{\left( 0,+\infty \right) }\left( t\right) =\frac{1}{\sqrt{2\pi \sigma ^{2}%
}}e^{-\frac{t^{2}+\mu ^{2}}{2\sigma ^{2}}}\left( e^{\frac{\mu t}{\sigma ^{2}}%
}+e^{-\frac{\mu t}{\sigma ^{2}}}\right) I_{\left( 0,+\infty \right) }\left(
t\right) $. $\mathbf{E}\left( Y\right) =\int_{0}^{+\infty }tf_{X}\left(
t\right) dt+\int_{0}^{+\infty }tf_{X}\left( -t\right) dt=\frac{1}{\sqrt{2\pi
\sigma ^{2}}}\left( \int_{0}^{+\infty }te^{-\frac{1}{2\sigma ^{2}}\left(
t-\mu \right) ^{2}}dt+\int_{0}^{+\infty }te^{-\frac{1}{2\sigma ^{2}}\left(
-t-\mu \right) ^{2}}dt\right) $ ??

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $Y:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria lognormale di media $\mu $ e varianza $\sigma
^{2}$, e si scrive $Y\sim \log \mathcal{N}\left( \mu ,\sigma ^{2}\right) $,
se $Y=e^{X}$ con $X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) $.

$F_{Y}\left( t\right) =\mathbf{P}\left( Y\leq t\right) =\mathbf{P}\left(
X\leq \ln t\right) =\int_{-\infty }^{\ln t}\frac{1}{\sqrt{2\pi \sigma ^{2}}}%
e^{-\frac{1}{2\sigma ^{2}}\left( x-\mu \right) ^{2}}dx$, cio\`{e}, con il
cambio di variabile $z=e^{x}$, $\int_{0}^{t}\frac{1}{\sqrt{2\pi \sigma ^{2}}}%
e^{-\frac{1}{2\sigma ^{2}}\left( \ln z-\mu \right) ^{2}}\frac{1}{z}dz$, cio%
\`{e} $Y$ \`{e} assolutamente continua con densit\`{a} $f_{Y}\left( z\right)
=\frac{1}{z\sqrt{2\pi \sigma ^{2}}}e^{-\frac{1}{2\sigma ^{2}}\left( \ln
z-\mu \right) ^{2}}I_{\left( 0,+\infty \right) }\left( z\right) $.

$\mathbf{E}\left( Y^{k}\right) =\mathbf{E}\left( e^{kX}\right) =\frac{1}{%
\sqrt{2\pi \sigma ^{2}}}\int_{-\infty }^{+\infty }e^{kx}e^{-\frac{1}{2\sigma
^{2}}\left( x-\mu \right) ^{2}}dx$: con la sostituzione $\frac{x-\mu }{%
\sigma }=t$, $e^{k\mu }\int_{-\infty }^{+\infty }\frac{1}{\sqrt{2\pi }}%
e^{k\sigma t}e^{-\frac{1}{2}t^{2}}dx$. Scrivo $-\frac{1}{2}t^{2}+k\sigma t=-%
\frac{1}{2}\left( t-k\sigma \right) ^{2}+\frac{1}{2}k^{2}\sigma ^{2}$:
allora ottengo $e^{k\mu }\int_{-\infty }^{+\infty }\frac{1}{\sqrt{2\pi }}e^{-%
\frac{1}{2}\left( t-k\sigma \right) ^{2}}e^{\frac{1}{2}k^{2}\sigma
^{2}}dx=e^{\frac{1}{2}k^{2}\sigma ^{2}+k\mu }$, perch\'{e} all'interno c'%
\`{e} l'integrale della densit\`{a} di una normale di valore atteso $k\sigma 
$ e varianza $1$.

Quindi $var\left( Y\right) =\mathbf{E}\left( Y^{2}\right) -\mathbf{E}%
^{2}\left( Y\right) =e^{2\sigma ^{2}+2\mu }-e^{\sigma ^{2}+2\mu }=e^{2\mu
+\sigma ^{2}}\left( e^{\sigma ^{2}}-1\right) $.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $ e $T:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria, si definisce intensit\`{a} di guasto di $T$ $h\left(
t\right) =\lim_{\Delta t\rightarrow 0}\frac{P\left( t<T<t+\Delta
t|T>t\right) }{\Delta t}=\lim_{\Delta t\rightarrow 0}\frac{\mathbf{P}\left(
t<T<t+\Delta t\right) }{\Delta t\mathbf{P}\left( T>t\right) }=\lim_{\Delta
t\rightarrow 0}\frac{F_{T}\left( t+\Delta t\right) -F_{T}\left( t\right) }{%
\Delta t}\frac{1}{1-F_{T}\left( t\right) }=\frac{F_{T}^{\prime }\left(
t\right) }{1-F_{T}\left( t\right) }$. Se inoltre $T$ \`{e} assolutamente
continua, $h\left( t\right) =\frac{f_{T}\left( t\right) }{1-F_{T}\left(
t\right) }$. L'intensit\`{a} di guasto, se $T$ rappresenta la durata di un
macchinario, esprime quanto \`{e} imminente un guasto, dato che $T$ \`{e}
arrivata al valore $t$. Si pu\`{o} dimostrare che $h$ caratterizza $F_{T}$,
cio\`{e} $F_{T}\left( t\right) =1-e^{-\int_{0}^{t}h\left( s\right) ds}$. Se $%
T\sim \varepsilon \left( \lambda \right) $, $h\left( t\right) =\frac{\lambda
e^{-\lambda t}}{e^{-\lambda t}}=\lambda $ \`{e} costante, dato che
l'esponenziale gode dell'assenza di memoria.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria Weibull di parametri $\alpha ,\lambda $, e si
scrive $X\sim weib\left( \alpha ,\lambda \right) $ se la sua legge ha
funzione di ripartizione $F_{X}\left( t\right) =\left( 1-e^{-\lambda
t^{\alpha }}\right) I_{[0,+\infty )}\left( t\right) $, o equivalentemente
densit\`{a} $f_{X}\left( t\right) =\lambda \alpha t^{\alpha -1}e^{-\lambda
t^{\alpha }}I_{\left( 0,+\infty \right) }\left( t\right) $. $X\sim
weib\left( 1,\lambda \right) $ \`{e} un'esponenziale. Calcolo $\mathbf{E}%
\left( X\right) =\lambda \alpha \int_{0}^{+\infty }t^{\alpha }e^{-\lambda
t^{\alpha }}dt$ con il cambio di variabile $t^{\alpha }=x$: si ottiene $%
\lambda \alpha \int_{0}^{+\infty }\frac{1}{\alpha }x^{\frac{1}{\alpha }%
-1}xe^{-\lambda x}dx=\lambda \int_{0}^{+\infty }x^{\frac{1}{\alpha }%
}e^{-\lambda x}dx=\frac{\Gamma \left( \frac{1}{\alpha }+1\right) }{\lambda ^{%
\frac{1}{\alpha }}}\int_{0}^{+\infty }\frac{\lambda ^{\frac{1}{\alpha }+1}}{%
\Gamma \left( \frac{1}{\alpha }+1\right) }x^{\frac{1}{\alpha }}e^{-\lambda
x}dx=\frac{\Gamma \left( \frac{1}{\alpha }+1\right) }{\lambda ^{\frac{1}{%
\alpha }}}=\frac{\Gamma \left( \frac{1}{\alpha }\right) }{\alpha \lambda ^{%
\frac{1}{\alpha }}}$.

L'intensit\`{a} di guasto di $T$ \`{e}, supponendo $t>0$, $h\left( t\right) =%
\frac{\lambda \alpha t^{\alpha -1}e^{-\lambda t^{\alpha }}}{e^{-\lambda
t^{\alpha }}}=\lambda \alpha t^{\alpha -1}$. Se $\alpha >1$ $h\left(
t\right) $ \`{e} crescente in $t$, se $\alpha \in \left( 0,1\right) $ \`{e}
decrescente: un guasto \`{e} pi\`{u} probabile all'inizio.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathbf{P}\right) $, $X:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ si dice variabile aleatoria beta di parametri $\alpha ,\beta $, e si
scrive $X\sim \beta \left( \alpha ,\beta \right) $, se \`{e} assolutamente
continua con densit\`{a} $f_{X}\left( t\right) =\frac{\Gamma \left( \alpha
+\beta \right) }{\Gamma \left( \alpha \right) \Gamma \left( \beta \right) }%
u^{\alpha -1}\left( 1-u\right) ^{\beta -1}I_{\left( 0,1\right) }\left(
u\right) $.
\end{enumerate}

\section{Variabili aleatorie indipendenti e spazi prodotto}

\textbf{Def 12.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}%
\right) $ spazi misurabili, $X:\Omega \rightarrow E,Y:\Omega \rightarrow F$
variabili aleatorie, si dice che $X$ e $Y$ sono variabili aleatorie
indipendenti se $\forall $ $A\in \mathcal{E},\forall $ $B\in \mathcal{F}$
vale $\mathbf{P}\left( \left( X\in A\right) \cap \left( Y\in B\right)
\right) =\mathbf{P}\left( X\in A\right) \mathbf{P}\left( Y\in B\right) $.

Si scrive spesso $\mathbf{P}\left( \left( X\in A\right) \cap \left( Y\in
B\right) \right) =\mathbf{P}\left( X\in A,Y\in B\right) $. Si noti che $X,Y$
devono avere lo stesso dominio. La definizione significa che gli tutti gli
eventi generati da $X$, cio\`{e} $X^{-1}\left( A\right) $ al variare di $%
A\in \mathcal{E}$, sono indipendenti da tutti gli eventi generati da $Y$, cio%
\`{e} $Y^{-1}\left( B\right) $ al variare di $B\in \mathcal{F}$.

\begin{enumerate}
\item Lancio due volte una moneta: $\Omega =\left\{ t,c\right\} ^{2}$, $%
\mathcal{A}=2^{\Omega }$. Definisco $C_{1}=\left\{ \omega \in \Omega :\omega
_{1}=c\right\} =\left\{ \left( c,c\right) ,\left( c,t\right) \right\} $, $%
C_{2}=\left\{ \omega \in \Omega :\omega _{2}=c\right\} =\left\{ \left(
c,c\right) ,\left( t,c\right) \right\} $, $T_{1}=C_{1}^{c}$, $%
T_{2}=C_{2}^{c} $. Essendo $\left\{ T_{1},C_{1}\right\} $, $\left\{
T_{2},C_{2}\right\} $ una partizione di $\Omega $, per assegnare $\mathbf{P}$
posso stabilire $\mathbf{P}\left( T_{1}\right) ,\mathbf{P}\left(
T_{2}\right) $ decidendo che i due lanci sono indipendenti, per 4.1, oppure
posso assegnare $\mathbf{P}$ su $\mathcal{C}=\left\{ T_{1},T_{2},T_{1}\cap
T_{2}\right\} $, dato che $\sigma \left( \mathcal{C}\right) =2^{\Omega }$, per 5.2. Stabilisco $\mathbf{P}\left( T_{1}\right) =\mathbf{%
P}\left( T_{2}\right) =p$ e $\mathbf{P}\left( T_{1}\cap T_{2}\right) =%
\mathbf{P}\left( T_{1}\right) \mathbf{P}\left( T_{2}\right) $, cio\`{e} la
moneta non \`{e} necessariamente equa: quindi $\mathbf{P}\left( C_{1}\right)
=1-p$. Definisco $X\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se }\omega _{1}=c \\ 
0\text{ altrimenti}%
\end{array}%
\right. $, $Y\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se }\omega _{2}=c \\ 
0\text{ altrimenti}%
\end{array}%
\right. $: $\left( X=1\right) =C_{1},\left( X=0\right) =T_{1},\left(
Y=1\right) =C_{2},\left( Y=0\right) =T_{2}$. Mi chiedo se $X\perp Y$, con $%
\mathcal{E}=\mathcal{F=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Ma $\left( X\in A\right) $ pu\`{o} essere solo $\left\{ 
\begin{array}{c}
\Omega \\ 
\varnothing \\ 
\left( X=0\right) \\ 
\left( X=1\right)%
\end{array}%
\right. $ $\forall $ $A\in \mathcal{E}$, e analogamente $\left( Y\in
B\right) $ solo $\left\{ 
\begin{array}{c}
\Omega \\ 
\varnothing \\ 
\left( Y=0\right) \\ 
\left( Y=1\right)%
\end{array}%
\right. $. Se almeno uno tra $X^{-1}\left( A\right) ,Y^{-1}\left( B\right) $ 
\`{e} $\Omega $ o $\varnothing $, vale l'indipendenza tra eventi. Se $%
A=\left\{ 0\right\} ,B=\left\{ 0\right\} $, $\mathbf{P}\left( X=0,Y=0\right)
=\mathbf{P}\left( T_{1}\cap T_{2}\right) =\mathbf{P}\left( T_{1}\right) 
\mathbf{P}\left( T_{2}\right) =\mathbf{P}\left( X=0\right) \mathbf{P}\left(
Y=0\right) $. Analogamente $\mathbf{P}\left( X=1,Y=1\right) =\mathbf{P}%
\left( T_{1}^{c}\cap T_{2}^{c}\right) =\mathbf{P}\left( C_{1}\cap
C_{2}\right) =\mathbf{P}\left( C_{1}\right) \mathbf{P}\left( C_{2}\right) $
perch\'{e} $T_{1}\perp T_{2}\Longleftrightarrow T_{1}^{c}\perp T_{2}^{c}$, e
poich\'{e} $T_{1}\perp T_{2}\Longleftrightarrow T_{1}\perp
T_{2}^{c}\Longleftrightarrow T_{1}^{c}\perp T_{2}^{c}$, vale anche $\mathbf{P%
}\left( X=0,Y=1\right) =\mathbf{P}\left( X=0\right) \mathbf{P}\left(
Y=1\right) $ e $\mathbf{P}\left( X=1,Y=0\right) =\mathbf{P}\left( X=1\right) 
\mathbf{P}\left( Y=0\right) $. Dunque $X,Y$ sono indipendenti, e per
verificarlo \`{e} sufficiente controllare che $\mathbf{P}\left(
X=0,Y=0\right) =\mathbf{P}\left( X=0\right) \mathbf{P}\left( Y=0\right) $.

Siano $Z=X+Y,W=X-Y,V=\left\vert X-Y\right\vert $. Mi chiedo se $Z\perp
W,Z\perp V$. Mostro che se $V=h\left( Z\right) $, non \`{e} possibile $%
V\perp Z$.

\item Considero un'urna con $N\geq 2$ palline nere e $B\geq 2$
bianche, e per $k=1,2$ $X_{k}\left( \omega \right) =\left\{ 
\begin{array}{c}
1\text{ se alla }k\text{-esima estrazione esce }N \\ 
0\text{ altrimenti}%
\end{array}%
\right. $. Estraggo con reimmissione: allora $X_{1}\perp X_{2}$, perch\'{e} $%
\mathbf{P}\left( X_{1}=1,X_{2}=1\right) =\frac{N}{N+B}\cdot \frac{N}{N+B}=%
\mathbf{P}\left( X_{1}=1)\mathbf{P}(X_{2}=1\right) $, quindi $X_{1}\perp
X_{2}$, come sopra. Se invece estraggo senza reimmissione, $\mathbf{P}\left(
X_{1}=1,X_{2}=1\right) =\frac{N}{N+B}\cdot \frac{N}{N+B-1}\neq \mathbf{P}%
\left( X_{1}=1)\mathbf{P}(X_{2}=1\right) $.

\item Siano $X_{1},...,X_{n}$ v. a. indipendenti, $X_{M}=\max \left\{
X_{1},...,X_{n}\right\} $, $X_{m}=\min \left\{ X_{1},...,X_{n}\right\} $. $%
F_{X_{M}}\left( t\right) =\mathbf{P}\left( \max \left\{
X_{1},...,X_{n}\right\} \leq t\right) =\mathbf{P}\left( X_{1}\leq
t,...,X_{n}\leq t\right) =F_{\mathbf{X}}\left( \left( t,t,..,t\right)
\right) $. Usando l'ipotesi d'indipendenza, $\mathbf{P}\left( X_{1}\leq
t,...,X_{n}\leq t\right) =\mathbf{P}\left( X_{1}\leq t\right) ...\mathbf{P}%
\left( X_{n}\leq t\right) =F_{X_{1}}\left( t\right) ...F_{X_{n}}\left(
t\right) $. Se le $X_{i}$ sono inoltre identicamente distribuite, si ottiene 
$F_{X_{M}}\left( t\right) =F_{X_{i}}^{n}\left( t\right) $. $F_{X_{m}}\left(
t\right) =\mathbf{P}\left( \min \left\{ X_{1},...,X_{n}\right\} \leq
t\right) =1-\mathbf{P}\left( X_{1}>t,...,X_{n}>t\right) $, cio\`{e}, per
indipendenza, $1-\mathbf{P}\left( X_{1}>t\right) ...\mathbf{P}\left(
X_{n}>t\right) =1-\left( 1-F_{X_{1}}\left( t\right) \right) ...\left(
1-F_{X_{n}}\left( t\right) \right) $\textbf{. }Se le $X_{i}$ sono inoltre
identicamente distribuite, si ottiene $F_{X_{m}}\left( t\right) =1-\left(
1-F_{X_{i}}\left( t\right) \right) ^{n}$.

Se quindi $X_{i}\sim \varepsilon \left( \lambda _{i}\right) $ $\forall $ $%
i=1,...,n$, allora $X_{m}\sim \varepsilon \left( \lambda _{1}+...+\lambda
_{n}\right) $. Infatti $F_{X_{m}}\left( t\right) =1-\left( 1-F_{X_{1}}\left(
t\right) \right) ...\left( 1-F_{X_{n}}\left( t\right) \right) =1-e^{-\left(
\lambda _{1}+...+\lambda _{n}\right) t}$, che \`{e} quindi assolutamente
continua.
\end{enumerate}

La definizione data \`{e} abbastanza difficile da usare.

\textbf{Teo 12.2 (condizioni equivalenti di indipendenza)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}%
\right) \text{ spazi misurabili, }X:\Omega \rightarrow E,Y:\Omega
\rightarrow F\text{ v. a.} \\
\text{Ts}\text{: (1) }X\perp Y\Longleftrightarrow \text{(2) }\forall \text{ }%
h:\left( E,\mathcal{E}\right) \rightarrow \left( E^{\prime },\mathcal{E}%
^{\prime }\right) \text{, }\forall \text{ }g:\left( F,\mathcal{F}\right)
\rightarrow \left( F^{\prime },\mathcal{F}^{\prime }\right) \text{ misurabili%
} \\
h\left( X\right) \perp g\left( Y\right) \Longleftrightarrow \text{(3) }%
\forall \text{ }h,g\text{ nelle classi 1, 2, 3 }\mathbf{E}\left( h\left(
X\right) g\left( Y\right) \right) =\mathbf{E}\left( h\left( X\right) \right) 
\mathbf{E}\left( g\left( Y\right) \right)
\end{gather*}

dove la classe $1$ \`{e} l'insieme delle $h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $g:F\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ misurabili con $h,g\geq 0$; la classe $2$ \`{e} l'insieme delle $%
h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $g:F\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ misurabili e limitate; la classe $3$ \`{e} l'insieme delle $h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $g:F\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ continue e limitate. Le tre classi sono insiemi di funzioni per cui sono
ben definiti i valori attesi nella tesi. (3) implica che se $X\perp Y$, $X=%
\tilde{X}$ q. c. e $Y=\tilde{Y}$ q. c., allora $\tilde{X}\perp $ $\tilde{Y}$%
: infatti, se $\forall $ $h,g$ nelle classi 1, 2, 3 $\mathbf{E}\left(
h\left( X\right) g\left( Y\right) \right) =\mathbf{E}\left( h\left( X\right)
\right) \mathbf{E}\left( g\left( Y\right) \right) $, vale anche $\mathbf{E}%
\left( h\left( \tilde{X}\right) g\left( \tilde{Y}\right) \right) =\mathbf{E}%
\left( h\left( \tilde{X}\right) \right) \mathbf{E}\left( g\left( \tilde{Y}%
\right) \right) $ $\forall $ $h,g$ nelle classi 1, 2, 3 (il valore atteso 
\`{e} lo stesso per v. a. uguali q. c.), quindi $\tilde{X}\perp $ $\tilde{Y}$%
.

Il teorema non semplifica particolarmente la verifica dell'indipendenza, ma
permette di dedurre propriet\`{a} complicate a partire dall'indipendenza. La
terza classe \`{e} contenuta nella seconda: si usa la terza classe per
verificare l'indipendenza, la seconda conoscendo l'indipendenza e per
dimostrare altre cose.

\textbf{Dim*} Dimostro che (1) implica (2). Se $\forall $ $C\in \mathcal{E}%
,\forall $ $D\in \mathcal{F}$ vale $\mathbf{P}\left( \left( X\in C\right)
\cap \left( Y\in D\right) \right) =\mathbf{P}\left( X\in C\right) \mathbf{P}%
\left( Y\in D\right) $, allora \`{e} anche vero che $\forall $ $A\in 
\mathcal{E}^{\prime },\forall $ $B\in \mathcal{F}^{\prime }$ vale $\mathbf{P}%
\left( \left( h\left( X\right) \in A\right) \cap \left( g\left( Y\right) \in
B\right) \right) =\mathbf{P}\left( h\left( X\right) \in A\right) \mathbf{P}%
\left( g\left( Y\right) \in B\right) $. Infatti $\left( h\left( X\right) \in
A\right) \cap \left( g\left( Y\right) \in B\right) =\left( h\left( X\right)
\right) ^{-1}\left( A\right) \cap \left( g\left( Y\right) \right)
^{-1}\left( B\right) =X^{-1}\left( h^{-1}\left( A\right) \right) \cap
Y^{-1}\left( g^{-1}\left( B\right) \right) $, ma $h^{-1}\left( A\right) \in 
\mathcal{E}$, $g^{-1}\left( B\right) \in \mathcal{F}$ perch\'{e} $h,g$ sono
misurabili, quindi si pu\`{o} porre $h^{-1}\left( A\right) =C,g^{-1}\left(
B\right) =D$, e vale $\mathbf{P}\left( \left( X\in C\right) \cap \left( Y\in
D\right) \right) =\mathbf{P}\left( X\in C\right) \mathbf{P}\left( Y\in
D\right) $, cio\`{e} $\mathbf{P}\left( \left( h\left( X\right) \in A\right)
\cap \left( g\left( Y\right) \in B\right) \right) =\mathbf{P}\left( h\left(
X\right) \in A\right) \mathbf{P}\left( g\left( Y\right) \in B\right) $. Vedi
FT per 2--\TEXTsymbol{>}3$\blacksquare $

E' noto che $X,Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\Longleftrightarrow \mathbf{E}\left( \left\vert X\right\vert \right)
<+\infty ,\mathbf{E}\left( \left\vert Y\right\vert \right) <+\infty $.

\textbf{Corollario (il prodotto di v. a. integrabili indipendenti \`{e}
integrabile)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\text{v. a., }X,Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
e }X\perp Y \\
\text{Ts}\text{: }XY\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\end{gather*}

($X,Y$ devono avere lo stesso codominio) Era gi\`{a} noto che $X,Y\in
L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ implica $XY\in
L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $: l'indipendenza permette
di richiedere meno regolarit\`{a} su $X,Y$.

\textbf{Dim} E' noto che $XY\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) \Longleftrightarrow \left\vert XY\right\vert \in L^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $. Ma $\left\vert XY\right\vert =\left\vert
X\right\vert \left\vert Y\right\vert $: si applica allora 12.2, cio\`{e} la
prima proposizione, $X\perp Y$, implica la terza con $h\left( x\right)
=\left\vert x\right\vert $, $g\left( y\right) =\left\vert y\right\vert $
(appartengono alla classe $1$), per cui $\mathbf{E}\left( \left\vert
X\right\vert \left\vert Y\right\vert \right) =\mathbf{E}\left( \left\vert
X\right\vert \right) \mathbf{E}\left( \left\vert Y\right\vert \right) $. Il
lato destro \`{e} finito perch\'{e} $X,Y\in L^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $, quindi anche $\mathbf{E}\left( XY\right) <+\infty $. $%
\blacksquare $

\textbf{Corollario 12.3 (il valore atteso si fattorizza per v. a.
indipendenti)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, } \\
X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a., }X,Y\in L^{1}\text{, }X\perp Y \\
\text{Ts}\text{: }\mathbf{E}\left( XY\right) =\mathbf{E}\left( X\right) 
\mathbf{E}\left( Y\right)
\end{gather*}

Per quanto visto sopra $\mathbf{E}\left( XY\right) $ esiste finito.


\textbf{Dim} Si \`{e} dimostrato sopra che $XY\in L^{1}$. Poich\'{e} $h,g$
funzioni identit\`{a} non rientrano in nessuna delle 3 classi sopra, per
scrivere $\mathbf{E}\left( XY\right) $ usando il teorema 12.2 occorre
ricorrere a una successione di funzioni troncate. Definisco per $n\geq 1$ la
funzione reale $h_{n}\left( t\right) =\left\{ 
\begin{array}{c}
-n\text{ se }t<-n \\ 
t\text{ se }\left\vert t\right\vert \leq n \\ 
n\text{ se }t>n%
\end{array}%
\right. $, che \`{e} limitata $\forall $ $n$ ($\left\vert h_{n}\left(
t\right) \right\vert \leq n$); la successione di funzioni $\left\{
h_{n}\right\} $ converge puntualmente alla funzione identit\`{a} $h\left(
t\right) =t$. $h_{n}\left( X\right) ,h_{n}\left( Y\right) $ sono due
successioni di funzioni che crescono a $X,Y$ rispettivamente: $h_{n}\left(
X\left( \omega \right) \right) \rightarrow X\left( \omega \right) $ $\forall 
$ $\omega $. $\mathbf{E}\left( h_{n}\left( X\right) h_{n}\left( Y\right)
\right) =\mathbf{E}\left( h_{n}\left( X\right) \right) \mathbf{E}\left(
h_{n}\left( Y\right) \right) $ per 12.2, essendo le $h_{n}$ limitate. Cerco
di usare il teorema di convergenza dominata, per poter affermare che $%
\mathbf{E}\left( XY\right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left(
h_{n}\left( X\right) h_{n}\left( Y\right) \right) $: cerco quindi una v.a.
nonnegativa e integrabile che maggiori la successione in valore assoluto $%
\forall $ $n$. Ma $\left\vert h_{n}\left( X\right) h_{n}\left( Y\right)
\right\vert =\left\vert h_{n}\left( X\right) \right\vert \left\vert
h_{n}\left( Y\right) \right\vert \leq \left\vert X\right\vert \left\vert
Y\right\vert $ $\forall $ $n$. $\left\vert XY\right\vert $ \`{e} integrabile
per il corollario sopra, quindi per convergenza dominata $\mathbf{E}\left(
XY\right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left( h_{n}\left( X\right)
h_{n}\left( Y\right) \right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left(
h_{n}\left( X\right) \right) \mathbf{E}\left( h_{n}\left( Y\right) \right) =%
\mathbf{E}\left( X\right) \mathbf{E}\left( Y\right) $, usando di nuovo la
convergenza dominata al contrario nell'altro verso. $\blacksquare $ \\
========================
\newpage

Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $X:\left( \Omega ,%
\mathcal{A}\right) \rightarrow \left( E,\mathcal{E}\right) ,Y:\left( \Omega ,%
\mathcal{A}\right) \rightarrow \left( F,\mathcal{F}\right) $, $\left(
X\left( \omega \right) ,Y\left( \omega \right) \right) \in E\times F$ $%
\forall $ $\omega \in \Omega $. Per poter valutare se la funzione $\left(
X\left( \omega \right) ,Y\left( \omega \right) \right) $ \`{e} una variabile
aleatoria - che, nel caso in cui abbia come componenti altre $n$ variabili
aleatorie, prende il nome di vettore aleatorio - occorre avere una $\sigma $%
-algebra su $E\times F$, che \`{e} naturale voler definire a partire da $%
\mathcal{E}$ e $\mathcal{F}$.

C'\`{e} un secondo problema. Date $X:\left( \Omega _{1},\mathcal{A}%
_{1}\right) \rightarrow \left( E,\mathcal{E}\right) ,Y:\left( \Omega _{2},%
\mathcal{A}_{2}\right) \rightarrow \left( F,\mathcal{F}\right) $, non si pu%
\`{o} usare la definizione di indipendenza tra $X,Y$, perch\'{e} queste non
sono definite sullo stesso $\Omega $; pu\`{o} per\`{o} capitare di avere
comunque un pregiudizio di indipendenza. Si cerca allora di definire
entrambe su uno spazio comune, per poterle confrontare: la cosa naturale 
\`{e} considerare $\Omega =\Omega _{1}\times \Omega _{2}$ e definire la v.
a. $\left( X_{1},X_{2}\right) :\Omega \rightarrow E\times F$, $\left( 
\begin{array}{c}
X_{1}\left( \omega _{1},\omega _{2}\right) \\ 
X_{2}\left( \omega _{1},\omega _{2}\right)%
\end{array}%
\right) =\left( 
\begin{array}{c}
X\left( \omega _{1}\right) \\ 
Y\left( \omega _{2}\right)%
\end{array}%
\right) $. Si ripresenta quindi il problema di scegliere una $\sigma $%
-algebra su $\Omega $.

Questa necessit\`{a} prende la forma della seguente domanda: dati due spazi
misurabili $\left( \Omega _{1},\mathcal{A}_{1}\right) ,\left( \Omega _{2},%
\mathcal{A}_{2}\right) $, $\mathcal{A}_{1}\times \mathcal{A}_{2}=\left\{
A\subseteq \Omega _{1}\times \Omega _{2}:A=A_{1}\times A_{2}\text{ al
variare di }A_{1}\in \mathcal{A}_{1},A_{2}\in \mathcal{A}_{2}\right\} $ \`{e}
una $\sigma $-algebra? La risposta \`{e} no, in generale.

\begin{enumerate}
\item Considero $\left( \Omega _{1},\mathcal{A}_{1}\right) ,\left( \Omega
_{2},\mathcal{A}_{2}\right) $ spazi misurabili, con $\mathcal{A}_{1}=\left\{
\Omega _{1},\varnothing \right\} ,\mathcal{A}_{2}=\left\{ \Omega
_{2},\varnothing \right\} $. $\mathcal{A}_{1}\times \mathcal{A}_{2}=\left\{
\Omega _{1}\times \Omega _{2},\varnothing \right\} $: in questo caso il
prodotto \`{e} una $\sigma $-algebra.
\end{enumerate}

Il fatto che in generale $\mathcal{A}_{1}\times \mathcal{A}_{2}$ non sia una 
$\sigma $-algebra \`{e} evidente se si considerano $\Omega _{1}=\Omega _{2}=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, con $\mathcal{A}_{1}=\mathcal{A}_{2}=\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Dato $\mathcal{A}_{1}\times \mathcal{A}_{2}$, se si prendono $%
A=A_{1}\times A_{2},B=B_{1}\times B_{2}\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ rettangoli non coincidenti, la loro unione non appartiene a $\mathcal{A%
}_{1}\times \mathcal{A}_{2}$ (che \`{e} formata da rettangoli o unioni di
rettangoli), che quindi non \`{e} chiusa per unione finita e dunque nemmeno
numerabile: perci\`{o} non \`{e} una $\sigma $-algebra. Questo porta alla
seguente definizione.

\textbf{Def} Dati $\left( \Omega _{1},\mathcal{A}_{1}\right) ,\left( \Omega
_{2},\mathcal{A}_{2}\right) $ spazi misurabili, si definisce $\sigma $%
-algebra prodotto tra $\mathcal{A}_{1}$ e $\mathcal{A}_{2}$, e si indica con 
$\mathcal{A}_{1}\otimes \mathcal{A}_{2}$, $\sigma \left( \mathcal{A}%
_{1}\times \mathcal{A}_{2}\right) $.

\textbf{Teo 12.5 (v. a. su spazi prodotto)}%
\begin{gather*}
\text{(1) }\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \otimes \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \\
\text{(2) Hp: }X:\left( \Omega ,\mathcal{A}\right) \rightarrow \left( E,%
\mathcal{E}\right) ,Y:\left( \Omega ,\mathcal{A}\right) \rightarrow \left( F,%
\mathcal{F}\right) \text{ sono v. a.} \\
\text{Ts: }\left( X,Y\right) :\left( \Omega ,\mathcal{A}\right) \rightarrow
\left( E\times F,\mathcal{E\otimes F}\right) \text{ \`{e} misurabile} \\
\text{(3) (misurabilit\`{a} delle restrizioni) Hp: }X:\left( \Omega
_{1}\times \Omega _{2},\mathcal{A}_{1}\mathcal{\otimes A}_{2}\right)
\rightarrow \left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \\
\text{\`{e} una variabile aleatoria misurabile} \\
\text{Ts: }\forall \text{ }\omega _{1}\in \Omega _{1}\text{ }X:\left( \Omega
_{2},\mathcal{A}_{2}\right) \rightarrow \left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) ,X\left( \omega _{2}\right) =X\left( \omega _{1},\omega
_{2}\right) \text{ \`{e}} \\
\text{misurabile, }\forall \text{ }\omega _{2}\in \Omega _{2}\text{ }%
X:\left( \Omega _{1},\mathcal{A}_{1}\right) \rightarrow \left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) ,X\left( \omega _{1}\right) =X\left( \omega _{1},\omega
_{2}\right) \text{ \`{e}} \\
\text{misurabile}
\end{gather*}

(1) significa che $\sigma \left( \left( a_{1},b_{1}\right) \times \left(
a_{2},b_{2}\right) :-\infty \leq a_{i}<b_{i}\leq +\infty \text{ }\forall 
\text{ }i=1,2\right) $ coincide con la $\sigma $-algebra prodotto. (2)
risponde al primo problema, cio\`{e} definire un vettore aleatorio a partire
da v. a. $X:\left( \Omega ,\mathcal{A}\right) \rightarrow \left( E,\mathcal{E%
}\right) ,Y:\left( \Omega ,\mathcal{A}\right) \rightarrow \left( F,\mathcal{F%
}\right) $. $\left( X,Y\right) $ vettore aleatorio significa che $\forall $ $%
C\in \mathcal{E\otimes F}$ $\left( X,Y\right) ^{-1}\left( C\right) =\left\{
\omega :\left( X,Y\right) \left( \omega \right) \in C\right\} \in \mathcal{A}
$: significa che un vettore che abbia per componenti v. a. \`{e} misurabile
rispetto alla $\sigma $-algebra prodotto. Si noti che in (3) si inverte la
situazione rispetto a (2).

Date $X:\Omega _{1}\rightarrow E$ e $Y:\Omega _{2}\rightarrow F$ in due
spazi di probabilit\`{a} $\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}%
_{1}\right) ,\left( \Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) $, si 
\`{e} visto che per costruire un modello di probabilit\`{a} congiunto si
prendono $\Omega _{1}\times \Omega _{2}$ e $\mathcal{A=A}_{1}\mathcal{%
\otimes A}_{2}$. Come definire la probabilit\`{a} $\mathbf{P}:\mathcal{%
A\rightarrow }\left[ 0,1\right] $? Essa in questo caso \`{e} detta probabilit%
\`{a} congiunta, mentre $\mathbf{P}_{1}\mathbf{,P}_{2}$ sono probabilit\`{a}
marginali.

Dato $A_{1}\in \mathcal{A}_{1}$, $A_{1}\times \Omega _{2}\in \mathcal{A}$: 
\`{e} ragionevole chiedere che $\mathbf{P}$ sia coerente con le probabilit%
\`{a} marginali, cio\`{e} che $\mathbf{P}\left( A_{1}\times \Omega
_{2}\right) =\mathbf{P}_{1}\left( A_{1}\right) $, e analogamente che $%
\mathbf{P}\left( \Omega _{1}\times A_{2}\right) =\mathbf{P}_{2}\left(
A_{2}\right) $ $\forall $ $A_{2}\in \mathcal{A}_{2}$. Richiedo inoltre che $%
\mathbf{P}\left( \left( A_{1}\times \Omega _{2}\right) \cap \left( \Omega
_{1}\times A_{2}\right) \right) =\mathbf{P}\left( A_{1}\times \Omega
_{2}\right) \mathbf{P}\left( \Omega _{1}\times A_{2}\right) $: questo
equivale a chiedere che $\mathbf{P}\left( A_{1}\times A_{2}\right) =\mathbf{P%
}_{1}\left( A_{1}\right) \mathbf{P}_{2}\left( A_{2}\right) $, cio\`{e} che
gli esperimenti descritti dai due modelli marginali siano indipendenti.
Quindi la $\mathbf{P}$ prodotto ha senso solo per esperimenti indipendenti.

\textbf{Teo 13.1 (esistenza e unicit\`{a} della probabilit\`{a} prodotto)}%
\begin{gather*}
\text{Hp: }\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right) ,\left(
\Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) \text{ spazi di probabilit%
\`{a}} \\
\text{Ts: (1) }\exists \text{ }!\text{ misura di probabilit\`{a} }\mathbf{P}:%
\mathcal{A}_{1}\mathcal{\otimes A}_{2}\rightarrow \left[ 0,1\right] : \\
\mathbf{P}\left( A_{1}\times A_{2}\right) =\mathbf{P}_{1}\left( A_{1}\right) 
\mathbf{P}_{2}\left( A_{2}\right) \text{ }\forall \text{ }A_{1}\times
A_{2}\in \mathcal{A}_{1}\mathcal{\times A}_{2}
\end{gather*}

Tale misura di probabilit\`{a} si dice misura o probabilit\`{a} prodotto e
si indica con $\mathbf{P}_{1}\mathcal{\otimes }\mathbf{P}_{2}$.
L'uguaglianza $\mathbf{P}\left( A_{1}\times A_{2}\right) =\mathbf{P}%
_{1}\left( A_{1}\right) \mathbf{P}_{2}\left( A_{2}\right) $ implica che
valgano anche $\mathbf{P}\left( A_{1}\times \Omega _{2}\right) =\mathbf{P}%
_{1}\left( A_{1}\right) $, $\mathbf{P}\left( \Omega _{1}\times A_{2}\right) =%
\mathbf{P}_{2}\left( A_{2}\right) $.

\textbf{Dim} Per il criterio di Caratheodory, essendo $\mathcal{C}=\left\{
A_{1}\times A_{2}:A_{1}\in \mathcal{A}_{1},A_{2}\in \mathcal{A}_{2}\right\} $
un $\pi $-sistema su $\mathcal{A}_{1}\mathcal{\times A}_{2}$ e dato che $%
\sigma \left( \mathcal{A}_{1}\times \mathcal{A}_{2}\right) =\mathcal{A}_{1}%
\mathcal{\otimes A}_{2}=\mathcal{A}$ per definizione, le richieste sopra
individuano univocamente $\mathbf{P}$. $\blacksquare $

\textbf{Def} Dati $\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right)
,\left( \Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) $ spazi di
probabilit\`{a}, lo spazio di probabilit\`{a} $\left( \Omega _{1}\times
\Omega _{2},\mathcal{A}_{1}\mathcal{\otimes A}_{2},\mathbf{P}_{1}\mathcal{%
\otimes }\mathbf{P}_{2}\right) $ \`{e} detto spazio prodotto.

\textbf{Teo 13.1} \textbf{(Fubini-Tonelli per v. a. nonnegative)}%
\begin{gather*}
\text{Hp: }\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right) ,\left(
\Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) \text{ spazi di probabilit%
\`{a}, }X:\Omega _{1}\times \Omega _{2}\rightarrow \left[ 0,+\infty \right]
\\
\text{\`{e} una v.a. }\mathcal{A}_{1}\mathcal{\otimes A}_{2}\text{ misurabile%
} \\
\text{Ts: (1)}\int_{\Omega _{1}}X\left( \omega _{1},\omega _{2}\right) d%
\mathbf{P}\left( \omega _{1}\right) \text{ \`{e} }\mathcal{A}_{2}\text{%
-misurabile, }\int_{\Omega _{2}}X\left( \omega _{1},\omega _{2}\right) d%
\mathbf{P}\left( \omega _{2}\right) \text{ \`{e} }\mathcal{A}_{1}\text{%
-misurabile} \\
\text{(2)}\int_{\Omega _{1}\times \Omega _{2}}X\left( \omega _{1},\omega
_{2}\right) d\mathbf{P}_{1}\mathcal{\otimes }\mathbf{P}_{2}\left( \omega
_{1},\omega _{2}\right) =\int_{\Omega _{2}}\left( \int_{\Omega _{1}}X\left(
\omega _{1},\omega _{2}\right) d\mathbf{P}_{1}\left( \omega _{1}\right)
\right) d\mathbf{P}_{2}\left( \omega _{2}\right) = \\
\int_{\Omega _{1}}\left( \int_{\Omega _{2}}X\left( \omega _{1},\omega
_{2}\right) d\mathbf{P}_{2}\left( \omega _{2}\right) \right) d\mathbf{P}%
_{1}\left( \omega _{1}\right)
\end{gather*}

Quindi in realt\`{a} questo non riguarda i vettori aleatori: \`{e} una v. a.
definita su uno spazio prodotto.

$\int_{\Omega _{1}}X\left( \omega _{1},\omega _{2}\right) d\mathbf{P}\left(
\omega _{1}\right) $ \`{e} una funzione che ha come dominio $\Omega _{2}$ e
come codominio $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$: la tesi afferma che \`{e} una variabile aleatoria. $X\in L^{1}\left(
\Omega _{1}\times \Omega _{2},\mathcal{A}_{1}\mathcal{\otimes A}_{2},\mathbf{%
P}_{1}\mathcal{\otimes }\mathbf{P}_{2}\right) \Longleftrightarrow
\int_{\Omega _{2}}\left( \int_{\Omega _{1}}X\left( \omega _{1},\omega
_{2}\right) d\mathbf{P}_{1}\left( \omega _{1}\right) \right) d\mathbf{P}%
_{2}\left( \omega _{2}\right) <+\infty $.

Il teorema afferma che si pu\`{o} calcolare un integrale doppio con due
integrali semplici.

\textbf{Teo 13.1 (Fubini-Tonelli per v. a. integrabili) }%
\begin{gather*}
\text{Hp: }\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right) ,\left(
\Omega _{2},\mathcal{A}_{2},\mathbf{P}_{2}\right) \text{ spazi di probabilit%
\`{a}, }X:\Omega _{1}\times \Omega _{2}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{,} \\
X\in L^{1}\left( \Omega _{1}\times \Omega _{2},\mathcal{A}_{1}\mathcal{%
\otimes A}_{2},\mathbf{P}_{1}\mathcal{\otimes }\mathbf{P}_{2}\right) \\
\text{Ts: (1) }X\left( \omega _{2}\right) =X\left( \omega _{1},\omega
_{2}\right) \text{ \`{e} }L^{1}\left( \Omega _{2},\mathcal{A}_{2},\mathbf{P}%
_{2}\right) \text{ q. c. rispetto a }\mathbf{P}_{1}\text{,} \\
X\left( \omega _{1}\right) =X\left( \omega _{1},\omega _{2}\right) \text{ 
\`{e} }L^{1}\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right) \text{
q. c. rispetto a }\mathbf{P}_{2} \\
\text{(2)}\int_{\Omega _{1}}X\left( \omega _{1},\omega _{2}\right) d\mathbf{P%
}\left( \omega _{1}\right) \text{ \`{e} }\mathcal{A}_{2}\text{-misurabile, }%
\int_{\Omega _{2}}X\left( \omega _{1},\omega _{2}\right) d\mathbf{P}\left(
\omega _{2}\right) \text{ \`{e} }\mathcal{A}_{1}\text{-misurabile} \\
\text{(3)}\int_{\Omega _{1}\times \Omega _{2}}X\left( \omega _{1},\omega
_{2}\right) d\mathbf{P}_{1}\mathcal{\otimes }\mathbf{P}_{2}\left( \omega
_{1},\omega _{2}\right) =\int_{\Omega _{2}}\left( \int_{\Omega _{1}}X\left(
\omega _{1},\omega _{2}\right) d\mathbf{P}_{1}\left( \omega _{1}\right)
\right) d\mathbf{P}_{2}\left( \omega _{2}\right) = \\
\int_{\Omega _{1}}\left( \int_{\Omega _{2}}X\left( \omega _{1},\omega
_{2}\right) d\mathbf{P}_{2}\left( \omega _{2}\right) \right) d\mathbf{P}%
_{1}\left( \omega _{1}\right)
\end{gather*}

(1) manca tesi di integrabilit\`{a} di $X,Y$


\textbf{Corollario 13.2 (la legge di v. a. indipendenti si fattorizza)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}%
\right) \text{ spazi misurabili, }X:\Omega \rightarrow E\text{,} \\
Y:\Omega \rightarrow F\text{ v. a., }\left( X,Y\right) :\Omega \rightarrow
E\times F\text{ ha legge }P^{\left( X,Y\right) }:\mathcal{E\otimes F}%
\rightarrow \left[ 0,1\right] \\
\text{Ts}\text{: }X\perp Y\Longleftrightarrow P^{\left( X,Y\right)
}=P^{\left( X\right) }\mathcal{\otimes }P^{\left( Y\right) }
\end{gather*}

$P^{\left( X,Y\right) }$ si \`{e} definita quando si \`{e} definita la legge
di una v. a. $X:\Omega \rightarrow E$. Si pu\`{o} parlare di legge del
vettore aleatorio a partire da variabili aleatorie grazie alla definizione
di spazio prodotto.

La tesi significa che la legge di un vettore aleatorio, quindi congiunta,
avente come componenti variabili aleatorie indipendenti si fattorizza nel
prodotto delle leggi marginali. Questo conferma che la definizione della
probabilit\`{a} prodotto ha senso quando si considerano eventi (o variabili
aleatorie) indipendenti.

\textbf{Dim} Mostro l'implicazione da sinistra a destra. $X\perp
Y\Longleftrightarrow \forall $ $A\in \mathcal{E},\forall $ $B\in \mathcal{F}$
$\mathbf{P}\left( X\in A,Y\in B\right) =\mathbf{P}\left( X\in A\right) 
\mathbf{P}\left( Y\in B\right) $. Posso scrivere l'evento $\left( X\in
A,Y\in B\right) =\left( \left( X,Y\right) \in A\times B\right) $. Allora $%
\mathbf{P}\left( \left( X,Y\right) \in A\times B\right) =\mathbf{P}\left(
X\in A\right) \mathbf{P}\left( Y\in B\right) $ per ipotesi e $P^{\left(
X,Y\right) }\left( A\times B\right) =\mathbf{P}\left( X\in A\right) \mathbf{P%
}\left( Y\in B\right) =P^{X}\left( A\right) P^{Y}\left( B\right) $ $\forall $
$\left( A,B\right) \in \mathcal{E\times F}$, dove $P^{X}\left( A\right) $ 
\`{e} la misura di $A$ sotto la legge di $X$. Questo, per il teorema di
Fubini-Tonelli, definisce univocamente $P^{\left( X,Y\right) }$, con la
probabilit\`{a} prodotto: $P^{\left( X,Y\right) }=P^{X}\mathcal{\otimes }%
P^{\left( Y\right) }$.

Mostro l'implicazione da destra a sinistra. Sia $P^{\left( X,Y\right)
}=P^{\left( X\right) }\mathcal{\otimes }P^{\left( Y\right) }$: allora in
particolare sui rettangoli $P^{\left( X,Y\right) }\left( A\times B\right)
=P^{X}\left( A\right) P^{Y}\left( B\right) $ $\forall $ $\left( A,B\right)
\in \mathcal{E\times F}$, per cui $P^{\left( X,Y\right) }\left( A\times
B\right) =\mathbf{P}\left( \left( X,Y\right) \in A\times B\right)
=P^{X}\left( A\right) P^{Y}\left( B\right) =\mathbf{P}\left( X\in A\right) 
\mathbf{P}\left( Y\in B\right) $, cio\`{e} $X,Y$ sono indipendenti. $%
\blacksquare $

Quindi, se so che $X,Y$ sono indipendenti e ho $P^{X},P^{Y}$, lo spazio di
probabilit\`{a} $\left( E\times F,\mathcal{E\otimes F},P^{\left( X\right) }%
\mathcal{\otimes }P^{\left( Y\right) }\right) $ \`{e} un buon modello.

\textbf{Corollario (la legge prodotto \`{e} coerente con le leggi marginali)}%
\begin{gather*}
\text{Hp: }X_{1}:\left( \Omega _{1},\mathcal{A}_{1},\mathbf{P}_{1}\right)
\rightarrow \left( E,\mathcal{E}\right) \text{, }X_{2}:\left( \Omega _{2},%
\mathcal{A}_{2},\mathbf{P}_{2}\right) \rightarrow \left( F,\mathcal{F}%
\right) \text{ sono v.a.,} \\
\Omega =\Omega _{1}\times \Omega _{2},\mathcal{A=A}_{1}\mathcal{\otimes A}%
_{2},\mathbf{P=P}_{1}\mathbf{\otimes P}_{2}\text{, }\left( X,Y\right)
:\Omega \rightarrow E\times F\text{, } \\
X\left( \omega _{1},\omega _{2}\right) =X_{1}\left( \omega _{1}\right) \text{%
, }Y\left( \omega _{1},\omega _{2}\right) =X_{2}\left( \omega _{2}\right) \\
\text{Ts: (1) date }X:\Omega \rightarrow E\text{, }X_{1}:\Omega
_{1}\rightarrow E\text{, vale }P^{X}=P^{X_{1}}\text{; date }Y:\Omega
\rightarrow F\text{,} \\
X_{2}:\Omega _{2}\rightarrow F\text{, vale }P^{Y}=P^{X_{2}} \\
\text{(2) }X\perp Y
\end{gather*}

La tesi 1 \`{e} $\mathbf{P}\left( X\in
B\right) =\mathbf{P}_{1}\left( X_{1}\in B\right) $, $\mathbf{P}\left( Y\in
B\right) =\mathbf{P}_{2}\left( X_{2}\in B\right) $.

Nella tesi 2, $X,Y$ possono essere confrontate perch\'{e} sono definite
sullo stesso $\Omega $. Il significato \`{e} che se mi aspetto che due v. a.
siano indipendenti, posso costruire un modello di probabilit\`{a} che me lo
garantisce; in generale, se un vettore aleatorio \`{e} definito su uno
spazio prodotto a partire da due variabili aleatorie definite su spazi
diversi, allora queste sono indipendenti sullo spazio prodotto.

\textbf{Dim} (1) $P^{X}\left( B_{1}\right) =\mathbf{P}\left( X\in
B_{1}\right) $ $\forall $ $B_{1}\in \mathcal{E}_{1}$. $\left( X\in
B_{1}\right) =\left\{ \omega \in \Omega :X\left( \omega _{1},\omega
_{2}\right) =X_{1}\left( \omega _{1}\right) \in B_{1}\right\} =\left(
X_{1}\in B_{1}\right) \times \Omega _{2}$. Allora, per definizione di
probabilit\`{a} prodotto, $\mathbf{P}\left( X\in B_{1}\right) =\mathbf{P}%
_{1}\left( X_{1}\in B_{1}\right) \mathbf{P}_{2}\left( \Omega _{2}\right) =%
\mathbf{P}_{1}\left( X_{1}\in B_{1}\right) =P^{X_{1}}\left( B_{1}\right) $.

(2) Devo mostrare che $\forall $ $A\in \mathcal{E},\forall $ $B\in \mathcal{F%
}$ $\mathbf{P}\left( X\in A,Y\in B\right) =\mathbf{P}\left( X\in A\right) 
\mathbf{P}\left( Y\in B\right) $. Vale $\mathbf{P}\left( X\in A,Y\in
B\right) =\mathbf{P}\left( \left( X,Y\right) \in A\times B\right) =\mathbf{P}%
\left( \left( X\in A\right) \times \left( Y\in B\right) \right) =\mathbf{P}%
\left( X\in A\right) \mathbf{P}\left( Y\in B\right) $ per definizione di
probabilit\`{a} prodotto: quindi si ha la tesi. $\blacksquare $

\begin{enumerate}
\item Lancio $2$ dadi. $\Omega _{1}=\left\{ 1,...,6\right\} ,\mathcal{A}%
_{1}=2^{\Omega _{1}},\mathbf{P}_{1}$ uniforme su $\Omega _{1}$ \`{e} il
modello di probabilit\`{a} per il primo esperimento, analogamente per il
secondo. $X_{1}$ descrive il risultato del primo lancio: $X_{1}:\Omega
_{1}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,X_{1}\left( \omega _{1}\right) =\omega _{1}$, e analogamente $X_{2}\left(
\omega _{2}\right) =\omega _{2}$. E' naturale aspettarsi che i due lanci
siano indipendenti: questo \`{e} vero per il corollario. Definisco $\Omega
=\left\{ 1,...,6\right\} ^{2},\mathcal{A=}2^{\Omega _{1}}\mathcal{\otimes }%
2^{\Omega _{2}}$ (che in questo caso coincide con $2^{\Omega _{1}\times
\Omega _{2}}$), $\mathbf{P=P}_{1}\mathbf{\otimes P}_{2}$ probabilit\`{a}
uniforme su $\Omega $, $X\left( \omega \right) =X_{1}\left( \omega
_{1}\right) ,Y\left( \omega \right) =X_{2}\left( \omega _{2}\right) $:
allora $X\perp Y$.
\end{enumerate}

\textbf{Famiglie di variabili aleatorie indipendenti}

\textbf{Def 13.3} Dato $\left( \Omega ,A,\mathbf{P}\right) $ spazio di
probabilit\`{a}, $\left( E_{k},\mathcal{E}_{k}\right) $ spazio misurabile $%
\forall $ $k=1,...,n$, $X_{k}:\Omega \rightarrow E_{k}$ variabile aleatoria $%
\forall $ $k=1,...,n$, si dice che $X_{1},...,X_{n}$ sono una famiglia di
variabili aleatorie indipendenti se $\mathbf{P}\left(
\bigcap_{j=1}^{n}\left( X_{j}\in B_{j}\right) \right) =\prod_{j=1}^{n}%
\mathbf{P}\left( X_{j}\in B_{j}\right) $ $\forall $ $B_{j}\in \mathcal{E}%
_{j} $ $\forall $ $j=1,...,n$.

Se $n=2$, si ottiene la 12.1. Si pu\`{o} scrivere equivalentemente $\mathbf{P%
}\left( X_{1}\in B_{1},X_{2}\in B_{2},...,X_{n}\in B_{n}\right)
=\prod_{j=1}^{n}\mathbf{P}\left( X_{j}\in B_{j}\right) $ $\forall $ $\left(
B_{1},...,B_{n}\right) \in \left( \mathcal{E}_{1}\times \mathcal{E}%
_{2}\times ...\mathcal{\times E}_{n}\right) $ $\forall $ $j=1,...,n$. A
differenza della definizione data per famiglie di eventi indipendenti, non
ci sono $2^{n}-n-1$ condizioni da confrontare: tuttavia, la definizione\
implica la richiesta di indipendenza su tutte le sottofamiglie; se e. g. si
prende $B_{k}=E_{k}$ per un certo $\bar{k}$, si ottiene $P\left( X_{\bar{k}%
}\in B_{\bar{k}}\right) =1$ e si ritrova la definizione per $n-1$ variabili
aleatorie. L'indipendenza permette di lavorare sui rettangoli, singolarmente
su ogni spazio, cio\`{e} di separare le variabili, fattorizzare.

Dalla definizione segue che se $X_{1},...,X_{n}$ sono indipendenti e $g$ 
\`{e} una funzione misurabile allora $g\left( X_{1}\right) ,...,g\left(
X_{n}\right) $ sono una famiglia di variabili aleatorie indipendenti:
infatti $\mathbf{P}\left( \bigcap_{j=1}^{n}\left( g\left( X_{j}\right) \in
B_{j}\right) \right) =\mathbf{P}\left( \bigcap_{j=1}^{n}\left( X_{j}\in
g^{-1}\left( B_{j}\right) \right) \right) =\prod_{j=1}^{n}\mathbf{P}\left(
X_{j}\in g^{-1}\left( B_{j}\right) \right) $.

\begin{enumerate}
\item Considero $X_{1},X_{2},X_{3}$ variabili aleatorie. La condizione di
indipendenza \`{e} che $\mathbf{P}\left( \left( X_{1}\in B_{1}\right) \cap
\left( X_{2}\in B_{2}\right) \cap \left( X_{3}\in B_{3}\right) \right) =%
\mathbf{P}\left( X_{1}\in B_{1}\right) \mathbf{P}\left( X_{2}\in
B_{2}\right) \mathbf{P}\left( X_{3}\in B_{3}\right) $ $\forall $ $\left(
B_{1},B_{2},B_{3}\right) \in \left( \mathcal{E}_{1}\times \mathcal{E}%
_{2}\times \mathcal{E}_{3}\right) $. Se si pone $B_{1}=E_{1}$, $\mathbf{P}%
\left( X_{1}\in B_{1}\right) =1$ e si ottiene la richiesta di indipendenza
tra due variabili aleatorie.
\end{enumerate}

\textbf{Prop 13.4 (indipendenza di sottofamiglie disgiunte)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( E_{k},\mathcal{E}_{k}\right) \text{ spazio
misurabile e }X_{k}:\Omega \rightarrow E_{k}\text{ v. a. } \\
\forall \text{ }k=1,...,n\text{, }X_{1},...,X_{n}\text{ v. a. indipendenti, }%
J_{1},J_{2}\subseteq \left\{ 1,...,n\right\} :J_{1}\cap J_{2}=\varnothing \\
\text{Ts: }\left( X_{i}\right) _{i\in J_{1}}\perp \left( X_{j}\right) _{j\in
J_{2}}
\end{gather*}

Se in particolare $\left\vert J_{1}\right\vert =\left\vert J_{2}\right\vert
=2$, la proposizione afferma che $\left( X_{h},X_{k}\right) \perp \left(
X_{i},X_{j}\right) $ se $\left\{ h,k\right\} \neq \left\{ i,j\right\} $. La
tesi significa che i vettori $\left( X_{i}\right) ,\left( X_{j}\right) $
sono indipendenti come variabili aleatorie: vedi esempio. Non vale
l'implicazione inversa.


\begin{enumerate}
\item Considero $X$ uniforme su $\left\{ -1,1\right\} $ con $\mathbf{P}%
\left( X=-1\right) =\frac{1}{2},P\left( X=1\right) =\frac{1}{2}$, e
analogamente $Y$ uniforme su $\left\{ -1,1\right\} $ con $\mathbf{P}\left(
Y=-1\right) =\frac{1}{2},P\left( Y=1\right) =\frac{1}{2}$. $X\perp Y$ (si 
\`{e} gi\`{a} verificato in un caso simile). Definisco $Z=XY$, tale che $%
\mathbf{P}\left( Z=-1\right) =\frac{1}{2},P\left( Z=1\right) =\frac{1}{2}$. $%
Z\perp X$ perch\'{e} $\mathbf{P}\left( Z=1,X=1\right) =\frac{1}{4}$, e $%
\func{Im}Z=\func{Im}X=\left\{ -1,1\right\} $. Allo stesso modo $Z\perp Y$.
Tuttavia $Z$ e $\left( X,Y\right) $ non sono indipendenti perch\'{e} il
valore di $\left( X,Y\right) $ individua univocamente $Z$. Quindi, pur
essendo indipendenti a coppie, non sono una famiglia di v. a. indipendenti,
usando l'implicazione inversa in 13.4.
\end{enumerate}

\textbf{Def 14.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( E_{k},\mathcal{E}_{k}\right) $ spazio
misurabile $\forall $ $k\geq 1$, $X_{k}:\Omega \rightarrow E_{k}$ variabile
aleatoria $\forall $ $k\geq 1$, si dice che la successione $\left(
X_{n}\right) _{n\geq 1}$ \`{e} una famiglia di variabili aleatorie
indipendenti se qualsiasi sottofamiglia finita di $\left( X_{n}\right)
_{n\geq 1}$ \`{e} una famiglia di v.a. indipendenti.

Si mostra che $\left( X_{n}\right) _{n\geq 1}$ \`{e} una famiglia di
variabili aleatorie indipendenti $\Longleftrightarrow X_{1},...,X_{k}$ \`{e}
una famiglia di v.a. indipendenti $\forall $ $k\geq 2$: non occorre
controllare qualsiasi famiglia, ma solo le prime $k$.

Si pu\`{o} allora estendere il corollario 13.2: $\mathbf{X}$ ha componenti
indipendenti $\Longleftrightarrow P^{\mathbf{X}}=P^{X_{1}}\otimes ...\otimes
P^{X_{n}}$.

\textbf{Def} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, $\left( E,\mathcal{E}\right) $ spazio misurabile $\forall $ 
$k=1,...,n$, $X_{k}:\Omega \rightarrow E$ variabile aleatoria $\forall $ $%
k=1,...,n$, si dice che $X_{1},...,X_{n}$ sono indipendenti e identicamente
distribuite se sono una famiglia di variabili aleatorie indipendenti e $%
P^{X_{1}}\left( B\right) =...=P^{X_{k}}\left( B\right) $ $\forall $ $B\in 
\mathcal{E}$.


\textbf{Def} Data $\left( X_{n}\right) _{n\geq 1}$ famiglia di v.a.
indipendenti definite su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, si indica con $\mathcal{B}_{n}=\sigma \left(
X_{n}\right) $, $\mathcal{C}_{n}=\sigma \left( \bigcup_{p=n}^{+\infty }%
\mathcal{B}_{p}\right) $; si dice $\sigma $-algebra di coda della famiglia $%
\left( X_{n}\right) _{n\geq 1}$, e si indica con $\mathcal{C}_{\infty }$, $%
\bigcap_{n=1}^{+\infty }\mathcal{C}_{n}$.

Intuitivamente, una propriet\`{a} della successione che dipende dal suo
comportamento "di coda", ad esempio la convergenza puntuale della
successione, dev'essere un evento della sua $\sigma $-algebra di coda; essa
contiene gli eventi il cui verificarsi o meno non \`{e} alterato dalla
modifica di un numero finito di elementi della successione.

\begin{enumerate}
\item $\left\{ \omega :\sup_{n}X_{n}\left( \omega \right) <1\right\} \not\in 
\mathcal{C}_{\infty }$ perch\'{e} l'estremo superiore della successione,
fissato $\omega $, dipende da tutti i suoi termini, che pu\`{o} quindi
essere modificato alterando un termine.

\item $\left\{ \omega :\lim_{n\rightarrow +\infty }X_{n}\left( \omega
\right) \text{ esiste}\right\} \in \mathcal{C}_{\infty }$ perch\'{e}
riguarda il comportamento di coda della successione.

\item $\left\{ \omega :\lim \sup_{n}X_{n}\left( \omega \right) <1\right\}
\in \mathcal{C}_{\infty }$ perch\'{e} il limsup \`{e} un concetto che si
basa sui limiti delle sottosuccessioni di $X_{n}$ e quindi sul comportamento
di coda della successione. Questo vale per qualsiasi evento generato da $%
\lim \sup_{n}X_{n}$.
\end{enumerate}

\textbf{Teo (legge zero-uno di Kolmogorov)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ famiglia di v.a.
indipendenti definite su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
} \\
\text{spazio di probabilit\`{a}, }\mathcal{C}_{\infty }\text{ loro }\sigma 
\text{-algebra di coda, }C\in \mathcal{C}_{\infty } \\
\text{Ts: }\mathbf{P}\left( C\right) =0\text{ oppure }\mathbf{P}\left(
C\right) =1
\end{gather*}

Il teorema afferma che ogni evento della $\sigma $-algebra di coda ha
probabilit\`{a} zero o uno.

Ne segue che ogni v. a. $\mathcal{C}_{\infty }$-misurabile, e. g. $\lim
\sup_{n}X_{n}$ e $\lim \inf_{n}X_{n}$, \`{e} q. c. costante: infatti ogni
evento generato da essa avr\`{a} probablit\`{a} zero o uno, in particolare
gli eventi del tipo $X_{n}=a$.

\section{Vettori aleatori}

Sia $\mathbf{X}=\left( X_{1},...,X_{n}\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ una n-upla di variabili aleatorie reali, detta vettore aleatorio, con $%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di probabilit\`{a}. E'
noto che:

\begin{enumerate}
\item Come $\sigma $-algebra su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ si prende $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \otimes ...\otimes \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ ($n$ fattori).

\item $\mathbf{X}$ \`{e} misurabile rispetto alle $2$ ($n$?) $\sigma $%
-algebre $\Longleftrightarrow X_{1},...,X_{n}$ sono misurabili separatamente.

\item Se $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$ \`{e} boreliana, $h\left( \mathbf{X}\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$ \`{e} un vettore aleatorio

\item $\mathbf{X=Y}$ q. c. $\Longleftrightarrow X_{k}=Y_{k}$ q. c. $\forall $
$k=1,...,n$

\item $P^{\mathbf{X}}\left( B\right) =\mathbf{P}\left( X\in B\right) $
(niente di nuovo: la definizione di legge si \`{e} data per $E$ generico),
che dipende solo da $\left[ X\right] $

\item $\mathbf{X}$ ha componenti indipendenti $\Longleftrightarrow
P^{X}=P^{X_{1}}\otimes ...\otimes P^{X_{n}}$

\item Se $X_{1},...,X_{n}\in L^{p}$ $\Longleftrightarrow $ $\mathbf{X}\in
L^{p}$ (come per le curve)

\item Date $X_{1},X_{2}\in L^{2}\left( \mathbf{P}\right) $, allora $%
X_{1},X_{2}\in L^{1}\left( \mathbf{P}\right) $. Se $X_{1},X_{2}\in
L^{1}\left( \mathbf{P}\right) $ e $X_{1}\perp X_{2}$, $X_{1}X_{2}\in
L^{1}\left( \mathbf{P}\right) $.
\end{enumerate}

\textbf{Def} Dato un vettore aleatorio $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ con legge $P^{\mathbf{X}}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,1\right] $, si definisce funzione di
ripartizione della sua legge $F_{\mathbf{X}}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow \left[ 0,1\right] ,F_{\mathbf{X}}\left( \mathbf{x}\right)
=P^{\mathbf{X}}\left( (-\infty ,x_{1}]\times ...\times (-\infty
,x_{n}]\right) =\mathbf{P}\left( X_{1}\leq x_{1},...,X_{n}\leq x_{n}\right) $%
.

$P^{X}\left( (-\infty ,x_{1}]\times ...\times (-\infty ,x_{n}]\right) $ \`{e}
la misura di un iperquadrante di sud-ovest sotto la legge di $X$. La
definizione di $F_{\mathbf{X}}$ non ha gli stessi vantaggi della definizione
di una funzione di ripartizione da $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ in $\left[ 0,1\right] $: e. g., non si pu\`{o} parlare di monotonia perch%
\'{e} in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ non \`{e} definibile una relazione d'ordine totale.

Dato $\mathbf{X}$, $X_{1},...,X_{n}$ sono indipendenti $\Longleftrightarrow
F_{\mathbf{X}}\left( \mathbf{x}\right) =F_{X_{1}}\left( x_{1}\right)
...F_{X_{n}}\left( x_{n}\right) $: questa propriet\`{a} permette una
semplice verifica dell'indipendenza, anche quando alcune componenti del
vettore sono discrete e altre continue. Significa che l'insieme degli
iperquadranti di sud-ovest \`{e} un $\pi $-sistema.

Se $F_{\mathbf{X}}$ \`{e} derivabile tranne e. g. un numero finito di punti, 
$f_{\mathbf{X}}\left( \mathbf{x}\right) =\frac{\partial ^{2}F_{\mathbf{X}%
}\left( \mathbf{x}\right) }{\partial x_{1}...\partial x_{n}}$.

\subsection{Vettori aleatori discreti}

\textbf{Def 14.2} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, un vettore aleatorio $\mathbf{X}:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ con legge $P^{\mathbf{X}}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,1\right] $ si dice vettore aleatorio
discreto se $P^{\mathbf{X}}$ \`{e} una misura di probabilit\`{a} discreta su 
$\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $, cio\`{e} se $\exists $ $T\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ discreto e $p_{\mathbf{X}}:T\rightarrow \left[ 0,1\right] $, detta
densit\`{a} discreta o densit\`{a} congiunta di $\mathbf{X}$, tale che $P^{%
\mathbf{X}}\left( B\right) =\sum_{\mathbf{x}\in T\cap B}p_{\mathbf{X}}\left( 
\mathbf{x}\right) $ $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $. In tal caso si dice supporto di $\mathbf{X}$, e si indica con 
$S_{\mathbf{X}}$, il supporto di $p_{\mathbf{X}}$, cio\`{e} $\left\{ \mathbf{%
x}\in T:p_{\mathbf{X}}\left( \mathbf{x}\right) >0\right\} $.

Se $\mathbf{X}$ descrive gli esiti del lancio di due dadi, $T$ \`{e} $%
\left\{ 1,...,6\right\} ^{2}$, cio\`{e} un reticolo di $36$ punti nel piano.

\textbf{Prop (definizioni equivalenti di vettore aleatorio discreto)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ \`{e} vettore aleatorio con legge }P^{\mathbf{X}} \\
\text{Ts: (1) }\mathbf{X}\text{ \`{e} discreto }\Longleftrightarrow \text{%
(2) }\exists \text{ }T^{\prime }\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ discreto}:\mathbf{P}\left( \mathbf{X}\in T^{\prime }\right)
=1\Longleftrightarrow \text{(3) }\exists \text{ }\mathbf{\tilde{X}:P}\left( 
\mathbf{X}=\mathbf{\tilde{X}}\right) =1 \\
\text{e }\func{Im}\left( \mathbf{\tilde{X}}\right) =S_{\mathbf{X}%
}\Longleftrightarrow \text{(4) }X_{1},...,X_{n}\text{ sono variabili
aleatorie discrete}
\end{gather*}

(3) significa che non necessariamente $\mathbf{X}$ ha come immagine $S_{%
\mathbf{X}}$, ma se \`{e} uguale quasi certamente con a un vettore che ha
quella come immagine, allora \`{e} discreto!

\textbf{Dim} Dimostro che (4) implica (2). Se $X_{1},...,X_{n}$ sono
variabili aleatorie discrete, $P^{X_{k}}$ \`{e} una probabilit\`{a} discreta
con $S_{X_{k}}$ discreto $\forall $ $k=1,...,n$. Allora definisco $T^{\prime
}=S_{X_{1}}\times S_{X_{2}}\times ...\times S_{X_{n}}$ e mostro che $\mathbf{%
P}\left( \mathbf{X}\in T^{\prime }\right) =1$. Osservo che $\left( \mathbf{X}%
\in S_{X_{1}}\times S_{X_{2}}\times ...\times S_{X_{n}}\right)
\Longleftrightarrow \left( X_{1}\in S_{X_{1}}\cap ...\cap X_{n}\in
S_{X_{n}}\right) \Longleftrightarrow \bigcap_{k=1}^{n}\left( X_{k}\in
S_{X_{k}}\right) $ per la propriet\`{a} distributiva della controimmagine
rispetto all'intersezione. Allora $\mathbf{P}\left( \mathbf{X}\in T^{\prime
}\right) =\mathbf{P}\left( \bigcap_{k=1}^{n}\left( X_{k}\in S_{X_{k}}\right)
\right) =1-\mathbf{P}\left( \bigcup_{k=1}^{n}\left( X_{k}\in
S_{X_{k}}\right) ^{c}\right) \geq 1-\sum_{k=1}^{n}\mathbf{P}\left( \left(
X_{k}\in S_{X_{k}}\right) ^{c}\right) $. Ma $\mathbf{P}\left( X_{k}\not\in
S_{X_{k}}\right) =0$ $\forall $ $k$ perch\'{e} $\mathbf{P}\left(
X_{k}\not\in S_{X_{k}}\right) =1-\mathbf{P}\left( X_{k}\in S_{X_{k}}\right)
=1-\sum_{k=1}^{n}\mathbf{P}\left( X_{k}=x_{k}\right) =1-1=0$, dove $x_{k}$ 
\`{e} il generico elemento di $S_{X_{k}}$, essendo $\sum_{k=1}^{n}\mathbf{P}%
\left( X_{k}=x_{k}\right) =\sum_{k=1}^{N}p_{X_{k}}\left( x_{k}\right) =1$,
quindi $\mathbf{P}\left( \mathbf{X}\in T^{\prime }\right) \geq 1$, cio\`{e} $%
\mathbf{P}\left( \mathbf{X}\in T^{\prime }\right) =1$. $\blacksquare $

Se $X_{1},...,X_{n}$ sono variabili aleatorie discrete su $T_{1},...,T_{n}$
discreti (con densit\`{a} $p_{X_{1}},...,p_{X_{k}}$, dette densit\`{a}
marginali), per la proposizione $\mathbf{P}\left( \mathbf{X}\in
T=T_{1}\times ...\times T_{n}\right) =1$, ma \`{e} possibile che $S_{\mathbf{%
X}}\subset T$.

\textbf{Prop 14.3 (regola del valore atteso per vettori aleatori discreti,
densit\`{a} marginali da densit\`{a} congiunta, fattorizzazione della densit%
\`{a})} 
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ \`{e} vettore } \\
\text{aleatorio discreto con densit\`{a} }p_{\mathbf{X}}\text{ su }%
T=T_{1}\times ...\times T_{n} \\
\text{Ts: (1) data }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, se }h\left( \mathbf{x}\right) \geq 0\text{ o }h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,P^{\mathbf{X}}\right) \text{ } \\
\mathbf{E}\left( h\left( \mathbf{X}\right) \right) =E^{\mathbf{X}}\left(
h\right) =\sum_{t\in T}p_{\mathbf{X}}\left( t\right) h\left( t\right) \\
\text{(2) la densit\`{a} discreta di }X_{k}\text{ \`{e} }p_{X_{k}}\left( 
\hat{x}_{k}\right) =\sum_{\substack{ x_{1}\in T_{1}  \\ ...  \\ x_{k-1}\in
T_{k-1}  \\ x_{k+1}\in T_{k+1}  \\ ...  \\ x_{n}\in T_{n}}}p_{X}\left(
x_{1},...,x_{k-1},\hat{x}_{k},...,x_{n}\right) \\
\text{con }\left( x_{1},...,x_{k-1},\hat{x}_{k},...,x_{n}\right) \in T \\
\text{(3) }X_{1},...,X_{n}\text{ sono indipendenti }\Longleftrightarrow p_{%
\mathbf{X}}\left( x_{1},...,x_{n}\right) =p_{X_{1}}\left( x_{1}\right)
...p_{X_{n}}\left( x_{n}\right) \text{ }\forall \text{ }\mathbf{x}
\end{gather*}

(1) implica che $h\in L^{1}\left( P^{\mathbf{X}}\right) \Longleftrightarrow
\sum_{t\in T}\left\vert h\left( t\right) \right\vert p_{\mathbf{X}}\left(
t\right) <+\infty $. (2) \`{e} ben posta perch\'{e} $\mathbf{X}$ \`{e}
discreto se e solo se tutte le sue componenti sono discrete; significa che
si possono ottenere le densit\`{a} marginali dalla densit\`{a} congiunta, cio%
\`{e} avendo la legge del vettore si pu\`{o} sapere tutto sulle componenti.
(3) significa che per v. a. indipendenti la densit\`{a} congiunta si
fattorizza nel prodotto delle densit\`{a} marginali.

\textbf{Dim (}1) vale per il teo 10.1 nel caso particolare $\left( E,%
\mathcal{E}\right) =\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) $.

(2) Nel caso particolare di $n=2$ per semplicit\`{a} di notazione. Se $%
x_{1}\in T_{1}$, $p_{X_{1}}\left( x_{1}\right) =\mathbf{P}\left(
X_{1}=x_{1}\right) =\mathbf{P}\left( X_{1}=x_{1},X_{2}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =P^{\mathbf{X}}\left( \left\{ x_{1}\right\} \times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ perch\'{e} $\left( X_{1}=\hat{x}_{1}\cap X_{2}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =X^{-1}\left( \hat{x}_{1}\right) \cap \Omega =X^{-1}\left( \hat{x}%
_{1}\right) $. Dunque $p_{X_{1}}\left( x_{1}\right) =P^{\mathbf{X}}\left(
\left\{ x_{1}\right\} \times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =\sum_{x_{2}\in T_{2}}p_{\mathbf{X}}\left( \mathbf{x}\right) $ per
definizione di probabilit\`{a} discreta.

(3) Se $X_{1},...,X_{n}$ sono indipendenti, $p_{\mathbf{X}}\left(
x_{1},...,x_{n}\right) =\mathbf{P}\left( X_{1}=x_{1},...,X_{n}=x_{n}\right) =%
\mathbf{P}\left( X_{1}=x_{1}\right) ...\mathbf{P}\left( X_{n}=x_{n}\right)
=p_{X_{1}}\left( x_{1}\right) ...p_{X_{n}}\left( x_{n}\right) $ per
definizione di indipendenza.

Se $p_{\mathbf{X}}\left( x_{1},...,x_{n}\right) =p_{X_{1}}\left(
x_{1}\right) ...p_{X_{n}}\left( x_{n}\right) $ $\forall $ $\mathbf{x}$, $%
\forall $ $B_{1},...,B_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ vale $\mathbf{P}\left( X_{1}\in B_{1},...,X_{n}\in
B_{n}\right) =\mathbf{P}\left( \mathbf{X}\in B_{1}\times ...\times
B_{n}\right) =\sum_{\mathbf{x}\in B\cap S}p_{\mathbf{X}}\left( \mathbf{x}%
\right) $: scrivendo la sommatoria componente per componente si ottiene $%
\sum_{\mathbf{x}\in B\cap S}p_{\mathbf{X}}\left( \mathbf{x}\right) $... $%
\blacksquare $

\begin{enumerate}
\item $\Omega =\left\{ 1,...,6\right\} ^{3}$, $\mathcal{A}=2^{\Omega }$, $%
\mathbf{P}$ uniforme. Lancio $3$ dadi: $X_{1}\left( \omega \right)
=\omega _{1},X_{2}=\omega _{2},X_{3}=\omega _{3}$ descrivono il risultato
dei lanci. Come trovo la densit\`{a} congiunta delle tre, cio\`{e} la densit%
\`{a} del vettore $\left( X_{1},X_{2},X_{3}\right) $? Se considero $\omega
=\left( 1,2,1\right) $, $p_{\mathbf{X}}\left( 1,2,1\right) =\mathbf{P}\left(
X_{1}=1,X_{2}=2,X_{3}=1\right) =\mathbf{P}\left( X_{1}=1\right) \mathbf{P}%
\left( X_{2}=2\right) \mathbf{P}\left( X_{3}=1\right) $, perch\'{e} le tre
v. a. sono indipendenti, quindi $p_{\mathbf{X}}\left( 1,2,1\right)
=p_{X_{1}}\left( 1\right) p_{X_{2}}\left( 2\right) p_{X_{3}}\left( 1\right) $%
.

$Y=X_{1}+X_{2}$ \`{e} una v. a. discreta perch\'{e} $\func{Im}\left(
X_{1}+X_{2}\right) =\left\{ 2,...,12\right\} $ \`{e} discreta. Costruisco il
vettore $\left( Y,X_{1}\right) $, che \`{e} un vettore aleatorio discreto
perch\'{e} ogni componente \`{e} discreta. Ne trovo la densit\`{a} su $%
T=\left\{ 2,...,12\right\} \times \left\{ 1,...,6\right\} $: calcolo ad
esempio $p_{\left( Y,X_{1}\right) }\left( 2,1\right) =\mathbf{P}\left(
Y=2,X_{1}=1\right) =\mathbf{P}\left( X_{1}=1,X_{2}=1\right) =\frac{1}{36}$
perch\'{e} $X_{1}$ e $X_{2}$ sono indipendenti (cf. v. a. che descrivono
l'esito di due lanci di moneta). Dato $\left( t_{1},t_{2}\right) \in T$, $%
p_{\left( Y,X_{1}\right) }\left( t_{1},t_{2}\right) =0$ se $t_{1}\leq t_{2}$
o se $t_{1}\geq 8$ e $t_{2}\leq t_{1}-7$, quindi la matrice delle densit\`{a}
\`{e} triangolare superiore.

$%
\begin{array}{cccccccc}
Y/X_{1} & 1 & 2 & 3 & 4 & 5 & 6 & p_{Y} \\ 
2 & \frac{1}{36} & 0 & 0 & 0 & 0 & 0 & \frac{1}{36} \\ 
3 & \frac{1}{36} & \frac{1}{36} & 0 & 0 & 0 & 0 & \frac{1}{18} \\ 
4 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & 0 & 0 & 0 & \frac{1}{12} \\ 
5 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & 0 & 0 & 
\frac{1}{9} \\ 
6 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36}
& 0 & \frac{5}{36} \\ 
7 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36}
& \frac{1}{36} & \frac{1}{6} \\ 
... & ... & ... & ... & ... & ... & ... & ... \\ 
p_{X_{1}} & \frac{1}{6} & \frac{5}{36} & \frac{1}{9} & \frac{1}{12} & \frac{1%
}{18} & \frac{1}{36} & 1%
\end{array}%
$

Mostro che $X_{1}$ e $Y$ non sono indipendenti: basta trovare $t:p_{\left(
Y,X_{1}\right) }\left( t\right) =0$, infatti e. g. $p_{\left( Y,X_{1}\right)
}\left( 2,2\right) =0\neq p_{Y}\left( 2\right) p_{X_{1}}\left( 2\right) =%
\frac{1}{36}\frac{1}{6}$. In generale, nei punti in cui la densit\`{a}
congiunta \`{e} $0$ cade l'indipendenza tra le componenti del vettore, perch%
\'{e} sono i punti in cui la densit\`{a} marginale di $Y$ \`{e} forzata da
quella di $X_{1}$. Dato quindi che in questo caso il supporto di $\left(
Y,X_{1}\right) $ non \`{e} un rettangolo, non posso separare le variabili: $%
S_{\left( Y,X_{1}\right) }$ non \`{e} fattorizzabile.

Invece $Y\perp X_{3}$ perch\'{e} $Y=h\left( X_{1},X_{2}\right) \perp g\left(
X_{3}\right) $ $\forall $ $h,g$ misurabili, per 12.2, essendo $\left(
X_{1},X_{2}\right) $ indipendente da $X_{3}$.
\end{enumerate}

\subsection{Vettori assolutamente continui}

\textbf{Def 14.4} Si dice misura di Lebesgue su $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ una funzione $m_{n}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,+\infty \right] $ con le seguenti propriet%
\`{a}:

\begin{description}
\item[M1] $m_{n}\left( A_{1}\times ...\times A_{n}\right) =m\left(
A_{1}\right) ...m\left( A_{n}\right) $ $\forall $ $A_{i}\in \mathcal{B}%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, $\forall $ $i=1,...,n$

\item[M2] $\sigma $-additivit\`{a}: $\forall $ $\left( B_{n}\right) _{n\geq
1}:B_{n}\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ $\forall $ $n$ e $B_{k}\cap B_{h}$ $\forall $ $k\neq h$, vale $%
m_{n}\left( \bigcup_{n=1}^{+\infty }B_{n}\right) =\sum_{n=1}^{+\infty
}m_{n}\left( B_{n}\right) $
\end{description}

M1 \`{e} ben posta perch\'{e} $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \otimes ...\otimes \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $: dev'essere $m_{n}\left( A_{1}\times ...\times A_{n}\right)
=m\left( A_{1}\right) ...m\left( A_{n}\right) $ $\forall $ $A_{i}\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, come per $\mathbf{P}$. $A_{1}\times ...\times A_{n}$ \`{e} un
generico elemento del $\pi $-sistema dei rettangoli in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$.

\textbf{Prop}%
\begin{equation*}
\exists \text{ }!\text{ misura di Lebesgue su }%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}
\end{equation*}

\textbf{Prop (propriet\`{a} di }$m_{n}$\textbf{)}%
\begin{gather*}
\text{Hp: }m_{n}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,+\infty \right] \text{ \`{e} la misura di
Lebesgue su }%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n} \\
\text{Ts: (1) }m_{2}\left( \left[ a,b\right] \times \left[ c,d\right]
\right) =\left( b-a\right) \left( d-c\right) \\
\text{(2) }m_{3}\left( \left[ a,b\right] \times \left[ c,d\right] \times %
\left[ e,f\right] \right) =\left( b-a\right) \left( d-c\right) \left(
f-e\right) \\
\text{(3) }m_{n}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =+\infty \\
\text{(4) }m_{n}\left( \left\{ \mathbf{x}\right\} \right) =0\text{ }\forall 
\text{ }\mathbf{x}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n} \\
\text{(5) }m_{n}\left( \left\{ \mathbf{x}\right\} \times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =0\text{ }\forall \text{ }\mathbf{x}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n-1} \\
\text{(6) }m_{2}\left( G_{f}\right) =0\text{ }\forall \text{ }f\text{
boreliana} \\
\text{(7) }m_{n}\left( A\right) =0\text{ }\forall \text{ }A\text{
sottospazio di }%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}:\dim A<n
\end{gather*}

In (6) $G_{f}=\left\{ \left( x,y\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}:y=f\left( x\right) \right\} $. $m_{2}\left( \left\{ \left( x,y\right)
\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}:x^{2}+y^{2}\leq r^{2}\right\} \right) =\pi r^{2}$: per $n=2$ e $n=3$ la
misura di Lebesgue coincide con le ordinarie nozioni di area e volume. Per (7) in realt\`{a} vale $m_{n}\left( A\right) =0$ 
$\forall $ $A:$ esiste un sottospazio $V$ di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}:\dim V<n$ e $A\subseteq V$, dove $V$ \`{e} un sottospazio eventualmente
affine ($V=\mathbf{v}_{0}+H$, $\dim V=\dim H$).

\textbf{Dim*} (1) (2) Sono conseguenze banali di M1 e della definizione di
misura di Lebesgue in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

(3) E' ancora una conseguenza di M1, dato che $m\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =+\infty $.

(5) significa in particolare che $m_{2}\left( \left\{ x\right\} \times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) =0$ $\forall $ $x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, cio\`{e} la misura di una retta verticale in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ \`{e} nulla. Si dimostra considerando un intorno tubolare della retta
di ampiezza che tende a $0$. $\blacksquare $

Si pu\`{o} definire, data $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,h\geq 0$ misurabile, l'integrale rispetto alla misura multidimensionale $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}hdm_{n}$ come fatto in precedenza. Scriveremo, con abuso, $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}hdm_{n}$ come $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( x_{1},...,x_{n}\right) dx_{1}...dx_{n}$. Si pu\`{o} definire
analogamente $L^{1}\left( m_{n}\right) =\left\{ \left[ h\right] :h\text{ 
\`{e} misurabile e }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\left\vert h\right\vert dm_{n}<+\infty \right\} $. Si definisce $%
\int_{A}hdm_{n}$ come $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}hI_{A}dm_{n}$; vale quindi $\int_{A}dm_{n}=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}I_{A}dm_{n}=m_{n}\left( A\right) $. Valgono le stesse propriet\`{a}
dell'integrale di Lebesgue in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, con due eccezioni: $h$ limitata e misurabile non implica $h$ integrabile;
non \`{e} vero che $L^{q}\left( m_{n}\right) \subseteq L^{p}\left(
m_{n}\right) $ $\forall $ $p\leq q$, sempre per il fatto che la misura non 
\`{e} finita.

\textbf{Def 14.5} Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,\mathbf{P}\right) $ spazio di probabilit\`{a}, $\mathbf{P}$ si
dice misura di probabilit\`{a} assolutamente continua se $\exists $ $f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ boreliana tale che $\mathbf{P}\left( A\right) =\int_{A}f\left(
x_{1},...,x_{n}\right) dm_{n}$ $\forall $ $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $.

Si scrive con abuso $\int_{A}f\left( x_{1},...,x_{n}\right) dx_{1}...dx_{n}$%
. Se $n=1$, si ottiene la definizione gi\`{a} data, per 11.5.

\textbf{Def 14.6} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a} e $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettore aleatorio con legge $P^{\mathbf{X}}$, $X$ si dice
assolutamente continuo se $P^{\mathbf{X}}$ \`{e} una misura di probabilit%
\`{a} assolutamente continua sullo spazio misurabile $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) $. In tal caso si indica con $f_{\mathbf{X}}$ una sua
densit\`{a}.

\textbf{Teo 14.7 (caratterizzazione delle densit\`{a})}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ \`{e} uno
spazio di probabilit\`{a}, }f:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: (1) }f\text{ \`{e} una densit\`{a} per }\mathbf{P}%
\Longleftrightarrow f\text{ \`{e} misurabile, }f\left( \mathbf{x}\right)
\geq 0\text{ }\forall \text{ }\mathbf{x}\text{,}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}f\left( x_{1},...,x_{n}\right) dm_{n}=1 \\
\text{(2) se vale }1\text{, }\mathbf{P}\left( A\right) =\int_{A}f\left(
x_{1},...,x_{n}\right) dm_{n}\text{ }\forall A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \text{ } \\
\text{(3) se }f_{1}=f_{2}\text{ q. o. e una delle due \`{e} una densit\`{a}
per }\mathbf{P}\text{, anche l'altra \`{e} } \\
\text{una densit\`{a} per }\mathbf{P}
\end{gather*}

(3) significa che $\mathbf{P}$ \`{e} caratterizzata da $\left[ f\right] $.

\begin{enumerate}
\item Considero $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\right) \right) $ e $C=\left\{ \left( x,y\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}:x^{2}+y^{2}\leq r^{2}\right\} $: voglio assegnare allo spazio una
misura di probabilit\`{a} uniforme su $C$. Questo significa intuitivamente
che c'\`{e} una densit\`{a} di probabilit\`{a} costante su $C$, cio\`{e} $%
f\left( x,y\right) =cI_{C}\left( x,y\right) $ (ne segue che si definisce $%
\mathbf{P}$ assolutamente continua). Per determinare $c\geq 0$ si usa (1): $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}}cI_{C}\left( x,y\right) dxdy=cm_{2}\left( C\right) =c\pi
r^{2}=1\Longleftrightarrow c=\frac{1}{r^{2}\pi }$.
\end{enumerate}

Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,\mathbf{P}\right) $ con $\mathbf{P}$ assolutamente continua con
densit\`{a} $f$, dato $A\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) :m_{n}\left( A\right) =0$, allora $\mathbf{P}\left( A\right) =0$%
.

\textbf{Teo 15.1 (regola del valore atteso per vettori aleatori continui,
densit\`{a} marginali da densit\`{a} congiunta, fattorizzazione della densit%
\`{a}) }%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ v. a. con legge }P^{\mathbf{X}} \\
\text{assolutamente continuo con densit\`{a} }f_{\mathbf{X}} \\
\text{Ts: (1) }\forall \text{ }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }h\in L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,P^{\mathbf{X}}\right) \Longleftrightarrow hf_{\mathbf{X}}\in
L^{1}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,m_{n}\right) \text{; } \\
\forall \text{ }h\in L^{1}\left( P^{\mathbf{X}}\right) \text{ o }h\geq 0%
\text{ misurabile vale }\mathbf{E}\left( h\left( \mathbf{X}\right) \right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( \mathbf{x}\right) f_{\mathbf{X}}\left( \mathbf{x}\right) dm_{n}
\\
\text{(2) }\forall \text{ }k=1,...,n\text{ }X_{k}:\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) \rightarrow \left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) \text{ \`{e} assolutamente } \\
\text{continua con densit\`{a} }f_{X_{k}}\left( \hat{x}_{k}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n-1}}f_{\mathbf{X}}\left( x_{1},...,\hat{x}_{k},...,x_{n}\right)
dx_{1}...dx_{k-1}dx_{k+1}...dx_{n} \\
\text{(3) }X_{1},...,X_{n}\text{ sono indipendenti e assolutamente continue
con densit\`{a} }f_{X_{1}}, \\
...,f_{X_{n}}\Longleftrightarrow \mathbf{X}\text{ \`{e} assolutamente
continuo e }f_{\mathbf{X}}\left( x_{1},...,x_{n}\right) =f_{X_{1}}\left(
x_{1}\right) ...f_{X_{n}}\left( x_{n}\right) \text{ q. o.}
\end{gather*}

E' l'analogo di 14.3 per vettori aleatori continui. $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( \mathbf{x}\right) f_{\mathbf{X}}\left( \mathbf{x}\right)
dm_{n}=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( \mathbf{x}\right) f_{\mathbf{X}}\left( \mathbf{x}\right)
dx_{1}...dx_{n}$. $hf_{\mathbf{X}}\in L^{1}\left( m_{n}\right) $ significa $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\left\vert h\left( \mathbf{x}\right) \right\vert f_{\mathbf{X}}\left( 
\mathbf{x}\right) dm_{n}<+\infty $. Ricordo che $\mathbf{E}\left( h\left(
X\right) \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( x_{1},...,x_{n}\right) dP^{\mathbf{X}}\left(
x_{1},...,x_{n}\right) $ per la regola del valore atteso. (2) significa
che la densit\`{a} della componente $k$ si ottiene integrando la densit\`{a}
congiunta avendo fissato la variabile $k$, come per le densit\`{a} discrete.

\textbf{Dim} (3) Se $X_{1},...,X_{n}$ sono indipendenti e assolutamente
continue con densit\`{a} $f_{X_{1}},...,f_{X_{n}}$, allora la legge di $%
\mathbf{X}$ \`{e} $P^{\mathbf{X}}\left( B\right) =\mathbf{P}\left( X_{1}\in
B_{1},..,X_{n}\in B_{n}\right) $, cio\`{e}, per indipendenza e assoluta
continuit\`{a} delle componenti, $\mathbf{P}\left( X_{1}\in B_{1}\right) ...%
\mathbf{P}\left( X_{n}\in B_{n}\right) =\int_{B_{1}}f_{X_{1}}\left(
x_{1}\right) dx_{1}...\int_{B_{n}}f_{X_{n}}\left( x_{n}\right)
dx_{n}=\int_{B_{1}\times ...\times B_{n}}f_{X_{1}}\left( x_{1}\right)
...f_{X_{n}}\left( x_{n}\right) dx_{1}...dx_{n}$, dove l'ultima uguaglianza
vale per il teorema di Fubini-Tonelli, essendo l'integrale fatto rispetto a $%
m_{n}$, che \`{e} la misura prodotto $m\otimes ...\otimes m$.
$\blacksquare $

Relativamente a (3), pu\`{o} capitare che $f_{\mathbf{X}}$ sia assegnata gi%
\`{a} fattorizzata in $n$ fattori, cio\`{e} $f_{\mathbf{X}}\left(
x_{1},...,x_{n}\right) =h_{1}\left( x_{1}\right) ...h_{n}\left( x_{n}\right) 
$: si sta affermando implicitamente che le componenti sono indipendenti; in
tal caso i fattori sono le densit\`{a} marginali, a meno di una costante da
determinare imponendo che $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X_{k}}\left( x_{k}\right) dx_{k}=1$ $\forall $ $k$.

Ovviamente $f_{\mathbf{X}}$ \`{e} assegnata gi\`{a} fattorizzata se questo 
\`{e} possibile: se e. g. $f_{\left( X,Y\right) }\left( x,y\right) =\frac{1}{%
\pi }I_{C}\left( x,y\right) $, con $C=\left\{ \left( x,y\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}:x^{2}+y^{2}\leq 1\right\} $, $\frac{1}{\pi }I_{C}\left( x,y\right) =%
\frac{1}{\pi }I_{\left[ -1,1\right] }\left( x\right) I_{\left[ -\sqrt{1-x^{2}%
},\sqrt{1-x^{2}}\right] }\left( y\right) $: ma la seconda $I$ dipende anche
da $x$, quindi $f$ non \`{e} fattorizzabile. Lo sarebbe passando in
coordinate polari, ma con una tale trasformazione si cambierebbe la legge
del vettore.

\begin{enumerate}
\item Se $n=2$ e ho $\mathbf{X}=\left( X_{1},X_{2}\right) $ assolutamente
continuo, la seconda densit\`{a} marginale \`{e} $f_{X_{2}}\left( \hat{x}%
_{2}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{\mathbf{X}}\left( x_{1},\hat{x}_{2}\right) dx_{1}$.
\end{enumerate}

Se $\mathbf{X}$ \`{e} assolutamente continuo, ogni componente $X_{k}$ \`{e}
assolutamente continua per 15.1 (2); in generale non \`{e} vero il
viceversa, a differenza del caso discreto, ma lo diventa se le componenti
sono indipendenti.

\begin{enumerate}
\item Considero $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $X:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ con legge esponenziale $\varepsilon \left( \lambda \right) $: \`{e}
assolutamente continua con densit\`{a} $f_{X}\left( t\right) =\lambda
e^{-\lambda t}I_{\left( 0,+\infty \right) }\left( t\right) $. Si \`{e} gi%
\`{a} visto che $X^{2}$ \`{e} assolutamente continua con densit\`{a} $%
f_{X^{2}}\left( t\right) =\frac{\lambda }{2\sqrt{t}}e^{-\lambda \sqrt{t}%
}I_{\left( 0,+\infty \right) }\left( t\right) $. Mi chiedo se il vettore $%
\mathbf{X}=\left( X,X^{2}\right) $ \`{e} assolutamente continuo. Osservo che 
$\forall $ $\omega \in \Omega $ $\left( X\left( \omega \right) ,X^{2}\left(
\omega \right) \right) \in G_{f}$, con $f\left( x\right) =x^{2}$, cio\`{e} $%
\mathbf{P}\left( \mathbf{X}\in G_{f}\right) =1$ (il boreliano $G_{f}$ ha
misura $1$ sotto la legge di $\mathbf{X}$), ma si \`{e} visto sopra che se $%
P^{\mathbf{X}}$ \`{e} assolutamente continua $m_{2}\left( G_{f}\right) =0$,
quindi $P^{\mathbf{X}}\left( G_{f}\right) =0$, che \`{e} assurdo. Dunque $P^{%
\mathbf{X}}$ non \`{e} assolutamente continua (vedi def 2.2.13)
\end{enumerate}

\textbf{Teo 15.2 (l'indipendenza a blocchi preserva l'assoluta continuit\`{a}%
)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}_{1}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{1}}\text{, }\mathbf{X}_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n2}\text{ sono v. a. } \\
\text{assolutamente continui con densit\`{a} }f_{\mathbf{X}_{1}},f_{\mathbf{X%
}_{2}}\text{ e indipendenti; }\mathbf{X}=\left( \mathbf{X}_{1}\mathbf{,X}%
_{2}\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{1}+n_{2}} \\
\text{Ts: }\mathbf{X}\text{ \`{e} assolutamente continuo con densit\`{a} } \\
f_{\mathbf{X}}\left( x_{1},...,x_{n_{1}},...,x_{n_{1}+n_{2}}\right) =f_{%
\mathbf{X}_{1}}\left( x_{1},...,x_{n_{1}}\right) f_{\mathbf{X}_{2}}\left(
x_{n_{1}+1},...,x_{n_{1}+n_{2}}\right)
\end{gather*}

Il teorema \`{e} una generalizzazione di 15.1 (3): nel caso $n_{1}=n_{2}=1$
afferma che un vettore con componenti assolutamente continue e indipendenti 
\`{e} assolutamente continuo, con densit\`{a} che si fattorizza.
L'indipendenza a blocchi
permette di preservare l'assoluta continuit\`{a}.

E' noto che se $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ \`{e} un v. a. e $\mathbf{h}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$ \`{e} misurabile, allora $\mathbf{h}\left( \mathbf{X}\right) :\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$ \`{e} un vettore aleatorio discreto se $\mathbf{X}$ \`{e} discreto.

Se $\mathbf{X}$ \`{e} assolutamente continuo, $\mathbf{h}\left( \mathbf{X}%
\right) $ \`{e} discreto se $\mathbf{h}$ ha immagine discreta. Se $\mathbf{h}
$ \`{e} un diffeomorfismo ($C^{1}$ con inversa $C^{1}$) anche $\mathbf{h}%
\left( \mathbf{X}\right) $ \`{e} assolutamente continuo. Se $\mathbf{h%
}$ non rientra in nessuna di queste categorie, $\mathbf{h}\left( \mathbf{X}%
\right) $ \`{e} generalmente difficile da trattare.

\begin{enumerate}
\item Se $\left( X,Y\right) $ \`{e} un ve. a. assolutamente continuo con
densit\`{a} $f_{\left( X,Y\right) }\left( x,y\right) $ e $Z=X+Y$, allora $Z$ 
\`{e} una v. a. assolutamente continua con densit\`{a} $f_{Z}\left( z\right)
=\int_{-\infty }^{+\infty }f_{\left( X,Y\right) }\left( z-x,x\right) dy$.
Infatti $F_{Z}\left( t\right) =\mathbf{P}\left( X+Y\leq t\right) =P^{\left(
X,Y\right) }\left( A\right) $, con $A=\left\{ \left( x,y\right) :x\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,y\in \left( -\infty ,t-x\right) \right\} $. Allora $P^{\left( X,Y\right)
}\left( A\right) =\int_{-\infty }^{+\infty }\left( \int_{-\infty
}^{t-x}f_{\left( X,Y\right) }\left( x,y\right) dy\right) dx$, e per il
teorema fondamentale del calcolo integrale $f_{Z}\left( t\right) =\frac{d}{dt%
}\left( \int_{-\infty }^{+\infty }\left( \int_{-\infty }^{t-x}f_{\left(
X,Y\right) }\left( x,y\right) dy\right) dx\right) =\int_{-\infty }^{+\infty }%
\frac{d}{dt}\left( \int_{-\infty }^{t-x}f_{\left( X,Y\right) }\left(
x,y\right) dy\right) dx=\int_{-\infty }^{+\infty }f_{\left( X,Y\right)
}\left( x,t-x\right) dx$ perch\'{e} $\lim_{y\rightarrow -\infty }f_{\left(
X,Y\right) }\left( x,y\right) =0$. Se $%
X\perp Y$, $f_{Z}\left( z\right) =\int_{-\infty }^{+\infty }f_{X}\left(
x\right) f_{Y}\left( t-x\right) dx$, detto prodotto di convoluzione delle
due densit\`{a}.

Alternativamente, si usa il vettore $\left( 
\begin{array}{c}
U \\ 
V%
\end{array}%
\right) =\left( 
\begin{array}{c}
X+Y \\ 
Y%
\end{array}%
\right) =\mathbf{h}\left( X,Y\right) $: $\mathbf{g}\left( U,V\right) =\left( 
\begin{array}{c}
U-V \\ 
V%
\end{array}%
\right) $ ha $J_{\mathbf{g}}\left( u,v\right) =\left[ 
\begin{array}{cc}
1 & -1 \\ 
0 & 1%
\end{array}%
\right] $, per cui $f_{\left( U,V\right) }\left( u,v\right) =f_{\left(
X,Y\right) }\left( u-v,v\right) \cdot 1$, e la densit\`{a} marginale di $U$ 
\`{e} $f_{Z}\left( u\right) =\int_{-\infty }^{+\infty }f_{\left( X,Y\right)
}\left( u-v,v\right) dv$.
\end{enumerate}

\subsection{Covarianza}

Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, considero $\left(
X,Y\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ v. a., con legge $P^{\left( X,Y\right) }:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\right) \rightarrow \left[ 0,1\right] $. Cerco un indice che misuri la
relazione tra le componenti del vettore. Ho gi\`{a} $\mathbf{E}\left(
X\right) ,\mathbf{E}\left( Y\right) ,var\left( X\right) ,var\left( Y\right) $%
, per calcolare i quali non \`{e} necessario conoscere $P^{\left( X,Y\right)
}$, e che non dicono nulla su $X,Y$ congiuntamente.

\textbf{Def 15.3} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a} e $\left( X,Y\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ v. a. tale che $X,Y\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $, si definisce covarianza di $X$ e $Y$, e si indica con $cov\left(
X,Y\right) $, il numero reale $\mathbf{E}\left( \left( X-\mathbf{E}\left(
X\right) \right) \left( Y-\mathbf{E}\left( Y\right) \right) \right) $. Se $%
cov\left( X,Y\right) >0$, $X$ e $Y$ si dicono positivamente correlate; se $%
cov\left( X,Y\right) =0$, $X$ e $Y$ si dicono scorrelate; se $cov\left(
X,Y\right) <0$, $X$ e $Y$ si dicono negativamente correlate.

La definizione \`{e} ben posta: perch\'{e} se $X,Y\in L^{2}$, allora $X,Y\in
L^{1}$, e perch\'{e} $X-\mathbf{E}\left( X\right) ,Y-\mathbf{E}\left(
Y\right) \in L^{2}$ (i numeri reali appartengono a $L^{p}$ $\forall $ $p$ e $%
L^{2}$ \`{e} uno spazio vettoriale) e il prodotto di v. a. $L^{2}$ \`{e} $%
L^{1}$.

Una covarianza positiva esprime la tendenza a crescere di una v. a. quando
l'altra cresce, mentre se \`{e} negativa una cresce quando l'altra decresce.
L'unit\`{a} di misura della varianza \`{e} l'unit\`{a} di misura delle v. a.
al quadrato.

Si pu\`{o} vedere $cov\left( X,Y\right) $ come $\mathbf{E}\left( h\left(
X,Y\right) \right) $ con $h\left( X,Y\right) =\left( X-\mu _{X}\right)
\left( Y-\mu _{Y}\right) $, per cui $cov\left( X,Y\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}}\left( x-\mu _{X}\right) \left( y-\mu _{Y}\right) dP^{\left( X,Y\right)
}\left( x,y\right) $ per la regola del valore atteso.

Se $\left( X,Y\right) $ \`{e} discreto con $T\subseteq 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ discreto e densit\`{a} $p_{\left( X,Y\right) }$, si ha $cov\left(
X,Y\right) =\sum_{\left( x,y\right) \in T}\left( x-\mu _{X}\right) \left(
y-\mu _{Y}\right) p_{\left( X,Y\right) }\left( x,y\right) $; se $\left(
X,Y\right) $ \`{e} assolutamente continuo con densit\`{a} $f_{\left(
X,Y\right) }$, si ha $cov\left( X,Y\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}}\left( x-\mu _{X}\right) \left( y-\mu _{Y}\right) f_{\left( X,Y\right)
}\left( x,y\right) dxdy$.

\textbf{Teo 15.4 (propriet\`{a} della covarianza)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X,Y\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\text{ v.a., }X,Y,Z\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\\
\text{Ts: (1) }cov\left( X,X\right) =var\left( X\right) \\
\text{(2) (commutativit\`{a}) }cov\left( X,Y\right) =cov\left( Y,X\right) \\
\text{(3) }cov\left( X,Y\right) =\mathbf{E}\left( XY\right) -\mathbf{E}%
\left( X\right) \mathbf{E}\left( Y\right) \\
\text{(4) (bilinearit\`{a}) }cov\left( aX+bY+c,Z\right) =acov\left(
X,Z\right) +bcov\left( Y,Z\right) \\
\text{(5) se }X\perp Y\text{, }cov\left( X,Y\right) =0 \\
\text{(6) (Cauchy-Schwarz) }\left\vert cov\left( X,Y\right) \right\vert \leq 
\sqrt{var\left( X\right) var\left( Y\right) } \\
\text{(7) se }X_{k}\in L^{2}\text{ }\forall \text{ }k=1,...,n\text{, }%
var\left( \sum_{k=1}^{n}X_{k}\right) =\sum_{k=1}^{n}var\left( X_{k}\right)
+2\sum_{h\neq k}cov\left( X_{k},X_{h}\right)
\end{gather*}

$\mathbf{E}\left( XY\right) =\mathbf{E}\left( h\left( X,Y\right) \right) $
con $h\left( x,y\right) =xy$: vedi regola valore atteso.

Le propriet\`{a} (1), (2) e (4), unitamente al fatto che $cov\left(
X,X\right) \geq 0$, implicano che $cov:L^{2}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) \times L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right)
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ definisce un'operazione con propriet\`{a} simili a un prodotto scalare su $%
L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $; non vale tuttavia $%
cov\left( X,X\right) =0\Longleftrightarrow X=0$, ma $X=c$ q. c.. E' un
prodotto scalare sullo spazio $L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $ quozientato rispetto alla relazione di equivalenza "differire
quasi certamente per una costante".

La norma indotta da tale prodotto scalare \`{e} $\left\vert \left\vert
X\right\vert \right\vert =\sqrt{var\left( X\right) }$. (3) \`{e}
un'uguaglianza analoga a quella che vale per la varianza, che diventa un
caso particolare di (3).

Due v. a. indipendenti hanno covarianza nulla, ma non vale il contrario. Per
calcolare $\mathbf{E}\left( XY\right) $ occorre $P^{\left( X,Y\right) }$. In
(4) si avrebbe $cov\left( c,Z\right) =0$ perch\'{e} la covarianza di una
costante e qualsiasi v. a. \`{e} nulla. (7), se $n=2$, \`{e} $var\left(
X+Y\right) =var\left( X\right) +var\left( Y\right) +2cov\left( X,Y\right) $.
Se le $X_{k}$ sono v. a. indipendenti, vale $var\left(
\sum_{k=1}^{n}X_{k}\right) =\sum_{k=1}^{n}var\left( X_{k}\right) $, perch%
\'{e} ogni covarianza \`{e} nulla per la (5), essendo le $X_{k}$ v. a.
indipendenti anche due a due.

\textbf{Dim} (1) $cov\left( X,X\right) =\mathbf{E}\left( \left( X-\mathbf{E}%
\left( X\right) \right) \left( X-\mathbf{E}\left( X\right) \right) \right)
=var\left( X\right) $ per definizione.

(2) $cov\left( X,Y\right) =\mathbf{E}\left( \left( X-\mathbf{E}\left(
X\right) \right) \left( Y-\mathbf{E}\left( Y\right) \right) \right) =\mathbf{%
E}\left( \left( Y-\mathbf{E}\left( Y\right) \right) \left( X-\mathbf{E}%
\left( X\right) \right) \right) =cov\left( Y,X\right) $ per commutativit\`{a}
del prodotto in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

(3) $cov\left( X,Y\right) =\mathbf{E}\left( \left( X-\mathbf{E}\left(
X\right) \right) \left( Y-\mathbf{E}\left( Y\right) \right) \right) =\mathbf{%
E}\left( XY-X\mathbf{E}\left( Y\right) -Y\mathbf{E}\left( X\right) +\mathbf{E%
}\left( X\right) \mathbf{E}\left( Y\right) \right) $, che \`{e}, per linearit%
\`{a}, $\mathbf{E}\left( XY\right) -\mathbf{E}\left( X\right) \mathbf{E}%
\left( Y\right) -\mathbf{E}\left( Y\right) \mathbf{E}\left( X\right) +%
\mathbf{E}\left( X\right) \mathbf{E}\left( Y\right) =\mathbf{E}\left(
XY\right) -\mathbf{E}\left( X\right) \mathbf{E}\left( Y\right) $.

(4) Per definzione $cov\left( aX+bY+c,Z\right) =\mathbf{E}\left( \left(
aX+bY+c-\mathbf{E}\left( aX+bY+c\right) \right) \left( Z-\mathbf{E}\left(
Z\right) \right) \right) $. L'argomento \`{e} $\left( aX+bY+c\right) Z-%
\mathbf{E}\left( Z\right) \left( aX+bY+c\right) -Z\mathbf{E}\left(
aX+bY+c\right) +\mathbf{E}\left( aX+bY+c\right) \mathbf{E}\left( Z\right) $:
i termini in cui compare $c$ sono $cZ-c\mathbf{E}\left( Z\right) -Zc+c%
\mathbf{E}\left( Z\right) =0$, e si ottiene quindi $\left( aX+bY\right) Z-%
\mathbf{E}\left( Z\right) \left( aX+bY\right) -Z\mathbf{E}\left(
aX+bY\right) +\mathbf{E}\left( aX+bY\right) \mathbf{E}\left( Z\right) $, che
coincide con $a\left( X-\mathbf{E}\left( X\right) \right) \left( Z-\mathbf{E}%
\left( Z\right) \right) +b\left( Y-\mathbf{E}\left( Y\right) \right) \left(
Z-\mathbf{E}\left( Z\right) \right) $. Calcolando il valore atteso di ci\`{o}
si ottiene per linearit\`{a} $\mathbf{E}\left( a\left( X-\mathbf{E}\left(
X\right) \right) \left( Z-\mathbf{E}\left( Z\right) \right) \right) +\mathbf{%
E}\left( b\left( Y-\mathbf{E}\left( Y\right) \right) \left( Z-\mathbf{E}%
\left( Z\right) \right) \right) =acov\left( X,Z\right) +bcov\left(
Y,Z\right) $.

(5) Per 12.3, per v. a. indipendenti $\mathbf{E}\left( XY\right) =\mathbf{E}%
\left( X\right) \mathbf{E}\left( Y\right) $, quindi usando (3) si ha $%
cov\left( X,Y\right) =0$.

(6) E' una conseguenza della struttura di spazio euclideo di $L^{2}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $: ponendo $cov\left( X,Y\right)
=\left\langle X,Y\right\rangle $, si ha per la disuguaglianza di
Cauchy-Schwarz $\left\vert \left\langle X,Y\right\rangle \right\vert \leq
\left\vert \left\vert X\right\vert \right\vert \left\vert \left\vert
Y\right\vert \right\vert =\sqrt{var\left( X\right) var\left( Y\right) }$.

(7) Per bilinearit\`{a} del prodotto scalare si ottiene $var\left(
\sum_{k=1}^{n}X_{k}\right) =\left\langle
X_{1}+...+X_{n},X_{1}+...+X_{n}\right\rangle =$ $\left\vert \left\vert
X_{1}\right\vert \right\vert ^{2}+...+\left\vert \left\vert X_{n}\right\vert
\right\vert ^{2}+2\left\langle X_{1},X_{2}\right\rangle +...+2\left\langle
X_{1},X_{n}\right\rangle +...+2\left\langle X_{n-1},X_{n}\right\rangle
=var\left( X_{1}\right) +...+var\left( X_{n}\right) +2\sum_{h\neq
k}cov\left( X_{h},X_{k}\right) $, dove l'ultimo addendo aggiunge tutti i
doppi prodotti. $\blacksquare $

\textbf{Def 15.5} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( X,Y\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ v.a. tali che $X,Y\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) ,var\left( X\right) =\sigma _{X}^{2}>0$ e $var\left( Y\right)
=\sigma _{Y}^{2}>0$, si definisce coefficiente di correlazione lineare di $X$
e $Y$, e si indica con $\rho \left( X,Y\right) $, $\frac{cov\left(
X,Y\right) }{\sqrt{\sigma _{X}^{2}\sigma _{Y}^{2}}}$.

La definizione \`{e} ben posta perch\'{e} $\sigma _{X}^{2},\sigma _{Y}^{2}>0$%
. Per (6) $\left\vert \rho \left( X,Y\right) \right\vert \leq 1$: quindi la
correlazione ha lo stesso significato della covarianza, ma \`{e} pi\`{u}
facilmente comprensibile perch\'{e} normalizzata.

\textbf{Prop 15.6 (correlazione unitaria)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }\left( X,Y\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\text{ v.a., } \\
X,Y\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }\sigma
_{X}^{2}>0,\sigma _{Y}^{2}>0 \\
\text{Ts}\text{: }\left\vert \rho \left( X,Y\right) \right\vert
=1\Longleftrightarrow \exists \text{ }a\neq 0,b\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:Y=aX+b\text{ q. c. e} \\
a=\frac{cov\left( X,Y\right) }{\sigma _{X}^{2}},b=\mathbf{E}\left( Y\right) -%
\frac{cov\left( X,Y\right) \mathbf{E}\left( X\right) }{\sigma _{Y}^{2}}
\end{gather*}

La proposizione afferma che due v. a. hanno coefficiente di correlazione
unitario se e solo se una \`{e} una trasformazione lineare affine
dell'altra. Nella tesi si pu\`{o} avere equivalentemente $a=\rho \left(
X,Y\right) \frac{\sigma _{Y}}{\sigma _{X}},b=\mu _{Y}-\mu _{X}\rho \left(
X,Y\right) \frac{\sigma _{X}}{\sigma _{Y}}$.

\textbf{Dim*} Dimostro l'implicazione da destra a sinistra. Se $Y=aX+b$, $%
var\left( Y\right) =a^{2}var\left( X\right) $ e $cov\left( X,Y\right)
=avar\left( X\right) $, per cui $\frac{cov\left( X,Y\right) }{\sqrt{\sigma
_{X}^{2}\sigma _{Y}^{2}}}=\frac{avar\left( X\right) }{\sqrt{var\left(
X\right) a^{2}var\left( X\right) }}=1$. $\blacksquare $

\textbf{Def 16.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettore aleatorio con $X_{k}\in L^{1}\left( \left( \Omega ,\mathcal{A},%
\mathbf{P}\right) \right) $ $\forall $ $k=1,...,n$, si definisce vettore
delle medie di $\mathbf{X}$, e si indica con $\mathbf{E}\left( \mathbf{X}%
\right) $ o $\mu _{\mathbf{X}}$, il vettore $\left( 
\begin{array}{c}
\mathbf{E}\left( X_{1}\right) \\ 
... \\ 
\mathbf{E}\left( X_{n}\right)%
\end{array}%
\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$.

\textbf{Def 16.2} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettore aleatorio con $X_{k}\in L^{2}\left( \left( \Omega ,\mathcal{A},%
\mathbf{P}\right) \right) $ $\forall $ $k=1,...,n$, si definisce matrice
delle covarianze di $\mathbf{X}$, e si indica con $C_{\mathbf{X}}$, la
matrice $\mathbf{E}\left( \left( \mathbf{X}-\mu _{\mathbf{X}}\right) \left( 
\mathbf{X}-\mu _{\mathbf{X}}\right) ^{T}\right) \in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( n,n\right) $.

$\left( \mathbf{X}-\mu _{\mathbf{X}}\right) \left( \mathbf{X}-\mu _{\mathbf{X%
}}\right) ^{T}=\left[ 
\begin{array}{ccc}
\left( X_{1}-\mathbf{E}\left( X_{1}\right) \right) ^{2} & ... & \left( X_{1}-%
\mathbf{E}\left( X_{1}\right) \right) \left( X_{n}-\mathbf{E}\left(
X_{n}\right) \right) \\ 
... & ... & ... \\ 
\left( X_{n}-\mathbf{E}\left( X_{n}\right) \right) \left( X_{1}-\mathbf{E}%
\left( X_{1}\right) \right) & ... & \left( X_{n}-\mathbf{E}\left(
X_{n}\right) \right) ^{2}%
\end{array}%
\right] $: se ne calcola il valore atteso componente per componente. Dalla
definizione \`{e} evidente che $\left( C_{\mathbf{X}}\right) _{ij}=E\left(
\left( X_{i}-\mathbf{E}\left( X_{i}\right) \right) \left( X_{j}-\mathbf{E}%
\left( X_{j}\right) \right) \right) =cov\left( X_{i},X_{j}\right) $, cio\`{e}
$C_{\mathbf{X}}=\left[ 
\begin{array}{ccc}
var\left( X_{1}\right) & ... & cov\left( X_{1},X_{n}\right) \\ 
... & ... & ... \\ 
cov\left( X_{n},X_{1}\right) & ... & var\left( X_{n}\right)%
\end{array}%
\right] $.

\textbf{Teo 16.3 (propriet\`{a} della matrice di covarianza)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ vettore aleatorio, } \\
X_{k}\in L^{2}\left( \left( \Omega ,\mathcal{A},\mathbf{P}\right) \right) 
\text{ }\forall k=1,...,n\text{, }C_{\mathbf{X}}\text{ matrice delle
covarianze di }\mathbf{X} \\
\text{Ts: (1) }C_{\mathbf{X}}\text{ \`{e} simmetrica e semidefinita positiva}
\\
\text{(2) }\mathbf{X\in }\func{col}C_{\mathbf{X}}+\mathbf{E}\left( \mathbf{X}%
\right) \text{ q. c.} \\
\text{(3) se }A\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( k,n\right) \text{, }\mathbf{b}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\text{, }\mathbf{Y}=A\mathbf{X+b}\text{, allora} \\
\mathbf{E}\left( \mathbf{Y}\right) =A\mathbf{E}\left( \mathbf{X}\right) +%
\mathbf{b}\text{ e }C_{\mathbf{Y}}=AC_{\mathbf{X}}A^{T}
\end{gather*}

$C_{\mathbf{X}}$ semidefinita positiva significa che $\mathbf{a}^{T}C_{%
\mathbf{X}}\mathbf{a}\geq 0$ $\forall $ $\mathbf{a}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$.

(2) significa che $\mathbf{E}\left( \mathbf{X}\right) $ rappresenta un
valore centrale per $\mathbf{X}$, attorno a cui $\mathbf{X}$ oscilla con
variabilit\`{a} governata dalla matrice delle covarianze. $\func{col}C_{%
\mathbf{X}}+\mathbf{E}\left( \mathbf{X}\right) $ \`{e} uno spazio lineare
affine. Se $\det C_{\mathbf{X}}\neq 0$, (2) diventa $\mathbf{X}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ q. c., che \`{e} un'informazione inutile: e. g., se $n=1$, significa
che $X\in \left\{ \mathbf{E}\left( X\right) +avar\left( X\right) :a\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right\} $ q. c., cio\`{e} $X$ appartiene q. c. all'asse reale se $var\left(
X\right) \neq 0$. Se invece $r\left( C_{\mathbf{X}}\right) =\dim \left( 
\func{col}C_{\mathbf{X}}\right) <n$, $\mathbf{X}$ non assume tutti i valori
in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, e soprattutto $\mathbf{P}\left( \mathbf{X\in }\func{col}C_{\mathbf{X}%
}+\mathbf{E}\left( \mathbf{X}\right) \right) =1$, dove $\func{col}C_{\mathbf{%
X}}+\mathbf{E}\left( \mathbf{X}\right) $ \`{e} un sottospazio affine di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ di dimensione inferiore a $n$. Ma \`{e} noto che in tal caso $%
m_{n}\left( \func{col}C_{\mathbf{X}}+\mathbf{E}\left( \mathbf{X}\right)
\right) =0$, per cui la legge di $\mathbf{X}$ non \`{e} una probabilit\`{a}
assolutamente continua, altrimenti dovrebbe preservare la misura nulla. Per
capire se $\mathbf{X}$ non \`{e} assolutamente continuo \`{e} quindi
sufficiente calcolare $\det C_{\mathbf{X}}$: se $\mathbf{X}$ \`{e}
assolutamente continuo $C_{\mathbf{X}}$ \`{e} definita positiva.

\textbf{Dim} (1) Poich\'{e} $\left( C_{\mathbf{X}}\right) _{ij}=cov\left(
X_{i},X_{j}\right) $, $\left( C_{\mathbf{X}}\right) _{ij}=\left( C_{\mathbf{X%
}}\right) _{ji}$ per commutativit\`{a} della varianza. Inoltre, per
definizione di forma quadratica, $\mathbf{a}^{T}C_{\mathbf{X}}\mathbf{a}%
=\sum_{k=1}^{n}\sum_{l=1}^{n}a_{k}\left( C_{\mathbf{X}}\right)
_{kl}a_{l}=\sum_{k=1}^{n}\sum_{l=1}^{n}a_{k}cov\left( X_{k},X_{l}\right)
a_{l}$, cio\`{e}, per bilinearit\`{a} della covarianza, $%
\sum_{k=1}^{n}a_{k}cov\left( X_{k},\sum_{l=1}^{n}a_{l}X_{l}\right)
=cov\left( \sum_{k=1}^{n}a_{k}X_{k},\sum_{l=1}^{n}a_{l}X_{l}\right)
=cov\left( a_{1}X_{1}+...+a_{n}X_{n},a_{1}X_{1}+...+a_{n}X_{n}\right)
=var\left( \sum_{k=1}^{n}a_{k}X_{k}\right) \geq 0$ per positivit\`{a} della
varianza. Questo \`{e} un modo per calcolare una varianza utile.

(2) Mostro che $\mathbf{X-E}\left( \mathbf{X}\right) \in \left( \ker C_{%
\mathbf{X}}\right) ^{\perp }$ q. c., cio\`{e} che $\forall $ $\mathbf{v}:C_{%
\mathbf{X}}\mathbf{v=0}$ vale $\left\langle \mathbf{X-\mu ,v}\right\rangle
=0 $ q. c.. E' noto che $C_{\mathbf{X}}=\mathbf{E}\left( \left( \mathbf{%
X-\mu }\right) \left( \mathbf{X-\mu }\right) ^{T}\right) $: quindi se $C_{%
\mathbf{X}}\mathbf{v=0}$ allora $\mathbf{E}\left( \left( \mathbf{X-\mu }%
\right) \left( \mathbf{X-\mu }\right) ^{T}\right) \mathbf{v=0}$ e $\mathbf{E}%
\left( \mathbf{v}^{T}\left( \mathbf{X-\mu }\right) \left( \mathbf{X-\mu }%
\right) ^{T}\mathbf{v}\right) \mathbf{=0}$. Ma $\mathbf{v}^{T}\left( \mathbf{%
X-\mu }\right) \left( \mathbf{X-\mu }\right) ^{T}\mathbf{v=}\left\vert
\left\vert \left( \mathbf{X-\mu }\right) ^{T}\mathbf{v}\right\vert
\right\vert ^{2}\geq 0$, e se il valore atteso di una v. a. nonnegativa \`{e}
zero allora la v. a. \`{e} nulla q. c., cio\`{e} $\left( \mathbf{X-\mu }%
\right) ^{T}\mathbf{v=0}$ q. c..

(3) Per definizione $C_{\mathbf{Y}}=\mathbf{E}\left( \left( \mathbf{Y}-\mu _{%
\mathbf{Y}}\right) \left( \mathbf{Y}-\mu _{\mathbf{Y}}\right) ^{T}\right) =%
\mathbf{E}\left( \left( A\mathbf{X+b}-A\mathbf{E}\left( X\right) -\mathbf{b}%
\right) \left( A\mathbf{X+b}-A\mathbf{E}\left( X\right) -\mathbf{b}\right)
^{T}\right) $ $=\mathbf{E}\left( \left( A\left( \mathbf{X-E}\left( X\right)
\right) \right) \left( A\left( \mathbf{X-E}\left( X\right) \right) \right)
^{T}\right) =A\mathbf{E}\left( \left( \mathbf{X-E}\left( X\right) \right)
\left( \mathbf{X-E}\left( X\right) \right) ^{T}\right) A^{T}$, per linearit%
\`{a} del valore atteso e trasposizione di un prodotto. $\blacksquare $

Date $X_{1},...,X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a. indipendenti e identicamente distribuite con $X_{k}\in L^{2}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) $, posso vedere tali v. a. come
componenti di un vettore $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$. $\mathbf{E}\left( \mathbf{X}\right) $ \`{e} un vettore con tutte le
componenti uguali a $\mu $, perch\'{e} $\mathbf{E}\left( X_{i}\right) $
dipende solo dalla legge di $X_{i}$ per la legge del valore atteso. $C_{%
\mathbf{X}}=\left[ 
\begin{array}{ccc}
\sigma ^{2} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \sigma ^{2}%
\end{array}%
\right] $ \`{e} una matrice diagonale, multipla dell'identit\`{a}, perch\'{e}
per indipendenza ogni covarianza tra v. a. diverse \`{e} nulla; la varianza 
\`{e} la stessa per tutte le v. a. perch\'{e} dipende solo dalla legge.

Se definisco media campionaria $\bar{X}_{n}=\frac{X_{1}+...+X_{n}}{n}$, vale
per linearit\`{a} che $\mathbf{E}\left( \bar{X}_{n}\right) =\frac{1}{n}n\mu
=\mu $. Per 15.4 (7) vale inoltre $var\left( \sum_{k=1}^{n}X_{k}\right)
=\sum_{k=1}^{n}var\left( X_{k}\right) =n\sigma ^{2}$, per cui $var\left( 
\bar{X}_{n}\right) =\frac{1}{n^{2}}n\sigma ^{2}=\frac{\sigma ^{2}}{n}$.

Se invece definisco varianza campionaria $S_{n}^{2}=\frac{1}{n-1}%
\sum_{k=1}^{n}\left( X_{k}-\bar{X}_{n}\right) ^{2}$, vale $S_{n}^{2}=\frac{1%
}{n-1}\sum_{k=1}^{n}\left( X_{k}^{2}+\bar{X}_{n}^{2}-2X_{k}\bar{X}%
_{n}\right) $. Poich\'{e} $var\left( X_{k}\right) =\mathbf{E}\left(
X_{k}^{2}\right) -\mathbf{E}^{2}\left( X_{k}\right) $, vale $\mathbf{E}%
\left( X_{k}^{2}\right) =\sigma ^{2}+\mu ^{2}$, e $\mathbf{E}\left( X_{k}%
\bar{X}_{n}\right) =cov\left( X_{k},\bar{X}_{n}\right) +\mathbf{E}\left(
X_{k}\right) \mathbf{E}\left( \bar{X}_{n}\right) =\frac{1}{n}var\left(
X_{k}\right) +\mathbf{E}\left( X_{k}\right) \mathbf{E}\left( \bar{X}%
_{n}\right) $: per linearit\`{a} $\mathbf{E}\left( S_{n}^{2}\right) =\frac{1%
}{n-1}\left( n\left( \sigma ^{2}+\mu ^{2}\right) +n\left( \frac{\sigma ^{2}}{%
n}+\mu ^{2}\right) -2n\frac{\sigma ^{2}}{n}-2n\mu ^{2}\right) =\frac{1}{n-1}%
\left( \ n\sigma ^{2}\ +\sigma ^{2}\ -2\sigma ^{2}\right) =\sigma ^{2}$.

\section{Funzione caratteristica}

Nel seguito $\mathbf{x=}\left( 
\begin{array}{c}
x_{1} \\ 
... \\ 
x_{n}%
\end{array}%
\right) $ indica il generico vettore colonna di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, $\mathbf{x}^{T}\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( 1,n\right) $, il prodotto scalare standard di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ \`{e} $\left\langle \mathbf{x,y}\right\rangle
=\sum_{i=1}^{n}x_{i}y_{i}=\left\langle \mathbf{x|y}\right\rangle $.

Introdurremo un nuovo modo per caratterizzare una probabilit\`{a} su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ - oltre alle gi\`{a} viste funzione di ripartizione e densit\`{a} -
che semplificher\`{a} il calcolo dei valori attesi e faciliter\`{a} lo
studio dell'indipendenza e delle combinazioni lineari di variabili aleatorie.

\textbf{Def 16.4} Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,\mathbf{P}\right) $ spazio di probabilit\`{a}, si dice funzione
caratteristica di $\mathbf{P}$, e si indica con $\phi $ o $\mathbf{\hat{P}}$%
, la funzione $\phi :%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
$, $\phi \left( \mathbf{u}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }d\mathbf{P}\left( 
\mathbf{x}\right) $.

(greg dice antitrasformata) Si noti che il prodotto scalare non ha senso se $%
\mathbf{P}$ non \`{e} una probabilit\`{a} sui boreliani.

La funzione integranda \`{e} $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
$, $h\left( \mathbf{x}\right) =e^{i\left\langle \mathbf{u},\mathbf{x}%
\right\rangle }$: $\exists $ $h_{1},h_{2}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:h\left( \mathbf{x}\right) =h_{1}\left( \mathbf{x}\right) +ih_{2}\left( 
\mathbf{x}\right) $, dunque $h$ \`{e} univocamente individuata dal vettore
delle sue componenti. Per definizione $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }d\mathbf{P}\left( 
\mathbf{x}\right) :=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h_{1}\left( \mathbf{x}\right) d\mathbf{P}\left( \mathbf{x}\right)
+i\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h_{2}\left( \mathbf{x}\right) d\mathbf{P}\left( \mathbf{x}\right) $,
dunque tutte le propriet\`{a} e i teoremi dell'integrale rispetto a una
misura di probabilit\`{a}, visti per $h$ a valori reali, valgono anche per
funzioni complesse, poich\'{e} valgono separatamente per parte reale e
immaginaria. In particolare $h\in L^{1}\left( \mathbf{P}\right)
\Longleftrightarrow h_{1},h_{2}\in L^{1}\left( \mathbf{P}\right) $.

Poich\'{e} $e^{i\theta }=\cos \theta +i\sin \theta $, $\left\vert e^{i\theta
}\right\vert =1$, e anche $\left\vert e^{i\left\langle \mathbf{u,x}%
\right\rangle }\right\vert =1$. Quindi $\left\vert \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( \mathbf{x}\right) d\mathbf{P}\left( \mathbf{x}\right)
\right\vert \leq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\left\vert h\left( \mathbf{x}\right) \right\vert d\mathbf{P}\left( 
\mathbf{x}\right) $. Se $h\left( \mathbf{x}\right) =e^{i\left\langle \mathbf{%
u},\mathbf{x}\right\rangle }$, $h=h_{\mathbf{u}}$ \`{e} limitata e quindi
integrabile rispetto a $\mathbf{P}$, dunque la definizione di $\phi $ \`{e}
ben posta qualsiasi sia $\mathbf{P}$ (come si pu\`{o} vedere anche
separatamente da parte reale e parte immaginaria, che sono funzioni
misurabili limitate e quindi integrabili rispetto a $\mathbf{P}$); inoltre $%
\left\vert \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }d\mathbf{P}\left( 
\mathbf{x}\right) \right\vert \leq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\left\vert e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle
}\right\vert d\mathbf{P}\left( \mathbf{x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}1d\mathbf{P}\left( \mathbf{x}\right) =\mathbf{P}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =1$, cio\`{e} $\phi $ \`{e} limitata in modulo.

\textbf{Def 16.5} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a} e $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettore aleatorio con legge $P^{\mathbf{X}}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,1\right] $, si dice funzione caratteristica
di $P^{\mathbf{X}}$, e si indica con $\phi _{\mathbf{X}}$ o $\hat{P}^{%
\mathbf{X}}$, la funzione $\phi _{\mathbf{X}}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
$, $\phi _{\mathbf{X}}\left( \mathbf{u}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }dP^{\mathbf{X}%
}\left( \mathbf{x}\right) $.

Per la regola del valore atteso $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }dP^{\mathbf{X}%
}\left( \mathbf{x}\right) =\int_{\Omega }e^{i\left\langle \mathbf{u},\mathbf{%
X}\left( \omega \right) \right\rangle }d\mathbf{P}\left( \omega \right) =%
\mathbf{E}\left( e^{i\left\langle \mathbf{u,X}\left( \omega \right)
\right\rangle }\right) $. $\phi _{\mathbf{X}}$ esiste qualsiasi sia $\mathbf{%
X}$, come la funzione di ripartizione. Se in particolare $\mathbf{X}$ \`{e}
assolutamente continuo, $\phi _{\mathbf{X}}\left( \mathbf{u}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}f_{X}\left( \mathbf{x}\right) e^{i\left\langle \mathbf{u},\mathbf{x}%
\right\rangle }d\mathbf{x}$.

\begin{enumerate}
\item Considero $X\sim \delta _{\mu }$. $p_{X}\left( \mu \right) =1$, $%
p_{X}\left( k\right) =0$ $\forall $ $k\neq \mu $. $\phi _{X}\left( u\right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}e^{iux}dP^{X}\left( x\right) =\mathbf{E}\left( e^{iuX}\right) =e^{iu\mu }%
\mathbf{P}\left( X=\mu \right) =e^{iu\mu }$ perch\'{e} $e^{iuX}$ \`{e} una
v. a. semplice.

\item Considero $X\sim poiss\left( \lambda \right) $. $\phi _{X}\left(
u\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}e^{iux}dP^{X}\left( x\right) =\mathbf{E}\left( e^{iuX}\right)
=\sum_{k=0}^{+\infty }e^{iuk}e^{-\lambda }\frac{\lambda ^{k}}{k!}%
=e^{-\lambda }\sum_{k=0}^{+\infty }\frac{\left( e^{iu}\lambda \right) ^{k}}{%
k!}=e^{-\lambda }e^{\lambda e^{iu}}$ per la regola del valore atteso per v.
a. discrete e perch\'{e} la serie \`{e} assolutamente convergente, dato che $%
\left\vert e^{iu}\right\vert =1$.

\item Considero $X\sim \varepsilon \left( \lambda \right) $. $\phi
_{X}\left( u\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}e^{iux}dP^{X}\left( x\right) =\mathbf{E}\left( e^{iuX}\right)
=\int_{0}^{+\infty }e^{iux}\lambda e^{-\lambda x}dx=\lambda
\int_{0}^{+\infty }e^{x\left( iu-\lambda \right) }dx=\frac{\lambda }{\lambda
-iu}$ per la regola del valore atteso per v. a. continue e perch\'{e} $%
\lim_{x\rightarrow +\infty }\frac{1}{iu-\lambda }e^{x\left( iu-\lambda
\right) }=0$ perch\'{e} $\left\vert e^{x\left( iu-\lambda \right)
}\right\vert =\left\vert e^{iux}e^{-\lambda x}\right\vert \leq e^{-\lambda
x} $ e $\lim_{x\rightarrow +\infty }e^{-\lambda x}=0$ (spiraleggia).
\end{enumerate}

\textbf{Teo 17.1 (}$\phi $\textbf{\ caratterizza }$\mathbf{P}$\textbf{;
propriet\`{a} analitiche di }$\phi $\textbf{)}%
\begin{gather*}
\text{Hp: }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,\mathbf{P}\right) \text{ spazio di probabilit\`{a}, }\mathbf{%
\hat{P}}/\phi \text{ \`{e} la funzione caratteristica di }\mathbf{P} \\
\text{Ts: (1) se }\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) ,\mathbf{Q}\right) \text{ \`{e} uno spazio di probabilit\`{a}, }%
\mathbf{P=Q\Longleftrightarrow \hat{Q}}\left( \mathbf{u}\right) =\mathbf{%
\hat{P}}\left( \mathbf{u}\right) \text{ }\forall \text{ }\mathbf{u} \\
\text{(2) }\phi \left( \mathbf{0}\right) =1\text{; }\left\vert \phi \left( 
\mathbf{u}\right) \right\vert \leq 1\text{ }\forall \text{ }\mathbf{u} \\
\text{(3) }\phi \text{ \`{e} continua in }\mathbf{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}^{n}
\end{gather*}

In (1) l'implicazione da sinistra e destra \`{e} ovvia per la definizione di 
$\phi $. (1) significa che il funzionale che a ogni probabilit\`{a} associa
la funzione caratteristica \`{e} biunivoco, quindi per controllare se due
misure di probabilit\`{a} coincidono \`{e} sufficiente confrontare le loro
funzioni caratteristiche, che \`{e} molto pi\`{u} semplice. (3) implica che $\phi $ in
generale \`{e} una funzione pi\`{u} regolare sia di $F$ che, quando esiste,
di $f$. Si pu\`{o} dimostrare che $\phi $ \`{e} anche uniformemente continua.

\textbf{Dim*} (2) $\phi \left( \mathbf{0}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}1d\mathbf{P}\left( \mathbf{x}\right) =\mathbf{P}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =1$. Per quanto gi\`{a} visto $\left\vert \phi \left( \mathbf{u}%
\right) \right\vert =\left\vert \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }d\mathbf{P}\left( 
\mathbf{x}\right) \right\vert \leq \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\left\vert e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle
}\right\vert d\mathbf{P}\left( \mathbf{x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}1d\mathbf{P}\left( \mathbf{x}\right) =\mathbf{P}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) =1$.

(3) Si vuole dimostrare che $\forall $ $\left\{ \mathbf{u}_{k}\right\}
:\lim_{k\rightarrow +\infty }\mathbf{u}_{k}=\mathbf{u}$ vale $%
\lim_{k\rightarrow +\infty }\phi \left( \mathbf{u}_{k}\right) =\phi \left( 
\mathbf{u}\right) $. $\lim_{k\rightarrow +\infty }e^{i\left\langle \mathbf{u}%
_{k}\mathbf{,x}\right\rangle }=e^{i\left\langle \mathbf{u,x}\right\rangle }$
per continuit\`{a} dell'esponenziale; $\phi \left( \mathbf{u}_{k}\right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u}_{k},\mathbf{x}\right\rangle }d\mathbf{P}%
\left( \mathbf{x}\right) $ e la funzione $\left\vert e^{i\left\langle 
\mathbf{u}_{k},\mathbf{x}\right\rangle }\right\vert =1$ \`{e} limitata da $1$%
, che \`{e} integrabile, quindi per il teorema di convergenza dominata (nel
caso particolare $\Omega =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$; gli elementi della successione sono tutti misurabili perch\'{e} funzioni
continue), dato che $e^{i\left\langle \mathbf{u}_{k},\mathbf{x}\right\rangle
}\rightarrow e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }$, $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u}_{k},\mathbf{x}\right\rangle }d\mathbf{P}%
\left( \mathbf{x}\right) $ converge a $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u},\mathbf{x}\right\rangle }d\mathbf{P}\left( 
\mathbf{x}\right) $. $\blacksquare $

\textbf{Teo 17.2 (regolarit\`{a} di }$\phi $, \textbf{formula dei momenti,
fattorizzazione della funzione caratteristica)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ vettore aleatorio } \\
\text{con legge }P^{\mathbf{X}}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \rightarrow \left[ 0,1\right] \text{ e funzione caratteristica }%
\phi _{\mathbf{X}} \\
\text{Ts: (1) se }\exists \text{ }m\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }:X_{k}\in L^{m}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \text{ }\forall \text{ }k=1,...,n\text{, allora }\phi _{\mathbf{X}%
}\in C^{m}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},%
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
\right) \\
\text{ e date }k_{1},...,k_{m}\text{ direzioni, }\frac{\partial ^{m}}{%
\partial u_{k_{1}}...\partial u_{k_{m}}}\phi _{\mathbf{X}}\left( \mathbf{u}%
\right) =i^{m}\mathbf{E}\left( X_{k_{1}}...X_{k_{m}}e^{i\left\langle \mathbf{%
u,X}\right\rangle }\right) \\
\text{(2) se }A\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( k,n\right) ,\mathbf{b}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k},\mathbf{Y}=A\mathbf{X+b}\text{, allora }\phi _{\mathbf{Y}}\left( 
\mathbf{v}\right) =e^{i\left\langle \mathbf{b,v}\right\rangle }\phi _{%
\mathbf{X}}\left( A^{T}\mathbf{v}\right) \\
\text{(3) }X_{1},...,X_{n}\text{ sono v. a. indipendenti }%
\Longleftrightarrow \phi _{\mathbf{X}}\left( \mathbf{u}\right) =\phi
_{X_{1}}\left( u_{1}\right) ...\phi _{X_{n}}\left( u_{n}\right) \text{ }%
\forall \text{ }\mathbf{u}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}
\end{gather*}

(1.1) afferma che l'integrabilit\`{a} delle componenti di $\mathbf{X}$
trasferisce regolarit\`{a} a $\phi _{\mathbf{X}}$; non vale il viceversa. In
(1.2) le direzioni possono anche non essere tutte distinte. (1.2) afferma la
possibilit\`{a} di scambiare derivata e integrale: in $\mathbf{E}\left(
X_{k_{1}}...X_{k_{m}}e^{i\left\langle \mathbf{u,X}\right\rangle }\right) $
si \`{e} derivato $e^{i\left\langle \mathbf{u,X}\right\rangle }$ rispetto
alle direzioni $u_{k_{1}},...,u_{k_{m}}$ prima di calcolare l'integrale:
l'uguaglianza \`{e} infatti $\frac{\partial ^{m}}{\partial
u_{k_{1}}...\partial u_{k_{m}}}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u,x}\right\rangle }dP^{X}\left( \mathbf{x}%
\right) =i^{m}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}x_{k_{1}}...x_{k_{m}}e^{i\left\langle \mathbf{u,x}\right\rangle }dP^{%
\mathbf{X}}\left( \mathbf{x}\right) $. (2) permette di calcolare $\phi _{%
\mathbf{Y}}$ con $\phi _{\mathbf{X}}$ se $\mathbf{Y}$ \`{e} una
trasformazione lineare affine di $\mathbf{X}$. Se in particolare $Y=-X$, $%
\phi _{Y}\left( v\right) =\phi _{X}\left( -v\right) =\bar{\phi}_{X}\left(
v\right) $. (3) afferma che $n$ v. a. sono indipendenti se e solo se la $%
\phi $ del vettore che esse compongono si fattorizza. Non \`{e} sufficiente
che $\phi _{\mathbf{X}}\left( u,u,...,u\right) =\phi _{X_{1}}\left( u\right)
...\phi _{X_{n}}\left( u\right) $ $\forall $ $u\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$.

$X_{k}\in L^{m}\left( \mathbf{P}\right) \Longleftrightarrow \mathbf{E}\left(
\left\vert X_{k}\right\vert ^{m}\right) <+\infty $. Quindi $\left\vert
X_{k_{1}}...X_{k_{m}}e^{i\left\langle \mathbf{u,X}\right\rangle }\right\vert
=\left\vert X_{k_{1}}\right\vert ...\left\vert X_{k_{m}}\right\vert $, che 
\`{e} il prodotto di $m$ v. a. ciascuna appartenente a $L^{m}$: come il
prodotto di $2$ v. a. in $L^{2}$ appartiene a $L^{1}$, $\left\vert
X_{k_{1}}\right\vert ...\left\vert X_{k_{m}}\right\vert $ appartiene a $%
L^{1} $ e dunque $X_{k_{1}}...X_{k_{m}}\in L^{1}$: perci\`{o} il lato destro
della formula \`{e} ben definito (!).

\textbf{Dim} (2) $\phi _{\mathbf{Y}}\left( \mathbf{v}\right) =\mathbf{E}%
\left( e^{i\left\langle \mathbf{v,Y}\right\rangle }\right) =\mathbf{E}\left(
e^{i\left\langle \mathbf{v,}A\mathbf{X+b}\right\rangle }\right) =\mathbf{E}%
\left( e^{i\left\langle \mathbf{v,}A\mathbf{X}\right\rangle
}e^{i\left\langle \mathbf{v,b}\right\rangle }\right) =e^{i\left\langle 
\mathbf{v,b}\right\rangle }\mathbf{E}\left( e^{i\left\langle \mathbf{v,}A%
\mathbf{X}\right\rangle }\right) $. Poich\'{e} $\left\langle \mathbf{v},A%
\mathbf{X}\right\rangle =\mathbf{v}^{T}A\mathbf{X=}\left( A^{T}\mathbf{v}%
\right) ^{T}\mathbf{X}$, si ha $\phi _{\mathbf{Y}}\left( \mathbf{v}\right)
=e^{i\left\langle \mathbf{v,b}\right\rangle }\mathbf{E}\left(
e^{i\left\langle A^{T}\mathbf{v,X}\right\rangle }\right) =e^{i\left\langle 
\mathbf{v,b}\right\rangle }\phi _{\mathbf{X}}\left( A^{T}\mathbf{v}\right) $%
\textbf{. }

(3) Se $X_{1},...,X_{n}$ sono indipendenti, $\phi _{\mathbf{X}}\left( 
\mathbf{u}\right) =\mathbf{E}\left( e^{i\left\langle \mathbf{u,X}%
\right\rangle }\right) =\mathbf{E}\left(
e^{iu_{1}X_{1}}...e^{iu_{n}X_{n}}\right) =\mathbf{E}\left(
e^{iu_{1}X_{1}}\right) ...\mathbf{E}\left( e^{iu_{n}X_{n}}\right) =\phi
_{X_{1}}\left( u_{1}\right) ...\phi _{X_{n}}\left( u_{n}\right) $. Il valore
atteso si fattorizza perch\'{e} $e^{iu_{1}X_{1}},...,e^{iu_{n}X_{n}}$ sono
una famiglia di v. a. indipendenti e $e^{iux}$ \`{e} misurabile e limitata.

Mostro l'implicazione da destra a sinistra: voglio mostrare che le $X_{i}$
sono indipendenti, cio\`{e} che la legge di $\mathbf{X}$ \`{e} la legge
prodotto. Allora considero la legge $P^{\mathbf{X}}=P^{X_{1}}\otimes
...\otimes P^{X_{n}}$ e mostro che ha funzione caratteristica $\phi _{%
\mathbf{X}}\left( \mathbf{u}\right) =\phi _{X_{1}}\left( u_{1}\right)
...\phi _{X_{n}}\left( u_{n}\right) $, per cui quella \`{e} la legge del
vettore $\mathbf{X}$, dato che $\phi _{\mathbf{X}}$ caratterizza $P^{\mathbf{%
X}}$. La funzione caratteristica della probabilit\`{a} prodotto \`{e} $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u,x}\right\rangle }dP^{X_{1}}\otimes
...\otimes P^{X_{n}}\left( \mathbf{x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{iu_{1}x_{1}}...e^{iu_{n}x_{n}}dP^{X_{1}}\otimes ...\otimes
P^{X_{n}}\left( \mathbf{x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{iu_{1}x_{1}}dP^{X_{1}}\left( x_{1}\right) ...\int
e^{iu_{n}x_{n}}dP^{X_{n}}\left( x_{n}\right) $, dove l'ultima uguaglianza
vale per il teorema di Fubini Tonelli (super Fubini 9.12), dato che la
funzione integranda \`{e} a variabili separabili. Quindi $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}e^{i\left\langle \mathbf{u,x}\right\rangle }dP^{X_{1}}\otimes
...\otimes P^{X_{n}}\left( \mathbf{x}\right) =\phi _{X_{1}}\left(
x_{1}\right) ...\phi _{X_{n}}\left( x_{n}\right) $. Allora la legge prodotto
dev'essere la legge di $\mathbf{X}$ e le sue componenti sono una famiglia di
v. a. indipendenti. $\blacksquare $

\begin{enumerate}
\item La formula 1.2 \`{e} detta dei momenti perch\'{e} permette di
calcolare pi\`{u} facilmente i momenti di una variabile aleatoria, prendendo 
$\mathbf{u=0}$: si ottiene $\frac{\partial ^{m}}{\partial
u_{k_{1}}...\partial u_{k_{m}}}\phi _{\mathbf{X}}\left( \mathbf{0}\right)
=i^{m}\mathbf{E}\left( X_{k_{1}}...X_{k_{m}}\right) $. Sia $n=1$, $X\in
L^{2}\left( \mathbf{P}\right) $: in questo caso $m=2$, quindi $\phi _{X}\in
C^{2}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,%
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
\right) $. Ma poich\'{e} $L^{2}\subseteq L^{1}$, posso anche scegliere $m=1$%
: applicando la formula, $\frac{d}{du}\phi _{X}\left( 0\right) =i\mathbf{E}%
\left( X\right) $, quindi $\mathbf{E}\left( X\right) =-i\phi _{X}^{\prime
}\left( 0\right) $. Analogamente, con $m=2$ $\frac{d^{2}}{du^{2}}\phi
_{X}\left( 0\right) =i^{2}\mathbf{E}\left( X^{2}\right) $, cio\`{e} $\mathbf{%
E}\left( X^{2}\right) =-\phi _{X}^{\prime \prime }\left( 0\right) $. In
generale, se si vuole conoscere il momento $m$-esimo, si prende $%
k_{1}=...=k_{m}=1$ e si ottiene $\phi _{X}^{\left( m\right) }\left( 0\right)
=i^{m}\mathbf{E}\left( X^{m}\right) $. Vale dunque $var\left( X\right)
=-\phi _{X}^{\prime \prime }\left( 0\right) +\left( \phi _{X}^{\prime
}\left( 0\right) \right) ^{2}$.

Sia $n=2$, $X_{1},X_{2}\in L^{2}\left( \mathbf{P}\right) $: essendo $m=2$, $%
\phi _{X}\in C^{2}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2},%
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
\right) $. Vale quindi $\frac{\partial ^{2}\phi _{\mathbf{X}}\left(
0,0\right) }{\partial u_{1}\partial u_{2}}=i^{2}\mathbf{E}\left(
X_{1}X_{2}\right) $, che implica $\mathbf{E}\left( X_{1}X_{2}\right) =-\frac{%
\partial ^{2}\phi _{X}\left( 0,0\right) }{\partial u_{1}\partial u_{2}}$.
Con $m=1$, prendendo $k_{1}=k_{2}=1$ si ottiene ancora $\mathbf{E}\left(
X_{1}\right) =-i\phi _{X_{1}}^{\prime }\left( 0\right) =-i\frac{\partial }{%
\partial u_{1}}\phi _{\mathbf{X}}\left( 0,0\right) $, $\mathbf{E}\left(
X_{2}\right) =-i\frac{\partial }{\partial u_{2}}\phi _{X}\left( 0,0\right) $%
, dunque $cov\left( X_{1},X_{2}\right) =-\frac{\partial ^{2}\phi _{X}\left( 
\mathbf{0}\right) }{\partial u_{1}\partial u_{2}}+\frac{\partial }{\partial
u_{1}}\phi _{X}\left( \mathbf{0}\right) \frac{\partial }{\partial u_{2}}\phi
_{X}\left( \mathbf{0}\right) $. L'integrabilit\`{a} delle componenti
permette quindi di risalire a tutti gli indici desiderati semplicemente
calcolando derivate.

Si noti che vale $\phi _{X_{1}}^{\prime }\left( 0\right) =\frac{\partial }{%
\partial u_{1}}\phi _{\mathbf{X}}\left( 0,0\right) $ perch\'{e} con $m=1$ si
ha $\frac{\partial }{\partial u_{1}}\phi _{\mathbf{X}}\left( \mathbf{0}%
\right) =i\mathbf{E}\left( X_{1}\right) $, cio\`{e} $\mathbf{E}\left(
X_{1}\right) =-i\frac{\partial }{\partial u_{1}}\phi _{\mathbf{X}}\left( 
\mathbf{0}\right) $.

\item Considero $X\sim geom\left( p\right) $: $p_{X}\left( k\right) =\left(
1-p\right) ^{k-1}p$ $\forall $ $k\geq 1$. Posso calcolare $\mathbf{E}\left(
X\right) $ usando la formula dei momenti: $\mathbf{E}\left( X\right) =-i\phi
_{X}^{\prime }\left( 0\right) $. Poich\'{e} $\phi _{X}\left( u\right) =%
\mathbf{E}\left( e^{iuX}\right) =\sum_{k=1}^{+\infty }e^{iuk}\left(
1-p\right) ^{k-1}p=pe^{iu}\sum_{k=1}^{+\infty }\left( e^{iu}\left(
1-p\right) \right) ^{k-1}=\frac{pe^{iu}}{1-e^{iu}\left( 1-p\right) }$, $\phi
_{X}^{\prime }\left( u\right) =\frac{ipe^{iu}}{\left( 1-e^{iu}\left(
1-p\right) \right) ^{2}}$, quindi $\mathbf{E}\left( X\right) =\frac{p}{p^{2}}%
=\frac{1}{p}$.

\item Considero $X\sim \mathcal{N}\left( 0,1\right) $. $\phi _{X}\left(
u\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}e^{iux}\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\cos ux\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx+i\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\sin ux\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\cos ux\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx$ (il secondo addendo 
\`{e} nullo perch\'{e} la funzione integranda \`{e} dispari). Si \`{e} visto
prima che $\phi _{X}^{\prime }\left( u\right) =i\mathbf{E}\left(
Xe^{iuX}\right) =i\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}x\cos ux\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx-\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}x\sin ux\frac{1}{\sqrt{2\pi }}e^{-\frac{1}{2}x^{2}}dx=-\frac{1}{\sqrt{2\pi }%
}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}x\sin uxe^{-\frac{1}{2}x^{2}}dx$. Integrando per parti si ha $\int x\sin
\left( ux\right) e^{-\frac{1}{2}x^{2}}dx=-e^{-\frac{1}{2}x^{2}}\sin \left(
ux\right) +\int ue^{-\frac{1}{2}x^{2}}\cos \left( ux\right) dx$, per cui $%
\phi _{X}^{\prime }\left( u\right) =-\frac{1}{\sqrt{2\pi }}\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}ue^{-\frac{1}{2}x^{2}}\cos uxdx=-u\phi _{X}\left( u\right) $. Si \`{e}
quindi ottenuto un problema di Cauchy $\left\{ 
\begin{array}{c}
\phi _{X}^{\prime }\left( u\right) =-u\phi _{X}\left( u\right) \\ 
\phi _{X}\left( 0\right) =1%
\end{array}%
\right. $: esiste un'unica soluzione $\phi _{X}\left( u\right) =e^{-\frac{1}{%
2}u^{2}}$, che \`{e} limitata come dev'essere e ha parte immaginaria nulla.

Considero $X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) $. $\exists $ $%
Z\sim \mathcal{N}\left( 0,1\right) :X=\sigma Z+\mu $: allora per 17.3 (2) $%
\phi _{X}\left( u\right) =e^{iu\mu }\phi _{X}\left( \sigma u\right)
=e^{iu\mu }e^{-\frac{1}{2}\sigma ^{2}u^{2}}$: si ha un termine lineare e uno
quadratico all'esponente.

\item Dato $\mathbf{X}$, se $\phi _{\mathbf{X}}\left( \mathbf{u}\right) $ 
\`{e} nota, come si ottiene $\phi _{X_{k}}\left( v\right) $? Vale $%
X_{k}=\left\langle \mathbf{e}_{k}\mathbf{,X}\right\rangle =\mathbf{e}_{k}^{T}%
\mathbf{X}$, quindi $\phi _{X_{k}}\left( v\right) =\phi _{\mathbf{X}}\left( 
\mathbf{e}_{k}v\right) =\phi _{\mathbf{X}}\left( 0,...,0,v,0,...,0\right) $.
\end{enumerate}

\textbf{Corollario 17.3}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}_{1}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{1}},\mathbf{X}_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{2}}\text{ } \\
\text{vettori aleatori con funzioni caratteristiche }\phi _{\mathbf{X}%
_{1}},\phi _{\mathbf{X}_{2}} \\
\text{Ts: }\mathbf{X}_{1}\mathbf{\perp X}_{2}\Longleftrightarrow \phi
_{\left( \mathbf{X}_{1},\mathbf{X}_{2}\right) }\left( \mathbf{u}\right)
=\phi _{\mathbf{X}_{1}}\left( u_{1},...,u_{n_{1}}\right) \phi _{\mathbf{X}%
_{2}}\left( u_{n_{1}+1},...,u_{n_{1}+n_{2}}\right)
\end{gather*}

\textbf{Dim} Si applica 17.2 (3) a $\mathbf{X}_{1}\mathbf{,X}_{2}$. $%
\blacksquare $

\textbf{Corollario 17.4 (}$\phi $\textbf{\ della somma)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ vettore } \\
\text{aleatorio con funzione caratteristica }\phi _{\mathbf{X}}\text{, }%
S_{n}=X_{1}+...+X_{n} \\
\text{Ts: }\phi _{S_{n}}\left( v\right) =\phi _{\mathbf{X}}\left(
v,...,v\right) \\
\text{(ii) se }X_{1},...,X_{k}\text{ sono indipendenti, }\phi _{S_{n}}\left(
v\right) =\phi _{X_{1}}\left( v\right) ...\phi _{X_{n}}\left( v\right) \\
\text{(iii) se }X_{1},...,X_{k}\text{ sono iid, }\phi _{S_{n}}\left(
v\right) =\left( \phi _{X_{i}}\left( v\right) \right) ^{n}
\end{gather*}

Non vale il viceversa in (ii), perch\'{e} il fatto che $\phi _{\mathbf{X}%
}\left( v,...,v\right) $ si fattorizzi $\forall $ $v$ non \`{e} sufficiente
a concludere che si fattorizzi $\forall $ $\mathbf{v}=\left(
v_{1},...,v_{n}\right) $.

\textbf{Dim} Vale $S_{n}=\left\langle \left( 
\begin{array}{c}
1 \\ 
... \\ 
1%
\end{array}%
\right) \mathbf{,X}\right\rangle $, quindi per 17.2 (2) $\phi _{S_{n}}\left(
v\right) =\phi _{\mathbf{X}}\left( v,...,v\right) $. Se inoltre le
componenti sono indipendenti, per 17.2 (3) la funzione caratteristica si
fattorizza: $\phi _{S_{n}}\left( v\right) =\phi _{X_{1}}\left( v\right)
...\phi _{X_{n}}\left( v\right) $. Se inoltre le componenti hanno tutte la
stessa legge, hanno la stessa funzione caratteristica e $\phi _{S_{n}}\left(
v\right) =\left( \phi _{X_{i}}\left( v\right) \right) ^{n}$. $\blacksquare $

\begin{enumerate}
\item Siano $X_{1}\sim \mathcal{N}\left( \mu _{1},\sigma _{1}^{2}\right)
,X_{2}\sim \mathcal{N}\left( \mu _{2},\sigma _{2}^{2}\right) $, $X_{1}\perp
X_{2}$. Mostro che $X_{1}+X_{2}\sim \mathcal{N}\left( \mu _{1}+\mu
_{2},\sigma _{1}^{2}+\sigma _{2}^{2}\right) $. Infatti per indipendenza vale 
$\phi _{S_{2}}\left( v\right) =e^{iu\mu _{1}}e^{-\frac{1}{2}\sigma
_{1}^{2}u^{2}}e^{iu\mu _{2}}e^{-\frac{1}{2}\sigma _{2}^{2}u^{2}}=e^{iu\left(
\mu _{1}+\mu _{2}\right) }e^{-\frac{1}{2}\left( \sigma _{1}^{2}+\sigma
_{2}^{2}\right) u^{2}}$, che \`{e} la funzione caratteristica di $Y\sim 
\mathcal{N}\left( \mu _{1}+\mu _{2},\sigma _{1}^{2}+\sigma _{2}^{2}\right) $%
. Poich\'{e} $\phi _{Y}$ individua univocamente la legge della variabile
aleatoria, $S_{2}$ deve avere la legge di $Y$.

\item Siano $X_{1}\sim poiss\left( \lambda _{1}\right) ,X_{2}\sim
poiss\left( \lambda _{2}\right) $, $X_{1}\perp X_{2}$, $\lambda _{1},\lambda
_{2}>0$. Mostro che $X_{1}+X_{2}\sim poiss\left( \lambda _{1}+\lambda
_{2}\right) $. Infatti per indipendenza vale $\phi _{S_{2}}\left( v\right)
=e^{-\lambda _{1}}e^{\lambda _{1}e^{iu}}e^{-\lambda _{2}}e^{\lambda
_{2}e^{iu}}=e^{-\left( \lambda _{1}+\lambda _{2}\right) }e^{\left( \lambda
_{1}+\lambda _{2}\right) e^{iu}}$, che \`{e} la funzione caratteristica di $%
Y\sim poiss\left( \lambda _{1}+\lambda _{2}\right) $. Poich\'{e} $\phi _{Y}$
individua univocamente la legge della variabile aleatoria, $S_{2}$ deve
avere la legge di $Y$.

\item Sia $Y\sim bin\left( n,p\right) $. $\phi _{Y}\left( u\right) =\mathbf{E%
}\left( e^{iuX}\right) =\sum_{k=0}^{n}e^{iuk}\binom{n}{k}p^{k}\left(
1-p\right) ^{n-k}=\sum_{k=0}^{n}\binom{n}{k}\left( e^{iu}p\right) ^{k}\left(
1-p\right) ^{n-k}$, che \`{e} il binomio di Newton: $\left(
e^{iu}p+1-p\right) ^{n}$. Se in particolare $n=1$, si ha $X\sim bin\left(
1,p\right) =b\left( p\right) $ e $\phi _{X}\left( u\right) =e^{iu}p+1-p$%
.\qquad

Se $X_{1}\sim b\left( p\right) ,X_{2}\sim b\left( p\right) $, $X_{1}\perp
X_{2}$, allora $X_{1}+X_{2}\sim bin\left( 2,p\right) $: infatti per quanto
visto sopra $\phi _{S_{2}}\left( u\right) =\left( e^{iu}p+1-p\right) ^{2}$,
che \`{e} la funzione caratteristica di $Y\sim bin\left( 2,p\right) $,
quindi $S_{2}$ deve avere la legge di $Y$. In generale se $%
X_{1},...,X_{n}\sim b\left( p\right) $ e $X_{1},...,X_{n}$ sono una famiglia
di v. a. indipendenti, allora $S_{n}\sim bin\left( n,p\right) $. Da questo
si deduce che $\mathbf{E}\left( Y\right) =np$, $var\left( Y\right) =np\left(
1-p\right) $.

Se $Y_{1}\sim bin\left( n_{1},p\right) ,Y_{2}\sim bin\left( n_{2},p\right) $%
, $Y_{1}\perp Y_{2}$, allora $Y_{1}+Y_{2}\sim bin\left( n_{1}+n_{2},p\right) 
$. Infatti $\phi _{S_{2}}\left( u\right) =\left( e^{iu}p+1-p\right)
^{n_{1}}\left( e^{iu}p+1-p\right) ^{n_{2}}=\left( e^{iu}p+1-p\right)
^{n_{1}+n_{2}}$, che \`{e} la funzione caratteristica di $Y\sim bin\left(
n_{1}+n_{2},p\right) $.

\item Siano $X_{1}\sim \Gamma \left( \alpha ,\lambda \right) ,X_{2}\sim
\Gamma \left( \beta ,\lambda \right) $, $X_{1}\perp X_{2}$, $\alpha ,\beta
,\lambda >0$. Mostro che $X_{1}+X_{2}\sim \Gamma \left( \alpha +\beta
,\lambda \right) $. Infatti $\phi _{\left( X_{1},X_{2}\right) }\left( 
\mathbf{u}\right) =\phi _{X_{1}}\left( u_{1}\right) \phi _{X_{2}}\left(
u_{2}\right) =\left( \frac{\lambda }{\lambda -iu}\right) ^{\alpha }\left( 
\frac{\lambda }{\lambda -iu}\right) ^{\beta }=\left( \frac{\lambda }{\lambda
-iu}\right) ^{\alpha +\beta }$, che \`{e} la funzione caratteristica di una $%
\Gamma \left( \alpha +\beta ,\lambda \right) $.
\end{enumerate}

\textbf{Teo 17.5 (legge della somma di due variabili aleatorie)}%
\begin{gather*}
\text{Hp: }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\text{ \`{e} un vettore aleatorio con legge }P^{\mathbf{X}}:\mathcal{B}%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\right) \rightarrow \left[ 0,1\right] \text{, } \\
Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }Y=X_{1}+X_{2}\text{ ha legge }P^{Y}:\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \rightarrow \left[ 0,1\right] \\
\text{Ts: (1) }P^{Y}\left( B\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}}I_{B}\left( x_{1}+x_{2}\right) dP^{\mathbf{X}}\left( x_{1},x_{2}\right) 
\text{ }\forall \text{ }B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \\
\text{(2) se }\mathbf{X}\text{ \`{e} assolutamente continuo con densit\`{a} }%
f_{\mathbf{X}}\text{, }Y\text{ \`{e} assolutamente} \\
\text{continua e }f_{Y}\left( y\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{\mathbf{X}}\left( y-t,t\right) dt\text{; se inoltre }X_{1}\perp X_{2}%
\text{, }f_{Y}\left( y\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X_{1}}\left( y-t\right) f_{X_{2}}\left( t\right) dt \\
\text{(3) se }\mathbf{X}\text{ \`{e} discreto con densit\`{a} discreta }p_{%
\mathbf{X}}\text{, }Y\text{ \`{e} discreta \`{e} con densit\`{a} discreta }
\\
p_{Y}\left( y\right) =\sum_{x_{2}\in \mathcal{S}_{2}}p_{\mathbf{X}}\left(
y-x_{2},x_{2}\right) \text{; se inoltre }X_{1}\perp X_{2}\text{, }%
p_{Y}\left( y\right) =\sum_{x_{2}\in \mathcal{S}_{2}}p_{X_{1}}\left(
y-x_{2}\right) p_{X_{2}}\left( x_{2}\right)
\end{gather*}

(2) \`{e} equivalentemente $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X_{2}}\left( y-t\right) f_{X_{1}}\left( t\right) dt$ (basta fare un
cambio di variabile). $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}f_{X_{1}}\left( y-t\right) f_{X_{2}}\left( t\right) dt$ \`{e} detto
prodotto di convoluzione di $f_{X_{1}}$ e $f_{X_{2}}$; $\sum_{x_{2}\in 
\mathcal{S}_{2}}p_{\mathbf{X}}\left( y-x_{2},x_{2}\right) $ \`{e} il
prodotto di convoluzione discreto. $f_{X_{1}}\left( y-t\right)
f_{X_{2}}\left( t\right) $ rappresenta il prodotto della probabilit\`{a} che 
$X_{1}$ sia circa $y-t$ e $X_{2}$ circa $t$, quindi la probabilit\`{a} che
la loro somma sia circa $y$; la somma viene quindi fatta su tutti i valori
di $t$.

\textbf{Dim*} (1) $P^{Y}\left( B\right) =\mathbf{P}\left( Y\in B\right) =%
\mathbf{E}\left( I_{\left( Y\in B\right) }\right) =\mathbf{E}\left(
I_{B}\left( Y\right) \right) =\mathbf{E}\left( I_{B}\left(
X_{1}+X_{2}\right) \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}}I_{B}\left( x_{1}+x_{2}\right) dP^{\mathbf{X}}\left( x_{1},x_{2}\right) 
$ per la regola del valore atteso.

(2) $F_{Y}\left( t\right) =\mathbf{P}\left( X_{1}+X_{2}\leq t\right)
=P^{\left( X_{1},X_{2}\right) }\left( A\right) $, con $A=\left\{ \left(
x,y\right) :x\in (-\infty ,t-y],y\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right\} $. Allora $P^{\left( X_{1},X_{2}\right) }\left( A\right)
=\int_{-\infty }^{+\infty }\left( \int_{-\infty }^{t-y}f_{\left(
X_{1},X_{2}\right) }\left( x,y\right) dx\right) dy$, e per il teorema
fondamentale del calcolo integrale $f_{Y}\left( t\right) =\frac{d}{dt}\left(
\int_{-\infty }^{+\infty }\left( \int_{-\infty }^{t-y}f_{\left(
X_{1},X_{2}\right) }\left( x,y\right) dx\right) dy\right) =\int_{-\infty
}^{+\infty }\frac{d}{dt}\left( \int_{-\infty }^{t-y}f_{\left(
X_{1},X_{2}\right) }\left( x,y\right) dx\right) dy=\int_{-\infty }^{+\infty
}f_{\left( X_{1},X_{2}\right) }\left( t-y,y\right) dy$ perch\'{e} $%
\lim_{y\rightarrow -\infty }f_{\left( X,Y\right) }\left( x,y\right) =0$. Se inoltre $X\perp Y$, la denst\`{a}
congiunta si fattorizza e $f_{Y}\left( t\right) =\int_{-\infty }^{+\infty
}f_{X_{1}}\left( t-y\right) f_{X_{2}}\left( y\right) dy$. Alternativamente,
si usa il vettore $\left( 
\begin{array}{c}
U \\ 
V%
\end{array}%
\right) =\left( 
\begin{array}{c}
X+Y \\ 
Y%
\end{array}%
\right) =\mathbf{h}\left( X,Y\right) $: $\mathbf{g}\left( U,V\right) =\left( 
\begin{array}{c}
U-V \\ 
V%
\end{array}%
\right) $ ha $J_{\mathbf{g}}\left( u,v\right) =\left[ 
\begin{array}{cc}
1 & -1 \\ 
0 & 1%
\end{array}%
\right] $, per cui $f_{\left( U,V\right) }\left( u,v\right) =f_{\left(
X,Y\right) }\left( u-v,v\right) \cdot 1$, e la densit\`{a} marginale di $U$ 
\`{e} $f_{Z}\left( u\right) =\int_{-\infty }^{+\infty }f_{\left( X,Y\right)
}\left( u-v,v\right) dv$. $\blacksquare $

\section{Vettori gaussiani}

Si \`{e} notato che $X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) $ ha
funzione caratteristica $\phi _{X}\left( u\right) =e^{iu\mu }e^{-\frac{1}{2}%
\sigma ^{2}u^{2}}$. Dato che $\phi _{X}$ caratterizza la legge di $X$, si
potrebbe dare una definizione equivalente di variabile aleatoria gaussiana a
partire da $\phi _{X}$. In verit\`{a} usare la funzione caratteristica
permette di includere tra le v. a. gaussiane nuove variabili aleatorie, perch%
\'{e} non occorre chiedere $\sigma ^{2}\neq 0$ come fatto per definire la
densit\`{a} della normale: nel caso $\sigma ^{2}=0$, per 9.10, si ottiene
infatti $\phi _{X}\left( u\right) =e^{iu\mu }$, che \`{e} la funzione
caratteristica di una v. a. $X=\mu $ q. c., cio\`{e} $X\sim \delta _{\mu }$:
quindi si sono incluse anche le v. a. quasi certamente costanti, la cui
densit\`{a} pu\`{o} essere vista come limite della densit\`{a} della normale
al ridursi di $\sigma ^{2}$.

\textbf{Def 18.1} Dato $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettore aleatorio e i parametri $\mathbf{\mu }=\left( 
\begin{array}{c}
\mu _{1} \\ 
... \\ 
\mu _{n}%
\end{array}%
\right) ,C=\left( c_{ij}\right) _{i,j=1,...,n}\in S^{+}\left( n,n\right) $, $%
\mathbf{X}$ si dice vettore gaussiano di parametri $\mathbf{\mu },C$ se ha
funzione caratteristica $\phi :%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
$, $\phi _{\mathbf{X}}\left( \mathbf{u}\right) =e^{i\left\langle \mathbf{%
u,\mu }\right\rangle -\frac{1}{2}\left\langle \mathbf{u},C\mathbf{u}%
\right\rangle }$.

La definizione generalizza il caso trattato sopra. $S^{+}$ indica l'insieme
delle matrici simmetriche semidefinite positive.

Affinch\'{e} la definizione sia ben posta occorre che $e^{i\left\langle 
\mathbf{u,\mu }\right\rangle -\frac{1}{2}\left\langle \mathbf{u},C\mathbf{u}%
\right\rangle }$ sia effettivamente una funzione caratteristica per
qualsiasi $\mathbf{\mu },C$, altrimenti non esisterebbero vettori gaussiani
con determinati parametri.

\textbf{Prop 18.2 (la definizione \`{e} ben posta)}%
\begin{gather*}
\text{Hp: }\mathbf{\mu }=\left( 
\begin{array}{c}
\mu _{1} \\ 
... \\ 
\mu _{n}%
\end{array}%
\right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{, }C\in S^{+}\left( n,n\right) \\
\text{Ts: }\exists \text{ }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ vettore aleatorio tale che }\hat{P}^{\mathbf{X}}\left( \mathbf{u}%
\right) =e^{i\left\langle \mathbf{u,\mu }\right\rangle -\frac{1}{2}%
\left\langle \mathbf{u},C\mathbf{u}\right\rangle }
\end{gather*}

La dimostrazione \`{e} costruttiva: $\mathbf{X}$ \`{e} costruito
esplicitamente.

\textbf{Dim} Sia $n=1$. Se $\sigma ^{2}\neq 0$, $X\sim \mathcal{N}\left( \mu
,\sigma ^{2}\right) $ ha legge con la funzione caratteristica richiesta. Se $%
\sigma ^{2}=0$, $X\sim \mathcal{\delta }_{\mu }$ ha $\hat{P}^{\mathbf{X}%
}\left( \mathbf{u}\right) =e^{iu\mu }$.

Sia $n>1$, $\mathbf{\mu =0}$, $C=Id$. Considero $Z_{1},...,Z_{n}\sim 
\mathcal{N}\left( 0,1\right) $ indipendenti: il vettore $\mathbf{Z}=\left( 
\begin{array}{c}
Z_{1} \\ 
... \\ 
Z_{n}%
\end{array}%
\right) $ ha funzione caratteristica $\phi _{\mathbf{Z}}\left( \mathbf{u}%
\right) =\phi _{Z_{1}}\left( u_{1}\right) ...\phi _{Z_{n}}\left(
u_{n}\right) =e^{-\frac{1}{2}u_{1}^{2}}...e^{-\frac{1}{2}u_{n}^{2}}=e^{-%
\frac{1}{2}\left\vert \left\vert \mathbf{u}\right\vert \right\vert
^{2}}=e^{i\left\langle \mathbf{u,0}\right\rangle -\frac{1}{2}\left\langle 
\mathbf{u},Id\mathbf{u}\right\rangle }$, quindi la tesi per $\mathbf{\mu },C$
scelti \`{e} dimostrata.

Se $C\in S^{+}\left( n,n\right) $, \`{e} ben definita $\sqrt{C}$, che ha la
propriet\`{a} $\sqrt{C}\left( \sqrt{C}\right) ^{T}=C$ (p. 258 FT). Definisco
allora $\mathbf{X}=\sqrt{C}\mathbf{Z+\mu }$: $\phi _{\mathbf{X}}\left( 
\mathbf{v}\right) =e^{i\left\langle \mathbf{v,\mu }\right\rangle }\phi _{%
\mathbf{Z}}\left( \left( \sqrt{C}\right) ^{T}\mathbf{v}\right)
=e^{i\left\langle \mathbf{v,\mu }\right\rangle }e^{-\frac{1}{2}\left\langle
\left( \sqrt{C}\right) ^{T}\mathbf{v},\left( \sqrt{C}\right) ^{T}\mathbf{v}%
\right\rangle }=e^{i\left\langle \mathbf{v,\mu }\right\rangle }e^{-\frac{1}{2%
}\mathbf{v}^{T}\sqrt{C}\left( \sqrt{C}\right) ^{T}\mathbf{v}%
}=e^{i\left\langle \mathbf{v,\mu }\right\rangle -\frac{1}{2}\left\langle 
\mathbf{v},C\mathbf{v}\right\rangle }$. $\blacksquare $

$\mathbf{Z}$, per com'\`{e} stato definito sopra, ha $\mathbf{E}\left( 
\mathbf{Z}\right) =\mathbf{0}$ e $C_{\mathbf{Z}}=Id$ perch\'{e} ogni
componente ha $\mu _{i}=0,\sigma _{i}^{2}=1$, e le componenti sono tutte
indipendenti. Si scrive allora $\mathbf{Z}\sim \mathcal{N}\left( \mathbf{0}%
,Id\right) $. Dalla dimostrazione si ricava che ogni vettore gaussiano ha la
stessa legge della trasformazione lineare affine di un vettore gaussiano
standard (\`{e} la generalizzazione della standardizzazione vista per v. a.
normali), cio\`{e} se $\mathbf{X}$ \`{e} gaussiano con parametri $\mathbf{%
\mu },C$ ($\mathbf{X}\sim \mathcal{N}\left( \mathbf{\mu },C\right) $), $%
\mathbf{X}=\sqrt{C}\mathbf{Z+\mu }$ con $\mathbf{Z}\sim \mathcal{N}\left( 
\mathbf{0},Id\right) $.

\textbf{Prop 18.3 (propriet\`{a} dei vettori gaussiani)}%
\begin{gather*}
\text{Hp: }\mathbf{\mu }\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{, }C\in S^{+}\left( n,n\right) \text{, }\mathbf{X}\sim \mathcal{N}%
\left( \mathbf{\mu },C\right) \\
\text{Ts: (1) }\mathbf{E}\left( \mathbf{X}\right) =\mathbf{\mu }\text{, }C_{%
\mathbf{X}}=C \\
\text{(2) }\forall \text{ }i=1,...,n\text{ }X_{i}\sim \mathcal{N}\left( \mu
_{i},c_{ii}\right) \\
\text{(3) se }A\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( k,n\right) ,\mathbf{b}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k},\mathbf{Y}=A\mathbf{X+b}\text{, allora }\mathbf{Y}\sim \mathcal{N}%
\left( A\mathbf{\mu }_{X}\mathbf{+b},AC_{\mathbf{X}}A^{T}\right) \\
\text{(4) }X_{1},...,X_{n}\text{ sono indipendenti }\Longleftrightarrow
cov\left( X_{i},X_{j}\right) =0\text{ }\forall \text{ }i,j=1,...,n
\end{gather*}

(2) afferma che ogni componente di un vettore gaussiano \`{e} una v. a.
normale. (3) afferma che con trasformazioni lineari affini di gaussiane si
ottengono ancora gaussiane: quindi in particolare ogni sottovettore di $%
\mathbf{X}$, potendo essere ottenuto come $A\mathbf{X}$, \`{e} ancora
gaussiano. (4) significa che, a differenza di quanto accade in generale, le
componenti di un vettore gaussiano sono indipendenti se e solo se $C_{%
\mathbf{X}}$ \`{e} diagonale.

\textbf{Dim} (1) E' noto che $\mathbf{X}$ ha la stessa distribuzione di $%
\sqrt{C}\mathbf{Z+\mu }$ con $\mathbf{Z}\sim \mathcal{N}\left( \mathbf{0}%
,Id\right) $ (non posso scrivere l'uguaglianza perch\'{e} $\mathbf{X}$
potrebbe essere discreta ed essere definita su uno spazio di probabilit\`{a}
molto piccolo su cui non \`{e} definito $\mathbf{Z}$, a differenza di prima
in cui erano definite sullo stesso spazio di probabilit\`{a} 50:24). Allora $%
\mathbf{E}\left( \mathbf{X}\right) =\sqrt{C}\mathbf{E}\left( \mathbf{Z}%
\right) +\mathbf{\mu }=\mathbf{\mu }$ e $C_{\mathbf{X}}=\sqrt{C}C_{\mathbf{Z}%
}\left( \sqrt{C}\right) ^{T}=\sqrt{C}Id\left( \sqrt{C}\right) ^{T}=C$. Si pu%
\`{o} dimostrare alternativamente con la formula dei momenti.

(2) Per quanto visto sopra $X_{i}=\mathbf{e}_{i}^{T}\mathbf{X}$, quindi $%
\phi _{X_{i}}\left( v_{i}\right) =\phi _{\mathbf{X}}\left( \mathbf{e}%
_{i}^{T}v_{i}\right) =e^{iv_{i}\mu _{i}-\frac{1}{2}C_{ii}v_{i}^{2}}$. Per
unicit\`{a} di $\phi $ allora $X_{i}\sim \mathcal{N}\left( \mu
_{i},C_{ii}\right) $.

(3) E' noto che $\phi _{\mathbf{Y}}\left( \mathbf{v}\right)
=e^{i\left\langle \mathbf{v,b}\right\rangle }\phi _{\mathbf{X}}\left( A^{T}%
\mathbf{v}\right) $, quindi, essendo $\phi _{X}\left( \mathbf{u}\right)
=e^{i\left\langle \mathbf{u,\mu }\right\rangle -\frac{1}{2}\left\langle 
\mathbf{u},C\mathbf{u}\right\rangle }$, si ottiene $\phi _{\mathbf{Y}}\left( 
\mathbf{v}\right) =e^{i\left\langle \mathbf{v,b}\right\rangle
}e^{i\left\langle A^{T}\mathbf{v,\mu }\right\rangle -\frac{1}{2}\left\langle
A^{T}\mathbf{v},CA^{T}\mathbf{v}\right\rangle }$. Vale $e^{i\left\langle 
\mathbf{v,b}\right\rangle }e^{i\left\langle A^{T}\mathbf{v,\mu }%
\right\rangle }=e^{i\left\langle \mathbf{v},A\mathbf{\mu }\right\rangle
}e^{i\left\langle \mathbf{v,b}\right\rangle }=e^{i\left\langle \mathbf{v},A%
\mathbf{\mu +b}\right\rangle }$, mentre $\left\langle A^{T}\mathbf{v},CA^{T}%
\mathbf{v}\right\rangle =\left\langle \mathbf{v},ACA^{T}\mathbf{v}%
\right\rangle $, quindi $\phi _{\mathbf{Y}}\left( \mathbf{v}\right)
=e^{i\left\langle \mathbf{v},A\mathbf{\mu +b}\right\rangle -\frac{1}{2}%
\left\langle \mathbf{v},ACA^{T}\mathbf{v}\right\rangle }$, quindi $Y\sim 
\mathcal{N}\left( A\mathbf{\mu +b},ACA^{T}\right) $.

(4) L'implicazione da sinistra a destra deriva da 15.4, perch\'{e}
l'indipendenza della famiglia implica anche l'indipendenza a coppie e quindi
covarianza nulla.

Dimostro l'implicazione da destra a sinistra: $C=\left[ 
\begin{array}{ccc}
\sigma _{1}^{2} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \sigma _{n}^{2}%
\end{array}%
\right] $, per cui $\phi _{\mathbf{X}}\left( \mathbf{u}\right)
=e^{i\left\langle \mathbf{u,\mu }\right\rangle -\frac{1}{2}\left\langle 
\mathbf{u},C\mathbf{u}\right\rangle }=e^{iu_{1}\mu _{1}+...+iu_{n}\mu
_{n}}e^{-\frac{1}{2}\left( \sigma _{1}^{2}u_{1}^{2}+...+\sigma
_{n}^{2}u_{n}^{2}\right) }=e^{iu\mu _{1}-\frac{1}{2}\sigma
_{1}^{2}u_{1}^{2}}...e^{iu\mu _{n}-\frac{1}{2}\sigma _{n}^{2}u_{n}^{2}}$.
Poich\'{e} ogni fattore \`{e} la funzione caratteristica di una componente,
significa che $\phi _{\mathbf{X}}$ si fattorizza, e quindi $X_{1},...,X_{n}$
sono indipendenti per 17.2 (3). $\blacksquare $

\begin{enumerate}
\item Dato $\mathbf{X}\sim \mathcal{N}\left( \mathbf{\mu },C\right) $, se $%
\exists $ $k\neq h:cov\left( X_{k},X_{h}\right) =0$, allora $\left( 
\begin{array}{c}
X_{k} \\ 
X_{h}%
\end{array}%
\right) $ \`{e} gaussiano (perch\'{e} trasformazione lineare di $\mathbf{X}$%
) con $X_{k}\perp X_{h}$ (perch\'{e} la nuova matrice di covarianza sar\`{a}
diagonale). Se e. g. $n=3$, sia $C=\left[ 
\begin{array}{ccc}
\sigma _{1}^{2} & \ast & \ast \\ 
\ast & \sigma _{2}^{2} & 0 \\ 
\ast & 0 & \sigma _{3}^{2}%
\end{array}%
\right] $. $\left( 
\begin{array}{c}
X_{2} \\ 
X_{3}%
\end{array}%
\right) =\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
0 & 0 & 1%
\end{array}%
\right] \left( 
\begin{array}{c}
X_{1} \\ 
X_{2} \\ 
X_{3}%
\end{array}%
\right) $, quindi $C_{\left( X_{2},X_{3}\right) }=ACA^{T}=\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
0 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{ccc}
\sigma _{1}^{2} & \ast & \ast \\ 
\ast & \sigma _{2}^{2} & 0 \\ 
\ast & 0 & \sigma _{3}^{2}%
\end{array}%
\right] \left[ 
\begin{array}{cc}
0 & 0 \\ 
1 & 0 \\ 
0 & 1%
\end{array}%
\right] =\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
0 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{cc}
\ast & \ast \\ 
\sigma _{2}^{2} & 0 \\ 
0 & \sigma _{3}^{2}%
\end{array}%
\right] =\left[ 
\begin{array}{cc}
\sigma _{2}^{2} & 0 \\ 
0 & \sigma _{3}^{2}%
\end{array}%
\right] $. Si applica allora 18.3 (4) a $\left( X_{2},X_{3}\right) $ e si
conclude che $X_{2}\perp X_{3}$.
\end{enumerate}

Ha senso chiedersi se vale l'implicazione opposta in 18.3 (2): in generale
no.

\textbf{Prop 18.4}%
\begin{gather*}
\text{(1) Hp: }X_{1},...,X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ variabili aleatorie} \\
\text{Ts: }X_{1},...,X_{n}\text{ sono indipendenti e }X_{k}\sim \mathcal{N}%
\left( \mu _{k},\sigma _{k}^{2}\right) \text{ }\forall \text{ }%
k=1,...,n\Longleftrightarrow \\
\mathbf{X}=\left( 
\begin{array}{c}
X_{1} \\ 
... \\ 
X_{n}%
\end{array}%
\right) \sim \mathcal{N}\left( \mathbf{\mu }_{X},C_{X}\right) \text{ con }%
\mathbf{\mu }_{X}=\left( 
\begin{array}{c}
\mu _{1} \\ 
... \\ 
\mu _{n}%
\end{array}%
\right) \text{ e }C_{\mathbf{X}}=\left[ 
\begin{array}{ccc}
\sigma _{1}^{2} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \sigma _{n}^{2}%
\end{array}%
\right] \\
\text{(2) Hp: }\mathbf{X}_{1}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{1}},\mathbf{X}_{2}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n_{2}}\text{ vettori aleatorii} \\
\text{Ts: }\mathbf{X}_{1}\sim \mathcal{N}\left( \mathbf{\mu }%
_{1},C_{1}\right) ,\mathbf{X}_{2}\sim \mathcal{N}\left( \mathbf{\mu }%
_{2},C_{2}\right) \text{, }\mathbf{X}_{1}\mathbf{\perp X}_{2}%
\Longleftrightarrow \\
\mathbf{X}=\left( 
\begin{array}{c}
\mathbf{X}_{1} \\ 
\mathbf{X}_{2}%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
\mathbf{\mu }_{1} \\ 
\mathbf{\mu }_{2}%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
C_{1} & 0_{M} \\ 
0_{M} & C_{2}%
\end{array}%
\right] \right)
\end{gather*}

L'implicazione da destra a sinistra in (1) vale per quanto visto sopra;
quella da sinistra a destra si basa sulla fattorizzazione della funzione
caratteristica. La tesi 2, in cui figura come matrice di covarianza una
matrice diagonale a blocchi, \`{e} la 1 nel caso di $n_{1}=1,n_{2}=1$.

\begin{enumerate}
\item Siano $X_{1}\sim \mathcal{N}\left( \mu _{1},\sigma _{1}^{2}\right)
,X_{2}\sim \mathcal{N}\left( \mu _{2},\sigma _{2}^{2}\right) $, $X_{1}\perp
X_{2}$. Allora $\alpha X_{1}+\beta X_{2}+c\sim \mathcal{N}\left( \alpha \mu
_{1}+\beta \mu _{2}+c,\alpha ^{2}\sigma _{1}^{2}+\beta ^{2}\sigma
_{2}^{2}\right) $ perch\'{e} per 18.4 (1) $\mathbf{X=}\left( 
\begin{array}{c}
X_{1} \\ 
X_{2}%
\end{array}%
\right) $ \`{e} gaussiano con $\mu _{X}=\left( 
\begin{array}{c}
\mu _{1} \\ 
\mu _{2}%
\end{array}%
\right) $ e $C_{\mathbf{X}}=\left[ 
\begin{array}{cc}
\sigma _{1}^{2} & 0 \\ 
0 & \sigma _{2}^{2}%
\end{array}%
\right] $, quindi $Y=\left[ \alpha |\beta \right] \left( 
\begin{array}{c}
X_{1} \\ 
X_{2}%
\end{array}%
\right) +c$ per 18.3 (3) \`{e} normale con parametri $\alpha \mu _{1}+\beta
\mu _{2}+c$ e $\alpha ^{2}\sigma _{1}^{2}+\beta ^{2}\sigma _{2}^{2}$.
\end{enumerate}

\textbf{Teo 18.5 (caratterizzazione dei vettori gaussiani)}%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ vettore aleatorio} \\
\text{Ts}\text{: }\exists \text{ }\mathbf{\mu }\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},C\in S^{+}\left( n,n\right) :\mathbf{X}\sim \mathcal{N}\left( \mathbf{%
\mu },C\right) \Longleftrightarrow \forall \text{ }\mathbf{a}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ }\left\langle \mathbf{a,X}\right\rangle \text{ \`{e} gaussiana}
\end{gather*}

L'implicazione da sinistra a destra \`{e} ovvia: $\left\langle \mathbf{a,X}%
\right\rangle $ \`{e} gaussiana con parametri $\mathbf{a}^{T}\mathbf{\mu }$, 
$\mathbf{a}^{T}C\mathbf{a}$. L'implicazione da destra a sinistra ha
un'ipotesi molto pi\`{u} forte della richiesta di $X_{1},...,X_{n}$
gaussiane: deve esserlo ogni loro combinazione lineare, non solo le
combinazioni lineari del tipo $\left\langle \mathbf{e}_{k}\mathbf{,X}%
\right\rangle $.

\textbf{Dim} L'implicazione da sinistra a destra \`{e} ovvia per 18.3, che
si usa con $A=\mathbf{a}^{T}$, quindi $\left\langle \mathbf{a,X}%
\right\rangle $ \`{e} gaussiana.

Se $\forall $ $\mathbf{a}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ $Y=\left\langle \mathbf{a,X}\right\rangle $ \`{e} gaussiana e si pone $%
\mathbf{\mu }:=\mathbf{E}\left( \mathbf{X}\right) ,C:=C_{\mathbf{X}}$, si ha 
$\phi _{Y}\left( v\right) =\phi _{\mathbf{X}}\left( \mathbf{a}^{T}v\right)
=e^{i\left\langle v,\mu _{Y}\right\rangle -\frac{1}{2}\sigma
_{Y}^{2}v^{2}}=e^{i\left\langle v,\mathbf{a}^{T}\mathbf{\mu }_{\mathbf{X}%
}\right\rangle -\frac{1}{2}\mathbf{a}^{T}C\mathbf{a}v^{2}}$, quindi se $v=1$
si ha $\phi _{\mathbf{X}}\left( \mathbf{a}\right) =e^{i\left\langle \mathbf{a%
},\mathbf{\mu }_{\mathbf{X}}\right\rangle -\frac{1}{2}\mathbf{a}^{T}C\mathbf{%
a}}$. $\blacksquare $

Ora ci chiediamo se i vettori gaussiani sono discreti o assolutamente
continui. E' noto che per $n=1$ se $\sigma ^{2}=0$ $X$ gaussiana \`{e}
discreta con supporto $\mathcal{S}=\mu $, mentre se $\sigma ^{2}\neq 0$ $X$
gaussiana \`{e} normale secondo la vecchia definizione, con densit\`{a} $%
f_{X}\left( t\right) =\frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{-\frac{1}{2\sigma
^{2}}\left( t-\mu \right) ^{2}}$.

Si \`{e} visto in passato che $\mathbf{X}\in \func{col}C_{X}+\mathbf{\mu }$
q. c., e che se $\mathbf{X}$ \`{e} assolutamente continuo allora $\det C_{%
\mathbf{X}}>0$. Il seguente teorema afferma che per i vettori gaussiani \`{e}
possibile invertire l'ultima implicazione.

[Se $\mathbf{X}\sim \mathcal{N}\left( \mathbf{\mu },C\right) $, $h\left( 
\mathbf{X}\right) $ se $h$ non \`{e} lineare affine non \`{e} gaussiana??.
Quindi ogni vettore gaussiano non pu\`{o} avere come immagine $G_{f}$ a meno
che lineare affine, cio\`{e} sottospazio lineare affine. I vettori gaussiani
hanno come immagine sottospazi vettoriali affini. Per questo vale il se e
solo se: non posso avere i casi $\left( 
\begin{array}{c}
X \\ 
f\left( X\right)%
\end{array}%
\right) $ in cui $\det >0$ ma vettore non assolutamente continuo.

Se $\mathbf{X}\sim \mathcal{N}\left( \mathbf{\mu },C\right) $, vale $\mathbf{%
X}\sim \mathbf{\mu }+\sqrt{C}\mathbf{Z}$: ogni componente di $\mathbf{Z}$ 
\`{e} una normale standard che assume con probabilit\`{a} non nulla ogni
valore reale; poich\'{e} le componenti sono indipendenti $\mathbf{Z}$ assume
con probabilit\`{a} non nulla ogni valore di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$. Se $\sqrt{C}$ \`{e} invertibile anche $\mathbf{\mu }+\sqrt{C}\mathbf{Z%
}$ assume con probabilit\`{a} non nulla ogni valore di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$. Se invece $\sqrt{C}$ non \`{e} invertibile $\mathbf{\mu }+\sqrt{C}%
\mathbf{Z}$ ha come supporto un sottospazio vettoriale di dimensione pari a $%
r\left( \sqrt{C}\right) $. Questo implica che ogni vettore gaussiano non pu%
\`{o} avere supporto qualsiasi, ma solo un sottospazio vettoriale affine di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$; se $n=2$, non pu\`{o} essere un grafico di funzione, a meno che non
si tratti di una funzione lineare affine, n\'{e} pu\`{o} avere come supporto
un cerchio o un quadrato. E' questo fatto, connaturato alla gaussianit\`{a},
che rende possibile l'equivalenza tra assoluta continuit\`{a} del vettore e
positivit\`{a} del determinante della matrice di covarianza: i casi in cui
il determinante della matrice di covarianza di un vettore \`{e} positivo, ma
il vettore non \`{e} assolutamente continuo, non possono verificarsi se un
vettore \`{e} gaussiano, perch\'{e} i vettori per cui accade ci\`{o} sono
del tipo $\left( 
\begin{array}{c}
X \\ 
f\left( X\right)%
\end{array}%
\right) $.]

\begin{enumerate}
\item Nonostante non esistano vettori gaussiani del tipo $\left( 
\begin{array}{c}
X \\ 
f\left( X\right)%
\end{array}%
\right) $ con $f$ non lineare affine, \`{e} comunque possibile che, data $%
X\sim \mathcal{N}\left( 0,1\right) $, $f\left( X\right) $ sia gaussiana con $%
f$ non lineare affine. Denominata $F$ la funzione di ripartizione di una $%
\chi ^{2}\left( 1\right) $, si consideri $f\left( X\right) =\Phi ^{-1}\left(
F\left( X^{2}\right) \right) $: $\mathbf{P}\left( f\left( X\right) \leq
t\right) =\mathbf{P}\left( \Phi ^{-1}\left( F\left( X^{2}\right) \right)
\leq t\right) =\mathbf{P}\left( F\left( X^{2}\right) \leq \Phi \left(
t\right) \right) $. Ma \`{e} noto che $F\left( X^{2}\right) \sim \mathcal{U}%
\left( \left( 0,1\right) \right) $, quindi $\mathbf{P}\left( f\left(
X\right) \leq t\right) =\Phi \left( t\right) $, cio\`{e} $f\left( X\right)
\sim \mathcal{N}\left( 0,1\right) $.
\end{enumerate}

\textbf{Teo (normalizzazione di un vettore gaussiano)}%
\begin{gather*}
\text{Hp: }\mathbf{\mu }\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},C\in S^{+}\left( n,n\right) \text{, }\mathbf{X}\sim \mathcal{N}\left( 
\mathbf{\mu },C\right) \\
\text{Ts: }\exists \text{ }Y_{1},...,Y_{n}\text{ v.a. indipendenti tali che}
\\
Y_{i}\sim \mathcal{N}\left( 0,\lambda _{i}\right) \text{ }\forall \text{ }i%
\text{, }\lambda _{i}\geq 0\text{ }\forall \text{ }i\text{ e }\exists \text{ 
}U\text{ ortogonale }:\mathbf{X}=\mathbf{\mu }+U\mathbf{Y}
\end{gather*}

La tesi implica che $\mathbf{Y}\sim \mathcal{N}\left( 0,\left[ 
\begin{array}{ccc}
\lambda _{1} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \lambda _{n}%
\end{array}%
\right] \right) $; questa normalizzazione \`{e} diversa da $\mathbf{\mu }+%
\sqrt{C}\mathbf{Z}$, perch\'{e} quest'ultimo \`{e} uguale a $\mathbf{X}$
solo in legge.

Il teorema esprime il fatto che ogni vettore gaussiano nasce dalla
combinazione lineare di v. a. gaussiane indipendenti.

\textbf{Dim} Poich\'{e} $C$ \`{e} simmetrica, per il teorema spettrale $%
\exists $ $U$ ortogonale e $D$ diagonale tale che $C=UDU^{T}$. Definendo $%
\mathbf{Y}=U^{T}\left( \mathbf{X-\mu }\right) $, si ha che $\mathbf{Y}\sim 
\mathcal{N}\left( 0,U^{T}CU\right) $, dato che \`{e} una trasformazionale
lineare affine di $\mathbf{X}$ gaussiano. Vale inoltre $U^{T}CU=D$
diagonale: dunque effettivamente esistono $Y_{1},...,Y_{n}$ indipendenti con 
$Y_{i}\sim \mathcal{N}\left( 0,\lambda _{i}\right) $ $\forall $ $i$, $%
\lambda _{i}\geq 0$ $\forall $ $i$. $\blacksquare $

\textbf{Teo 18.5 (assoluta continuit\`{a} dei vettori gaussiani)}%
\begin{gather*}
\text{Hp}\text{: }\mathbf{\mu }\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},C\in S^{+}\left( n,n\right) \text{, }\mathbf{X}\sim \mathcal{N}\left( 
\mathbf{\mu },C\right) \\
\text{Ts}\text{: }\mathbf{X}\text{ \`{e} assolutamente continuo }%
\Longleftrightarrow \det C_{\mathbf{X}}>0\text{, e in tal } \\
\text{caso }f_{\mathbf{X}}\left( x_{1},...,x_{n}\right) =\frac{1}{\left(
2\pi \right) ^{n/2}\sqrt{\det C_{X}}}e^{-\frac{1}{2}\left\langle \mathbf{%
x-\mu },C^{-1}\left( \mathbf{x-\mu }\right) \right\rangle }
\end{gather*}

Si noti che la formula per la densit\`{a} \`{e} ben posta perch\'{e} $C_{X}$ 
\`{e} invertibile. Nel caso $n=1$ il teorema si riduce a dire che una v. a.
con $\phi _{X}\left( u\right) =e^{iu\mu -\frac{1}{2}\sigma ^{2}u^{2}}$ \`{e}
assolutamente continua se e solo se $\sigma ^{2}\neq 0$, e in tal caso $%
f_{X}\left( x\right) =\frac{1}{\left( 2\pi \right) ^{1/2}\sqrt{\sigma ^{2}}}%
e^{-\frac{1}{2}\left( x-\mu \right) \frac{1}{\sigma ^{2}}\left( x-\mu
\right) }$: cio\`{e} se $X$ non \`{e} una delta di Dirac ma una normale
secondo la vecchia definizione.

Il teorema implica che $\mathbf{Z}\sim \mathcal{N}\left( \mathbf{0}%
,Id\right) $ \`{e} assolutamente continua, dato che $\det Id=1$.

\textbf{Dim} E' noto che $\mathbf{X}=\sqrt{C}\mathbf{Z+\mu }$: poich\'{e}
esiste $C^{-1}$, posso scegliere $\sqrt{C}$ invertibile: in tal caso la
trasformazione scritta \`{e} un diffeomorfismo. Allora anche $\mathbf{X}$
ammette densit\`{a} continua.

Sia $\det C_{\mathbf{X}}>0$. Allora $\exists \ \mathbf{Y}\sim \mathcal{N}%
\left( 0,\left[ 
\begin{array}{ccc}
\lambda _{1} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \lambda _{n}%
\end{array}%
\right] \right) $, $U$ ortogonale e $D$ diagonale tale che $C=UDU^{T}$ e $%
\mathbf{X=\mu }+U\mathbf{Y}$. Poich\'{e} $Y_{i}\sim \mathcal{N}\left(
0,\lambda _{i}\right) $ e le $Y_{i}$ sono indipendenti, $\mathbf{Y}$ ammette
la densit\`{a} $f_{\mathbf{Y}}\left( \mathbf{y}\right) =\prod_{j=1}^{n}\frac{%
1}{\sqrt{2\pi \lambda _{i}}}e^{-\frac{1}{2\lambda _{i}}y_{i}^{2}}=\frac{1}{%
2\pi ^{n/2}\sqrt{\det C_{\mathbf{X}}}}e^{-\frac{1}{2\det }y_{i}^{2}}$:
allora $\mathbf{X}$ ha la densit\`{a} (...)

$\blacksquare $


Ricapitolando, se $\det C>0$, $\exists $ $C^{-1}$, $\dim \left( \func{col}%
C\right) =n$ e $\mathbf{X}$ \`{e} assolutamente continuo. Se invece $\det
C=0 $, $\dim \left( \func{col}C\right) <n$: quindi la trasformazione $%
\mathbf{X}=\sqrt{C}\mathbf{Z+\mu }$ non \`{e} di rango massimo ($\det \sqrt{C%
}=0$).

Sia $\mathbf{X}\sim \mathcal{N}\left( \mathbf{\mu },C\right) $ con $\det C=0$
(e affinch\'{e} questo accada \`{e} sufficiente un solo autovalore nullo):
allora $\ker C$ non contiene il solo vettore nullo, cio\`{e} $\exists $ $%
\mathbf{\hat{a}}\neq 0:C\mathbf{\hat{a}=0}$. Poich\'{e} $\mathbf{X}$ \`{e}
gaussiano, $\mathbf{\hat{a}}^{T}\mathbf{X}$ \`{e} gaussiana con parametri $%
\mathbf{\hat{a}}^{T}\mathbf{\mu }$, $\mathbf{\hat{a}}C\mathbf{\hat{a}}^{T}$,
cio\`{e} $\mathbf{\hat{a}}^{T}\mathbf{X}\sim \mathcal{N}\left( \mathbf{\hat{a%
}}^{T}\mathbf{\mu },0_{M}\right) $. Questo implica che, poich\'{e} $\mathbf{%
\hat{a}}^{T}\mathbf{X}\in \func{col}0_{M}+\mathbf{\hat{a}}^{T}\mathbf{\mu }$%
, $\mathbf{\hat{a}}^{T}\mathbf{X=\mathbf{\hat{a}}^{T}\mu }$ q. c., cio\`{e} $%
\mathbf{\hat{a}}^{T}\mathbf{X}$ \`{e} una v. a. degenere. Questo \`{e}
equivalente a dire che $\left\langle \mathbf{\hat{a},X-\mu }\right\rangle =0$%
, cio\`{e} $\mathbf{P}\left( \mathbf{X}\in H=\left\{ \mathbf{x}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}:\left\langle \mathbf{x-\mu },\mathbf{\hat{a}}\right\rangle =0\right\}
\right) =1$: $\mathbf{X}$ appartiene quasi certamente all'iperpiano definito
dall'equazione $\left\langle \mathbf{x-\mu },\mathbf{\hat{a}}\right\rangle
=0 $, che \`{e} un sottospazio vettoriale affine di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$.

\begin{enumerate}
\item Sia $\mathbf{X=}\left( 
\begin{array}{c}
X_{1} \\ 
X_{2}%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
1 \\ 
1%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
1 & 1 \\ 
1 & 1%
\end{array}%
\right] \right) $. $X_{1},X_{2}\sim \mathcal{N}\left( 1,1\right) $; $\det
C=0 $, quindi $\dim \ker C=1$. Una base normale di $\ker C$ \`{e} $\left\{
\left( 
\begin{array}{c}
1/\sqrt{2} \\ 
-1/\sqrt{2}%
\end{array}%
\right) \right\} $. Allora $\mathbf{P}\left( \mathbf{X}\in H=\left\{ \mathbf{%
x}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}:\frac{x_{1}-1}{\sqrt{2}}-\frac{x_{2}-1}{\sqrt{2}}=0\right\} \right) =1$%
, cio\`{e} $\mathbf{X}$ appartiene q. c. al piano definito da $x_{1}=x_{2}$,
che ha come base $t\left( 
\begin{array}{c}
1 \\ 
1%
\end{array}%
\right) $: questo significa che $\mathbf{P}\left( X_{1}=X_{2}\right) =1$.

Se e. g. voglio calcolare $\mathbf{P}\left( \left\vert \left\vert \mathbf{X}%
\right\vert \right\vert ^{2}\leq 1\right) $, ho $\mathbf{P}\left(
X_{1}^{2}+X_{2}^{2}\leq 1\right) =\mathbf{P}\left( X_{1}^{2}+X_{2}^{2}\leq
1,X_{1}=X_{2}\right) $ (se $\mathbf{P}\left( B\right) =1$, $\mathbf{P}\left(
A\cap B\right) =\mathbf{P}\left( A\right) $), quindi si ottiene $\mathbf{P}%
\left( 2X_{1}^{2}\leq 1,X_{1}=X_{2}\right) =\mathbf{P}\left( 2X_{1}^{2}\leq
1\right) =\mathbf{P}\left( X_{1}\in \left[ -\frac{1}{\sqrt{2}},\frac{1}{%
\sqrt{2}}\right] \right) $, che si pu\`{o} ricavare attraverso $f_{X_{1}}$.
Quindi conoscere l'iperpiano cui appartiene q. c. $\mathbf{X}$ permette di
calcolare le probabilit\`{a} che lo coinvolgono riducendosi al pi\`{u}
grande sottospazio in cui esiste una densit\`{a}, che seleziono usando le
componenti che vedo trovando la pi\`{u} grande sottomatrice di $C$ con
determinante non nullo.
\end{enumerate}

\subsection{Funzioni non lineari di vettori gaussiani e statistiche
campionarie}

\textbf{Def} Dato $\mathbf{Z}\sim \mathcal{N}\left( \mathbf{0},Id\right) $
vettore gaussiano standard a valori in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, si dice legge chi-quadro a $n$ gradi di libert\`{a}, e si indica con $%
\chi ^{2}\left( n\right) $, la legge della variabile aleatoria $%
V_{n}=\left\vert \left\vert \mathbf{Z}\right\vert \right\vert
^{2}=Z_{1}^{2}+...+Z_{n}^{2}$.

Poich\'{e} le $Z_{i}$ sono indipendenti e quindi anche le $Z_{i}^{2}$, si
ricava che $\mathbf{E}\left( V_{n}\right) =n$ e $var\left( V_{n}\right)
=nvar\left( Z_{1}^{2}\right) =n\left( \mathbf{E}\left( Z_{1}^{4}\right) -%
\mathbf{E}^{2}\left( Z_{2}^{2}\right) \right) =2n$. Una chi-quadro a $n$
gradi di libert\`{a} \`{e} quindi uguale in legge alla somma di $n$
gaussiane standard ed \`{e} non negativa.

\textbf{Prop (densit\`{a} della chi-quadro)}%
\begin{gather*}
\text{Hp: }V_{n}\sim \chi ^{2}\left( n\right) \\
\text{Ts: }V_{n}\text{ \`{e} assolutamente continua con} \\
\text{ densit\`{a} }f_{V_{n}}\left( t\right) =\frac{\left( \frac{1}{2}%
\right) ^{\frac{n}{2}}}{\Gamma \left( \frac{n}{2}\right) }t^{\frac{n}{2}%
-1}e^{\frac{-t}{2}}I_{\left( 0,+\infty \right) }\left( t\right)
\end{gather*}

Quindi $\Gamma \left( \frac{n}{2},\frac{1}{2}\right) =\chi ^{2}\left(
n\right) $: $var\left( V_{n}\right) =\frac{\alpha }{\lambda ^{2}}=2n$,
essendo la varianza di una gamma nota.

\begin{enumerate}
\item Se $X_{1},...,X_{n}\sim iid\mathcal{N}\left( \mu ,\sigma ^{2}\right) $%
, $\sum_{k=1}^{n}\frac{\left( X_{k}-\mu \right) ^{2}}{\sigma ^{2}}$ \`{e} la
somma di $n$ gaussiane standard indipendenti al quadrato e quindi ha legge $%
\chi ^{2}\left( n\right) $.
\end{enumerate}

\textbf{Def} Data $Z\sim \mathcal{N}\left( 0,1\right) $ e $V_{n}\sim \chi
^{2}\left( n\right) $, $V_{n}\perp Z$, si dice legge t di Student a $n$
gradi di libert\`{a}, e si indica con $t\left( n\right) $, la legge della
variabile aleatoria $T=\frac{Z}{\sqrt{\frac{V_{n}}{n}}}$.

\textbf{Prop (densit\`{a} della t di Student)}%
\begin{gather*}
\text{Hp: }T\sim t\left( n\right) \\
\text{Ts: }T\text{ \`{e} assolutamente continua con} \\
\text{ densit\`{a} }f_{T}\left( t\right) =\frac{\Gamma \left( \frac{n+1}{2}%
\right) }{\Gamma \left( \frac{n}{2}\right) \sqrt{n\pi }}\left( 1+\frac{x^{2}%
}{n}\right) ^{-\frac{n+1}{2}}
\end{gather*}

$\lim_{n\rightarrow +\infty }\left( f_{T_{n}}\left( t\right) =\frac{\Gamma
\left( \frac{n+1}{2}\right) }{\Gamma \left( \frac{n}{2}\right) \sqrt{n\pi }}%
\left( 1+\frac{x^{2}}{n}\right) ^{-\frac{n+1}{2}}=\frac{\Gamma \left( \frac{%
n+1}{2}\right) }{\Gamma \left( \frac{n}{2}\right) \sqrt{n\pi }}\left[ \left(
1+\frac{x^{2}}{n}\right) ^{n}\right] ^{-\frac{1}{2}}\left( 1+\frac{x^{2}}{n}%
\right) ^{-\frac{1}{2}}\right) =\frac{1}{\sqrt{2\pi }}e^{\frac{-t^{2}}{2}}$ $%
\forall $ $t\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ (dim), cio\`{e} la densit\`{a} di una t di Student, al crescere del numero
di gradi di libert\`{a}, si avvicina alla densit\`{a} di una normale
standard (quindi $T_{n}\rightarrow ^{\tciLaplace }Z$). Se $n=1$, $%
f_{T_{n}}\left( t\right) =\frac{1}{\pi \left( x^{2}+1\right) }$, che \`{e}
la densit\`{a} di una v. a. di Cauchy: quindi $\NEG{\exists}$ $\mathbf{E}%
\left( T_{1}\right) $. Se invece $n>1$, $\exists $ $\mathbf{E}\left(
T_{n}\right) =0$ perch\'{e} $f_{T_{n}}$ \`{e} simmetrica. Se $n=1,2$ $%
var\left( T_{n}\right) $ $\NEG{\exists}$; se $n>2$ $var\left( T_{n}\right) =%
\frac{n}{n-2}$. In generale esistono solo i momenti per $k<n$: $\mathbf{E}%
\left( T_{n}^{k}\right) <+\infty $ $\Longleftrightarrow k<n$.

Se definisco media campionaria $\bar{X}_{n}=\frac{X_{1}+...+X_{n}}{n}$, vale
per linearit\`{a} che $\mathbf{E}\left( \bar{X}_{n}\right) =\frac{1}{n}n\mu
=\mu $. Per 15.4 (7) vale inoltre $var\left( \sum_{k=1}^{n}X_{k}\right)
=\sum_{k=1}^{n}var\left( X_{k}\right) =n\sigma ^{2}$, per cui $var\left( 
\bar{X}_{n}\right) =\frac{1}{n^{2}}n\sigma ^{2}=\frac{\sigma ^{2}}{n}$.

Sia $\left( 
\begin{array}{c}
X_{1} \\ 
... \\ 
X_{n}%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
\mu \\ 
... \\ 
\mu%
\end{array}%
\right) ,\left[ 
\begin{array}{ccc}
\sigma ^{2} & ... & 0 \\ 
... & ... & ... \\ 
0 & ... & \sigma ^{2}%
\end{array}%
\right] \right) $ un campione casuale, cio\`{e} un insieme di v. a. iid con
distribuzione $\mathcal{N}\left( \mu ,\sigma ^{2}\right) $. Siano, come gi%
\`{a} visto, la media campionaria $\bar{X}_{n}=\frac{X_{1}+...+X_{n}}{n}$,
la varianza campionaria $S_{n}^{2}=\frac{1}{n-1}\sum_{k=1}^{n}\left( X_{k}-%
\bar{X}_{n}\right) ^{2}$.

, vale $S_{n}^{2}=\frac{1}{n-1}\sum_{k=1}^{n}\left( X_{k}^{2}+\bar{X}%
_{n}^{2}-2X_{k}\bar{X}_{n}\right) $. Poich\'{e} $var\left( X_{k}\right) =%
\mathbf{E}\left( X_{k}^{2}\right) -\mathbf{E}^{2}\left( X_{k}\right) $, vale 
$\mathbf{E}\left( X_{k}^{2}\right) =\sigma ^{2}+\mu ^{2}$, e $\mathbf{E}%
\left( X_{k}\bar{X}_{n}\right) =cov\left( X_{k},\bar{X}_{n}\right) +\mathbf{E%
}\left( X_{k}\right) \mathbf{E}\left( \bar{X}_{n}\right) =\frac{1}{n}%
var\left( X_{k}\right) +\mathbf{E}\left( X_{k}\right) \mathbf{E}\left( \bar{X%
}_{n}\right) $: per linearit\`{a} $\mathbf{E}\left( S_{n}^{2}\right) =\frac{1%
}{n-1}\left( n\left( \sigma ^{2}+\mu ^{2}\right) +n\left( \frac{\sigma ^{2}}{%
n}+\mu ^{2}\right) -2n\frac{\sigma ^{2}}{n}-2n\mu ^{2}\right) =\frac{1}{n-1}%
\left( \ n\sigma ^{2}\ +\sigma ^{2}\ -2\sigma ^{2}\right) =\sigma ^{2}$.

\textbf{Teo 19.1 (relazioni tra statistiche campionarie)}%
\begin{gather*}
\text{Hp: }X_{1},...,X_{n}\text{ \`{e} un campione casuale estratto da }%
X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) \\
\text{Ts: (1) }\bar{X}_{n}\sim \mathcal{N}\left( \mu ,\frac{\sigma ^{2}}{n}%
\right) \\
\text{(2) }\frac{n-1}{\sigma ^{2}}S_{n}^{2}\sim \chi ^{2}\left( n-1\right) \\
\text{(3) }\bar{X}_{n}\perp S_{n}^{2} \\
\text{(4) }\frac{\bar{X}_{n}-\mu }{\sqrt{\frac{S_{n}^{2}}{n}}}\sim t\left(
n-1\right)
\end{gather*}

Da (2) si ricava che $var\left( S_{n}^{2}\right) =\frac{2\sigma ^{4}}{n-1}$
e $\phi _{S_{n}^{2}}\left( u\right) =\left( 1-\frac{2i\sigma ^{2}}{n-1}%
u\right) ^{-\frac{n-1}{2}}$.

\textbf{Dim} (1) $\mathbf{E}\left( \frac{X_{1}+...+X_{n}}{n}\right) =\frac{1%
}{n}\sum_{i=1}^{n}\mathbf{E}\left( X_{i}\right) =\frac{1}{n}n\mu =\mu $. $%
var\left( \frac{X_{1}+...+X_{n}}{n}\right) =\frac{1}{n^{2}}%
\sum_{i=1}^{n}var\left( X_{i}\right) =\frac{1}{n^{2}}n\sigma ^{2}=\frac{%
\sigma ^{2}}{n}$.

(2) (3) Suppongo $\mu =0,\sigma ^{2}=1$. Allora $\left( 
\begin{array}{c}
X_{1} \\ 
... \\ 
X_{n}%
\end{array}%
\right) \sim \mathcal{N}\left( \mathbf{0},Id\right) $ perch\'{e} le
componenti sono indipendenti. Considero $U\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( n,n\right) $ ortogonale, avente la prima riga $\left[ \frac{1}{\sqrt{%
n}}|...|\frac{1}{\sqrt{n}}\right] $ e tutte le altre righe ortonormali alla
prima. Costruisco $\mathbf{Z}=U\mathbf{X}$: sar\`{a} $\mathbf{Z}\sim 
\mathcal{N}\left( U\cdot \mathbf{0},UIdU^{T}\right) =\mathcal{N}\left( 
\mathbf{0},Id\right) $. Inoltre $Z_{1}=\frac{1}{\sqrt{n}}\left(
X_{1}+...+X_{n}\right) =\sqrt{n}\bar{X}_{n}$. $\sum_{k=2}^{n}Z_{k}^{2}=\left%
\vert \left\vert \mathbf{Z}\right\vert \right\vert ^{2}-Z_{1}^{2}=f\left(
Z_{2},...,Z_{n}\right) $, che \`{e} indipendente da $Z_{1}$ perch\'{e} $%
\mathbf{Z}$ ha matrice $C$ diagonale e quindi componenti indipendenti. Si 
\`{e} gi\`{a} visto che $\left( n-1\right) S_{n}^{2}=\sum_{k=1}^{n}\left(
X_{k}-\bar{X}_{n}\right) ^{2}=\left\vert \left\vert \mathbf{X}\right\vert
\right\vert ^{2}-n\bar{X}_{n}^{2}$. Ma $\left\vert \left\vert \mathbf{Z}%
\right\vert \right\vert ^{2}=\left\langle U\mathbf{X,}U\mathbf{X}%
\right\rangle =\left\vert \left\vert \mathbf{X}\right\vert \right\vert ^{2}$
perch\'{e} $U$ \`{e} ortogonale, quindi $\left( n-1\right)
S_{n}^{2}=\left\vert \left\vert \mathbf{Z}\right\vert \right\vert ^{2}-n\bar{%
X}_{n}^{2}=\left\vert \left\vert \mathbf{Z}\right\vert \right\vert
^{2}-Z_{1}^{2}=\sum_{k=2}^{n}Z_{k}^{2}$ perch\'{e} $\frac{Z_{1}}{\sqrt{n}}=%
\bar{X}_{n}$. $\sum_{k=2}^{n}Z_{k}^{2}\sim \chi ^{2}\left( n-1\right) $ per
definizione di $\chi ^{2}$, ed \`{e} dimostrata (2) perch\'{e} sono nel caso
di $\sigma ^{2}=1$.

Ne segue che $\sum_{k=1}^{n}\left( X_{k}-\bar{X}_{n}\right)
^{2}=\sum_{k=2}^{n}Z_{k}^{2}$ \`{e} indipendente da $Z_{1}=\sqrt{n}\bar{X}%
_{n}$, per cui $S_{n}^{2}=\frac{1}{n-1}\sum_{k=1}^{n}\left( X_{k}-\bar{X}%
_{n}\right) ^{2}$ \`{e} indipendente da $\bar{X}_{n}=\frac{Z_{1}}{\sqrt{n}}$
(applicare funzioni misurabili a due v. a. indipendenti preserva
l'indipendenza). Con la standardizzazione si mostra che $\frac{n-1}{\sigma
^{2}}S_{n}^{2}\sim \chi ^{2}\left( n-1\right) $ e $\bar{X}_{n}\perp
S_{n}^{2} $.

(4) Voglio scrivere $\frac{\bar{X}_{n}-\mu }{\sqrt{\frac{S_{n}^{2}}{n}}}$
come $\frac{Z}{\sqrt{\frac{V_{n-1}}{n-1}}}$. Vale $Z=\frac{\bar{X}_{n}-\mu }{%
\sqrt{\frac{\sigma ^{2}}{n}}}\sim N\left( 0,1\right) $ e $V_{n-1}=\frac{%
\left( n-1\right) S_{n-1}^{2}}{\sigma ^{2}}\sim \chi ^{2}\left( n-1\right) $%
, ma $\frac{\bar{X}_{n}-\mu }{\sqrt{\frac{S_{n}^{2}}{n}}}$ \`{e} proprio
uguale a $\frac{Z}{\sqrt{\frac{V_{n-1}}{n-1}}}$, quindi $\frac{\bar{X}%
_{n}-\mu }{\sqrt{\frac{S_{n}^{2}}{n}}}\sim t\left( n-1\right) $. $%
\blacksquare $

\section{Leggi condizionali}

Sia $\left( 
\begin{array}{c}
X \\ 
Y%
\end{array}%
\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}$ un vettore aleatorio discreto con densit\`{a} congiunta $p_{\left(
X,Y\right) }$ e densit\`{a} marginali $p_{X},p_{Y}$, con supporti delle
componenti $S_{X},S_{Y}$ rispettivamente. Supponiamo di venire a sapere che $%
X=x_{i}$. In assenza di questa informazione, la legge di $Y$ si calcola come 
$\mathbf{P}\left( Y\in B\right) $, partendo dalla terna $\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $; avendola, per calcolare probabilit\`{a}
legate a $Y$ ha senso usare $\mathbf{P}\left( Y\in B|X=x_{i}\right) $, il
che definisce una nuova legge. In generale, dato $x\in S_{X}$, la funzione
avente come dominio $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ che a ogni $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ associa $\mathbf{P}\left( Y\in B|X=x\right) $ \`{e} una misura di
probabilit\`{a} (si \`{e} gi\`{a} visto che la probabilit\`{a} condizionata 
\`{e} una misura di probabilit\`{a} nel suo primo argomento). $\mathbf{P}%
\left( Y\in B|X=x\right) $ si indica con $P^{Y|X}\left( B|x\right) $, con $%
x\in S_{X}$ e $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $.

La v. a. $Y|X=x$ non \`{e} ben definita in s\'{e}: \`{e} la notazione usata
per indicare le v. a. con la legge $\mathbf{P}\left( Y\in B|X=x\right) $.

$Y$ \`{e} discreta anche rispetto a questa misura di probabilit\`{a}, perch%
\'{e} $\mathbf{P}\left( Y\in S_{Y}|X=x\right) =\frac{\mathbf{P}\left( Y\in
S_{Y},X=x\right) }{\mathbf{P}\left( X=x\right) }=\frac{\mathbf{P}\left(
X=x\right) }{\mathbf{P}\left( X=x\right) }=1$, dato che $\mathbf{P}\left(
A\cap B\right) =\mathbf{P}\left( B\right) $ se $\mathbf{P}\left( A\right) =1$%
.

Calcolo la densit\`{a} discreta di $Y$ rispetto alla nuova misura: dato $%
y\in S_{Y}$, $p_{Y|X}\left( y|x\right) =\mathbf{P}\left( Y=y|X=x\right) =%
\frac{p_{\left( X,Y\right) }\left( x,y\right) }{p_{X}\left( x\right) }$. E'
facile mostrare che \`{e} una densit\`{a} discreta.

Il valore atteso di $Y$ rispetto alla nuova misura di probabilit\`{a} $%
P^{Y|X}\left( B|x\right) $, che si indica con $\mathbf{E}\left( Y|X=x\right) 
$, \`{e} $\int_{\Omega }Y\left( \omega \right) P\left( d\omega |X=x\right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}yP^{Y|X}\left( dy|x\right) =\sum_{y\in S_{Y}}yp_{Y|X}\left( y|x\right) $.
In generale, data $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ boreliana e limitata oppure nonnegativa, $\mathbf{E}\left( h\left(
Y\right) |X=x\right) =\sum_{y\in S_{Y}}h\left( y\right) p_{Y|X}\left(
y|x\right) $.

Vale inoltre $p_{\left( X,Y\right) }\left( x,y\right) =p_{X|Y}\left(
y|x\right) p_{X}\left( x\right) $ $\forall $ $x\in S_{X},\forall $ $y\in
S_{Y}$.

\begin{enumerate}
\item Lancio un dado equilibrato: si descrive il risultato $k$ con una v. a. 
$D\sim \mathcal{U}\left( \left\{ 1,...,6\right\} \right) $, con densit\`{a} $%
p_{D}\left( d\right) =\frac{1}{6}$ $\forall $ $d\in \left\{ 1,...,6\right\} $%
. Lancio quindi una moneta equa per $k$ volte; il numero di teste \`{e} la
v. a. $T$. So che $T$, una volta lanciato il dado, \`{e} binomiale di
parametri $d$ e $\frac{1}{2}$: per $d\in \left\{ 1,...,6\right\} $, $n\in
\left\{ 1,...,d\right\} $ vale $p_{T|D}\left( n|d\right) =P\left(
T=n|D=d\right) =\binom{d}{n}\left( \frac{1}{2}\right) ^{n}\left( \frac{1}{2}%
\right) ^{d-n}=\binom{d}{n}\left( \frac{1}{2}\right) ^{d}$. La densit\`{a}
congiunta di $D$ e $T$ \`{e} $p_{\left( D,T\right) }\left( d,n\right)
=p_{T|D}\left( t|n\right) p_{D}\left( d\right) =\binom{d}{n}\left( \frac{1}{2%
}\right) ^{d}\frac{1}{6}$ per quanto detto sulla densit\`{a} discreta della
legge condizionata. $D$ e $T$ non sono indipendenti perch\'{e} il supporto
di $\left( D,T\right) $ non \`{e} quadrato: ho degli zeri. La legge
marginale di $T$ \`{e} $p_{T}\left( n\right) =\sum_{d=n}^{6}\binom{d}{n}%
\left( \frac{1}{2}\right) ^{d}\frac{1}{6}$.
\end{enumerate}

Finora si sono considerate $X,Y$ discrete; tuttavia, quanto detto non cambia
se $Y$ non \`{e} discreta, perch\'{e} $\mathbf{P}\left( Y\in B|X=x\right) $
si definisce come visto, $\forall $ $x\in S_{X}$. In generale \`{e} invece
necessario che $\mathbf{P}\left( X=x\right) \neq 0$ per poter definire $%
\mathbf{P}\left( Y\in B|X=x\right) $ come fatto finora: questa ipotesi
dev'essere rimossa per trattare il caso di $X$ assolutamente continua.
L'obiettivo \`{e} quindi, dato che $\mathbf{P}\left( X=x\right) =0$, rendere
sensata la scrittura $\mathbf{P}\left( Y\in B,X=x\right) =\mathbf{P}\left(
X=x\right) \mathbf{P}\left( Y\in B|X=x\right) $ definendo arbitrariamente $%
\mathbf{P}\left( Y\in B|X=x\right) $.

Traiamo ancora ispirazione dal caso in cui $X$ \`{e} discreta. In questo
caso, usando la disintegrazione grazie alla propriet\`{a} distributiva
dell'intersezione rispetto all'unione ($X^{-1}\left( A\right) \cap
Y^{-1}\left( B\right) =\left[ \bigcup_{x\in A\cap S_{X}}X^{-1}\left( \left\{
x\right\} \right) \right] \cap Y^{-1}\left( B\right) =\bigcup_{x\in A\cap
S_{X}}\left( X^{-1}\left( \left\{ x\right\} \right) \cap Y^{-1}\left(
B\right) \right) $), vale $\mathbf{P}\left( X\in A,Y\in B\right) =\sum_{x\in
S_{X}\cap A}\mathbf{P}\left( X=x,Y\in B\right) =\sum_{x\in S_{X}}I_{A}\left(
x\right) \mathbf{P}\left( Y\in B|X=x\right) \mathbf{P}\left( X=x\right) $:
si cerca una formula analoga per il caso continuo, in modo da ottenere
un'uguaglianza del tipo $\mathbf{P}\left( X\in A,Y\in B\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}I_{A}\left( x\right) ?dP^{X}\left( x\right) $, con $?$ funzione che estenda
quanto visto. Infatti $\sum_{x\in S_{X}}I_{A}\left( x\right) \mathbf{P}%
\left( Y\in B|X=x\right) \mathbf{P}\left( X=x\right) $ pu\`{o} essere vista
come integrale di Lebesgue rispetto a una legge discreta: $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}I_{A}\left( x\right) \mathbf{P}\left( Y\in B|X=x\right) dP^{X}\left(
x\right) $.

\textbf{Def 20.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( E,\mathcal{E}\right) ,\left( F,\mathcal{F}%
\right) $ spazi misurabili, $X:\Omega \rightarrow E,Y:\Omega \rightarrow F$
variabili aleatorie, si dice legge condizionale di $Y$ data $X$ una funzione 
$Q:E\times \mathcal{F}\rightarrow \left[ 0,1\right] $ tale che

\begin{description}
\item[C1] $\forall $ $B\in \mathcal{F}$ $Q:E\rightarrow \left[ 0,1\right] $, 
$Q=Q\left( \cdot ,B\right) =Q_{B}\left( \cdot \right) $ \`{e} $\mathcal{E}$%
-misurabile

\item[C2] $\forall $ $x\in E$ $Q:\mathcal{F}\rightarrow \left[ 0,1\right] $, 
$Q=Q\left( x,\cdot \right) =Q_{x}\left( \cdot \right) $ \`{e} una misura di
probabilit\`{a} su $\left( F,\mathcal{F}\right) $

\item[C3] $\forall $ $A\in \mathcal{E},\forall $ $B\in \mathcal{F}$ vale $%
\mathbf{P}\left( X\in A,Y\in B\right) =\int_{E}I_{A}\left( x\right) Q\left(
x,B\right) dP^{X}\left( x\right) $
\end{description}

C1 serve perch\'{e} per integrare rispetto a $P^{X}$ serve che la funzione
integranda sia misurabile rispetto a $\mathcal{E}$. Si noti che la
definizione \`{e} estremamente generale: $X$ e $Y$ sono funzioni misurabili
da $\Omega $ a spazi misurabili qualsiasi (e. g., se $X$ e $Y$ sono vettori
aleatori). $Q$ \`{e} definita su $E\times \mathcal{F}$ perch\'{e} serve a
calcolare una probabilit\`{a} relativa a $Y$ (quindi di $B\in \mathcal{F}$)
avendo un valore di $X$ (quindi $x\in E$). C1 significa che $\forall $ $C\in 
\mathcal{B}\left( \left[ 0,1\right] \right) $ $Q_{B}^{-1}\left( C\right) \in 
\mathcal{E}$: serve e. g. a poter calcolare la probabilit\`{a} che $X$
appartenga all'insieme degli $x$ tali che $Q_{B}\left( x\right) \in C$.

C3 \`{e} un'estensione della formula delle probabilit\`{a} totali: \`{e}
noto che, se $E_{1},...,E_{n}$ sono una partizione di $A$, $\mathbf{P}\left(
A\cap B\right) =\sum \mathbf{P}\left( B|E_{n}\right) \mathbf{P}\left(
E_{n}\right) $, mentre ora $P^{\left( X,Y\right) }\left( A\times B\right)
=\int_{E}I_{A}\left( x\right) Q\left( x,B\right) dP^{X}\left( x\right) $. In
C3, le $x$ "partizionano" $A$. L'integrale \`{e} ben definito perch\'{e},
fissato $B$, per C1 $Q\left( x,B\right) $ \`{e} misurabile rispetto a $%
\mathcal{E}$, limitata e nonnegativa, quindi integrabile secondo la legge di 
$X$. Vale inoltre l'uguaglianza%
\begin{equation*}
P^{\left( X,Y\right) }\left( A\times B\right) =\int_{E}I_{A}\left( x\right)
Q\left( x,B\right) dP^{X}\left( x\right) =\int_{E}I_{A}\left( x\right)
\left( \int_{F}I_{B}\left( y\right) Q\left( x,dy\right) \right) dP^{X}\left(
x\right)
\end{equation*}

per C2, dato che in generale $P\left( A\right) =\int_{\Omega }I_{A}\left(
\omega \right) dP\left( \omega \right) $.

Ho quindi trovato l'estensione desiderata: $Q\left( x,B\right) $ fa le veci
di $\mathbf{P}\left( Y\in B|X=x\right) $ vista nel caso discreto, per cui $%
Q\left( x,dy\right) $ si merita di essere indicata anche con $P^{Y|X}\left(
dy|x\right) $.

Se $Q$ \`{e} una legge condizionale, grazie a C3 (che definisce $P^{\left(
X,Y\right) }\left( C\right) $ solo per $C\in \mathcal{E\times F}$) si ha che 
$\forall $ $C\in \mathcal{E\otimes F}$ $P^{\left( X,Y\right) }\left(
C\right) =\int_{E}\left( \int_{F}I_{C}\left( x,y\right) Q\left( x,dy\right)
\right) dP^{X}\left( x\right) $, perch\'{e} $\mathcal{E\times F}$ \`{e} un $%
\pi $-sistema: non vale pi\`{u} $I_{C}\left( x,y\right) =I_{A}\left(
x\right) I_{B}\left( y\right) $ perch\'{e} $C$ non \`{e} necessariamente un
rettangolo!

In generale ($P^{\left( X,Y\right) }\left( C\right) =\mathbf{E}^{\left(
X,Y\right) }\left( I_{C}\left( X,Y\right) \right) $), $\forall $ $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{2}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:\left\vert h\right\vert \leq M$ o $h\geq 0$ vale $\mathbf{E}\left( h\left(
X,Y\right) \right) =\int_{E\times F}h\left( x,y\right) dP^{\left( X,Y\right)
}\left( x,y\right) =\int_{E}\left( \int_{F}h\left( x,y\right) Q\left(
x,dy\right) \right) dP^{X}\left( x\right) $: questo \`{e} quanto afferma il
teorema di Fubini-Tonelli generalizzato, che non richiede pi\`{u} di
lavorare sulla legge prodotto e pu\`{o} essere quindi applicato anche se $X$
e $Y$ non sono indipendenti.

\textbf{Prop 20.2 (unicit\`{a} della legge condizionale se }$F=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$\textbf{)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( E,\mathcal{E}\right) ,\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) \text{ } \\
\text{spazi misurabili, }X:\Omega \rightarrow E,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ v. a.} \\
\text{Ts: }\exists \text{ }!\text{ legge condizionale di }Y\text{ data }X
\end{gather*}

L'unicit\`{a} significa che $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $, se $Q$ e $\tilde{Q}$ sono due leggi condizionali, allora $%
Q\left( x,B\right) =\tilde{Q}\left( x,B\right) $ quasi certamente secondo $%
P^{X}$. Questo nel seguito giustificher\`{a} la possibilit\`{a} di definire
arbitrariamente la legge condizionale su insiemi che hanno misura nulla
secondo $P^{X}$.

Si affrontano ora alcuni casi notevoli di legge condizionata.

\begin{description}
\item[1] \textbf{Componenti indipendenti} Partiamo dal caso estremo di v. a.
indipendenti. Se $X\perp Y$, $P^{\left( X,Y\right) }=P^{X}\otimes P^{Y}$.
L'intuizione suggerisce in tal caso $\mathbf{P}\left( Y\in B|X=x\right) =%
\mathbf{P}\left( Y\in B\right) $: $Q$, se la sua definizione \`{e} stata ben
scelta, deve rispettare questa intuizione di $P^{Y|X}\left( dy|x\right)
=P^{Y}\left( dy\right) $. Definisco allora $Q\left( x,B\right) =P^{Y}\left(
B\right) $ e mostro che \`{e} effettivamente una legge condizionale.

\item $\forall $ $B\in \mathcal{F}$ $Q_{B}\left( x\right) =P^{Y}\left(
B\right) $ \`{e} costante rispetto a $x$, quindi la controimmagine di
qualsiasi boreliano in $\left[ 0,1\right] $ \`{e} vuota e $Q_{B}\left(
x\right) $ \`{e} misurabile rispetto a $\mathcal{E}$. $Q\left( x,B\right) $ 
\`{e} una misura di probabilit\`{a} perch\'{e} coincide con $P^{Y}\left(
B\right) $, che lo \`{e} in quanto legge di $Y$.

\item Per definizione di legge prodotto e per il teorema di Fubini-Tonelli $%
P^{\left( X,Y\right) }\left( A\times B\right) =\int_{E\times F}I_{A\times
B}\left( x,y\right) dP^{\left( X,Y\right) }\left( x,y\right) =\int_{E\times
F}I_{A}\left( x\right) I_{B}\left( y\right) dP^{\left( X,Y\right) }\left(
x,y\right) $ $=\int_{E\times F}I_{A}\left( x\right) I_{B}\left( y\right)
dP^{X}\left( x\right) \otimes P^{Y}\left( y\right) =\int_{E}I_{A}\left(
x\right) \left( \int_{F}I_{B}\left( y\right) dP^{Y}\left( y\right) \right)
dP^{X}\left( x\right) =\int_{E}I_{A}\left( x\right) P^{Y}\left( B\right)
dP^{X}\left( x\right) $, dato che $P^{Y}\left( B\right) =E^{Y}\left(
I_{B}\left( y\right) \right) $. Vale quindi anche C3, e $P^{Y}\left(
B\right) $ \`{e} l'unica legge condizionale. E' vero quindi che $X\perp
Y\Longleftrightarrow Q\left( x,B\right) =P^{Y}\left( B\right) $.

\item[2] \textbf{Una componente funzione dell'altra} Il caso estremo opposto
al precedente \`{e} il seguente. Sia $Y=h\left( X\right) $ con $%
h:E\rightarrow F$ misurabile e non costante. Intuitivamente, $P^{Y|X}\left(
B|x\right) =\left\{ 
\begin{array}{c}
1\text{ se }h\left( x\right) \in B \\ 
0\text{ se }h\left( x\right) \not\in B%
\end{array}%
\right. =\delta _{h\left( x\right) }\left( B\right) $. Definisco allora $%
Q\left( x,B\right) =\delta _{h\left( x\right) }\left( B\right) $. $%
Q_{B}\left( x\right) $ \`{e} $\mathcal{E}$-misurabile perch\'{e} $\forall $ $%
C\in \mathcal{F}$ $Q_{B}^{-1}\left( C\right) =\left\{ 
\begin{array}{c}
h^{-1}\left( B\right) \text{ se }1\in C,0\not\in C \\ 
\left( h^{-1}\left( B\right) \right) ^{c}\text{ se }0\in C,1\not\in C \\ 
E\text{ se }\left\{ 0,1\right\} \subseteq C \\ 
\varnothing \text{ se }\left\{ 0,1\right\} \subseteq C^{c}%
\end{array}%
\right. $, che \`{e} in ogni caso un elemento di $\mathcal{E}$ perch\'{e} $h$
\`{e} misurabile.

\item $\delta _{h\left( x\right) }\left( F\right) =1$ perch\'{e} sicuramente 
$h\left( x\right) \in F$; se $\left( F_{i}\right) _{i\geq 1}$ \`{e} una
famiglia di elementi disgiunti di $\mathcal{F}$, $\delta _{h\left( x\right)
}\left( \bigcup_{i=1}^{+\infty }F_{i}\right) =\left\{ 
\begin{array}{c}
1\text{ se }\exists \text{ }i:h\left( x\right) \in F_{i} \\ 
0\text{ se }\NEG{\exists}i:h\left( x\right) \in F_{i}%
\end{array}%
\right. =\sum_{i=1}^{+\infty }\delta _{h\left( x\right) }\left( F_{i}\right) 
$, quindi $\delta _{h\left( x\right) }\left( B\right) $ \`{e} una misura di
probabilit\`{a} su $\left( F,\mathcal{F}\right) $.

\item $\int_{E}I_{A}\left( x\right) Q\left( x,B\right) dP^{X}\left( x\right)
=\int_{E}I_{A}\left( x\right) \delta _{h\left( x\right) }\left( B\right)
dP^{X}\left( x\right) =\int_{E}I_{A}\left( x\right) I_{h^{-1}\left( B\right)
}\left( x\right) dP^{X}\left( x\right) =\int_{A\cap h^{-1}\left( B\right)
}dP^{X}\left( x\right) =\mathbf{P}\left( X\in \left( A\cap h^{-1}\left(
B\right) \right) \right) $, che coincide con $\mathbf{P}\left( X\in
A,h\left( X\right) \in B\right) =\mathbf{P}\left( X\in A,Y\in B\right) $.

\item[3] \textbf{Vettore discreto} Considero $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k},\mathbf{Y}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ vettori aleatori discreti e il vettore $\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n+k}$, con $\mathcal{E=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\right) ,\mathcal{F=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $. Definisco $Q\left( \mathbf{x},B\right) =\left\{ 
\begin{array}{c}
\mathbf{P}\left( \mathbf{Y}\in B|\mathbf{X=x}\right) \text{ se }\mathbf{x}%
\in S_{\mathbf{X}} \\ 
\tilde{Q}\left( B\right) \text{ se }\mathbf{x}\not\in S_{\mathbf{X}}%
\end{array}%
\right. $ dove $\tilde{Q}:\mathcal{F\rightarrow }\left[ 0,1\right] $ \`{e}
una misura di probabilit\`{a} qualsiasi e $S_{\mathbf{X}}=\left\{ \mathbf{x}%
\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}:p_{\mathbf{X}}\left( \mathbf{x}\right) >0\right\} $, e mostro che \`{e}
effettivamente una legge condizionale. $Q$ \`{e} una funzione misurabile nel
suo primo argomento perch\'{e} $Q\left( \mathbf{x},B\right) =\mathbf{P}%
\left( \mathbf{Y}\in B|\mathbf{X=x}\right) I_{S_{\mathbf{X}}}\left( \mathbf{x%
}\right) +\tilde{Q}\left( B\right) I_{S_{\mathbf{X}}^{c}}\left( \mathbf{x}%
\right) $ ha $\mathbf{P}\left( \mathbf{Y}\in B|\mathbf{X=x}\right) $
misurabile dato che ogni insieme discreto \`{e} in $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\right) $, in quanto unione di singoletti. $Q$ \`{e} una misura di
probabilit\`{a} nel suo secondo argomento perch\'{e} lo \`{e} la probabilit%
\`{a} condizionata e perch\'{e} $\tilde{Q}$ lo \`{e} per ipotesi. Inoltre,
poich\'{e} $\mathbf{X}$ \`{e} discreto, per la regola del valore atteso $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}}I_{A}\left( \mathbf{x}\right) Q\left( \mathbf{x},B\right) dP^{\mathbf{X}%
}\left( \mathbf{x}\right) =\sum_{\mathbf{x}\in S_{\mathbf{X}}}I_{A}\left( 
\mathbf{x}\right) \mathbf{P}\left( \mathbf{Y}\in B|\mathbf{X=x}\right) P^{%
\mathbf{X}}\left( \mathbf{x}\right) =\sum_{\mathbf{x}\in S_{\mathbf{X}}\cap
A}\mathbf{P}\left( \mathbf{Y}\in B|\mathbf{X=x}\right) \mathbf{P}\left( 
\mathbf{X}=\mathbf{x}\right) $, che \`{e}, per la formula delle probabilit%
\`{a} totali, $\mathbf{P}\left( \mathbf{X}\in A,\mathbf{Y}\in B\right) $. Si
noti che la scelta di $\tilde{Q}$ \`{e} irrilevante.

\item $\mathbf{P}\left( \mathbf{Y}\in B|\mathbf{X=x}\right) $ \`{e} una
probabilit\`{a} discreta perch\'{e} $\mathbf{P}\left( \mathbf{Y}\in S_{%
\mathbf{Y}}|\mathbf{X=x}\right) =\frac{\mathbf{P}\left( \mathbf{Y}\in S_{Y},%
\mathbf{X=x}\right) }{\mathbf{P}\left( \mathbf{X=x}\right) }=\frac{\mathbf{P}%
\left( \mathbf{X=x}\right) }{\mathbf{P}\left( \mathbf{X=x}\right) }=1$, con
densit\`{a} discreta di $Y$ $p_{\mathbf{Y|X}}\left( \mathbf{y|x}\right) =%
\mathbf{P}\left( \mathbf{Y=y|X=x}\right) =\frac{p_{\left( \mathbf{X,Y}%
\right) }\left( \mathbf{x,y}\right) }{p_{\mathbf{X}}\left( \mathbf{x}\right) 
}$.
\end{description}

Nel caso discreto il valore atteso di $Y$ rispetto alla nuova misura di
probabilit\`{a} $P^{Y|X}\left( B|x\right) $, che si indica con $\mathbf{E}%
\left( Y|X=x\right) $, \`{e} $\int_{\Omega }Y\left( \omega \right) P\left(
d\omega |X=x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}yP^{Y|X}\left( dy|x\right) =\sum_{y\in S_{Y}}yp_{Y|X}\left( y|x\right) $.
In generale, data $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ boreliana e limitata oppure nonnegativa, $\mathbf{E}\left( h\left(
Y\right) |X=x\right) =\sum_{y\in S_{Y}}h\left( y\right) p_{Y|X}\left(
y|x\right) $.

\begin{description}
\item[4] \textbf{Vettore assolutamente continuo} Considero $\mathbf{X}%
:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k},\mathbf{Y}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ v. a. tali che il vettore $\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n+k}$ \`{e} assolutamente continuo, con densit\`{a} congiunta $f_{\left( 
\mathbf{X,Y}\right) }$ e densit\`{a} marginali $f_{\mathbf{X}},f_{\mathbf{Y}%
} $ (rappresentanti scelte arbitrariamente), con $\mathcal{E=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\right) ,\mathcal{F=B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $. Posto $S_{\mathbf{X}}=\left\{ \mathbf{x}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}:f_{\mathbf{X}}\left( \mathbf{x}\right) >0\right\} $, definisco la densit%
\`{a} condizionale di $\mathbf{Y}$ dato che $\mathbf{X=x}$ $f_{\mathbf{Y|X}%
}\left( \mathbf{y|x}\right) =\left\{ 
\begin{array}{c}
\text{\textbf{\ }}\frac{f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{x,y}%
\right) }{f_{\mathbf{X}}\left( \mathbf{x}\right) }\text{ se }\mathbf{x}\in
S_{\mathbf{X}} \\ 
\tilde{f}\left( \mathbf{y}\right) \text{ se }\mathbf{x}\not\in S_{\mathbf{X}}%
\end{array}%
\right. $ dove $\tilde{f}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} una qualsiasi densit\`{a} continua (nonnegativa, borel, ecc.).
Definisco allora $Q\left( \mathbf{x},B\right) =\int_{B}f_{\mathbf{Y|X}%
}\left( \mathbf{y|x}\right) d\mathbf{y}$ e mostro che \`{e} effettivamente
una legge condizionale. $Q$ \`{e} una funzione misurabile nel suo primo
argomento perch\'{e} $Q\left( \mathbf{x},B\right) =\int_{B}\left( \frac{%
f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) }{f_{\mathbf{X}%
}\left( \mathbf{x}\right) }I_{S_{\mathbf{X}}}\left( \mathbf{x}\right) +%
\tilde{f}\left( \mathbf{y}\right) I_{S_{\mathbf{X}}^{c}}\left( \mathbf{x}%
\right) \right) d\mathbf{y}$: le $f$ sono tutte misurabili in quanto densit%
\`{a} continue, le funzioni indicatrici lo sono perch\'{e} $S_{\mathbf{X}}$ 
\`{e} un boreliano ($f$ deve avere un insieme di punti di discontinuit\`{a}
di misura nulla); poich\'{e} somme, prodotti, integrali (si sta integrando
rispetto a $m\otimes m=m_{2}$, quindi si applica Fubini-Tonelli) di funzioni
misurabili sono misurabili, $Q$ \`{e} misurabile. Inoltre, fissato $\mathbf{x%
}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$, $Q\left( \mathbf{x},B\right) $ \`{e} una misura di probabilit\`{a}
perch\'{e} la funzione di $\mathbf{y}$ $\frac{f_{\left( \mathbf{X,Y}\right)
}\left( \mathbf{x,y}\right) }{f_{\mathbf{X}}\left( \mathbf{x}\right) }$ \`{e}
una densit\`{a} continua su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ ($\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}}\left( \frac{f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) 
}{f_{\mathbf{X}}\left( \mathbf{x}\right) }I_{S_{\mathbf{X}}}\left( \mathbf{x}%
\right) +\tilde{f}\left( \mathbf{y}\right) I_{S_{\mathbf{X}}^{c}}\left( 
\mathbf{x}\right) \right) d\mathbf{y=}I_{S_{\mathbf{X}}}+I_{S_{\mathbf{X}%
}^{c}}\left( \mathbf{x}\right) =1$), e poi l'integrale \`{e} sempre una
misura di probabilit\`{a}. Vale poi $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}I_{A}\left( \mathbf{x}\right) Q\left( \mathbf{x},B\right) P^{\mathbf{X}%
}\left( d\mathbf{x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}I_{A}\left( \mathbf{x}\right) Q\left( \mathbf{x},B\right) f_{\mathbf{X}%
}\left( \mathbf{x}\right) d\mathbf{x}$, cio\`{e}, essendo nulla la densit%
\`{a} in $S_{\mathbf{X}}^{c}$, $\int_{S_{\mathbf{X}}}I_{A}\left( \mathbf{x}%
\right) \left( \int_{B}\frac{f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{%
x,y}\right) }{f_{\mathbf{X}}\left( \mathbf{x}\right) }d\mathbf{y}\right) f_{%
\mathbf{X}}\left( \mathbf{x}\right) d\mathbf{x=}$ $\int_{S_{\mathbf{X}%
}}I_{A}\left( \mathbf{x}\right) \left( \int_{B}f_{\left( \mathbf{X,Y}\right)
}\left( \mathbf{x,y}\right) d\mathbf{y}\right) d\mathbf{x=}\int_{S_{\mathbf{X%
}}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}I_{A}\left( \mathbf{x}\right) I_{B}\left( \mathbf{y}\right) f_{\left( 
\mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) d\mathbf{y}d\mathbf{x=}$ $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}I_{A}\left( \mathbf{x}\right) I_{B}\left( \mathbf{y}\right) f_{\left( 
\mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) d\mathbf{y}d\mathbf{x}=%
\mathbf{P}\left( \mathbf{X}\in A,\mathbf{Y}\in B\right) $.

\item Cos\`{\i} ho scoperto che se un vettore \`{e} a. c., allora la sua
probabilit\`{a} condizionale \`{e} assolutamente continua e le componenti
sono continue. La seguente proposizione mostra anche che vale il viceversa.
\end{description}

Come nel caso discreto, $\forall $ $\mathbf{x}\in S_{\mathbf{X}}$ $\mathbf{E}%
\left( \mathbf{Y|X=x}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\mathbf{y}Q\left( \mathbf{x},d\mathbf{y}\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\mathbf{y}f_{\mathbf{Y|X}}\left( \mathbf{y|x}\right) d\mathbf{y}$,
mentre $\mathbf{E}\left( h\left( \mathbf{Y}\right) |\mathbf{X=x}\right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}h\left( \mathbf{y}\right) f_{\mathbf{Y|X}}\left( \mathbf{y|x}\right) d%
\mathbf{y}$.

\textbf{Prop 20.3 (densit\`{a} congiunta da densit\`{a} condizionale)}%
\begin{gather*}
\text{Hp: }\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ ve. a., }\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\text{ v. a. assolutamente } \\
\text{continuo con densit\`{a} }f_{\mathbf{X}}\text{, }P^{\mathbf{Y|X}%
}\left( d\mathbf{y|x}\right) \text{ ha densit\`{a} }f_{\mathbf{Y|X}}\left( 
\mathbf{y|x}\right) \text{ }\forall \text{ }\mathbf{x}\in S_{\mathbf{X}} \\
\text{Ts: }\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) \text{ \`{e} assolutamente continuo con densit\`{a} } \\
f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) =\left\{ 
\begin{array}{c}
f_{\mathbf{X}}\left( \mathbf{x}\right) f_{\mathbf{Y|X}}\left( \mathbf{y|x}%
\right) \text{ }\forall \text{ }\left( \mathbf{x,y}\right) \in S_{\mathbf{X}%
}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n} \\ 
0\text{ altrove}%
\end{array}%
\right.
\end{gather*}

Nel caso particolare in cui $\mathbf{X\perp Y}$ si ottiene, come gi\`{a}
visto, che $f_{\left( \mathbf{X,Y}\right) }\left( \mathbf{x,y}\right) =f_{%
\mathbf{X}}\left( \mathbf{x}\right) f_{\mathbf{Y}}\left( \mathbf{y}\right) $%
. Questo permette di assegnare una densit\`{a} congiunta avendo stabilito
quella condizionale!

\begin{description}
\item[5] \textbf{Vettore misto} Sia $\mathbf{X}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$ una ve. a. discreto con supporto $S_{\mathbf{X}}$ e densit\`{a}
discreta $p_{\mathbf{X}}$ e $\mathbf{Y}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ un vettore aleatorio qualsiasi. Suppongo inoltre che $\mathbf{P}\left( 
\mathbf{Y}\in B|\mathbf{X=x}\right) $, fissato $\mathbf{x}$, sia una
probabilit\`{a} assolutamente continua, cio\`{e} $\exists $ $f_{\left( 
\mathbf{Y|X}\right) }^{\ast }\left( \mathbf{y|x}\right) :\mathbf{P}\left( 
\mathbf{Y}\in B|\mathbf{X=x}\right) =\int_{B}f_{\left( \mathbf{Y|X}\right)
}^{\ast }\left( \mathbf{y|x}\right) d\mathbf{y}$ $\forall $ $\mathbf{x}\in
S_{\mathbf{X}}$. Pongo allora $f_{\mathbf{Y|X}}\left( \mathbf{y|x}\right)
=\left\{ 
\begin{array}{c}
f_{\mathbf{Y|X}}^{\ast }\left( \mathbf{y|x}\right) \text{\textbf{\ } se }%
\mathbf{x}\in S_{\mathbf{X}} \\ 
\tilde{f}\left( \mathbf{y}\right) \text{ se }\mathbf{x}\not\in S_{\mathbf{X}}%
\end{array}%
\right. $, dove $\tilde{f}:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} una qualsiasi densit\`{a} continua, e definisco $Q\left( \mathbf{x}%
,B\right) =\int_{B}f_{\mathbf{Y|X}}\left( \mathbf{y|x}\right) d\mathbf{y}$,
che si pu\`{o} dimostrare essere effettivamente una legge condizionale (come
abbiamo fatto prima). Le propriet\`{a} 1 e 2 si dimostrano in modo identico
al caso assolutamente continuo. Devo poi mostrare che $\forall $ $A\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}\right) ,\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ vale $\mathbf{P}\left( X\in A,Y\in B\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}}I_{A}\left( x\right) Q\left( x,B\right) dP^{X}\left( x\right) $.
Essendo $X$ discreta, per la formula di disintegrazione il lato sinistro 
\`{e} $\mathbf{P}\left( X\in A,Y\in B\right) =\sum_{k\in A\cap S_{X}}\mathbf{%
P}\left( X=k,Y\in B\right) $. $\mathbf{P}\left( X=k,Y\in B\right) =\mathbf{P}%
\left( Y\in B|X=k\right) \mathbf{P}\left( X=k\right) =\left(
\int_{B}f_{\left( Y|X\right) }^{\ast }\left( y|k\right) dy\right)
P^{X}\left( k\right) $, quindi il lato sinistro \`{e} $\sum_{k\in A\cap
S_{X}}P^{X}\left( k\right) \int_{B}f_{\left( Y|X\right) }^{\ast }\left(
y|k\right) dy$; poich\'{e} la somma \`{e} fatta per $k\in A\cap S_{X}$, vale 
$\sum_{k\in A\cap S_{X}}P^{X}\left( k\right) \int_{B}f_{\left( Y|X\right)
}^{\ast }\left( y|k\right) dy=\sum_{k\in A\cap S_{X}}P^{X}\left( k\right)
\int_{B}f_{\left( Y|X\right) }\left( y|k\right) dy$. Il lato destro \`{e} $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}}I_{A}\left( x\right) Q\left( x,B\right) dP^{X}\left( x\right)
=\int_{A}Q\left( x,B\right) dP^{X}\left( x\right) $, che per la regola del
valore atteso per le v. a. discrete \`{e} uguale a $\sum_{x\in A\cap
S_{X}}Q\left( x,B\right) P^{X}\left( x\right) $. Quindi effettivamente lato
sinistro e destro coincidono e $\mathbf{P}\left( X\in A,Y\in B\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}}I_{A}\left( x\right) Q\left( x,B\right) dP^{X}\left( x\right) $.

\item Se in particolare $A=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k}$, si ottiene $\mathbf{P}\left( \mathbf{X}\in A,\mathbf{Y}\in B\right) =%
\mathbf{P}\left( Y\in B\right) =\sum_{\mathbf{k}\in S_{\mathbf{X}}}P^{%
\mathbf{X}}\left( k\right) \int_{B}f_{\left( \mathbf{Y|X}\right) }\left( 
\mathbf{y|k}\right) d\mathbf{y=}\int_{B}\sum_{\mathbf{k}\in S_{\mathbf{X}%
}}P^{\mathbf{X}}\left( k\right) f_{\left( \mathbf{Y|X}\right) }\left( 
\mathbf{y|k}\right) d\mathbf{y}$: dunque $\mathbf{Y}$ \`{e} assolutamente
continuo con densit\`{a} $f_{\mathbf{Y}}\left( \mathbf{y}\right) =\sum_{%
\mathbf{x}\in S_{\mathbf{X}}}p_{\mathbf{X}}\left( \mathbf{x}\right) f_{%
\mathbf{Y|X}}\left( \mathbf{y|x}\right) $ $\forall $ $\mathbf{y}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ (si sta usando una formula di disintegrazione).

\item[6] \textbf{Vettore gaussiano} Sia $\left( 
\begin{array}{c}
X \\ 
Y%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
\mu _{X} \\ 
\mu _{Y}%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
\sigma _{X}^{2} & \rho \sigma _{X}\sigma _{Y} \\ 
\rho \sigma _{X}\sigma _{Y} & \sigma _{Y}^{2}%
\end{array}%
\right] \right) $ un vettore gaussiano bidimensionale, dove $\sigma
_{X}=\left\vert \sqrt{\sigma _{X}^{2}}\right\vert $ (deviazione standard).
Cerco $P^{Y|X}\left( dy|x\right) $.

\item Se $\sigma _{X}^{2}=0$, $X\sim \delta _{\mathbf{\mu }_{X}}$ e $X\perp
Y $ per ogni $Y$ (una costante \`{e} indipendente da qualsiasi v. a.),
quindi si ricade nel caso 1 e $P^{Y|X}\left( dy|x\right) $ \`{e} $\mathcal{N}%
\left( \mu _{Y},\sigma _{Y}^{2}\right) $. Il caso di $\sigma _{X}^{2}\neq 0$ 
\`{e} affrontato nella seguente proposizione.
\end{description}

\textbf{Prop 21.1 (legge condizionale di un vettore gaussiano)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( 
\begin{array}{c}
X \\ 
Y%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
\mu _{X} \\ 
\mu _{Y}%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
\sigma _{X}^{2} & \rho \sigma _{X}\sigma _{Y} \\ 
\rho \sigma _{X}\sigma _{Y} & \sigma _{Y}^{2}%
\end{array}%
\right] \right) \text{, }\sigma _{X}^{2}>0 \\
\text{Ts}\text{: } &&P^{Y|X}\left( dy|x\right) \sim \mathcal{N}\left(
m\left( x\right) ,q^{2}\right) \text{, con }m\left( x\right) =\mu _{Y}+\rho 
\frac{\sigma _{Y}}{\sigma _{X}}\left( x-\mu _{X}\right) \text{ e }%
q^{2}=\sigma _{Y}^{2}\left( 1-\rho ^{2}\right)
\end{eqnarray*}

Si ha quindi $m\left( x\right) =\mathbf{E}\left(
Y|X=x\right) =\mu _{Y}+\rho \frac{\sigma _{Y}}{\sigma _{X}}\left( x-\mu
_{X}\right) $, mentre $q^{2}=var\left( Y|X=x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( y-m\left( x\right) \right) ^{2}P^{Y|X}\left( dy|x\right) =\sigma
_{Y}^{2}\left( 1-\rho ^{2}\right) $ \`{e} la varianza di $Y$ condizionata.
Se $\sigma _{Y}^{2}=0$, $X\perp Y$ e si ricade nel primo caso visto: $%
P^{Y|X}\left( dy|x\right) \sim \mathcal{N}\left( \mu _{Y},\sigma
_{Y}^{2}\right) $. Se $\rho ^{2}=1$ c'\`{e} una relazione lineare affine e
quindi deterministica tra $X$ e $Y$: si ha ancora $q^{2}=0$, per cui $%
Y|X=x\sim \delta _{m\left( x\right) }$, cio\`{e} $Y$ condizionata giace
sempre sulla retta di regressione, quindi l'interpolazione \`{e} perfetta. $%
q^{2}$, pur funzione di $x$ in teoria, \`{e} costante.

\textbf{Dim*} Se $\sigma _{Y}^{2}=0$, $Y=\mu _{Y}$ q. c. e quindi $X\perp Y$%
: si ricade nel primo caso visto e $P^{Y|X}\left( dy|x\right) \sim
P^{Y}\left( dy|x\right) =P^{Y}\left( y\right) =\mathcal{N}\left( \mu
_{Y},0\right) $.

Se $\rho ^{2}=1$, per 15.6 $Y=aX+b$ con $a=\rho \frac{\sigma _{Y}}{\sigma
_{X}},b=\mu _{Y}-\mu _{X}\rho \frac{\sigma _{X}}{\sigma _{Y}}$, quindi si
ricade nel secondo caso e $P^{Y|X}\left( dy|x\right) \sim \delta _{ax+b}$,
cio\`{e} $\mathcal{N}\left( m\left( x\right) ,0\right) $, con $m\left(
x\right) =ax+b=\rho \frac{\sigma _{Y}}{\sigma _{X}}x+\mu _{Y}-\mu _{X}\rho 
\frac{\sigma _{X}}{\sigma _{Y}}$.

Se invece $\det C=\left( 1-\rho ^{2}\right) \sigma _{X}^{2}\sigma _{Y}^{2}>0$%
, il vettore \`{e} assolutamente continuo e si ottiene $P^{Y|X}$ dal caso 4
affrontato sopra. E' noto che $f_{\left( X,Y\right) }\left( x,y\right) =%
\frac{1}{2\pi \sqrt{\left( 1-\rho ^{2}\right) \sigma _{X}^{2}\sigma _{Y}^{2}}%
}e^{-\frac{1}{2\left( 1-\rho ^{2}\right) }\left( \frac{\left( x-\mu
_{X}\right) ^{2}}{\sigma _{X}^{2}}-2\rho \frac{\left( x-\mu _{X}\right)
\left( y-\mu _{Y}\right) }{\sigma _{X}\sigma _{Y}}+\frac{\left( y-\mu
_{Y}\right) ^{2}}{\sigma _{Y}^{2}}\right) }$, per cui si \`{e} nel caso
assolutamente continuo e la densit\`{a} condizionale \`{e} $\frac{f_{\left(
X,Y\right) }\left( x,y\right) }{f_{X}\left( x\right) }=\frac{1}{\sqrt{2\pi
\left( 1-\rho ^{2}\right) \sigma _{Y}^{2}}}e^{-\frac{1}{2\left( 1-\rho
^{2}\right) }\left( \frac{\left( x-\mu _{X}\right) ^{2}}{\sigma _{X}^{2}}%
-2\rho \frac{\left( x-\mu _{X}\right) \left( y-\mu _{Y}\right) }{\sigma
_{X}\sigma _{Y}}+\frac{\left( y-\mu _{Y}\right) ^{2}}{\sigma _{Y}^{2}}%
\right) -\frac{1}{2\sigma _{X}^{2}}\left( x-\mu _{X}\right) ^{2}}$.
L'esponente \`{e} $-\frac{1}{2\left( 1-\rho ^{2}\right) }\left( \frac{\left(
x-\mu _{X}\right) ^{2}}{\sigma _{X}^{2}}-2\rho \frac{\left( x-\mu
_{X}\right) \left( y-\mu _{Y}\right) }{\sigma _{X}\sigma _{Y}}+\frac{\left(
y-\mu _{Y}\right) ^{2}}{\sigma _{Y}^{2}}\right) -\frac{1}{2\sigma _{X}^{2}}%
\left( x-\mu _{X}\right) ^{2}=-\frac{1}{2\sigma _{Y}^{2}\left( 1-\rho
^{2}\right) }\left( x-\left( \mu _{Y}+\rho \frac{\sigma _{Y}}{\sigma _{X}}%
\left( x-\mu _{X}\right) \right) \right) ^{2}$, per cui la densit\`{a}
condizionale coincide con $\frac{1}{\sqrt{2\pi \left( 1-\rho ^{2}\right)
\sigma _{Y}^{2}}}e^{-\frac{1}{2\sigma _{Y}^{2}\left( 1-\rho ^{2}\right) }%
\left( x-\left( \mu _{Y}+\rho \frac{\sigma _{Y}}{\sigma _{X}}\left( x-\mu
_{X}\right) \right) \right) ^{2}}$. $\blacksquare $

Si affronta lo stesso problema per due vettori aleatori generici.

\textbf{Prop 21.1 (legge condizionale di un vettore gaussiano)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) :\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{k+n}\text{, }\left( 
\begin{array}{c}
\mathbf{X} \\ 
\mathbf{Y}%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
\mathbf{\mu }_{\mathbf{X}} \\ 
\mathbf{\mu }_{\mathbf{Y}}%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
C_{\mathbf{X}} & C_{\mathbf{XY}} \\ 
C_{\mathbf{YX}} & C_{\mathbf{Y}}%
\end{array}%
\right] \right) \text{, }\det C_{\mathbf{X}}>0 \\
\text{Ts}\text{: } &&P^{\mathbf{Y|X}}\left( d\mathbf{y|x}\right) \sim 
\mathcal{N}\left( \mathbf{m}\left( \mathbf{x}\right) ,Q\right) \text{, con }%
\mathbf{m}\left( \mathbf{x}\right) =\mathbf{\mu }_{Y}+C_{\mathbf{YX}}C_{%
\mathbf{X}}^{-1}\left( \mathbf{x-\mu }_{\mathbf{X}}\right) \text{ e }Q=C_{%
\mathbf{Y}}-C_{\mathbf{YX}}C_{\mathbf{X}}^{-1}C_{\mathbf{XY}}
\end{eqnarray*}

Nelle ipotesi si ha $\left[ 
\begin{array}{cc}
C_{\mathbf{X}} & C_{\mathbf{XY}} \\ 
C_{\mathbf{YX}} & C_{\mathbf{Y}}%
\end{array}%
\right] \in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( n+k,n+k\right) $ e $C_{\mathbf{YX}}=C_{\mathbf{XY}}$, dato che la
matrice di covarianza dev'essere simmetrica.

\subsection{Attese condizionate}

Voglio studiare $\mathbf{E}\left( Y|X=x\right) $ al variare di $x$,
ragionando a priori e non pi\`{u} in medias res.

Considero $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, $\left( E,\mathcal{E}\right) $ spazio misurabile, $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n},\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) \right) $, $X:\Omega \rightarrow E$ v. a., $Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ v. a. limitata, quindi tale che $\exists $ $M>0:\left\vert \left\vert
Y\left( \omega \right) \right\vert \right\vert \leq M$ $\forall $ $\omega
\in \Omega $. Si richiede che $F=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ perch\'{e} in tal caso, per 20.2, $\exists $ $!$ $Q\left( x,B\right) $%
. La richiesta di limitatezza \`{e} pi\`{u} forte che richiedere che $Y$ sia
finita, cio\`{e} che $\mathbf{P}\left( Y=+\infty \right) =0$: infatti se $%
\left\vert \left\vert Y\left( \omega \right) \right\vert \right\vert \leq M$ 
$\forall $ $\omega \in \Omega $, $\mathbf{P}\left( Y=+\infty \right) =0=%
\mathbf{P}\left( \bigcap_{n=1}^{+\infty }\left( Y\geq n\right) \right) =0$
perch\'{e} per $n=M+1$ si ha un evento di probabilit\`{a} nulla, ma esistono
v. a. non limitate e q. c. finite. La limitatezza implica che $Y\in
L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, quindi $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}yP^{Y|X}\left( dy|x\right) $ esiste finito per la regola del valore atteso;
invece con $Y$ finita potremmo avere valore atteso infinito.

In base a quanto visto finora, se $n=1$ e si fissa a $x$ il valore di $X$, $%
\mathbf{E}\left( Y|X=x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}yP^{Y|X}\left( dy|x\right) $, che si sceglie di indicare con $m\left(
x\right) $, $m:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, che \`{e} una funzione di $x$ misurabile rispetto a $\mathcal{E}$ (si
dimostra facilmente perch\'{e} $P^{Y|X}\left( dy|x\right) $ \`{e} $\mathcal{E%
}$-misurabile). In realt\`{a}, dato che si conosce il valore di $X\left(
\omega \right) $, ma non tutto il risultato dell'esperimento, $m\left(
x\right) $ pu\`{o} anche essere vista come $m\left( X\left( \omega \right)
\right) $, con $m\circ X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, e ha il significato di valore centrale assunto da $Y$ conoscendo il
valore di $X$, $\mathbf{E}\left( Y|X=X\left( \omega \right) \right) $. $%
m\left( X\left( \omega \right) \right) $ \`{e} composizione di funzioni
misurabili e quindi $\mathcal{A}$-misurabile: $m\left( X\right) $ \`{e} una
variabile aleatoria detta attesa condizionata, o valore atteso condizionale,
di $Y$ data $X$.

\begin{enumerate}
\item Considero l'esperimento gi\`{a} visto del dado e della moneta: $D\sim 
\mathcal{U}\left( \left\{ 1,...,6\right\} \right) $, $T$ numero di teste
uscite nei lanci della moneta, $p_{T|D}\left( \cdot |d\right) =bin\left( d,%
\frac{1}{2}\right) $, con $d\in \left\{ 1,.....,6\right\} $. Calcolo $%
\mathbf{E}\left( T|D\right) $. $\mathbf{E}\left( T|D=d\right) =\frac{1}{2}d$%
, per cui $\mathbf{E}\left( T|D\right) =\frac{D}{2}$, in accordo con
l'intuizione secondo cui, se si sono fatti $D$ lanci, il numero di teste 
\`{e} circa la met\`{a}.
\end{enumerate}

Se si conosce $X\left( \omega \right) $, \`{e} noto anche se si sono
realizzati tutti gli eventi $A$ che possono essere scritti tramite $X$, cio%
\`{e} tali che $\exists $ $B\in \mathcal{E}:A=\left( X\in B\right) $.
L'insieme $\left\{ \left( X\in B\right) :B\in \mathcal{E}\right\} $ \`{e}
detto insieme degli eventi generati da $X$ e si indica con $\sigma \left(
X\right) $; si \`{e} gi\`{a} dimostrato che \`{e} una $\sigma $-algebra su $%
\Omega $. Essendo $X$ misurabile rispetto a $\mathcal{A}$, $\sigma \left(
X\right) \subseteq \mathcal{A}$, ed \`{e} quindi detta sotto $\sigma $%
-algebra di $\mathcal{A}$; si dimostra che $\sigma \left( X\right) $ \`{e}
la pi\`{u} piccola $\sigma $-algebra su $\Omega $ rispetto a cui $X$ \`{e}
misurabile. $\sigma \left( X\right) $ rappresenta l'informazione "rivelata"
da $X$, cio\`{e} l'insieme degli eventi su cui si sa tutto se si conosce il
valore di $X$.

$X$ \`{e} $\mathcal{A}$-misurabile sse $\sigma \left( X\right) \subseteq 
\mathcal{A}$.

\begin{enumerate}
\item Sia $\left( \left\{ 0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
},\mathcal{A},\mathbf{P}\right) $ lo spazio di Bernoulli, $%
X_{k}:\Omega \rightarrow \left\{ 0,1\right\} $, $X_{k}\left( \omega \right)
=\omega _{k}$. Allora, dato $k=3$, $\sigma \left( X_{3}\right) =\left\{
A\subseteq \Omega :A=X^{-1}\left( B\right) ,B\in \left\{ \varnothing
,\left\{ 0,1\right\} ,\left\{ 0\right\} ,\left\{ 1\right\} \right\} \right\} 
$. Sapendo che $X_{3}=1$, so anche che se si sono verificati gli eventi $%
\left( X_{3}>0\right) $ (si \`{e} verificato), $\left( X_{3}<\frac{1}{2}%
\right) $ (non si \`{e} verificato), mentre non ho informazioni sull'evento $%
\left( X_{1}=0\right) $, che non appartiene a $\sigma \left( X_{3}\right)
=\left\{ \Omega ,\varnothing ,X_{3}^{-1}\left( \left\{ 1\right\} \right)
,X_{3}^{-1}\left( \left\{ 0\right\} \right) \right\} $.
\end{enumerate}

\textbf{Lemma 21.2 (lemma di misurabilit\`{a} di Doob)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
spazio di probabilit\`{a}, }X:\Omega \rightarrow E,V:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ v. a.} \\
\text{Ts}\text{: } &&V\text{ \`{e} }\sigma \left( X\right) \text{-misurabile 
}\Longleftrightarrow \exists \text{ }h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\text{ misurabile}:V=h\left( X\right)
\end{eqnarray*}

Il senso del lemma \`{e} che, affinch\'{e} ogni controimmagine di $B\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ attraverso $V$ appartenga a $\sigma \left( X\right) $, $B$
deve poter essere scritto come evento generato da $X$ ($\sigma \left(
V\right) \subseteq \sigma \left( X\right) $), e questo \`{e} possibile per
ogni $B$ se e solo se $V=h\left( X\right) $.

\textbf{Dim} Se $\exists $ $h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$ misurabile $:V=h\left( X\right) $, allora $\forall $ $B\in \mathcal{B}%
\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}\right) $ $V^{-1}\left( B\right) =X^{-1}\left( h^{-1}\left( B\right)
\right) \in \sigma \left( X\right) $ perch\'{e} ovviamente $X$ \`{e} $\sigma
\left( X\right) $-misurabile.

Sia $V$ $\sigma \left( X\right) $-misurabile e semplice. Suppongo $%
V=a_{1}I_{A_{1}}+...+a_{N}I_{A_{N}}$: essendo $\sigma \left( X\right) $%
-misurabile, $A_{1},...,A_{N}\in \sigma \left( X\right) $ e $\exists $ $%
B_{1},...,B_{N}:A_{1}=X^{-1}\left( B_{1}\right) ,...,A_{N}=X^{-1}\left(
B_{N}\right) $, per cui $h\left( x\right) =a_{1}I_{B_{1}}\left( x\right)
+...+a_{N}I_{B_{N}}\left( x\right) $ d\`{a} la tesi.

Sia $V$ nonnegativa: esiste una successione $V_{n}$ di v. a. semplici e $%
\sigma \left( X\right) $-misurabili che cresce a $V$; per ciascuna di esse $%
\exists $ $h_{n}:V_{n}=h_{n}\left( X\right) $. Allora $\forall $ $\omega $ $%
\lim_{n\rightarrow +\infty }V_{n}\left( \omega \right) =V\left( \omega
\right) =\lim_{n\rightarrow +\infty }h_{n}\left( X\left( \omega \right)
\right) =h\left( X\left( \omega \right) \right) $: poich\'{e} $h\left(
x\right) =\lim_{n\rightarrow +\infty }h_{n}\left( x\right) $ \`{e}
misurabile per i criteri di misurabilit\`{a}, vale $V=h\left( X\right) $. $%
\blacksquare $

Segue da tale lemma che $\mathbf{E}\left( Y|X\right) =m\left( X\right) =Z$ 
\`{e} $\sigma \left( X\right) $-misurabile.

La triplice notazione per il valore atteso condizionale evidenzia
rispettivamente il significato modellistico relativo alla probabilit\`{a}
condizionata, l'essere una funzione di $X$, l'essere una variabile aleatoria.

\textbf{Prop 21.3 }%
\begin{gather*}
\text{Hp}\text{: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio
di probabilit\`{a}, }\left( E,\mathcal{E}\right) \text{ spazio misurabile, }
\\
X:\Omega \rightarrow E\text{ v. a., }Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. limitata, }Z=m\left( X\right) =\mathbf{E}\left( Y|X\right) \\
\text{Ts}\text{: }Z\text{ \`{e} l'unica (a meno di eventi trascurabili) v.
a. reale } \\
\sigma \left( X\right) \text{-misurabile tale che }\forall \text{ }A\in
\sigma \left( X\right) \text{ }\int_{A}Yd\mathbf{P}=\int_{A}Zd\mathbf{P}
\end{gather*}

Nel caso di $A=\Omega $ $\int_{\Omega }Yd\mathbf{P}=\mathbf{E}\left(
Y\right) =\int_{\Omega }\mathbf{E}\left( Y|X\right) d\mathbf{P=E}\left( 
\mathbf{E}\left( Y|X\right) \right) =\mathbf{E}\left( Z\right) $: questo 
\`{e} dovuto al fatto che $Z$ \`{e} il valore atteso di $Y$ condizionato a
un certo valore di $X$, che per\`{o} non \`{e} noto a priori e quindi varia
su tutto il supporto di $X$ senza fornire informazioni aggiuntive. Quindi $%
\mathbf{E}\left( Y\right) $ pu\`{o} essere ottenuto con una prima
"centratura" condizionata a $X$, che non d\`{a} nuova informazioni, e una
seconda centratura: da questo si evince che $\mathbf{E}\left( Y|X\right) $
dipende solo da $\sigma \left( X\right) $. $\int_{A}Yd\mathbf{P}=\int_{A}Zd%
\mathbf{P}$, se $Y$ e $Z$ fossero in $L^{2}$, verrebbe da $\left\langle
X,Y\right\rangle =\left\langle X,\Pi Y\right\rangle $ con $X=I_{A}$.

La tesi pu\`{o} essere scritta equivalentemente come $\mathbf{E}\left(
I_{A}Y\right) =\mathbf{E}\left( I_{A}Z\right) =\mathbf{E}\left( I_{A}\mathbf{%
E}\left( Y|X\right) \right) $. Il senso della proposizione \`{e} che se $A$ 
\`{e} un evento generato da $X$, nel calcolare l'integrale ristretto ad $A$
si possiede gi\`{a} tutta l'informazione rivelata da $X$, e si pu\`{o}
quindi calcolare $\mathbf{E}\left( I_{A}Y\right) $ invece che $\mathbf{E}%
\left( I_{A}\mathbf{E}\left( Y|X\right) \right) $.

Da $\mathbf{E}\left( Y\right) =\mathbf{E}\left( \mathbf{E}\left( Y|X\right)
\right) $ si deduce che, se $X$ \`{e} discreta, per la regola del valore
atteso $\mathbf{E}\left( Y\right) =\int_{\Omega }\mathbf{E}\left( Y|X\right)
d\mathbf{P}\left( \omega \right) =\int_{E}\mathbf{E}\left( Y|x\right)
dP^{X}\left( x\right) =\sum_{x\in S_{X}}\mathbf{E}\left( Y|x\right)
p_{X}\left( x\right) $ (!); se $X$ \`{e} assolutamente continua, $\mathbf{E}%
\left( Y\right) =\int_{\Omega }\mathbf{E}\left( Y|X\right) d\mathbf{P}\left(
\omega \right) =\int_{E}\mathbf{E}\left( Y|x\right) dP^{X}\left( x\right)
=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}}\mathbf{E}\left( Y|x\right) f_{X}\left( x\right) dx$.

Nella tesi non compare direttamente $X$, ma solo $\sigma \left( X\right) $.
Questo significa che se due v. a. generano la stessa $\sigma $-algebra
avranno la stessa attesa condizionata: e. g. se $h\left( X\right) $ \`{e}
biunivoca e bimisurabile (cio\`{e} misurabile e con inversa misurabile),
allora $\sigma \left( h\left( X\right) \right) =\sigma \left( X\right) $
(non cambia l'informazione rivelata) e $\mathbf{E}\left( Y|h\left( X\right)
\right) =\mathbf{E}\left( Y|X\right) $.

\begin{enumerate}
\item Sia $h\left( X\right) =X^{3}$. Allora $\sigma \left( X^{3}\right)
=\sigma \left( X\right) $, per cui $\mathbf{E}\left( Y|X\right) =\mathbf{E}%
\left( Y|X^{3}\right) $.
\end{enumerate}

Quindi la tesi, che racchiude il significato fondamentale di $Z$, pu\`{o}
essere usata come definizione alternativa di attesa condizionata - cosa
conveniente perch\'{e} \`{e} indipendente dalla legge condizionale - per una
generica $\sigma $-algebra.

Data $\mathcal{A}$ $\sigma $-algebra su $\Omega $, si indica con $\mathcal{%
G\subseteq A}$ una generica sotto $\sigma $-algebra di $\mathcal{A}$. Finora
si \`{e} considerata $\mathcal{G}=\sigma \left( X\right) $.

\textbf{Def 21.4} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria tale che $Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{%
P}\right) $, $\mathcal{G\subseteq A}$ sotto $\sigma $-algebra di $\mathcal{A}
$, si dice attesa condizionale di $Y$ data $\mathcal{G}$, e si indica con $%
\mathbf{E}\left( Y|\mathcal{G}\right) $, una variabile aleatoria $Z:\Omega
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ tale che

\begin{description}
\item[C1] $Z\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $

\item[C2] $Z$ \`{e} $\mathcal{G}$-misurabile

\item[C3] $\forall $ $G\in \mathcal{G}$ $\int_{G}Zd\mathbf{P=}\int_{G}Yd%
\mathbf{P}$
\end{description}

Modellisticamente parlando, $\mathbf{E}\left( Y|\mathcal{G}\right) $
rappresenta la modifica di $\mathbf{E}\left( Y\right) $ in base alle nuove
informazioni ottenute in medias res, che sono il verificarsi o meno degli
eventi di $\mathcal{G}$. C2 significa che $\forall $ $B\in \mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ $Z^{-1}\left( B\right) \in \mathcal{G\varsubsetneq A}$. C3 pu\`{o}
essere espressa equivalentemente dicendo che $\mathbf{E}\left( I_{G}Y\right)
=\mathbf{E}\left( I_{G}Z\right) $, con $I_{G}=I_{G}\left( \omega \right) $. $%
Z$ esprime come cambia $Y$ sapendo se si sono verificati o no tutti gli
eventi di $\mathcal{G}$. Si noti che in generale $\mathbf{E}\left( Y|%
\mathcal{G}\right) \neq Y$, se $Y$ non \`{e} $\mathcal{G}$-misurabile.

Se $\mathbf{Y}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{n}$, $\mathbf{E}\left( \mathbf{Y}|\mathcal{G}\right) $ \`{e} definita come 
$\left( 
\begin{array}{c}
\mathbf{E}\left( Y_{1}|\mathcal{G}\right) \\ 
... \\ 
\mathbf{E}\left( Y_{n}|\mathcal{G}\right)%
\end{array}%
\right) $.

C3 \`{e} equivalente alla condizione C3' $\forall $ $W$ $\mathcal{G}$%
-misurabile e limitata vale $\int_{\Omega }ZWd\mathbf{P=}\int_{\Omega }YWd%
\mathbf{P}$, cio\`{e} $\mathbf{E}\left( WZ\right) =\mathbf{E}\left(
WY\right) $. Infatti, se vale C3', nel caso particolare di $W=I_{G}$ con $%
G\in \mathcal{G}$ si ha $\int_{G}Zd\mathbf{P=}\int_{G}Yd\mathbf{P}$. Mostro
il contrario: suppongo che valga C3, cio\`{e} $\forall $ $G\in \mathcal{G}$ $%
\mathbf{E}\left( I_{G}Y\right) =\mathbf{E}\left( I_{G}Z\right) $. Suppongo $%
W $ sia $\mathcal{G}$-misurabile e semplice, per cui $%
W=w_{1}I_{A_{1}}+...+w_{N}I_{A_{N}}$. Allora per linearit\`{a} $\mathbf{E}%
\left( WY\right) =\mathbf{E}\left( \left(
w_{1}I_{A_{1}}+...+w_{N}I_{A_{N}}\right) Y\right) =w_{1}\mathbf{E}\left(
I_{A_{1}}Y\right) +...+w_{N}\mathbf{E}\left( I_{A_{N}}Y\right) $ coincide
con $\mathbf{E}\left( WZ\right) $. Sia ora $W$ $\mathcal{G}$-misurabile
limitata non negativa: esiste una successione $W_{n}$ di v. a. semplici che
la approssima, per le quali vale $\mathbf{E}\left( W_{n}Z\right) =\mathbf{E}%
\left( W_{n}Y\right) $. Allora $\left\vert W_{n}Z\right\vert \leq LZ$, che 
\`{e} integrabile, e $W_{n}Z$ converge a $WZ$, per cui $\lim_{n\rightarrow
+\infty }\mathbf{E}\left( W_{n}Z\right) =\mathbf{E}\left( WZ\right) $; ma
d'altro canto, per motivi analoghi $\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( W_{n}Y\right) =\mathbf{E}\left( WY\right) $, per cui $\mathbf{E}%
\left( WZ\right) =\mathbf{E}\left( WY\right) $.

Si pu\`{o} dimostrare che nelle ipotesi della definizione esiste $Z$;
inoltre vale il seguente teorema.

\textbf{Teo 21.5 (unicit\`{a} quasi certa dell'attesa condizionata a una
sotto }$\sigma $\textbf{-algebra)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a., }Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{,%
} \\
\text{ }\mathcal{G\subseteq A}\text{ sotto }\sigma \text{-algebra di }%
\mathcal{A} \\
\text{Ts: }\exists \text{ }!Z\text{ che soddisfa 21.4}
\end{gather*}

Vale quindi l'unicit\`{a} dell'attesa condizionale a una sotto $\sigma $%
-algebra, a meno di identit\`{a} quasi certa: se $Z,\tilde{Z}$ attese
condizionali di $Y$ data $\mathcal{G}$, $Z=\tilde{Z}$ quasi certamente. In
realt\`{a} quindi si indica con $\mathbf{E}\left( Y|\mathcal{G}\right) $ una
classe di equivalenza di v. a.

Se $\mathcal{G}=\sigma \left( X\right) $, $\mathbf{E}\left( Y|\sigma \left(
X\right) \right) $ coincide con $m\left( X\right) $ definita sopra, che \`{e}
infatti integrabile, $\sigma \left( X\right) $-misurabile (perch\'{e} uguale
a $m\left( X\right) $, per il lemma di Doob), e ha la propriet\`{a} C3 per
la 21.3.

Non esiste una ricetta standard per trovare $Z=\mathbf{E}\left( Y|\mathcal{G}%
\right) $; tuttavia la 21.5 fa s\`{\i} che se seguendo l'intuito si trova
una $Z$ che soddisfa le tre propriet\`{a}, allora quella \`{e} l'attesa
condizionale.

\begin{enumerate}
\item Sia $X\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $%
\mathcal{G}=\sigma \left( X\right) $, $Y=X$. Per quanto visto sopra $Z=%
\mathbf{E}\left( Y|\sigma \left( X\right) \right) $ si indica in tal caso
con $\mathbf{E}\left( X|X\right) $. Intuitivamente, \`{e} ragionevole che $%
\mathbf{E}\left( X|X\right) =X$. Ovviamente $X\in L^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $, \`{e} $\sigma \left( X\right) $-misurabile
perch\'{e} $\sigma \left( X\right) $ \`{e} la pi\`{u} piccola $\sigma $%
-algebra su $\mathcal{A}$ che renda $X$ misurabile, e vale ovviamente $%
\forall $ $G\in \sigma \left( X\right) $ $\int_{G}Xd\mathbf{P=}\int_{G}Xd%
\mathbf{P}$.

\item Sia $X$ gaussiana di parametri $\mu ,\sigma ^{2}$ con $\sigma ^{2}>0$. 
$\mathbf{E}\left( X|X^{2}\right) =\mathbf{E}\left( X|\sigma \left(
X^{2}\right) \right) $. $h\left( X\right) =X^{2}$ non \`{e} biunivoca,
quindi non soddisfa le ipotesi su $h$ che servono per afferma $\mathbf{E}%
\left( X|X^{2}\right) =\mathbf{E}\left( X|X\right) $: infatti $X^{2}$ rivela
meno informazione di $X$, $\sigma \left( X^{2}\right) \varsubsetneq \sigma
\left( X\right) $. Per trovare $\mathbf{E}\left( X|X^{2}\right) $ si pu\`{o}
ragionare intuitivamente sul fatto che data $X^{2}$ i valori possibili sono $%
-X$ e $X$, il cui "centro" \`{e} $0$ perch\'{e} la densit\`{a} normale \`{e}
simmetrica. Rigorosamente, si vuole imporre $\mathbf{E}\left( I_{G}Z\right) =%
\mathbf{E}\left( I_{G}X\right) $, dove $G\in \sigma \left( X^{2}\right) $ 
\`{e} sempre della forma $G=\left( X^{2}\in B\right) $. Vale $\mathbf{E}%
\left( I_{G}X\right) =\mathbf{E}\left( I_{\left( X^{2}\in B\right) }X\right)
=\mathbf{E}\left( I_{B}\left( X^{2}\right) X\right) =\int_{-\infty
}^{+\infty }I_{B}\left( x^{2}\right) x\frac{1}{\sqrt{2\pi \sigma ^{2}}}e^{-%
\frac{1}{2\sigma ^{2}}\left( x-\mu \right) ^{2}}dx=0$ $\forall $ $B$ perch%
\'{e} la funzione integranda \`{e} integrabile in senso improprio e dispari.
Allora la variabile aleatoria $Z=0$ soddisfa C1, C2, C3, quindi per unicit%
\`{a} $\mathbf{E}\left( X|X^{2}\right) =0$.
\end{enumerate}

\textbf{Teo 22.1 (propriet\`{a} dell'attesa condizionata)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ variabile aleatoria,} \\
Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }\mathcal{%
G\subseteq A}\text{ sotto }\sigma \text{-algebra di }\mathcal{A} \\
\text{Ts: (1) }\mathbf{E}\left( \cdot |\mathcal{G}\right) :L^{1}\left(
\Omega ,\mathcal{A},\mathbf{P}\right) \rightarrow L^{1}\left( \Omega ,%
\mathcal{G},\mathbf{P}\right) \text{ \`{e} una mappa lineare positiva} \\
\text{(2) }\mathbf{E}\left( \mathbf{E}\left( Y|\mathcal{G}\right) \right) =%
\mathbf{E}\left( Y\right) \\
\text{(3) se }Y\text{ \`{e} }\mathcal{G}\text{-misurabile }\mathbf{E}\left(
Y|\mathcal{G}\right) =Y\text{ q. c.} \\
\text{(4) se }Y\perp \mathcal{G}\text{ allora }\mathbf{E}\left( Y|\mathcal{G}%
\right) =\mathbf{E}\left( Y\right) \text{ q. c.} \\
\text{(5) se }\mathcal{H\subseteq G\subseteq A}\text{ \`{e} una sotto-sotto }%
\sigma \text{-algebra, }\mathbf{E}\left( Y|\mathcal{H}\right) =\mathbf{E}%
\left( \mathbf{E}\left( Y|\mathcal{G}\right) |\mathcal{H}\right) \text{ q. c.%
} \\
\text{(6) se }W\text{ \`{e} }\mathcal{G}\text{-misurabile e }WY\in
L^{1}\left( \mathcal{A}\right) \text{, allora }\mathbf{E}\left( WY|\mathcal{G%
}\right) =W\mathbf{E}\left( Y|\mathcal{G}\right) \text{ q. c. } \\
\text{(7) se }Y_{1}=Y_{2}\text{ q. c., allora }\mathbf{E}\left( Y_{1}|%
\mathcal{G}\right) =\mathbf{E}\left( Y_{2}|\mathcal{G}\right) \text{ q. c.}
\\
\text{(8) se }Y_{n}\geq 0\text{ }\forall \text{ }n\text{, }Y_{n}\nearrow Y%
\text{ q. c., allora }\mathbf{E}\left( Y_{n}|\mathcal{G}\right) \nearrow 
\mathbf{E}\left( Y|\mathcal{G}\right) \text{ q. c.} \\
\text{(9) se }\left\vert Y_{n}\right\vert \leq V\in L^{1}\text{ }\forall 
\text{ }n\text{, }Y_{n}\rightarrow Y\text{ q. c., allora }\mathbf{E}\left(
Y_{n}|\mathcal{G}\right) \rightarrow \mathbf{E}\left( Y|\mathcal{G}\right) 
\text{ q. c.} \\
\text{(10) se }Y\in L^{p}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{%
, allora }\mathbf{E}\left( Y|\mathcal{G}\right) \in L^{p}\left( \Omega ,%
\mathcal{G},\mathbf{P}\right) \\
\text{(11) se }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} boreliana, }h\left( Y\right) \in L^{1}\text{, }\mathcal{G}%
=\sigma \left( X\right) \text{, allora }\mathbf{E}\left( h\left( Y\right) |%
\mathcal{G}\right) =n\left( X\right) \\
\text{con }n\left( X\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( y\right) P^{Y|X}\left( dy|x\right)
\end{gather*}

(1) significa che $\forall $ $Y_{1},Y_{2}\in L^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $, $\forall $ $a,b\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, vale $\mathbf{E}\left( aY_{1}+bY_{2}|\mathcal{G}\right) =a\mathbf{E}%
\left( Y_{1}|\mathcal{G}\right) +b\mathbf{E}\left( Y_{2}|\mathcal{G}\right) $%
, e che $\forall $ $Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $%
, se $Y\geq 0$ $\mathbf{E}\left( Y|\mathcal{G}\right) \geq 0$ q. c.
(ottenere delle informazioni su $Y$ non cambia il fatto che $\mathbf{E}%
\left( Y\right) \geq 0$, poich\'{e} $Y\geq 0$). In (2) \`{e} fondamentale
l'ipotesi $Y\in L^{1}$. (3) \`{e} sensata perch\'{e} sapere se si sono
verificati o no tutti gli eventi di $\mathcal{G}$ permette di sapere se si
sono verificati tutti gli eventi generati da $Y$, e quindi di conoscere il
valore esatto di $Y$: tutta l'informazione presente in $\mathcal{G}$ rivela
anche $Y$. In questo la proiezione produce la migliore approssimazione
possibile. In (4) $Y\perp \mathcal{G}$ significa che $\sigma \left( Y\right)
\perp \mathcal{G}$, cio\`{e} per $\forall $ $A\in \sigma \left( Y\right)
,B\in \mathcal{G}$ vale $A\perp B$. E' una sorta di ortogonalit\`{a}:
ottengo la peggiore approssimazione possibile, se ho informazioni slegate da 
$Y$ e che quindi non sono di alcuna utilit\`{a}. (5) \`{e} detta propriet%
\`{a} di inscatolamento. (6) discende da (3): $\mathbf{E}\left( W|\mathcal{G}%
\right) =W$ q. c. (8) \`{e} il teorema di convergenza monotona. (9) \`{e}
quello di convergenza dominata. In (11) $h\left( Y\right) \in L^{1}$ serve
per poter parlare di $\mathbf{E}\left( Y|\mathcal{G}\right) $. Si capisce
che $n\left( X\right) $ \`{e} un'estensione di $m\left( X\right) $, per cui
la nuova definizione di attesa condizionale \`{e} effettivamente
un'estensione; coerenza.

Una conseguenza del teorema \`{e} che se considero $\mathcal{G=}\left\{
\varnothing ,\Omega \right\} $ $\sigma $-algebra banale, allora $Y$ \`{e}
indipendente da $\mathcal{G}$ e per 22.1 (4) vale $\mathbf{E}\left( Y|%
\mathcal{G}\right) =\mathbf{E}\left( Y\right) $.

\textbf{Dim*} (1) mostro che $\forall $ $Y_{1},Y_{2}\in L^{1}\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $ e $\forall $ $a,b\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\mathbf{E}\left( aY_{1}+bY_{2}|\mathcal{G}\right) =a\mathbf{E}\left(
Y_{1}|\mathcal{G}\right) +b\mathbf{E}\left( Y_{2}|\mathcal{G}\right) $. $a%
\mathbf{E}\left( Y_{1}|\mathcal{G}\right) +b\mathbf{E}\left( Y_{2}|\mathcal{G%
}\right) $ \`{e} in $L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
perch\'{e} lo \`{e} ogni addendo; \`{e} $\mathcal{G}$-misurabile perch\'{e}
lo \`{e} ogni addendo. Inoltre $\forall $ $G\in \mathcal{G}$ $\int_{G}\left(
aY_{1}+bY_{2}\right) d\mathbf{P}=\int_{G}\left( a\mathbf{E}\left( Y_{1}|%
\mathcal{G}\right) +b\mathbf{E}\left( Y_{2}|\mathcal{G}\right) \right) d%
\mathbf{P}$ perch\'{e} per linearit\`{a} dell'integrale $\int_{G}\left(
aY_{1}+bY_{2}\right) d\mathbf{P=}a\int_{G}Y_{1}d\mathbf{P+}b\int_{G}Y_{2}d%
\mathbf{P=}a\int_{G}\mathbf{E}\left( Y_{1}|\mathcal{G}\right) d\mathbf{P}%
+\int_{G}b\mathbf{E}\left( Y_{2}|\mathcal{G}\right) d\mathbf{P=}%
\int_{G}\left( a\mathbf{E}\left( Y_{1}|\mathcal{G}\right) +b\mathbf{E}\left(
Y_{2}|\mathcal{G}\right) \right) d\mathbf{P}$.

Se $Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e $Y\geq 0$
allora $\mathbf{E}\left( Y|\mathcal{G}\right) \geq 0$ q. c. Infatti per la
terza propriet\`{a} $\forall $ $G\in \mathcal{G}$ $\int_{G}Yd\mathbf{P}%
=\int_{G}\mathbf{E}\left( Y|\mathcal{G}\right) d\mathbf{P}$, ma se $Y\geq 0$%
, per positivit\`{a} del valore atteso $\int_{G}Yd\mathbf{P}\geq 0$ e di
conseguenza $\int_{G}\mathbf{E}\left( Y|\mathcal{G}\right) d\mathbf{P}\geq 0$
q. c.

(2) E' noto $\mathbf{E}\left( I_{G}Y\right) =\mathbf{E}\left( I_{G}Z\right) $
$\forall $ $G\in \mathcal{G}$: se si considera in particolare $G=\Omega $,
si ha $\mathbf{E}\left( Y\right) =\mathbf{E}\left( Z\right) $.

(3) Se $Y$ \`{e} $\mathcal{G}$-misurabile, poich\'{e} per ipotesi $Y\in
L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ e banalmente $\mathbf{E}%
\left( I_{G}Y\right) =\mathbf{E}\left( I_{G}Y\right) $ $\forall $ $G\in 
\mathcal{G}$, $Y$ soddisfa le tre propriet\`{a} richieste all'attesa
condizionata, per cui, per unicit\`{a} - a meno di identit\`{a} quasi certa
- dell'attesa condizionata, $Z=Y$.

(4) Se $Z=\mathbf{E}\left( Y\right) $ e $\forall $ $G\in \mathcal{G}$, $%
\forall $ $B\in \sigma \left( Y\right) $ $\mathbf{P}\left( BG\right) =%
\mathbf{P}\left( B\right) \mathbf{P}\left( G\right) $, le v. a. $Y$ e $I_{G}$
sono indipendenti. Vale allora $\mathbf{E}\left( I_{G}Y\right) =\mathbf{E}%
\left( I_{G}Z\right) $ $\forall $ $G\in \mathcal{G}$, perch\'{e} si ha $%
\mathbf{E}\left( I_{G}Y\right) =\mathbf{E}\left( Y\right) \mathbf{E}\left(
I_{G}\right) =\mathbf{E}\left( I_{G}\mathbf{E}\left( Y\right) \right) $ $%
\forall $ $G\in \mathcal{G}$, dato che il valore atteso per v. a.
indipendenti si fattorizza. $\blacksquare $

Abbiamo visto il significato di $\mathbf{E}\left( Y|\mathcal{G}\right) $ se $%
Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $: \`{e} il valore
atteso di $Y$ acquisita l'informazione $\mathcal{G}$. Se per\`{o} $Y\in
L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, dell'attesa
condizionata si pu\`{o} dare un'ulteriore interpretazione, dovuta al fatto
che $L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ \`{e} uno spazio di
Hilbert: essa ha infatti un'importante propriet\`{a} di ottimizzazione.

\textbf{Prop 22.2 (propriet\`{a} di minimo dell'attesa condizionata)}%
\begin{eqnarray*}
\text{Hp} &\text{: }&\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
spazio di probabilit\`{a}, }Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a., } \\
Y &\in &L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }\mathcal{%
G\subseteq A}\text{ sotto }\sigma \text{-algebra di }\mathcal{A} \\
\text{Ts} &\text{: }&\min_{V\in L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}%
\right) }\mathbf{E}\left( \left( Y-V\right) ^{2}\right) =\mathbf{E}\left(
\left( Y-\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}\right)
\end{eqnarray*}

Il significato della tesi \`{e} che $\mathbf{E}\left( Y|\mathcal{G}\right) $ 
\`{e} la proiezione di $Y$ sul sottospazio vettoriale, e spazio di Hilbert, $%
L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}\right) $, cio\`{e} l'attesa
condizionata a $\mathcal{G}$ \`{e} la migliore approssimazione di $Y$
tramite una variabile aleatoria che \`{e} solo $\mathcal{G}$-misurabile (il
senso di questo \`{e} che se in medias res si conosce $\mathcal{G}$, allora
si conosce anche tale v.a.). Infatti $\mathbf{E}\left( \left( Y-V\right)
^{2}\right) $, in quanto norma al quadrato di $Y-V$ (e quindi distanza al
quadrato tra $Y$ e $V$), rappresenta la bont\`{a} dell'approssimazione di $Y$
operata da $V$. Si sarebbe quindi potuta dare la definizione di attesa
condizionata meno in generale, per $Y\in L^{2}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $, e dal fatto che $\mathbf{E}\left( Y|\mathcal{G}\right)
:=\Pi _{L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}\right) }\left( Y\right) $
si sarebbero dedotte tutte le propriet\`{a} gi\`{a} viste pi\`{u} in
generale.

$Y\in L^{2}$ implica $\mathbf{E}\left( Y|\mathcal{G}\right) \in L^{2}$ per
22.1 (10), quindi il lato destro \`{e} ben posto. L'ipotesi implica peraltro
che $Y\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, per cui $%
\mathbf{E}\left( Y|\mathcal{G}\right) $ esiste ed \`{e} unico.

\textbf{Dim} Sia $Z=\mathbf{E}\left( Y|\mathcal{G}\right) $. $\mathbf{E}%
\left( \left( Y-V\right) ^{2}\right) =\mathbf{E}\left( \left( Y-Z+Z-V\right)
^{2}\right) =\mathbf{E}\left( \left( Y-Z\right) ^{2}\right) +\mathbf{E}%
\left( \left( Z-V\right) ^{2}\right) +2\mathbf{E}\left( \left( Z-V\right)
\left( Y-Z\right) \right) $ $=\mathbf{E}\left( \left( Y-\mathbf{E}\left( Y|%
\mathcal{G}\right) \right) ^{2}\right) +I_{2}+I_{1}$. $\frac{1}{2}I_{1}=%
\mathbf{E}\left( \left( Z-V\right) \left( Y-Z\right) \right) =\mathbf{E}%
\left( \mathbf{E}\left( \left( Z-V\right) \left( Y-Z\right) |\mathcal{G}%
\right) \right) $ per 22.1 (3). Ma $Z-V$ \`{e} $\mathcal{G}$-misurabile perch%
\'{e} $V$ lo \`{e} per ipotesi e $Z$ lo \`{e} per costruzione, inoltre $%
\left( Z-V\right) \left( Y-Z\right) \in L^{1}\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) $ perch\'{e} ognuna delle due v. a. \`{e} in $L^{2}$ ($%
Z\in L^{2}$ perch\'{e} $Y\in L^{2}$), quindi per 22.1 (6) vale $\mathbf{E}%
\left( \left( Z-V\right) \left( Y-Z\right) |\mathcal{G}\right) =\left(
Z-V\right) \mathbf{E}\left( Y-Z|\mathcal{G}\right) $. Per linearit\`{a} e
22.1 (3) $\mathbf{E}\left( Y-Z|\mathcal{G}\right) =\mathbf{E}\left( Y|%
\mathcal{G}\right) -\mathbf{E}\left( Z|\mathcal{G}\right) =\mathbf{E}\left(
Y|\mathcal{G}\right) -Z=0$ q. c., quindi $I_{1}=0$.

Inoltre $I_{2}\geq 0$ per positivit\`{a} del valore atteso. Ne segue che $%
\mathbf{E}\left( \left( Y-V\right) ^{2}\right) =\mathbf{E}\left( \left( Y-%
\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}\right) +I_{2}\geq \mathbf{%
E}\left( \left( Y-\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}\right) $
$\forall $ $V\in L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}\right) $, da cui
la tesi. L'uguaglianza vale se $V=Z$. $\blacksquare $

Per le propriet\`{a} della proiezione, vale inoltre $Y-\mathbf{E}\left( Y|%
\mathcal{G}\right) \in \left( L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}%
\right) \right) ^{\perp }$, cio\`{e} $\left\langle Y-\mathbf{E}\left( Y|%
\mathcal{G}\right) ,W\right\rangle _{L^{2}\left( \Omega ,\mathcal{G},\mathbf{%
P}\right) }=0$ $\forall $ $W\in L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}%
\right) $. Da questo segue in particolare $\left\langle Y,W\right\rangle
_{L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}\right) }=\int_{\Omega }YWd%
\mathbf{P}\left( \omega \right) =\left\langle \mathbf{E}\left( Y|\mathcal{G}%
\right) ,W\right\rangle _{L^{2}\left( \Omega ,\mathcal{G},\mathbf{P}\right)
}=\int_{\Omega }\mathbf{E}\left( Y|\mathcal{G}\right) Wd\mathbf{P}\left(
\omega \right) $. Se scelgo $W=I_{G}$, ritrovo la propriet\`{a} 3 richiesta
in 21.4.

\subsection{Varianza condizionata}

Date $X:\left( \Omega ,\mathcal{A},\mathbf{P}\right) \rightarrow \left( E,%
\mathcal{E}\right) $, $Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., suppongo che esista $P^{Y|X}\left( dy|x\right) $. Allora $%
var\left( Y|X=x\right) $ pu\`{o} essere banalmente vista come $\mathbf{E}%
\left( h\left( Y\right) |X=x\right) $ con $h\left( Y\right) =\left(
Y-m\left( Y\right) \right) ^{2}$, che \`{e} gi\`{a} stato definito, per cui $%
var\left( Y|X=x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( y-m\left( x\right) \right) ^{2}P^{Y|X}\left( dy|x\right) $, che
scegliamo di indicare con $q^{2}:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. $q^{2}$ \`{e} $\mathcal{E}$-misurabile. Se si pone $x=X\left( \omega
\right) $, si ottiene $q^{2}\left( X\left( \omega \right) \right) $, che 
\`{e} una v. a. $q^{2}\circ X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ detta varianza di $Y$ data $X$ e indicata con $var\left( Y|X\right) $.
Come visto per l'attesa condizionata, la definizione pu\`{o} essere estesa
alla varianza condizionata a una sotto $\sigma $-algebra generica e non $%
\sigma \left( X\right) $.

\textbf{Def 22.3} Data $Y\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $ e $\mathcal{G\subseteq A}$ sotto $\sigma $-algebra di $\mathcal{A}$%
, si dice varianza condizionale di $Y$ dato $\mathcal{G}$, e si indica con $%
var\left( Y|\mathcal{G}\right) $, la variabile aleatoria $\mathbf{E}\left(
\left( Y-\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}|\mathcal{G}%
\right) $.

$var\left( Y|\mathcal{G}\right) $ \`{e} ben definita perch\'{e} $Y\in L^{2}$
implica $Y^{2}\in L^{1}$ e $\mathbf{E}\left( Y|\mathcal{G}\right) \in L^{2}$
per 22.1 (10), per cui $\left( Y-\mathbf{E}\left( Y|\mathcal{G}\right)
\right) ^{2}\in L^{1}$ ed esiste la sua attesa condizionata.

\textbf{Teo (propriet\`{a} della varianza condizionata)}%
\begin{gather*}
\text{Hp: }Y\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ e }%
\mathcal{G\subseteq A}\text{ sotto }\sigma \text{-algebra di }\mathcal{A} \\
\text{Ts: (1) }var\left( Y|\mathcal{G}\right) \geq 0 \\
\text{(2) }var\left( Y|\mathcal{G}\right) =\mathbf{E}\left( Y^{2}|\mathcal{G}%
\right) -\mathbf{E}^{2}\left( Y|\mathcal{G}\right) \text{ q. c.} \\
\text{(3) }\mathbf{E}\left( var\left( Y|\mathcal{G}\right) \right) =\mathbf{E%
}\left( \left( Y-\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}\right) \\
\text{(4) se }\mathcal{G}=\sigma \left( X\right) \text{, }var\left( Y|\sigma
\left( X\right) \right) =q\left( X\right) \text{ definita sopra} \\
\text{(5) }var\left( Y\right) =var\left( \mathbf{E}\left( Y|\mathcal{G}%
\right) \right) +\mathbf{E}\left( var\left( Y|\mathcal{G}\right) \right)
\end{gather*}

(4) mostra la coerenza con quanto fatto inizialmente. (5) \`{e} detta
formula di scomposizione della varianza.

\textbf{Dim} (1) $var\left( Y|\mathcal{G}\right) =\mathbf{E}\left[ \left( Y-%
\mathbf{E}\left( Y|\mathcal{G}\right) \right) ^{2}|\mathcal{G}\right] \geq 0$
per la positivit\`{a} dell'attesa condizionata, in 22.1 (1).

(2) $var\left( Y|\mathcal{G}\right) =\mathbf{E}\left[ \left( Y-Z\right) ^{2}|%
\mathcal{G}\right] $. $\left( Y-Z\right) ^{2}=Y^{2}+\mathbf{E}^{2}\left( Y|%
\mathcal{G}\right) -2YZ$: $\mathbf{E}\left[ \left( Y^{2}+Z^{2}-2YZ\right) |%
\mathcal{G}\right] =\mathbf{E}\left[ Y^{2}|\mathcal{G}\right] +\mathbf{E}%
\left[ Z^{2}|\mathcal{G}\right] -2\mathbf{E}\left[ YZ|\mathcal{G}\right] $. $%
\mathbf{E}\left[ Z^{2}|\mathcal{G}\right] =Z^{2}$ (per 22.1 (3) e (6)), $%
\mathbf{E}\left[ YZ|\mathcal{G}\right] =Z\mathbf{E}\left[ Y|\mathcal{G}%
\right] =Z^{2}$ per 22.1 (6), quindi si ottiene $var\left( Y|\mathcal{G}%
\right) =\mathbf{E}\left[ Y^{2}|\mathcal{G}\right] -Z^{2}$.

(3) Per definizione $\mathbf{E}\left( var\left( Y|\mathcal{G}\right) \right)
=\mathbf{E}\left( \mathbf{E}\left( \left( Y-\mathbf{E}\left( Y|\mathcal{G}%
\right) \right) ^{2}|\mathcal{G}\right) \right) $. Per 22.1 (2) $\mathbf{E}%
\left( \mathbf{E}\left( \left( Y-\mathbf{E}\left( Y|\mathcal{G}\right)
\right) ^{2}|\mathcal{G}\right) \right) =\mathbf{E}\left( \left( Y-\mathbf{E}%
\left( Y|\mathcal{G}\right) \right) ^{2}\right) $.

(5) Sia $Z=\mathbf{E}\left( Y|\mathcal{G}\right) $. $var\left( Y\right) =%
\mathbf{E}\left( \left( Y-\mathbf{E}\left( Y\right) \right) ^{2}\right) $, $%
\mathbf{E}\left( var\left( Y|\mathcal{G}\right) \right) =\mathbf{E}\left[ 
\mathbf{E}\left( \left( Y-Z\right) ^{2}|\mathcal{G}\right) \right] $, $%
var\left( Z\right) =\mathbf{E}\left( \left( Z-\mathbf{E}\left( Z\right)
\right) ^{2}\right) $. Con lo stesso trucco di prima, $\mathbf{E}\left(
\left( Y-\mathbf{E}\left( Y\right) \right) ^{2}\right) =\mathbf{E}\left(
\left( Y-Z\right) ^{2}\right) +\mathbf{E}\left( \left( Z-\mathbf{E}\left(
Y\right) \right) ^{2}\right) +2\mathbf{E}\left( \left( Z-\mathbf{E}\left(
Y\right) \right) \left( Y-Z\right) \right) =I_{1}+I_{2}+I_{3}$. $2I_{3}=%
\mathbf{E}\left( \mathbf{E}\left[ \left( Z-\mathbf{E}\left( Y\right) \right)
\left( Y-Z\right) |\mathcal{G}\right] \right) $. Per quanto visto prima $%
\mathbf{E}\left[ \left( Z-\mathbf{E}\left( Y\right) \right) \left(
Y-Z\right) |\mathcal{G}\right] =\left( Z-\mathbf{E}\left( Y\right) \right) 
\mathbf{E}\left( Y-Z|\mathcal{G}\right) $, quindi si ottiene $2I_{3}=\mathbf{%
E}\left[ \left( Z-\mathbf{E}\left( Y\right) \right) \mathbf{E}\left( Y-Z|%
\mathcal{G}\right) \right] $: applicando di nuovo 22.1 (6) si ha $\left( Z-%
\mathbf{E}\left( Y\right) \right) \mathbf{E}\left[ \mathbf{E}\left( \left(
Y-Z\right) |\mathcal{G}\right) \right] $, che \`{e} nulla perch\'{e} $%
\mathbf{E}\left( \left( Y-Z\right) |\mathcal{G}\right) =0$, come visto
sopra. Si ha quindi $\mathbf{E}\left( \left( Y-\mathbf{E}\left( Y\right)
\right) ^{2}\right) =\mathbf{E}\left( \left( Y-Z\right) ^{2}\right) +\mathbf{%
E}\left( \left( Z-\mathbf{E}\left( Y\right) \right) ^{2}\right) $, ma $%
\mathbf{E}\left( Y\right) =\mathbf{E}\left( Z\right) $, quindi vale la tesi,
viste le uguaglianze iniziali. $\blacksquare $

Per la formula di decomposizione, dato che ogni varianza \`{e} nonnegativa, $%
var\left( Y\right) \geq var\left( \mathbf{E}\left( Y|\mathcal{G}\right)
\right) $: la dispersione dell'attesa condizionata \`{e} inferiore alla
dispersione di $Y$, dato che si sta considerando la proiezione su uno spazio
pi\`{u} piccolo; a livello modellistico, avendo acquisito nuove
informazioni, la varianza deve diminuire. Il caso estremo si ha se $Y\perp 
\mathcal{G}$: $\mathbf{E}\left( Y|\mathcal{G}\right) $ \`{e} la costante $%
\mathbf{E}\left( Y\right) $ e ha quindi varianza nulla.

Vale d'altronde $var\left( Y\right) =\mathbf{E}\left( \left( Y-\mathbf{E}%
\left( Y\right) \right) ^{2}\right) \geq \mathbf{E}\left( var\left( Y|%
\mathcal{G}\right) \right) =\mathbf{E}\left( \left( Y-\mathbf{E}\left( Y|%
\mathcal{G}\right) \right) ^{2}\right) $. Questo ribadisce la propriet\`{a}
di minimo dell'attesa condizionata, confrontandola in particolare con $%
\mathbf{E}\left( Y\right) $, che - essendo costante - \`{e} una v. a. $%
\mathcal{G}$-misurabile: l'attesa condizionata \`{e} un'approssimazione di $%
Y $ migliore rispetto al valore atteso.

\begin{enumerate}
\item $D\sim \mathcal{U}\left( \left\{ 1,...,6\right\} \right) $, $T|D=d\sim
bin\left( d,\frac{1}{2}\right) $, con $d\in \left\{ 1,...,6\right\} $.
Verifico la formula di decomposizione della varianza: $var\left( T\right)
=var\left( \mathbf{E}\left( T|D\right) \right) +\mathbf{E}\left( var\left(
T|D\right) \right) $, per (5) nel caso particolare di $\mathcal{G}=\sigma
\left( D\right) $. $\mathbf{E}\left( T|D=d\right) =\frac{d}{2}$ perch\'{e} 
\`{e} il valore atteso di una binomiale, quindi $\mathbf{E}\left( T|D\right)
=\frac{D}{2}$; analogamente $var\left( T|D=d\right) =\frac{d}{4}$ e $%
var\left( T|D\right) =\frac{D}{4}$. Allora $var\left( T\right) =var\left( 
\frac{D}{2}\right) +\mathbf{E}\left( \frac{D}{4}\right) =\frac{1}{4}\frac{35%
}{12}+\frac{1}{4}\frac{7}{2}=\allowbreak \frac{77}{48}$.

\item $\left( 
\begin{array}{c}
X \\ 
Y%
\end{array}%
\right) \sim N\left( \left( 
\begin{array}{c}
\mu _{X} \\ 
\mu _{Y}%
\end{array}%
\right) ,\left[ 
\begin{array}{cc}
\sigma _{X}^{2} & \rho \sigma _{X}\sigma _{Y} \\ 
\rho \sigma _{X}\sigma _{Y} & \sigma _{Y}^{2}%
\end{array}%
\right] \right) $. E' noto che $\mathbf{E}\left( Y|X=x\right) =\mu _{Y}+\rho 
\frac{\sigma _{Y}}{\sigma _{X}}\left( x-\mu _{X}\right) $, mentre $var\left(
Y|X=x\right) =\sigma _{Y}^{2}\left( 1-\rho ^{2}\right) $. Vale
effettivamente la formula di decomposizione della varianza, perch\'{e} $%
var\left( \mathbf{E}\left( Y|X\right) \right) +\mathbf{E}\left( var\left(
Y|X\right) \right) =var\left( \mu _{Y}+\rho \frac{\sigma _{Y}}{\sigma _{X}}%
\left( X-\mu _{X}\right) \right) +\mathbf{E}\left( \sigma _{Y}^{2}\left(
1-\rho ^{2}\right) \right) =\rho ^{2}\frac{\sigma _{Y}^{2}}{\sigma _{X}^{2}}%
var\left( X\right) +\sigma _{Y}^{2}\left( 1-\rho ^{2}\right) =\sigma
_{Y}^{2} $.
\end{enumerate}

\section{Convergenza di successioni di variabili aleatorie}

Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di probabilit%
\`{a}, sia $\left( X_{n}\right) _{n\geq 1}$ una successione di variabili
aleatorie, con $X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$. E' possibile dare diverse definizioni di convergenza di
tale successione a un'altra variabile aleatoria $X$ per $n\rightarrow
+\infty $. Scegliamo come codominio $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, che \`{e} uno spazio metrico particolarmente semplice.

\textbf{Def 23.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( X_{n}\right) _{n\geq 1}$ successione di
v. a. con $X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., si dice che $X_{n}$ converge a $X$ certamente, e si scrive $%
X_{n}\rightarrow _{n\rightarrow +\infty }X$, se $\forall $ $\omega \in
\Omega $ $\lim_{n\rightarrow +\infty }X_{n}\left( \omega \right) =X\left(
\omega \right) $.

[per v. a. non reali dovremmo metrizzare $E$]

Fissato $\omega $, $X_{n}\left( \omega \right) $ \`{e} una successione
numerica; la convergenza certa coincide con la convergenza puntuale vista in
analisi. Tuttavia in probabilit\`{a} la convergenza certa \`{e} una
richiesta troppo forte nella maggior parte dei casi, che non cattura il
significato modellistico della convergenza di variabili aleatorie: il fatto
che un piccolo insieme di sperimentatori non osservi lo stesso fenomeno
degli altri (cio\`{e} che per alcuni $\omega $ non valga $\lim_{n\rightarrow
+\infty }X_{n}\left( \omega \right) =X\left( \omega \right) $) non \`{e}
rilevante.

\begin{enumerate}
\item Considero lo spazio di Bernoulli, con $\Omega =\left\{ 0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}$, che rappresenti ad esempio il lancio ripetuto di una moneta. Siano $%
X_{1},...,X_{n}\sim iidb\left( \frac{1}{2}\right) $ le v. a. che valgono $1$
se \`{e} uscita testa all'i-esimo lancio. Ogni $\omega \in \Omega $ \`{e} un
risultato dell'esperimento, cio\`{e} una successione di Bernoulli, e si pu%
\`{o} considerare svolto da un certo sperimentatore. Ci si aspetta che la
media campionaria di tali v. a. sia tale che $\lim_{n\rightarrow +\infty }%
\frac{X_{1}+...+X_{n}}{n}=\frac{1}{2}$. Tuttavia, in $\Omega $ esiste anche $%
\bar{\omega}=\left( 1,1,...\right) $, per la quale $\lim_{n\rightarrow
+\infty }\frac{X_{1}\left( \bar{\omega}\right) +...+X_{n}\left( \bar{\omega}%
\right) }{n}=1$; oppure $\tilde{\omega}=\left( 0,0,...\right) $, per la
quale $\lim_{n\rightarrow +\infty }\frac{X_{1}\left( \tilde{\omega}\right)
+...+X_{n}\left( \tilde{\omega}\right) }{n}=0$: non \`{e} quindi vero che $%
\frac{X_{1}+...+X_{n}}{n}$ converge puntualmente a $\frac{1}{2}$. Vedremo
che la convergenza \`{e} detta quasi certa, cio\`{e} il numero di
sperimentatori per cui non vale $\lim_{n\rightarrow +\infty }\frac{%
X_{1}+...+X_{n}}{n}=\frac{1}{2}$ \`{e} trascurabile.
\end{enumerate}

\textbf{Def 23.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( X_{n}\right) _{n\geq 1}$ successione di
v. a. con $X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., si dice che $X_{n}$ converge a $X$ quasi certamente, e si scrive $%
X_{n}\rightarrow _{n\rightarrow +\infty }X$ q. c., se $A=\left\{ \omega \in
\Omega :\lim_{n\rightarrow +\infty }X_{n}\left( \omega \right) =X\left(
\omega \right) \right\} $ \`{e} tale che $\mathbf{P}\left( A\right) =1$.

$A\in \mathcal{A}$ perch\'{e} $\lim_{n\rightarrow +\infty }X_{n}$ \`{e} una
v. a. (vedi criteri di misurabilit\`{a}), per cui $\mathbf{P}\left( A\right) 
$ \`{e} ben definita. La convergenza quasi certa si \`{e} gi\`{a} vista come
ipotesi nei teoremi di convergenza monotona e dominata. Il significato
modellistico \`{e} che quasi ogni sperimentatore osserva lo stesso fenomeno.
Evidentemente, se $X_{n}$ converge a $X$ certamente, allora $X_{n}$ converge
a $X$ quasi certamente, perch\'{e} $A=\Omega $; non vale il viceversa.

Per ogni $\omega $ fissato l'insieme dei valori di $X_{n}\left( \omega
\right) $, al variare di $n$, \`{e} detta traiettoria.

\begin{enumerate}
\item Sia $X$ reale, per cui $\mathbf{P}\left( X<+\infty \right) =1$.
Definisco $X_{n}\left( \omega \right) =\frac{X\left( \omega \right) }{n}$: $%
X_{n}\rightarrow 0$ certamente.

\item Considero $X\geq 0$ e le $X_{n}$ usate per dare la definizione di
valore atteso: $X_{n}\rightarrow X$ certamente per costruzione.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathcal{U}\left( \left( 0,1\right) \right) \right) $, sia $%
X_{n}\left( \omega \right) =I_{\left[ 0,\frac{1}{n}\right] }\left( \omega
\right) $. Per $\omega \in \left[ 0,1\right] ^{c}$ evidentemente $%
\lim_{n\rightarrow +\infty }X_{n}\left( \omega \right) =0$. Fissato $\omega
\in (0,1]$, vale $\omega >\frac{1}{n}$ definitivamente per $n\rightarrow
+\infty $, per cui $X_{n}\rightarrow 0$ $\forall $ $\omega \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash \left\{ 0\right\} $. Invece $\lim_{n\rightarrow +\infty
}X_{n}\left( 0\right) =1$. Dunque $X_{n}\rightarrow 0$ quasi certamente,
essendo $A=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash \left\{ 0\right\} :\mathbf{P}\left( A\right) =1$.

\item Dato $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathcal{U}\left( \left( 0,1\right) \right) \right) $, sia $%
X_{n}\left( \omega \right) =nI_{\left[ 0,\frac{1}{n}\right] }\left( \omega
\right) $. Per $\omega \in \left[ 0,1\right] ^{c}$ $\lim_{n\rightarrow
+\infty }X_{n}\left( \omega \right) =0$. Fissato $\omega \in (0,1]$, vale $%
\omega >\frac{1}{n}$ definitivamente per $n\rightarrow +\infty $, per cui $%
X_{n}\rightarrow 0$ $\forall $ $\omega \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash \left\{ 0\right\} $. Invece $\lim_{n\rightarrow +\infty
}X_{n}\left( 0\right) =+\infty $. Dunque $X_{n}\rightarrow 0$ quasi
certamente, essendo $A=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash \left\{ 0\right\} :\mathbf{P}\left( A\right) =1$.

\item Se $\left( Y_{n}\right) _{n\geq 1}$ \`{e} una successione di v.a. tale
che $\forall $ $\omega \in \Omega $ $Y_{n}\left( \omega \right) $ \`{e}
crescente e superiormente limitata (e. g. data $\left( X_{n}\right) _{n\geq
1}$, $Y_{n}=\max \left\{ X_{1},...,X_{n}\right\} $), allora $\forall $ $%
\omega $ la successione reale $\left( Y_{n}\left( \omega \right) \right)
_{n\geq 1}$ converge a $\sup_{n}\left\{ Y_{n}\left( \omega \right) \right\} $%
, quindi $Y_{n}\left( \omega \right) $ converge q. c. alla variabile
aleatoria $\sup_{n}Y_{n}$. Quindi, qualora sia noto che $Y_{n}\rightarrow ^{%
\mathbf{P}}Y$ in probabilit\`{a}, sicuramente $Y_{n}\rightarrow Y$ q. c. per
unicit\`{a} del limite in probabilit\`{a}. Questo si applica analogamente
per successioni decrescenti e inferiormente limitate.
\end{enumerate}

\textbf{Teo 23.3 (propriet\`{a} della convergenza quasi certa)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1},\left( Y_{n}\right) _{n\geq
1}\text{ successioni di v.a., }X_{n},Y_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\forall \text{ }n\text{, }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a, }a\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ continua, }X_{n}\rightarrow X\text{ q. c., }Y_{n}\rightarrow Y\text{
q. c.} \\
\text{Ts: (1) }aX_{n}\rightarrow aX\text{ q. c., }aY_{n}\rightarrow aY\text{
q. c.} \\
\text{(2) se }X_{n}\rightarrow X\text{ q. c. e }X_{n}\rightarrow \tilde{X}%
\text{ q. c., }X=\tilde{X}\text{ q. c.} \\
\text{(3) }h\left( X_{n}\right) \rightarrow h\left( X\right) \text{ q. c.} \\
\text{(4) }X_{n}+Y_{n}\rightarrow X+Y\text{ q. c.} \\
\text{(5) }X_{n}Y_{n}\rightarrow XY\text{ q. c.} \\
\text{(6) }\frac{X_{n}}{Y_{n}}\rightarrow \frac{X}{Y}\text{ q. c. se }%
Y_{n},Y\neq 0
\end{gather*}

(2) significa che il limite quasi certo \`{e} unico a meno di identit\`{a}
quasi certa. (1) \`{e} un sottocaso di (3).

\textbf{Dim} (1) \`{e} una conseguenza delle propriet\`{a} dei limiti di
successioni.

(2) Per definizione, $A_{1}=\left\{ \omega \in \Omega :\lim_{n\rightarrow
+\infty }X_{n}\left( \omega \right) =X\left( \omega \right) \right\} $ e $%
A_{2}=\left\{ \omega \in \Omega :\lim_{n\rightarrow +\infty }X_{n}\left(
\omega \right) =\tilde{X}\left( \omega \right) \right\} $ sono tali che $%
\mathbf{P}\left( A_{1}\right) =\mathbf{P}\left( A_{2}\right) =1$. Poich\'{e} 
$A_{1}\cap A_{2}\neq \varnothing $, considero $\omega \in A_{1}\cap A_{2}$:
per tale $\omega $ vale $X\left( \omega \right) =\tilde{X}\left( \omega
\right) $ per unicit\`{a} del limite di successioni reali. Allora considero $%
\left\{ \omega \in \Omega :X\left( \omega \right) =\tilde{X}\left( \omega
\right) \right\} \supseteq A_{1}\cap A_{2}$: $\mathbf{P}\left( A_{1}\cap
A_{2}\right) =\mathbf{P}\left( A_{1}\right) +\mathbf{P}\left( A_{2}\right) -%
\mathbf{P}\left( A_{1}\cup A_{2}\right) =2-1=1$, per cui $\mathbf{P}\left(
\left\{ \omega \in \Omega :X\left( \omega \right) =\tilde{X}\left( \omega
\right) \right\} \right) =1$ e $X=\tilde{X}$ q. c.

(3) deriva dalla continuit\`{a} di $h$.

(4),(5),(6) si dimostrano come (2), usando anche le propriet\`{a} dei limiti
di successioni. $\blacksquare $

\textbf{Def 23.4} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( X_{n}\right) _{n\geq 1}$ successione di
v. a. con $X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., si dice che $X_{n}$ converge a $X$ in $L^{p}$, con $p\geq 1$, e si
scrive $X_{n}\rightarrow ^{L^{p}}X$, se $X_{n}\in L^{p}$ $\forall $ $n\geq 1$%
, $X\in L^{p}$ e $\lim_{n\rightarrow +\infty }\mathbf{E}\left( \left\vert
X_{n}-X\right\vert ^{p}\right) =0$.

$\mathbf{E}\left( \left\vert X_{n}-X\right\vert ^{p}\right) $ \`{e} una
successione numerica (ben definita perch\'{e} $X_{n}\in L^{p}$ $\forall $ $%
n,X\in L^{p}$), che pu\`{o} essere scritta come $\left( \left\vert
\left\vert X_{n}-X\right\vert \right\vert _{p}\right) ^{p}$ (elevare alla $p$
non cambia la convergenza a $0$): di fatto la convergenza in $L^{p}$ \`{e}
una convergenza in norma p-esima (in particolare metrica), che \`{e} una
propriet\`{a} in media, in cui i singoli sperimentatori (cio\`{e} i singoli $%
\omega $, le traiettorie) non sono considerati.

Se $X_{n}\rightarrow ^{L^{p}}X$, ogni sottosuccessione di $X_{n}$ converge a 
$X$ in $L^{p}$.

\textbf{Prop 23.5 (propriet\`{a} della convergenza in }$L^{p}$)%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1},\left( Y_{n}\right) _{n\geq
1}\text{ successioni di v.a., } \\
X_{n},Y_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ }\forall \text{ }n\text{, }X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a., }a\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }X_{n}\rightarrow ^{L^{p}}X\text{, }Y_{n}\rightarrow ^{L^{p}}Y \\
\text{Ts: (1) se }X_{n}\rightarrow ^{L^{p}}X\text{ e }X_{n}\rightarrow
^{L^{p}}\tilde{X}\text{, }X=\tilde{X}\text{ q. c.} \\
\text{(2) }aX_{n}\rightarrow ^{L^{p}}aX \\
\text{(3) }X_{n}+Y_{n}\rightarrow ^{L^{p}}X+Y \\
\text{(4) }\mathbf{E}\left( \left\vert X_{n}\right\vert ^{p}\right)
\rightarrow \mathbf{E}\left( \left\vert X\right\vert ^{p}\right)
\end{gather*}

(1) \`{e} l'unicit\`{a} quasi certa del limite. Si noti che, mentre \`{e}
lecito considerare la convergenza in $L^{p}$ di $X_{n}+Y_{n}$ perch\'{e} gli 
$L^{p}$ sono spazi vettoriali, non lo \`{e} considerare quella di $%
X_{n}Y_{n} $, che in generale non appartiene a $L^{p}$. (4) significa che la
successione numerica delle norme $p$-esime converge alla norma $p$-esima del
limite. La convergenza in $L^{p}$ serve ad approssimare i momenti. (!!)

\begin{enumerate}
\item Dimostro che se $X_{n}\rightarrow ^{L^{2}}X$ allora $var\left(
X_{n}\right) \rightarrow var\left( X\right) =\mathbf{E}\left( X^{2}\right) -%
\mathbf{E}^{2}\left( X\right) $. So che $X_{n}\in L^{2}$ $\forall $ $n\geq 1$%
, $X\in L^{2}$ e $\lim_{n\rightarrow +\infty }\mathbf{E}\left( \left\vert
X_{n}-X\right\vert ^{2}\right) =0$. Poich\'{e} $var\left( X\right) =\mathbf{E%
}\left( X^{2}\right) -\mathbf{E}^{2}\left( X\right) $ e $var\left(
X_{n}\right) =\mathbf{E}\left( X_{n}^{2}\right) -\mathbf{E}^{2}\left(
X_{n}\right) $, Voglio dimostrare che $\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( X_{n}\right) =\mathbf{E}\left( X\right) $ e $\lim_{n\rightarrow
+\infty }\mathbf{E}\left( X_{n}^{2}\right) =\mathbf{E}\left( X^{2}\right) $.
La seconda uguaglianza \`{e} vera per 23.5 (4) con $p=2$. Per la prima
basterebbe usare il fatto che $X_{n}\rightarrow ^{L^{1}}X$, cos\`{\i} anche
la successione dei momenti primi converge; tuttavia, si dimostra
direttamente.

Per la disuguaglianza di Cauchy-Schwarz con $Y=1$, $\left\vert \mathbf{E}%
\left( X_{n}-X\right) \right\vert \leq \sqrt{\mathbf{E}\left( \left(
X_{n}-X\right) ^{2}\right) }$, e il lato destro tende a $0$ per $%
n\rightarrow +\infty $: per il teorema dei carabinieri, $\lim_{n\rightarrow
+\infty }\left\vert \mathbf{E}\left( X_{n}-X\right) \right\vert =0$, cio\`{e}
$\lim_{n\rightarrow +\infty }\mathbf{E}\left( X_{n}\right) =\mathbf{E}\left(
X\right) $ per linearit\`{a} del valore atteso e continuit\`{a} del valore
assoluto. Quindi $\lim_{n\rightarrow +\infty }var\left( X_{n}\right)
=\lim_{n\rightarrow +\infty }\left( \mathbf{E}\left( X_{n}^{2}\right) -%
\mathbf{E}^{2}\left( X_{n}\right) \right) =\mathbf{E}\left( X^{2}\right) -%
\mathbf{E}^{2}\left( X\right) $, cio\`{e} $var\left( X\right) $.
\end{enumerate}

\textbf{Def 23.6} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( X_{n}\right) _{n\geq 1}$ successione di
v. a. con $X_{n}:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., si dice che $X_{n}$ converge a $X$ in probabilit\`{a}, e si scrive $%
X_{n}\rightarrow ^{\mathbf{P}}X$, se $\forall $ $\varepsilon >0$ $\exists $ $%
\lim_{n\rightarrow +\infty }\mathbf{P}\left( \left\vert X_{n}-X\right\vert
>\varepsilon \right) =0$.

La definizione, significativa per $\varepsilon $ piccoli, indica che la
percentuale di sperimentatori per cui la distanza tra $X_{n}$ e $X$ supera $%
\varepsilon $ tende a $0$ per $n\rightarrow +\infty $. $\left\vert
X_{n}-X\right\vert >\varepsilon \in \mathcal{A}$ perch\'{e} $X_{n},X$ sono
v. a., il valore assoluto \`{e} continuo e la somma di v.a. \`{e} una v.a.

\begin{enumerate}
\item Se $X_{n}\rightarrow ^{\mathbf{P}}X$, $\lim_{n\rightarrow +\infty }%
\mathbf{P}\left( \left\vert X_{n}-X\right\vert =x\right) =0$ $\forall $ $%
x\neq 0$, perch\'{e} se si applica 23. 6 con $\varepsilon <x$ si ha $\left(
\left\vert X_{n}-X\right\vert =x\right) \subseteq \left( \left\vert
X_{n}-X\right\vert >\varepsilon \right) $, quindi $\mathbf{P}\left(
\left\vert X_{n}-X\right\vert =x\right) \leq \mathbf{P}\left( \left\vert
X_{n}-X\right\vert >\varepsilon \right) $ e $\mathbf{P}\left( \left\vert
X_{n}-X\right\vert =x\right) $ tende a $0$ per il teorema dei carabinieri.
\end{enumerate}

\textbf{Prop 23.7 (caratterizzazione della convergenza in probabilit\`{a})}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{
spazio di probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ successione
di v. a. r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a.} \\
\text{Ts}\text{: } &&X_{n}\rightarrow ^{\mathbf{P}}X\Longleftrightarrow 
\mathbf{E}\left( \frac{\left\vert X_{n}-X\right\vert }{1+\left\vert
X_{n}-X\right\vert }\right) \rightarrow 0\text{ per }n\rightarrow +\infty
\end{eqnarray*}

$\mathbf{E}\left( \frac{\left\vert X_{n}-X\right\vert }{1+\left\vert
X_{n}-X\right\vert }\right) $ \`{e} ben definito per qualsiasi $X_{n},X$
perch\'{e} l'argomento \`{e} limitato. La proposizione chiarisce che anche
la convergenza in probabilit\`{a} pu\`{o} essere vista come convergenza
metrica: $\mathbf{E}\left( \frac{\left\vert X_{n}-X\right\vert }{%
1+\left\vert X_{n}-X\right\vert }\right) $ definisce una metrica
sull'insieme delle v. a. r., che diventa cos\`{\i} uno spazio metrico
completo. Infatti $d\left( X_{n},X\right) =\mathbf{E}\left( \frac{\left\vert
X_{n}-X\right\vert }{1+\left\vert X_{n}-X\right\vert }\right) $ \`{e} nulla
se e solo se $X_{n}=X$ q. c., \`{e} chiaramente simmetrica, e per
disuguaglianza triangolare del valore assoluto, monotonia e linearit\`{a}
del valore atteso $\mathbf{E}\left( \frac{\left\vert X-Y\right\vert }{%
1+\left\vert X-Y\right\vert }\right) =\mathbf{E}\left( 1-\frac{1}{%
1+\left\vert X-Y\right\vert }\right) =\mathbf{E}\left( 1-\frac{1}{%
1+\left\vert X-Z+Z-Y\right\vert }\right) $ $\leq \mathbf{E}\left( \frac{%
\left\vert X-Z\right\vert +\left\vert Z-Y\right\vert }{1+\left\vert
X-Z\right\vert +\left\vert Z-Y\right\vert }\right) =$ $\mathbf{E}\left( 
\frac{\left\vert X-Z\right\vert }{1+\left\vert X-Z\right\vert +\left\vert
Z-Y\right\vert }\right) +\mathbf{E}\left( \frac{\left\vert Z-Y\right\vert }{%
1+\left\vert X-Z\right\vert +\left\vert Z-Y\right\vert }\right) $ $\leq 
\mathbf{E}\left( \frac{\left\vert X-Z\right\vert }{1+\left\vert
X-Z\right\vert }\right) +\mathbf{E}\left( \frac{\left\vert Z-Y\right\vert }{%
1+\left\vert Z-Y\right\vert }\right) $. Quindi $X_{n}$ converge in probabilit%
\`{a} a $X$ se e solo se $X_{n}$ converge a $X$ secondo la metrica data (il
che implica che sia una successione di Cauchy secondo tale metrica).

Questo teorema facilita molto la verifica della convergenza in probabilit%
\`{a}, riducendola alla verifica della convergenza di una successione
numerica: non \`{e} la convergenza in $L^{1}$, ma una propriet\`{a} pi\`{u}
debole, dato che il denominatore controlla le traiettorie per cui il
numeratore diventa grande e rende pi\`{u} facile la convergenza.

Valgono le stesse propriet\`{a} della convergenza quasi certa.

\textbf{Teo 23.8 (propriet\`{a} della convergenza in probabilit\`{a})}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1},\left( Y_{n}\right) _{n\geq
1}\text{ successioni di v.a.r., } \\
X,Y:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a., }a\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ continua, }X_{n}\rightarrow ^{\mathbf{P}}X\text{, }Y_{n}\rightarrow ^{%
\mathbf{P}}Y \\
\text{Ts: (1) }aX_{n}\rightarrow ^{\mathbf{P}}aX\text{, }aY_{n}\rightarrow ^{%
\mathbf{P}}aY \\
\text{(2) se }X_{n}\rightarrow ^{\mathbf{P}}X\text{ e }X_{n}\rightarrow ^{%
\mathbf{P}}\tilde{X}\text{, }X=\tilde{X}\text{ q. c.} \\
\text{(3) }h\left( X_{n}\right) \rightarrow ^{\mathbf{P}}h\left( X\right) \\
\text{(4) }X_{n}+Y_{n}\rightarrow ^{\mathbf{P}}X+Y \\
\text{(5) }X_{n}Y_{n}\rightarrow ^{\mathbf{P}}XY \\
\text{(6) }\frac{X_{n}}{Y_{n}}\rightarrow ^{\mathbf{P}}\frac{X}{Y}\text{ se }%
Y_{n},Y\neq 0
\end{gather*}

(2) ancora q. c. Si dimostrano usando la seconda definizione.

\textbf{Teo 23.9 (relazioni tra convergenze)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a.
r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a} \\
\text{Ts: (1) }X_{n}\rightarrow X\text{ q. c.}\Longrightarrow
X_{n}\rightarrow ^{\mathbf{P}}X \\
\text{(2) }X_{n}\rightarrow ^{L^{p}}X\Longrightarrow X_{n}\rightarrow
^{L^{q}}X\text{ e }X_{n}\rightarrow ^{\mathbf{P}}X\text{ }\forall \text{ }%
1\leq q\leq p
\end{gather*}

La tesi rende evidente che la convergenza in legge \`{e} la propriet\`{a} pi%
\`{u} debole. Usando (1), dalla convergenza certa si pu\`{o} dedurre la
convergenza in probabilit\`{a}. La convergenza in $L^{p}$ non implica n\'{e} 
\`{e} implicata dalla convergenza quasi certa.

\textbf{Dim} (1) L'idea \`{e} di usare il teorema di convergenza monotona o
dominata per sfruttare la caratterizzazione della convergenza in probabilit%
\`{a}. Dato che $X_{n}\rightarrow X$ q. c., $Z_{n}=\frac{\left\vert
X_{n}-X\right\vert }{1+\left\vert X_{n}-X\right\vert }\rightarrow 0$ q. c.
per le propriet\`{a} del limite puntuale e la continuit\`{a} del valore
assoluto. Inoltre $\left\vert Z_{n}\right\vert \leq 1$ $\forall $ $n$, e la
v. a. costante $1$ \`{e} integrabile, per cui, per il teorema di convergenza
dominata, $\lim_{n\rightarrow +\infty }\mathbf{E}\left( Z_{n}\right) =%
\mathbf{E}\left( 0\right) =0$, perci\`{o} $X_{n}\rightarrow ^{\mathbf{P}}X$
per 23.7.

(2) *Mostro che $X_{n}\rightarrow ^{L^{2}}X\Longrightarrow X_{n}\rightarrow
^{L^{1}}X$. Per la disuguaglianza di Cauchy-Schwarz con $Y=1$, $\left\vert 
\mathbf{E}\left( X_{n}-X\right) \right\vert \leq \sqrt{\mathbf{E}\left(
\left( X_{n}-X\right) ^{2}\right) }$, e il lato destro tende a $0$ per $%
n\rightarrow +\infty $: per il teorema dei carabinieri, $\lim_{n\rightarrow
+\infty }\left\vert \mathbf{E}\left( X_{n}-X\right) \right\vert =0$, cio\`{e}
$\lim_{n\rightarrow +\infty }\mathbf{E}\left( X_{n}\right) =\mathbf{E}\left(
X\right) $ per linearit\`{a} del valore atteso e continuit\`{a} del valore
assoluto.

Mostro solo che $X_{n}\rightarrow ^{L^{1}}X\Longrightarrow X_{n}\rightarrow
^{\mathbf{P}}X$. So che $\lim_{n\rightarrow +\infty }\mathbf{E}\left(
\left\vert X_{n}-X\right\vert \right) =0$; voglio mostrare che $\forall $ $%
\varepsilon >0$ $\lim_{n\rightarrow +\infty }\mathbf{P}\left( \left\vert
X_{n}-X\right\vert >\varepsilon \right) =0$. Dalla disuguaglianza di Markov 
\`{e} noto che $\mathbf{P}\left( \left\vert X_{n}-X\right\vert >\varepsilon
\right) \leq \frac{\mathbf{E}\left( \left\vert X_{n}-X\right\vert \right) }{%
\varepsilon }$, quindi per il teorema dei carabinieri $\lim_{n\rightarrow
+\infty }\mathbf{P}\left( \left\vert X_{n}-X\right\vert >\varepsilon \right)
=0$. $\blacksquare $

Se $X_{n}\rightarrow X$ q. c. e $X_{n}\rightarrow Y$ in $L^{p}$ allora $X=Y$
q. c. per unicit\`{a} q. c. del limite in probabilit\`{a}.

\begin{enumerate}
\item Se $X_{n}\sim $ , le $X_{n}$ sono iid e $T_{n}=\max \left\{
X_{1},...,X_{n}\right\} \rightarrow ^{\mathbf{P}}c$, allora $%
T_{n}\rightarrow c$ q. c.. Infatti, \`{e} noto che $\forall $ $\varepsilon
>0 $ $\lim_{n\rightarrow +\infty }\mathbf{P}\left( \left\vert
T_{n}-c\right\vert <\varepsilon \right) =1$: ma l'evento $A=\left(
T_{n}\rightarrow c\right) $ \`{e} uguale a $\bigcap_{\varepsilon
>0}A_{\varepsilon }$, con $A_{\varepsilon }=\bigcap_{n=\nu }^{+\infty
}\left( \left\vert T_{n}-c\right\vert <\varepsilon \right) $, e $%
A_{n+1}=\left( \left\vert T_{n+1}-c\right\vert <\varepsilon \right)
\subseteq \left( \left\vert T_{n}-c\right\vert <\varepsilon \right) =A_{n}$,
cio\`{e} la successione degli eventi $A_{n}$ \`{e} decrescente. Dunque $%
\mathbf{P}\left( A\right) =1$ perch\'{e} $\mathbf{P}\left( A_{\varepsilon
}\right) =\lim_{n\rightarrow +\infty }\mathbf{P}\left( \left\vert
T_{n}-c\right\vert <\varepsilon \right) =1$ $\forall $ $\varepsilon >0$.
\end{enumerate}

\textbf{Teo 23.10 (la rivincita della convergenza in probabilit\`{a})}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ successione } \\
\text{di v.a. r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a, }X_{n}\rightarrow ^{\mathbf{P}}X \\
\text{(1) }\exists \text{ }\left( n_{k}\right) _{k\geq
1}:X_{n_{k}}\rightarrow X\text{ q. c. per }k\rightarrow +\infty \\
\text{(2) se inoltre }\exists \text{ }Y\in L^{p}:\left\vert X_{n}\right\vert
\leq Y\text{ }\forall \text{ }n\text{, allora }X_{n}\in L^{p},X\in
L^{p},X_{n}\rightarrow ^{L^{p}}X
\end{gather*}

Se $p=1$, (2) diventa il solito teorema di convergenza dominata: infatti, se 
$\lim_{n\rightarrow +\infty }\mathbf{E}\left( \left\vert X_{n}-X\right\vert
\right) =0$, allora $\lim_{n\rightarrow +\infty }\left\vert \mathbf{E}\left(
X_{n}-X\right) \right\vert =0$ perch\'{e} $0\leq \left\vert \mathbf{E}\left(
X_{n}-X\right) \right\vert \leq \mathbf{E}\left( \left\vert
X_{n}-X\right\vert \right) $ e dunque $\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( X_{n}-X\right) =0$.

\textbf{Dim*} (1) Per ipotesi $\lim_{n\rightarrow +\infty }\mathbf{E}\left( 
\frac{\left\vert X_{n}-X\right\vert }{1+\left\vert X_{n}-X\right\vert }%
\right) =0$: quindi $\exists $ $\left( n_{k}\right) _{k\geq
1}:\lim_{k\rightarrow +\infty }\mathbf{E}\left( \frac{\left\vert
X_{n_{k}}-X\right\vert }{1+\left\vert X_{n_{k}}-X\right\vert }\right) =0$ e $%
\mathbf{E}\left( \frac{\left\vert X_{n_{k}}-X\right\vert }{1+\left\vert
X_{n_{k}}-X\right\vert }\right) \leq \frac{1}{2^{k}}$. Allora per 9.4 (1),
essendo il termine generale della serie una v. a. nonnegativa, $\mathbf{E}%
\left( \sum_{k=1}^{+\infty }\frac{\left\vert X_{n_{k}}-X\right\vert }{%
1+\left\vert X_{n_{k}}-X\right\vert }\right) =\sum_{k=1}^{+\infty }\mathbf{E}%
\left( \frac{\left\vert X_{n_{k}}-X\right\vert }{1+\left\vert
X_{n_{k}}-X\right\vert }\right) \leq \sum_{k=1}^{+\infty }\frac{1}{2^{k}}%
<+\infty $. Se $\mathbf{E}\left( \sum_{k=1}^{+\infty }\frac{\left\vert
X_{n_{k}}-X\right\vert }{1+\left\vert X_{n_{k}}-X\right\vert }\right) $ \`{e}
finito, allora $\sum_{k=1}^{+\infty }\frac{\left\vert X_{n_{k}}-X\right\vert 
}{1+\left\vert X_{n_{k}}-X\right\vert }<+\infty $ q. c. (una v. a. con
valore atteso finito \`{e} quasi certamente finita). Questo implica che il
termine generale $\frac{\left\vert X_{n_{k}}-X\right\vert }{1+\left\vert
X_{n_{k}}-X\right\vert }\rightarrow 0$ per $k\rightarrow +\infty $ q. c., cio%
\`{e} $\left\vert X_{n_{k}}-X\right\vert \rightarrow 0$ q. c., cio\`{e} $%
X_{n_{k}}\rightarrow X$ q. c. $\blacksquare $

\begin{enumerate}
\item Si d\`{a} un esempio del fatto che la convergenza in $L^{1}$ non
implica la convergenza quasi certa, detto esempio della macchina da
scrivere. Considero lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathcal{U}\left( \left( 0,1\right) \right) \right) $ e la v. a. $%
X_{n,k}\left( \omega \right) =I_{[\frac{k-1}{n},\frac{k}{n})}\left( \omega
\right) $ con $k=1,...,n$ (si fa corrispondere a ogni $\left( n,k\right) $
una $j$ in modo da avere un solo indice: $%
Y_{1}:=X_{1,1},Y_{2}:=X_{2,1},Y_{3}:=X_{2,2}$,...). Fissato $n$, al variare
di $k$ $[\frac{k-1}{n},\frac{k}{n})$ \`{e} una partizione di $[0,1)$
mediante intervalli di ampiezza $\frac{1}{n}$, che si infittisce al crescere
di $n$: $X_{1,1}\left( \omega \right) =I_{[0,1)}\left( \omega \right) $, $%
X_{2,1}\left( \omega \right) =I_{[0,\frac{1}{2})}\left( \omega \right) $, $%
X_{2,2}\left( \omega \right) =I_{[\frac{1}{2},1)}\left( \omega \right) $,... 
$\mathbf{E}\left( \left\vert X_{n,k}\right\vert \right) =\mathbf{E}\left(
I_{[\frac{k-1}{n},\frac{k}{n})}\left( \omega \right) \right) =\mathbf{P}%
\left( [\frac{k-1}{n},\frac{k}{n})\right) =\frac{1}{n}$, quindi $%
\lim_{n\rightarrow +\infty }\mathbf{E}\left( \left\vert X_{n,k}\right\vert
\right) =0$, dalla qual cosa si intuisce che $X_{n,k}\rightarrow ^{L^{1}}0$:
ogni $X_{n,k}$ \`{e} integrabile, $0$ lo \`{e} e $\lim_{n\rightarrow +\infty
}\mathbf{E}\left( \left\vert X_{n,k}-0\right\vert \right) =0$. Allora, se $%
X_{n}$ ha un limite quasi certo, questo deve essere $0$, per unicit\`{a}
quasi certa del limite!!. Non vale per\`{o} che $X_{n,k}\rightarrow 0$ q.
c., perch\'{e}, fissato $\bar{\omega}\in \lbrack 0,1)$, $X_{n,k}\left( \bar{%
\omega}\right) $ oscilla tra $0$ e $1$: $\forall $ $n\geq 1$ $\exists $ $%
\bar{k}:X_{n,\bar{k}}\left( \bar{\omega}\right) =1$ e per $k\neq $ $\bar{k}$
vale $X_{n,k}\left( \bar{\omega}\right) =0$. Non \`{e} quindi possibile che $%
\lim_{n\rightarrow +\infty }X_{n}\left( \bar{\omega}\right) =X\left( \bar{%
\omega}\right) =0$, per nessun $\bar{\omega}$, e la convergenza non \`{e}
quasi certa. Questo si pu\`{o} dedurre argomentando che la convergenza a $%
X=0 $ in $L^{1}$ implica la convergenza in probabilit\`{a}, che implica che $%
\exists $ $\left( n_{k}\right) _{k\geq 1}:X_{n_{k}}\rightarrow 0$ q. c. per $%
k\rightarrow +\infty $. Tuttavia $\left\{ \omega :\lim_{n\rightarrow +\infty
}X_{n}\left( \omega \right) \neq 0\right\} =[0,1)$, per cui $%
X_{n}\not\rightarrow 0$ q. c.

\item Considero una sottosuccessione di $X_{n,k}$: $Y_{n}:=X_{n,1}$ $\forall 
$ $n\geq 1$. $X_{n,1}\left( \omega \right) =I_{[0,\frac{1}{n})}\left( \omega
\right) $: $\lim_{n\rightarrow +\infty }X_{n,1}\left( \omega \right) =0$ $%
\forall $ $\omega \neq 0$, quindi $Y_{n}\rightarrow 0$ q. c. Inoltre $%
Y_{n}\rightarrow ^{L^{1}}0$: ogni $Y_{n}$ \`{e} integrabile, $0$ lo \`{e} e $%
\lim_{n\rightarrow +\infty }\mathbf{E}\left( \left\vert Y_{n}-0\right\vert
\right) =\lim_{n\rightarrow +\infty }\frac{1}{n}=0$, coerentemente con 23.10
(1)

\item Dato lo spazio di probabilit\`{a} $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) ,\mathcal{U}\left( \left( 0,1\right) \right) \right) $, si \`{e} gi%
\`{a} visto che $X_{n}=nI_{[0,\frac{1}{n})}\rightarrow 0$ q. c. Non vale per%
\`{o} $X_{n}\not\rightarrow ^{L^{1}}0$: ogni $X_{n}$ \`{e} integrabile perch%
\'{e} limitata e $0$ lo \`{e}, ma $\mathbf{E}\left( \left\vert
X_{n}\right\vert \right) =\mathbf{E}\left( nI_{[0,\frac{1}{n})}\right) =n%
\mathbf{P}\left( [0,\frac{1}{n})\right) =1$, quindi $\lim_{n\rightarrow
+\infty }\mathbf{E}\left( \left\vert X_{n}-0\right\vert \right) =1$.
\end{enumerate}

\subsection{Convergenza debole}

\textbf{Def 24.1} Data $\left( Q_{n}\right) _{n\geq 1}$ successione di
misure di probabilit\`{a}, $Q$ misura di probabilit\`{a} su $\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) \right) $, si dice che $Q_{n}$ converge debolmente a $Q$ se $\forall 
$ $h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ continua e limitata vale $\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dQ_{n}\left( x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dQ\left( x\right) $.

$\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdQ_{n}$ \`{e} una successione numerica. $h$ \`{e} detta funzione test; la
classe delle funzioni test $\left\{ h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
:h\text{ \`{e} continua e limitata}\right\} $ \`{e} indicata con $%
C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. La definizione richiede di testare un limite su tutte le $h$
siffatte, che grazie alle ipotesi aggiuntive costituiscono un insieme pi\`{u}
piccolo delle funzioni solo misurabili. La continuit\`{a} di $h$ ne implica
la misurabilit\`{a}, la limitatezza l'integrabilit\`{a}, per cui $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdQ_{n},\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}hdQ$ sono ben definiti.

\begin{enumerate}
\item La convergenza debole di misure \`{e} una generalizzazione della
consueta convergenza di una successione numerica. Considero una successione
a valori reali $x_{n}\rightarrow x$, e $Q_{n}\left( x\right) =\delta
_{x_{n}}\left( x\right) $. $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dQ_{n}\left( x\right) =h\left( x_{n}\right) $, dato che si
sta calcolando il valore atteso di $h\left( X_{n}\left( \omega \right)
\right) $, dove la legge di $X_{n}$ \`{e} una delta di Dirac $\delta
_{x_{n}} $. $\lim_{n\rightarrow +\infty }h\left( x_{n}\right) =h\left(
x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dQ\left( x\right) $, grazie alla continuit\`{a} di $h$ (la
sola misurabilit\`{a} non \`{e} sufficiente). Allora $Q_{n}=\delta _{x_{n}}$
converge debolmente a $Q=\delta _{x}$. Vale anche il viceversa.
\end{enumerate}

La definizione di convergenza debole serve a poter dare una nozione di
convergenza anche per una successione di v. a. r. non tutte definite sullo
stesso spazio di probabilit\`{a}: in tal caso infatti una scrittura del tipo 
$X_{n}\left( \omega \right) -X\left( \omega \right) $ non ha significato,
perch\'{e} non \`{e} chiaro a quale insieme appartenga $\omega $. E' solo
possibile confrontare le leggi delle v. a.

\textbf{Def 24.2} Dato $\left( \Omega _{n},\mathcal{A}_{n},\mathbf{P}%
_{n}\right) $ spazio di probabilit\`{a} $\forall $ $n$, $\left( \Omega ,%
\mathcal{A},\mathbf{P}\right) $ spazio di probabilit\`{a}, $\left(
X_{n}\right) _{n\geq 1}$ successione di v. a. con $X_{n}:\Omega
_{n}\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ $\forall $ $n$, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ v. a., si dice che $X_{n}$ converge a $X$ in legge, e si scrive $%
X_{n}\rightarrow ^{\tciLaplace }X$ o $X_{n}\rightarrow ^{\mathcal{D}}X$, se
la successione di misure di probabilit\`{a} $\left( P^{X_{n}}\right) _{n\geq
1}$ converge debolmente a $P^{X}$.

D'ora in poi, quando si scrive $X_{n}\rightarrow ^{\tciLaplace }X$, si
suppone implicitamente che siano v. a. r. definite su spazi di probabilit%
\`{a} come sopra.

\begin{enumerate}
\item Se $\left( X_{n}\right) _{n\geq 1}$ \`{e} una successione di v. a.
costante rispetto a $n$, cio\`{e} tale che $X_{n}=X_{1}$ $\forall $ $n$,
allora $X_{n}\rightarrow X$ certamente, q. c., in $L^{p}$ $\forall $ $p$, in
probabilit\`{a}, in legge.

\item Se $\left( X_{n}\right) _{n\geq 1}$ \`{e} una successione di v. a.
costante rispetto a $\omega $, cio\`{e} tale che $\forall $ $n$ $X_{n}$ non
dipende da $\omega $, cio\`{e} \`{e} una successione di v. a. costanti (a
valori reali), allora $\lim_{n\rightarrow +\infty }X_{n}$ \`{e} il limite
certo, q. c., in $L^{p}$ $\forall $ $p$, in probabilit\`{a}, in legge di $%
X_{n}$.
\end{enumerate}

\textbf{Prop 24.3 (caratterizzazione della convergenza in legge)}%
\begin{eqnarray*}
\text{Hp}\text{: } &&\left( X_{n}\right) _{n\geq 1}\text{ successione di v.
a., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a.} \\
\text{Ts}\text{: } &&X_{n}\rightarrow ^{\tciLaplace }X\Longleftrightarrow
\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( h\left( X_{n}\right)
\right) =\mathbf{E}\left( h\left( X\right) \right) \text{ }\forall \text{ }%
h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right)
\end{eqnarray*}

Questo significa che se $X_{n}\rightarrow ^{\tciLaplace }X$ e $Y$ ha la
stessa legge di $X$, allora vale anche $X_{n}\rightarrow ^{\tciLaplace }Y$,
perch\'{e} il valore atteso dipende solo dalla legge. Non implica $%
\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( X_{n}\right) =\mathbf{E}%
\left( X\right) $.

\textbf{Dim} Per definizione $X_{n}\rightarrow ^{\tciLaplace
}X\Longleftrightarrow \forall $ $h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ vale $\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{X_{n}}\left( x\right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{X}\left( x\right) $. Per la regola del valore atteso $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{X_{n}}\left( x\right) =\int_{\Omega }h\left(
X_{n}\left( \omega \right) \right) d\mathbf{P}_{n}\left( \omega \right) $ e $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) dP^{X}\left( x\right) =\int_{\Omega }h\left( X\left(
\omega \right) \right) d\mathbf{P}\left( \omega \right) $, quindi quanto
scritto \`{e} equivalente a $\lim_{n\rightarrow +\infty }\mathbf{E}%
_{n}\left( h\left( X_{n}\right) \right) =\mathbf{E}\left( h\left( X\right)
\right) $, dove $\mathbf{E}_{n}$ indica l'integrale rispetto alla misura $%
\mathbf{P}_{n}$. $\blacksquare $

Vale l'unicit\`{a} in legge del limite in legge: se $X_{n}\rightarrow
^{\tciLaplace }X$ e $X_{n}\rightarrow ^{\tciLaplace }Y$, allora $P^{X}=P^{Y}$%
, che non implica affatto $X=Y$ q. c.: $X$ e $Y$ potrebbero anche essere
definite su spazi diversi.

\begin{enumerate}
\item Considero $\left( X_{n}\right) _{n\geq 1}$ su $\left( \Omega ,\mathcal{%
A},\mathbf{P}\right) $, $X\sim b\left( \frac{1}{2}\right) $ e $X_{n}=X$ $%
\forall $ $n\geq 1$: ovviamente $X_{n}\rightarrow ^{\tciLaplace }X$.
Considero $Y=1-X$: anche $Y\sim b\left( \frac{1}{2}\right) $ (si pu\`{o}
ricavare facilmente con la funzione caratteristica) e $X_{n}\rightarrow
^{\tciLaplace }Y$, ma $\mathbf{P}\left( X=Y\right) =\mathbf{P}\left( X=Y=%
\frac{1}{2}\right) =0$, quindi, pur essendo $P^{X}=P^{Y}$, non \`{e} vero
che $X=Y$ q. c.
\end{enumerate}

\textbf{Prop 24.4 (convergenza in legge nel caso discreto)}%
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a.r.
discrete, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. discreta} \\
\text{con supporti }S_{X_{n}}\text{ }\forall \text{ }n,S_{X}\text{ e densit%
\`{a} discrete }p_{X_{n}}\text{ }\forall \text{ }n,p_{X}\text{; }%
S:=\bigcup_{n=1}^{+\infty }S_{X_{n}}\cup S\text{)} \\
\text{Ts}\text{: }\text{(1) se }p_{X_{n}}\left( s\right) \rightarrow
p_{X}\left( s\right) \text{ }\forall \text{ }s\in S\text{, }X_{n}\rightarrow
^{\tciLaplace }X \\
\text{(2) se }\exists \text{ }A:\mathcal{D}A=\varnothing \text{ e }%
S_{X_{n}},S\subseteq A\text{ }\forall \text{ }n\text{, } \\
p_{X_{n}}\left( s\right) \rightarrow p_{X}\left( s\right) \text{ }\forall 
\text{ }s\in S\Longleftrightarrow X_{n}\rightarrow ^{\tciLaplace }X
\end{gather*}

Essendo i supporti tutti discreti, anche $S$ \`{e} discreto. (1) afferma che
la convergenza puntuale della successione delle densit\`{a} \`{e}
sufficiente per la convergenza in legge. (2) richiede che i supporti siano
tutti contenuti in un insieme privo di punti di accumulazione: e. g. $%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ o $%
%TCIMACRO{\U{2124} }%
%BeginExpansion
\mathbb{Z}
%EndExpansion
$. La valutazione di una convergenza puntuale \`{e} molto pi\`{u} semplice
della verifica della definizione.

\begin{enumerate}
\item Sia $X_{n}\sim bin\left( n,\frac{\lambda }{n}\right) $, $\lambda >0$, $%
n\geq \lambda $. $S_{X_{n}}=\left\{ 0,...,n\right\} \subseteq 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$. Considero $X\sim poiss\left( \lambda \right) $, con $S_{X}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$: dunque $S=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ e posso applicare (2). $p_{X_{n}}\left( k\right) =\binom{n}{k}\left( \frac{%
\lambda }{n}\right) ^{k}\left( 1-\frac{\lambda }{n}\right) ^{n-k}$, che
converge a $e^{-\lambda }\frac{\lambda ^{k}}{k!}$ per $n\rightarrow +\infty $%
. Infatti $\frac{n!}{k!\left( n-k\right) !}\frac{\lambda ^{k}}{n^{k}}\frac{%
\left( n-\lambda \right) ^{n-k}}{n^{n-k}}=\frac{\lambda ^{k}}{k!}\frac{n!}{%
\left( n-k\right) !}\frac{\left( n-\lambda \right) ^{n-k}}{n^{n}}\sim \frac{%
\lambda ^{k}}{k!}\frac{n^{n}e^{-n}\sqrt{2\pi n}}{\left( n-k\right)
^{n-k}e^{-\left( n-k\right) }\sqrt{2\pi \left( n-k\right) }}\frac{\left(
n-\lambda \right) ^{n-k}}{n^{n}}$ per l'approssimazione di Sterling: quindi
si ha $\frac{\lambda ^{k}}{k!}\sqrt{\frac{n}{n-k}}e^{-k}\left( \frac{%
n-\lambda }{n-k}\right) ^{n-k}$, e in particolare $\left( \frac{n-\lambda }{%
n-k}\right) ^{n-k}=\left( 1+\frac{k-\lambda }{n-k}\right) ^{n-k}=\left( 1+%
\frac{1}{\frac{n-k}{k-\lambda }}\right) ^{n-k}=\left( \left( 1+\frac{1}{%
\frac{n-k}{k-\lambda }}\right) ^{\frac{n-k}{k-\lambda }}\right) ^{k-\lambda
} $, che per $n\rightarrow +\infty $ tende a $e^{k-\lambda }$, per cui il
risultato finale \`{e} $\frac{\lambda ^{k}}{k!}e^{-k}e^{k-\lambda
}=e^{-\lambda }\frac{\lambda ^{k}}{k!}$ e $X_{n}$ converge in legge a $X$.

\item Sia $X_{n}\sim \delta _{\frac{1}{n}}$. $S_{X_{n}}=\left\{ 0,1\right\}
\subseteq 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$. Considero $X\sim \delta _{0}$: so che $X_{n}\rightarrow ^{\tciLaplace }X$
perch\'{e} si sta studiando la convergenza di una successione numerica, come
nell'esempio sopra. Studio per\`{o} anche la convergenza puntuale della
successione delle densit\`{a}; $S=\left\{ 0\right\} \cup \left\{ \frac{1}{n}%
:n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
^{\ast }\right\} $. $p_{X_{n}}\left( \frac{1}{n}\right) =1$, $%
p_{X_{n}}\left( 0\right) =0$ $\forall $ $n$: $\lim_{n\rightarrow +\infty
}p_{X_{n}}\left( 0\right) =0$, mentre $p_{X}\left( 0\right) =1$, quindi non 
\`{e} vero che $p_{X_{n}}\left( s\right) \rightarrow p_{X}\left( s\right) $ $%
\forall $ $s\in S$, nonostante $X_{n}\rightarrow ^{\tciLaplace }X$. Infatti
non si pu\`{o} applicare (2) perch\'{e} $\mathcal{D}S=\left\{ 0\right\} $.
\end{enumerate}

\textbf{Prop 24.5 (lemma di Scheff\'{e}: convergenza in legge nel caso
continuo)} 
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a.r.
assolutamente continue, }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ } \\
\text{v. a. assolutamente continua con densit\`{a} }\left( f_{X_{n}}\right)
_{n\geq 1},f_{X}\text{ rispettivamente } \\
\text{Ts}\text{: }\text{se }f_{X_{n}}\rightarrow f_{X}\text{ quasi ovunque,
allora }X_{n}\rightarrow ^{\tciLaplace }X
\end{gather*}

Il teorema \`{e} del tutto analogo a 24.4 (1).

\textbf{Dim} So che $\left\{ x:\lim_{n\rightarrow +\infty }f_{X_{n}}\left(
x\right) \neq f_{X}\left( x\right) \right\} $ ha misura $0$ secondo
Lebesgue. Devo mostrare che $\forall $ $h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $ vale $\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( h\left(
X_{n}\right) \right) =\mathbf{E}\left( h\left( X\right) \right) $, cio\`{e} $%
\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) f_{X_{n}}\left( x\right) dm=\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) f_{X}\left( x\right) dm$, quindi che $\lim_{n\rightarrow
+\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) \left[ f_{X_{n}}\left( x\right) -f_{X}\left( x\right) %
\right] dm=0$.

Dimostro che $\lim_{n\rightarrow +\infty }\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert f_{X_{n}}-f_{X}\right\vert dm=0$. $\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert f_{X_{n}}-f_{X}\right\vert dm=2\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( f_{X_{n}}-f_{X}\right) _{+}dm$

\begin{enumerate}
\item Sia $X_{n}\sim \mathcal{N}\left( \mu _{n},\sigma _{n}^{2}\right) $ con 
$\mu _{n}\rightarrow \mu $, $\sigma _{n}^{2}\rightarrow \sigma ^{2}>0$.
Allora $f_{X_{n}}\left( x\right) =\frac{1}{\sqrt{2\pi \sigma _{n}^{2}}}e^{-%
\frac{1}{2}\frac{\left( x-\mu _{n}\right) ^{2}}{\sigma _{n}^{2}}}$ e $%
\lim_{n\rightarrow +\infty }f_{X_{n}}\left( x\right) =\frac{1}{\sqrt{2\pi
\sigma ^{2}}}e^{-\frac{1}{2}\frac{\left( x-\mu \right) ^{2}}{\sigma ^{2}}%
}=f_{X}\left( x\right) $ $\forall $ $x$, con $X\sim \mathcal{N}\left( \mu
,\sigma ^{2}\right) $. Dunque $X_{n}\rightarrow ^{\tciLaplace }X$.
\end{enumerate}

I criteri visti hanno l'evidente limite di essere applicabili solo a
particolari classi di v. a. Si vedono nel seguito criteri basati su altre
due funzioni caratterizzanti una v. a., cio\`{e} funzione di ripartizione e
funzione caratteristica.

In generale $X_{n}\rightarrow ^{\tciLaplace }X$ non implica che $%
P^{X_{n}}\left( B\right) \rightarrow P^{X}\left( B\right) $ $\forall $ $B\in 
\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Infatti dalla convergenza in legge non si pu\`{o} dedurre che $%
\mathbf{E}_{n}\left( I_{B}\left( X_{n}\right) \right) \rightarrow \mathbf{E}%
\left( I_{B}\left( X\right) \right) $, perch\'{e} in generale $I_{B}\left(
x\right) $ non \`{e} continua. Se per\`{o} $B$ \`{e} del tipo $(-\infty ,t]$%
, le cose cambiano.

\textbf{Teo 24.6 (convergenza in legge e convergenza delle funzioni di
ripartizione)} 
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 1}\text{ successione di
v.a.r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. con funzioni } \\
\text{di ripartizione }\left( F_{X_{n}}\right) _{n\geq 1},F_{X}\text{
rispettivamente } \\
\text{Ts}\text{: }X_{n}\rightarrow ^{\tciLaplace }X\Longleftrightarrow
\lim_{n\rightarrow +\infty }F_{X_{n}}\left( t\right) =F_{X}\left( t\right) 
\text{ }\forall \text{ }t\in \left\{ t:F_{X}\text{ \`{e} continua in }%
t\right\}
\end{gather*}

Quindi $X_{n}\rightarrow ^{\tciLaplace }X\Longleftrightarrow P^{X_{n}}\left(
(-\infty ,t]\right) \rightarrow P^{X}\left( (-\infty ,t]\right) $ per $t$
che sta nell'insieme dei punti di continuit\`{a} di $F_{X}$: $F_{X}$ \`{e}
continua in $t$ se e solo se $\mathbf{P}\left( X=t\right) =0$.

Se in particolare $X$ \`{e} assolutamente continua, la convergenza in legge
equivale alla convergenza puntuale di $F_{X_{n}}$ a $F_{X}$. In tal caso
vale $P^{X_{n}}\left( B\right) \rightarrow P^{X}\left( B\right) $ $\forall $ 
$B$ del tipo $(-\infty ,s],\left[ a,b\right] ,(a,b],[a,b),\left( a,b\right) $%
,...

\begin{enumerate}
\item Considero $\left( X_{n}\right) _{n\geq 1}$ successione di v.a.r., con $%
F_{X_{n}}\left( s\right) =\left\{ 
\begin{array}{c}
0\text{ se }s<-\frac{1}{n} \\ 
\frac{1}{2}+\frac{n}{2}s\text{ se }s\in \lbrack -\frac{1}{n},\frac{1}{n}) \\ 
1\text{ se }s\geq \frac{1}{n}%
\end{array}%
\right. $, e valuto la convergenza in legge della successione a qualche v.
a.. $\left( F_{X_{n}}\right) $ converge puntualmente a $G\left( s\right)
=\left\{ 
\begin{array}{c}
0\text{ se }s<0 \\ 
\frac{1}{2}\text{ se }s=0 \\ 
1\text{ se }s>0%
\end{array}%
\right. $, che non \`{e} una funzione di ripartizione perch\'{e} non \`{e}
continua da destra in $0$. Questo fa intuire che se si considera $%
F_{X}\left( s\right) =\left\{ 
\begin{array}{c}
0\text{ se }s<0 \\ 
1\text{ se }s\geq 0%
\end{array}%
\right. $ - che \`{e} la funzione di ripartizione di $X\sim \delta _{0}$ -,
allora \`{e} vero che $\lim_{n\rightarrow +\infty }F_{X_{n}}\left( t\right)
=F_{X}\left( t\right) $ $\forall $ $t\in \left\{ t:F_{X}\text{ \`{e}
continua in }t\right\} =%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\backslash \left\{ 0\right\} $. Dunque $X_{n}\rightarrow ^{\tciLaplace }X$.

\item Sia $X_{n}\sim \mathcal{U}\left( \left\{ \frac{1}{n},\frac{2}{n}%
,...,1\right\} \right) $. Data $X\sim \mathcal{U}\left( \left( 0,1\right)
\right) $, $X_{n}\rightarrow ^{\tciLaplace }X$. La funzione di ripartizione
di $X_{n}$ \`{e} $F_{X_{n}}\left( t\right) =\left\{ 
\begin{array}{c}
0\text{ se }t<\frac{1}{n} \\ 
\frac{1}{n}\text{ se }t\in \lbrack \frac{1}{n},\frac{2}{n}) \\ 
... \\ 
\frac{n-1}{n}\text{ se }t\in \lbrack \frac{n-1}{n},\frac{n}{n}) \\ 
1\text{ se }t\geq 1%
\end{array}%
\right. $: $F_{X_{n}}\left( t\right) $ converge puntualmente a $F_{X}\left(
t\right) =\left\{ 
\begin{array}{c}
0\text{ se }t<0 \\ 
t\text{ se }t\in \left( 0,1\right) \\ 
1\text{ se }t\geq 1%
\end{array}%
\right. $ $\forall $ $t$. Infatti, fissato $t\in \left( 0,1\right) $, $%
\forall $ $n\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ $\exists $ $k:t\in \lbrack \frac{k}{n},\frac{k+1}{n})$, che \`{e}
equivalente $nt\in \lbrack k,k+1)$. Questo significa che si pu\`{o} scrivere 
$k=\lfloor nt\rfloor $, per cui $t\in \lbrack \frac{\lfloor nt\rfloor }{n},%
\frac{\lfloor nt\rfloor +1}{n})$. $\lim_{n\rightarrow +\infty }\frac{\lfloor
nt\rfloor }{n}=\lim_{n\rightarrow +\infty }\frac{\lfloor nt\rfloor +1}{n}=t$.
\end{enumerate}

\textbf{Def} Data $M$ collezione di misure di probabilit\`{a} $\mu $ su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, $M$ si dice tight se $\forall $ $\varepsilon >0$ esiste un insieme
compatto $K:\inf_{\mu \in M}\mu \left( K\right) >1-\varepsilon $.

La definizione \`{e} ben posta perch\'{e} gli insiemi compatti sono un
sottinsieme degli insiemi chiusi, che appartengono a $\mathcal{B}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $; applicheremo la definizione nel caso di $M$ rappresentata da una
successione $\left( Q_{n}\right) _{n\geq 1}$. Il significato \`{e} che,
stabilito un numero arbitrariamente vicino a $1$, \`{e} possibile trovare un
compatto che abbia misura maggiore secondo tutte le $\mu $ della famiglia.

Vale il seguente teorema:

\textbf{Teo}%
\begin{gather*}
\text{Hp: }\left( Q_{n}\right) _{n\geq 1}\text{ successione tight di misure
di probabilit\`{a} su }%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{Ts: esiste }n_{k}:Q_{n_{k}}\text{ converge debolmente}
\end{gather*}

\textbf{Teo 24.7 (teorema di continuit\`{a} di Levy)}%
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 1}\text{ successione di
v.a.r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v. a. con funzioni } \\
\text{caratteristiche }\left( \phi _{X_{n}}\right) _{n\geq 1},\phi _{X}\text{
rispettivamente } \\
\text{Ts}\text{: (1) }X_{n}\rightarrow ^{\tciLaplace }X\Longrightarrow
\lim_{n\rightarrow +\infty }\phi _{X_{n}}\left( u\right) =\phi _{X}\left(
u\right) \text{ }\forall \text{ }u\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{(2) se }\phi _{X_{n}}\left( u\right) \rightarrow \psi \left( u\right) 
\text{ }\forall \text{ }u\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ e }\psi \left( u\right) \text{ \`{e} continua in }u=0\text{, allora}
\\
\exists \text{ }Y\text{ v.a.r. tale che }\phi _{Y}=\psi \text{ e }%
X_{n}\rightarrow ^{\tciLaplace }Y
\end{gather*}

(1) \`{e} una conseguenza dell'unicit\`{a} della legge limite e della
reciproca caratterizzazione tra una legge e la sua funzione caratteristica.

(2) permette di caratterizzare il limite in legge della successione mediante
la sua funzione caratteristica, pur non riconoscendola e non avendo un
candidato limite.

\textbf{Corollari}%
\begin{gather*}
\text{(1) }X_{n}\rightarrow ^{\tciLaplace }X\Longleftrightarrow
\lim_{n\rightarrow +\infty }\phi _{X_{n}}\left( u\right) =\phi _{X}\left(
u\right) \text{ }\forall \text{ }u\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\\
\text{(2) }X_{n}\text{ converge in legge }\Longleftrightarrow \phi
_{X_{n}}\left( u\right) \rightarrow \psi \left( u\right) \text{ con }\psi 
\text{ continua in }0
\end{gather*}

Sia (1) che (2) sono una conseguenza di 24.7 (1),(2).

(1, sx-\TEXTsymbol{>}dx) permette di controllare agevolmente, avendo la
candidata $X$, se $X_{n}\rightarrow ^{\tciLaplace }X$ usando le funzioni
caratteristiche. E' evidente l'unicit\`{a} in legge del limite: la funzione
caratteristica del limite ne caratterizza la legge. Se invece $\phi
_{X_{n}}\left( u\right) \rightarrow \psi \left( u\right) $ e $\psi $ non 
\`{e} continua in $0$, allora $\left( X_{n}\right) _{n\geq 1}$ non ha limite
in legge.

\begin{enumerate}
\item $X_{n}\sim \mathcal{N}\left( \mu _{n},\sigma _{n}^{2}\right) $ con $%
\mu _{n}\rightarrow \mu $, $\sigma _{n}^{2}\rightarrow \sigma ^{2}\geq 0$. $%
\phi _{X_{n}}\left( u\right) =e^{iu\mu _{n}-\frac{1}{2}\sigma _{n}^{2}u^{2}}$%
, che converge puntualmente a $\phi _{X}\left( u\right) =e^{iu\mu -\frac{1}{2%
}\sigma ^{2}u^{2}}$, con $X\sim \mathcal{N}\left( \mu ,\sigma ^{2}\right) $.
Dunque $X_{n}\rightarrow ^{\tciLaplace }X$.

\item $X_{n}\sim \mathcal{U}\left( \left( -n,n\right) \right) $ ha $\phi
_{X_{n}}\left( u\right) =\left\{ 
\begin{array}{c}
1\text{ se }u=0 \\ 
\frac{\sin \left( nu\right) }{nu}\text{ se }u\neq 0%
\end{array}%
\right. $: $\phi _{X_{n}}\left( u\right) \rightarrow 0$ $\forall $ $u\neq 0$%
, quindi $\psi \left( u\right) =\left\{ 
\begin{array}{c}
1\text{ se }u=0 \\ 
0\text{ se }u\neq 0%
\end{array}%
\right. $, che non \`{e} continua in $0$: quindi $X_{n}$ non converge in
legge (intuitivamente, infatti, sarebbe un'uniforme su $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$).

\item $X_{n}\sim bin\left( n,\frac{\lambda }{n}\right) $, con $n\geq \lambda 
$, ha $\phi _{X_{n}}\left( u\right) =\left( 1-p+pe^{iu}\right) ^{n}=\left( 1-%
\frac{\lambda }{n}+\frac{\lambda }{n}e^{iu}\right) ^{n}=\left( 1+\frac{%
\lambda \left( e^{iu}-1\right) }{n}\right) ^{n}\rightarrow e^{\lambda \left(
e^{iu}-1\right) }$, che \`{e} la $\phi $ di $X\sim poiss\left( \lambda
\right) $.
\end{enumerate}

----------

Aside: logaritmo complesso

Sia $z\in 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
,z\neq 0$. Si definisce logaritmo complesso di $z$, e si indica con $w=\log
z $, un numero complesso tale che $e^{w}=z$.

Posto $w=x+iy$, essendo $z=\left\vert z\right\vert e^{i\arg z}$, affinch\'{e}
si abbia $e^{w}=e^{x}e^{iy}=\left\vert z\right\vert e^{i\arg z}$ \`{e}
necessario e sufficiente che $e^{x}=\left\vert z\right\vert $ e $y=\arg
z+2k\pi $, per cui $\log z=\left\vert z\right\vert +i\left( \arg z+2k\pi
\right) $. Questo significa che ogni numero complesso non nullo ha infiniti
logaritmi: la funzione logaritmo \`{e} polidroma. Si dice logaritmo
principale di $z$, e si indica con $Logz$ il logaritmo che si ottiene con $%
k=0$ e $\arg z\in \left[ -\pi ,\pi \right] $. Il logaritmo complesso
(principale) ha le seguenti propriet\`{a}:%
\begin{gather*}
\text{(1) }\exp \left( Logz\right) =z \\
\text{(2) }Log\left( z_{1}z_{2}\right) \neq Log\left( z_{1}\right)
+Log\left( z_{2}\right) \\
\text{(3) }\exp \left( Log\left( z_{1}z_{2}\right) \right) =\exp \left(
Logz_{1}+Logz_{2}\right) \\
\text{(4) }\exp \left( w+v\right) =\exp \left( w\right) \exp \left( v\right)
\\
\text{(5) }Log\left( 1+z\right) =z-\frac{1}{2}z^{2}+\frac{1}{3}z^{3}-\frac{1%
}{4}z^{4}+o\left( z^{4}\right) \\
\forall \text{ }z\in 
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
:\left\vert z\right\vert <1\text{; }\lim_{z\rightarrow 0}\frac{Log\left(
1+z\right) }{z}=1
\end{gather*}

Vale poi che se $z_{n}\rightarrow z$, $\left( 1+\frac{z_{n}}{n}\right)
^{n}\rightarrow e^{z}$: infatti $\left( 1+\frac{z_{n}}{n}\right)
^{n}=e^{n\log \left( 1+\frac{z_{n}}{n}\right) }=e^{n\left( \frac{z_{n}}{n}%
+o\left( \frac{z_{n}}{n}\right) \right) }=e^{z_{n}}e^{\frac{o\left( \frac{%
z_{n}}{n}\right) }{1/b}}\rightarrow e^{z}$.

\textbf{Teo 25.1 (c'\`{e} sempre uno messo peggio)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ successione } \\
\text{di v.a. r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a, }X_{n}\rightarrow ^{\mathbf{P}}X \\
\text{Ts: }X_{n}\rightarrow ^{\tciLaplace }X
\end{gather*}

Quindi \`{e} la convergenza in legge a essere il tipo di convergenza pi\`{u}
debole.

\textbf{Dim} Voglio mostrare che $\lim_{n\rightarrow +\infty }\mathbf{E}%
\left( h\left( X_{n}\right) \right) =\mathbf{E}\left( h\left( X\right)
\right) $ $\forall $ $h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $: l'idea \`{e} usare qualcosa di simile alla convergenza dominata.
Per le propriet\`{a} della convergenza in probabilit\`{a}, $\forall $ $h$
continua $h\left( X_{n}\right) \rightarrow ^{\mathbf{P}}h\left( X\right) $;
se inoltre $\exists $ $M>0:\left\vert h\left( x\right) \right\vert \leq M$ $%
\forall $ $x$, allora $\left\vert h\left( X_{n}\right) \right\vert \in
L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ $\forall $ $n$, $h\left(
X_{n}\right) \in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ $%
\forall $ $n$ e per 23.10 (2), versione pi\`{u} forte della convergenza
dominata, $\lim_{n\rightarrow +\infty }\mathbf{E}\left( h\left( X_{n}\right)
\right) =\mathbf{E}\left( h\left( X\right) \right) $. $\blacksquare $ !

In generale non vale l'implicazione opposta perch\'{e} l'unicit\`{a} del
limite in legge \`{e} in legge, non \`{e} quasi certa, quindi non sarebbe
ben identificata la v. a. a cui la successione converge in probabilit\`{a};
tranne nel caso che segue.

\textbf{Teo 25.2 (l'implicazione si inverte se la convergenza in legge \`{e}
a una costante)}%
\begin{gather*}
\text{Hp: }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di
probabilit\`{a}, }\left( X_{n}\right) _{n\geq 1}\text{ } \\
\text{successione di v.a. r., }c\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a, }X_{n}\rightarrow ^{\tciLaplace }c \\
\text{Ts: }X_{n}\rightarrow ^{\mathbf{P}}c
\end{gather*}

Occorre che le v. a. siano definite tutte sullo spazio per parlare di
convergenza in probabilit\`{a}.

\textbf{Dim} So che $\lim_{n\rightarrow +\infty }\mathbf{E}\left( h\left(
X_{n}\right) \right) =\mathbf{E}\left( h\left( c\right) \right) $ $\forall $ 
$h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $; voglio mostrare che $\lim_{n\rightarrow +\infty }\mathbf{E}\left( 
\frac{\left\vert X_{n}-c\right\vert }{1+\left\vert X_{n}-c\right\vert }%
\right) =0$. Allora considero $\bar{h}\left( x\right) =\frac{\left\vert
x-c\right\vert }{1+\left\vert x-c\right\vert }$: \`{e} continua perch\'{e}
rapporto di funzioni continue, e superiormente limitata da $1$. Quindi $%
\lim_{n\rightarrow +\infty }\mathbf{E}\left( \bar{h}\left( X_{n}\right)
\right) =\lim_{n\rightarrow +\infty }\mathbf{E}\left( \frac{\left\vert
X_{n}-c\right\vert }{1+\left\vert X_{n}-c\right\vert }\right) =\mathbf{E}%
\left( \bar{h}\left( c\right) \right) =0$. $\blacksquare $

\textbf{Prop 25.3 (propriet\`{a} della convergenza in legge)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1},\left( Y_{n}\right) _{n\geq 1}%
\text{ successioni di v.a. r., }X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }c\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ v.a, } \\
X_{n}\rightarrow ^{\tciLaplace }X\text{, }Y_{n}\rightarrow ^{\tciLaplace }c%
\text{, }h:%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ \`{e} continua} \\
\text{Ts: (1) }P^{X}\text{ \`{e} unica} \\
\text{(2) }aX_{n}\rightarrow ^{\tciLaplace }aX \\
\text{(3) }h\left( X_{n}\right) \rightarrow ^{\tciLaplace }h\left( X\right)
\\
\text{(4) }X_{n}+Y_{n}\rightarrow ^{\tciLaplace }X+c \\
\text{(5) }X_{n}Y_{n}\rightarrow ^{\tciLaplace }cX \\
\text{(6) }\frac{X_{n}}{Y_{n}}\rightarrow ^{\tciLaplace }\frac{X}{c}\text{
se }Y_{n},c\neq 0
\end{gather*}

Nelle ipotesi si suppone implicitamente che ogni $X_{n}$ sia definita su un
diverso spazio di probabilit\`{a}. (4),(5),(6) vengono anche detti teorema di
Slutsky.

\textbf{Dim} (1) \`{e} una conseguenza del teorema di Levy.

(2) Poich\'{e} $\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( h\left(
X_{n}\right) \right) =\mathbf{E}\left( h\left( X\right) \right) $ $\forall $ 
$h\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, allora $\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( g\left(
aX_{n}\right) \right) =\mathbf{E}\left( g\left( aX\right) \right) $ $\forall 
$ $g\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $, poich\'{e} $g$ \`{e} limitata e pu\`{o} inoltre essere vista come
la composizione di $g$ e della funzione continua $ax$, per cui \`{e} ancora
continua e $g\left( ax\right) $ pu\`{o} essere presa come $h$.

(3) So che $\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( f\left(
X_{n}\right) \right) =\mathbf{E}\left( f\left( X\right) \right) $ $\forall $ 
$f\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Voglio mostrare che $\lim_{n\rightarrow +\infty }\mathbf{E}%
_{n}\left( g\left( h\left( X_{n}\right) \right) \right) =\mathbf{E}\left(
g\left( h\left( X\right) \right) \right) $ $\forall $ $g\in C_{b}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\right) $. Ma se $g$ \`{e} limitata, qualsiasi sia $h$, $g\left( h\left(
x\right) \right) $ \`{e} limitata; inoltre $g\left( h\left( x\right) \right) 
$ \`{e} continua perch\'{e} composizione di funzioni continue, quindi $%
g\circ h$ pu\`{o} essere presa come $f$ e vale effettivamente $%
\lim_{n\rightarrow +\infty }\mathbf{E}_{n}\left( g\left( h\left(
X_{n}\right) \right) \right) =\mathbf{E}\left( g\left( h\left( X\right)
\right) \right) $.

$\blacksquare $

Dalla dimostrazione di (3) si ricava che non occorre chiedere $h$ limitata.

Il teorema non vale se $Y_{n}\not\rightarrow ^{\tciLaplace }c$, come si
evince dal seguente esempio.

\begin{enumerate}
\item Siano $Z_{1},Z_{2}\sim iid\mathcal{N}\left( 0,1\right) $. Definisco $%
X_{n}=Z_{1}$ $\forall $ $n$, $Y_{n}=Z_{1}$ $\forall $ $n$: ovviamente $%
X_{n}\rightarrow ^{\tciLaplace }Z_{1}$, $Y_{n}\rightarrow ^{\tciLaplace
}Z_{1}$, ma \`{e} anche vero $Y_{n}\rightarrow ^{\tciLaplace }Z_{2}$. $%
X_{n}+Y_{n}\sim Z_{1}+Z_{1}=2Z_{1}\sim \mathcal{N}\left( 0,4\right) $,
mentre $Z_{1}+Z_{2}\sim \mathcal{N}\left( 0,2\right) $. Quindi non \`{e}
possibile che $X_{n}+Y_{n}$, avendo sempre legge $\mathcal{N}\left(
0,4\right) $, converga in legge a una normale $\mathcal{N}\left( 0,2\right) $%
. La convergenza in legge delle componenti non \`{e} quindi abbastanza
forte: occorrerebbe la convergenza in legge del vettore.

Se aggiungessi anche hp di indipendenza, varrebbe.
\end{enumerate}

\section{Teoremi limite}

Un teorema che fa un'affermazione sulla convergenza della media campionaria 
\`{e} detto legge dei grandi numeri. Se la convergenza \`{e} quasi certa, la
legge \`{e} detta forte.

\textbf{Teo 25.2 (legge forte dei grandi numeri 1)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a. r. su }%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di probabilit\`{a}%
, } \\
\left( X_{n}\right) _{n}\text{ iid, }X_{n}\in L^{1}\left( \Omega ,\mathcal{A}%
,\mathbf{P}\right) \text{ }\forall \text{ }n\text{, }\mathbf{E}\left(
X_{n}\right) =\mu \text{ }\forall \text{ }n\text{, }\bar{X}_{n}=\frac{%
X_{1}+...+X_{n}}{n} \\
\text{Ts: }\bar{X}_{n}\rightarrow \mu \text{ q. c.}
\end{gather*}

Serve che le v. a. siano definite tutte sullo stesso spazio per poter dire
che sono indipendenti. Si noti che il teorema richiede delle ipotesi su $%
\left( X_{n}\right) _{n\geq 1}$, ma la tesi riguarda la convergenza di
un'altra successione, la media campionaria; richiede delle ipotesi di
integrabilit\`{a}, quindi sulla legge delle $X_{n}$ (che $\mathbf{E}\left(
\left\vert X_{n}\right\vert \right) =\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert x\right\vert dP^{X_{n}}\left( x\right) $ esista finito), ma la
tesi riguarda una propriet\`{a} quasi certa secondo $\mathbf{P}$ dello
spazio di partenza. Il significato del teorema \`{e} che la media
campionaria, o media empirica, converge alla media teorica di ogni v. a. (cio%
\`{e} l'andamento orizzontale, delle traiettorie, tende a essere coerente
con "la media che si calcola in verticale"): questo giustifica l'approccio
frequentista alla probabilit\`{a}. Si \`{e} gi\`{a} visto in un esempio
passato che il risultato non pu\`{o} valere certamente. La tesi implica la
convergenza anche in probabilit\`{a}.

Vale in realt\`{a} un risultato pi\`{u} forte: vale anche l'implicazione
inversa.

\textbf{Teo 25.2 (legge forte dei grandi numeri 2)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a. r. su }%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di } \\
\text{probabilit\`{a}, }\left( X_{n}\right) _{n}\text{ iid, }\mu \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{, }\bar{X}_{n}=\frac{X_{1}+...+X_{n}}{n} \\
\text{Ts: }X_{n}\in L^{1}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ 
}\forall \text{ }n\text{ e }\mathbf{E}\left( X_{n}\right) =\mu \text{ }%
\forall \text{ }n\Longleftrightarrow \bar{X}_{n}\rightarrow \mu \text{ q. c.}
\end{gather*}

Si dimostra il teorema nella seguente versione:

\textbf{Teo 25.2 (legge forte dei grandi numeri 3)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a. r. su }%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di probabilit\`{a}%
, }\left( X_{n}\right) _{n}\text{ iid, } \\
X_{n}\in L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ }\forall 
\text{ }n\text{, }\mathbf{E}\left( X_{n}\right) =\mu \text{ }\forall \text{ }%
n\text{, }var\left( X_{n}\right) =\sigma ^{2}\text{, }\bar{X}_{n}=\frac{%
X_{1}+...+X_{n}}{n} \\
\text{Ts: }\bar{X}_{n}\rightarrow \mu \text{ q. c. e }\bar{X}_{n}\rightarrow
^{L^{2}}\mu
\end{gather*}

\textbf{Dim} Posso supporre $\mu =0$ senza perdita di generalit\`{a}: per le
propriet\`{a} delle convergenze basta considerare $\tilde{X}_{n}=X_{n}-\mu $%
. Questo implica $\mathbf{E}\left( X_{n}\right) =0$ e $var\left(
X_{n}\right) =\mathbf{E}\left( X_{n}^{2}\right) $.

(1) Mostro che $\bar{X}_{n}\rightarrow ^{L^{2}}0$. Ogni elemento della
successione $\bar{X}_{n}$ \`{e} in $L^{2}$ perch\'{e} \`{e} uno spazio
vettoriale, $\mu $ ovviamente \`{e} in $L^{2}$, e $\lim_{n\rightarrow
+\infty }\mathbf{E}\left( \left( \bar{X}_{n}-0\right) ^{2}\right)
=\lim_{n\rightarrow +\infty }var\left( \bar{X}_{n}\right)
=\lim_{n\rightarrow +\infty }\frac{\sigma ^{2}}{n}=0$.

(2) Costruisco una sottosuccessione di $\bar{X}_{n}$ che converge a $0$ q.
c. Prendo $\bar{X}_{n^{2}}=\frac{X_{1}+...+X_{n^{2}}}{n^{2}}$ (costituita
dagli elementi $\bar{X}_{1},\bar{X}_{4},\bar{X}_{9}$,...): $\mathbf{E}\left( 
\bar{X}_{n^{2}}\right) =\mu =0$, $var\left( \bar{X}_{n^{2}}\right) =\frac{1}{%
n^{4}}n^{2}\sigma ^{2}=\frac{\sigma ^{2}}{n^{2}}$ per indipendenza.
Considero $\sum_{n=1}^{+\infty }\mathbf{E}\left( \bar{X}_{n^{2}}^{2}\right)
=\sum_{n=1}^{+\infty }\frac{\sigma ^{2}}{n^{2}}<+\infty $ (qui sta il senso
di scegliere proprio $\bar{X}_{n^{2}}$ come sottosuccessione!); ma per 9.4 $%
\sum_{n=1}^{+\infty }\mathbf{E}\left( \bar{X}_{n^{2}}^{2}\right) =\mathbf{E}%
\left( \sum_{n=1}^{+\infty }\bar{X}_{n^{2}}^{2}\right) <+\infty $. Allora $%
\sum_{n=1}^{+\infty }\bar{X}_{n^{2}}^{2}<+\infty $ q. c., essendo $%
\sum_{n=1}^{+\infty }\bar{X}_{n^{2}}^{2}$ una v. a. nonnegativa: quindi $%
\lim_{n\rightarrow +\infty }\bar{X}_{n^{2}}^{2}=0$ q. c. e $%
\lim_{n\rightarrow +\infty }\bar{X}_{n^{2}}=0$, e ho trovato quello che
cercavo.

(3) Mostro, a partire da tale sottosuccessione, che anche $\bar{X}_{n}$
converge a $0$ q. c. $\forall $ $n\geq 1$ chiamo $p\left( n\right) $ un
numero naturale tale che $p^{2}\left( n\right) \leq n\leq \left( p\left(
n\right) +1\right) ^{2}$; ad esempio $p\left( n\right) =\lfloor \sqrt{n}%
\rfloor $. La validit\`{a} delle disuguaglianze implica peraltro $\left( 
\sqrt{n}-1\right) ^{2}\leq p^{2}\left( n\right) \leq n$$%
\Longleftrightarrow \frac{\left( \sqrt{n}-1\right) ^{2}}{n}\leq \frac{%
p^{2}\left( n\right) }{n}\leq 1$, per cui $\lim_{n\rightarrow +\infty }\frac{%
p^{2}\left( n\right) }{n}=1$.

Data la sottosuccessione $\bar{X}_{n^{2}}$, considero la
sottosottosuccessione $\bar{X}_{p^{2}\left( n\right) }$. Poich\'{e} $\bar{X}%
_{n^{2}}\rightarrow 0$ q. c, anche ogni sua sottosuccessione converge a $0$
q. c., per cui $\lim_{n\rightarrow +\infty }\bar{X}_{p^{2}\left( n\right)
}=0 $ q. c.; devo mostrare che $\lim_{n\rightarrow +\infty }\bar{X}_{n}=0$
q.c, quindi mostro che $\lim_{n\rightarrow +\infty }\left( \bar{X}_{n}-\frac{%
p^{2}\left( n\right) }{n}\bar{X}_{p^{2}\left( n\right) }\right) =0$ q. c. $%
\bar{X}_{n}-\frac{p^{2}\left( n\right) }{n}\bar{X}_{p^{2}\left( n\right) }=%
\frac{1}{n}\sum_{i=1}^{n}X_{i}-\frac{p^{2}\left( n\right) }{n}\frac{1}{%
p^{2}\left( n\right) }\sum_{i=1}^{p^{2}\left( n\right) }X_{i}=\frac{1}{n}%
\sum_{i=p^{2}\left( n\right) +1}^{n}X_{i}$ perch\'{e} $n\geq p^{2}\left(
n\right) $: vale quindi $\mathbf{E}\left( \left( \bar{X}_{n}-\frac{%
p^{2}\left( n\right) }{n}\bar{X}_{p^{2}\left( n\right) }\right) ^{2}\right) =%
\mathbf{E}\left( \left( \frac{1}{n}\sum_{i=p^{2}\left( n\right)
+1}^{n}X_{i}\right) ^{2}\right) $ $=\frac{1}{n^{2}}\mathbf{E}\left( \left(
\sum_{i=p^{2}\left( n\right) +1}^{n}X_{i}\right) ^{2}\right) =\frac{1}{n^{2}}%
var\left( \sum_{i=p^{2}\left( n\right) +1}^{n}X_{i}\right) =\allowbreak $ $%
\frac{1}{n^{2}}\sum_{i=p^{2}\left( n\right) +1}^{n}var\left( X_{i}\right) =%
\frac{1}{n^{2}}\sigma ^{2}\left( n-p^{2}\left( n\right) \right) \leq \frac{%
\sigma ^{2}\left( \left( p\left( n\right) +1\right) ^{2}-p^{2}\left(
n\right) \right) }{n^{2}}=\frac{\sigma ^{2}\left( 1+2p\left( n\right)
\right) }{n^{2}}\leq \frac{\sigma ^{2}3p\left( n\right) }{n^{2}}\leq \frac{%
3\sigma ^{2}\sqrt{n}}{n^{2}}=\frac{3\sigma ^{2}}{n^{\frac{3}{2}}}$, la cui
serie converge. Allora si pu\`{o} concludere che $\sum_{n=1}^{+\infty }%
\mathbf{E}\left( \left( \bar{X}_{n}-\frac{p^{2}\left( n\right) }{n}\bar{X}%
_{p^{2}\left( n\right) }\right) ^{2}\right) \leq \sum_{n=1}^{+\infty }\frac{%
3\sigma ^{2}}{n^{\frac{3}{2}}}<+\infty $, per cui anche $\mathbf{E}\left(
\sum_{n=1}^{+\infty }\left( \bar{X}_{n}-\frac{p^{2}\left( n\right) }{n}\bar{X%
}_{p^{2}\left( n\right) }\right) ^{2}\right) <+\infty $, vale a dire che $%
\sum_{n=1}^{+\infty }\left( \bar{X}_{n}-\frac{p^{2}\left( n\right) }{n}\bar{X%
}_{p^{2}\left( n\right) }\right) ^{2}$ \`{e} finita q. c., per cui $%
\lim_{n\rightarrow +\infty }\left( \bar{X}_{n}-\frac{p^{2}\left( n\right) }{n%
}\bar{X}_{p^{2}\left( n\right) }\right) ^{2}=0$ q.c., $\lim_{n\rightarrow
+\infty }\left( \bar{X}_{n}-\frac{p^{2}\left( n\right) }{n}\bar{X}%
_{p^{2}\left( n\right) }\right) =0$ q. c. e $\lim_{n\rightarrow +\infty }%
\bar{X}_{n}=\lim_{n\rightarrow +\infty }\left( \bar{X}_{n}-\frac{p^{2}\left(
n\right) }{n}\bar{X}_{p^{2}\left( n\right) }\right) +\lim_{n\rightarrow
+\infty }\frac{p^{2}\left( n\right) }{n}\bar{X}_{p^{2}\left( n\right) }=0$
perch\'{e} era gi\`{a} noto che $\bar{X}_{p^{2}\left( n\right) }\rightarrow
0 $ q. c. e $\frac{p^{2}\left( n\right) }{n}$ \`{e} limitata da $1$. $%
\blacksquare $

\textbf{Teo 26.1 (teorema centrale del limite)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a. r. su }%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di } \\
\text{probabilit\`{a}, }\left( X_{n}\right) _{n}\text{ iid, }X_{n}\in
L^{2}\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ }\forall \text{ }n%
\text{, }\mathbf{E}\left( X_{n}\right) =\mu \text{ }\forall \text{ }n\text{, 
} \\
var\left( X_{n}\right) =\sigma ^{2}>0\text{, }\bar{X}_{n}=\frac{%
X_{1}+...+X_{n}}{n}\text{, }T_{n}=\frac{\bar{X}_{n}-\mu }{\sqrt{\sigma ^{2}/n%
}}\text{, }Z\sim \mathcal{N}\left( 0,1\right) \\
\text{Ts: }T_{n}\rightarrow ^{\tciLaplace }Z
\end{gather*}

$T_{n}$ \`{e} la media campionaria standardizzata; vale l'unicit\`{a} del
limite solo in legge. Come per la LGN, la tesi riguarda la convergenza di
una successione che non \`{e} quella su cui sono state fatte le ipotesi ($%
\left( X_{n}\right) _{n\geq 1}$ converge in legge a qualsiasi v. a. che
abbia la stessa legge delle $X_{n}$, dato che queste sono identicamente
distribuite).

Il teorema implica che la funzione di ripartizione della media campionaria 
\`{e} $\mathbf{P}\left( \bar{X}_{n}\leq x\right) =\mathbf{P}\left( \frac{%
\bar{X}_{n}-\mu }{\sqrt{\sigma ^{2}/n}}\leq \frac{x-\mu }{\sqrt{\sigma ^{2}/n%
}}\right) \simeq \Phi \left( \frac{x-\mu }{\sqrt{\sigma ^{2}}}\sqrt{n}%
\right) $ per $n\rightarrow +\infty $. Quindi il TCL, rispetto alla LGN, dice qualcosa
anche sulla legge della v. a. limite.

Il TCL implica che per $n\rightarrow +\infty $ $\bar{X}_{n}$ ha legge $%
\mathcal{N}\left( \mu ,\sigma ^{2}\right) $. Inoltre $T_{n}=\frac{n\left( 
\bar{X}_{n}-\mu \right) }{n\sqrt{\sigma ^{2}/n}}=\frac{X_{1}+...+X_{n}-n\mu 
}{\sqrt{n\sigma ^{2}}}=\frac{S_{n}-n\mu }{\sqrt{n\sigma ^{2}}}$: $S_{n}$ 
\`{e} la somma parziale delle $X_{n}$, $\mathbf{E}\left( S_{n}\right) =n\mu $%
, $var\left( S_{n}\right) =n\sigma ^{2}$, quindi $T_{n}$ \`{e} anche la
standardizzata della somma parziale. Il TCL fornisce anche la legge
asintotica delle $S_{n}$, perch\'{e} la funzione di ripartizione delle $%
S_{n} $ \`{e} $\mathbf{P}\left( S_{n}\leq x\right) =\mathbf{P}\left(
T_{n}\leq \frac{x-n\mu }{\sqrt{n\sigma ^{2}}}\right) \simeq \Phi \left( 
\frac{x-n\mu }{\sqrt{n\sigma ^{2}}}\right) $ per $n\rightarrow +\infty $.

Quando sono verificate le ipotesi del TCL, valgono anche quelle della LGN,
per cui \`{e} anche noto che $\bar{X}_{n}\rightarrow \mu $ q. c.: da questo 
\`{e} noto che $\bar{X}_{n}-\mu \rightarrow 0$ q. c., per\`{o} non \`{e}
nota la velocit\`{a} di convergenza. Questa \`{e} data dal TCL, che afferma
che $\frac{\bar{X}_{n}-\mu }{\sqrt{\sigma ^{2}/n}}\rightarrow ^{\tciLaplace
}Z\sim \mathcal{N}\left( 0,1\right) $, fornendo anche il confronto con $%
\sqrt{\frac{\sigma ^{2}}{n}}$.

Se $\sigma ^{2}=0$, ogni $X_{n}$ \`{e} una v. a. costante con legge $\delta
_{\mu }$, quindi converge in legge a $\mu $, normale di media $\mu $ e
varianza $0$.

\textbf{Dim} Suppongo, senza perdita di generalit\`{a}, che $\mu =0$. $%
\mathbf{E}\left( \bar{X}_{n}\right) =0$, quindi $var\left( \bar{X}%
_{n}\right) =\mathbf{E}\left( \bar{X}_{n}^{2}\right) $. Voglio usare il
teorema di Levy, quindi calcolo la funzione caratteristica di $X_{n}$: poich%
\'{e} $X_{n}\in L^{2}$, $\phi _{X_{n}}\in C^{2}\left( 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
,%
%TCIMACRO{\U{2102} }%
%BeginExpansion
\mathbb{C}
%EndExpansion
\right) $ $\forall $ $n$ e vale $\phi _{X_{n}}^{\prime }\left( 0\right) =i%
\mathbf{E}\left( X_{n}\right) =0$, $\phi _{X_{n}}^{\prime \prime }\left(
0\right) =-\mathbf{E}\left( X_{n}^{2}\right) =-\sigma ^{2}$. Allora, per il
teorema di Taylor, $\phi _{X_{n}}\left( v\right) =\phi _{X_{n}}\left(
0\right) +\phi _{X_{n}}^{\prime }\left( 0\right) v+\frac{1}{2}\phi
_{X_{n}}^{\prime \prime }\left( 0\right) v^{2}+o\left( v^{2}\right) =1-\frac{%
1}{2}\sigma ^{2}v^{2}+o\left( v^{2}\right) $. $\phi _{T_{n}}\left( u\right) =%
\mathbf{E}\left( e^{iuT_{n}}\right) =\mathbf{E}\left( e^{iu\frac{\bar{X}%
_{n}-\mu }{\sqrt{\sigma ^{2}/n}}}\right) =\mathbf{E}\left( e^{iu\frac{%
X_{1}+...+X_{n}}{\sigma \sqrt{n}}}\right) $. Questa \`{e} la funzione
caratteristica di $S_{n}$ calcolata in $\frac{u}{\sigma \sqrt{n}}$, cio\`{e} 
$\phi _{X_{1}+...+X_{n}}\left( \frac{u}{\sigma \sqrt{n}}\right) =\left( \phi
_{X_{1}}\left( \frac{u}{\sigma \sqrt{n}}\right) \right) ^{n}$ perch\'{e} le $%
X_{n}$ sono indipendenti e identicamente distribuite. Allora si ha $\phi
_{T_{n}}\left( u\right) =\left( \phi _{X_{1}}\left( \frac{u}{\sigma \sqrt{n}}%
\right) \right) ^{n}=\left( 1-\frac{1}{2}\frac{u^{2}}{n}+o\left( \frac{u^{2}%
}{\sigma ^{2}n}\right) \right) ^{n}=\left( 1+\frac{z_{n}}{n}\right) ^{n}$
con $z_{n}=-\frac{1}{2}u^{2}+no\left( \frac{u^{2}}{\sigma ^{2}n}\right) $,
che, se $\lim_{n\rightarrow +\infty }z_{n}=z$, per $n\rightarrow +\infty $
converge a $e^{z}$. Poich\'{e} $z=\frac{-1}{2}u^{2}$, $\phi _{T_{n}}\left(
u\right) $ converge puntualmente a $e^{-\frac{1}{2}u^{2}}$, funzione
caratteristica di una normale standard. Allora $T_{n}$ converge in legge a
una normale standard per il corollario al teorema di Levy. $\blacksquare $

\subsection{Applicazioni}

\begin{description}
\item[1] Sia $S_{n}\sim \chi ^{2}\left( n\right) $. $%
S_{n}=^{D}Z_{1}^{2}+...+Z_{n}^{2}$, con $Z_{1},...,Z_{n}\sim iid\mathcal{N}%
\left( 0,1\right) $. $Z_{k}^{2}\in L^{2}$ $\forall $ $k$ (perch\'{e} $%
\int_{-\infty }^{+\infty }x^{p}e^{-\frac{1}{2}x^{2}}dx<+\infty $ $\forall $
), quindi posso applicare il TLC alla successione $\left( Z_{k}^{2}\right)
_{k\geq 1}$: $\frac{S_{n}-\mathbf{E}\left( S_{n}\right) }{\sqrt{var\left(
S_{n}\right) }}$ converge in legge a una normale standard. $\mathbf{E}\left(
S_{n}\right) =n$ perch\'{e} $\mathbf{E}\left( Z_{1}^{2}\right) =1$, $%
var\left( S_{n}\right) =var\left( Z_{1}^{2}\right) +...+var\left(
Z_{n}^{2}\right) $. $var\left( Z_{i}^{2}\right) =2$ perch\'{e} \`{e} la
varianza di una $\chi ^{2}\left( 1\right) $, quindi $var\left( S_{n}\right)
=2n$. Allora $\mathbf{P}\left( S_{n}\leq x\right) =\Phi \left( \frac{x-n}{%
\sqrt{2n}}\right) $: in questo modo si possono calcolare facilmente i
quantili della chi-quadro.

\item[2] Sia $V_{n}\sim t\left( n\right) $. Si \`{e} gi\`{a} visto che $%
f_{V_{n}}\left( t\right) \rightarrow f_{Z}\left( t\right) $ $\forall $ $t$,
dove $Z\sim \mathcal{N}\left( 0,1\right) $: allora, per il lemma di Scheff%
\'{e}, $V_{n}\rightarrow ^{\tciLaplace }Z$. Si pu\`{o} dimostrare anche
considerando che $V_{n}=^{D}\frac{Z}{\sqrt{S_{n}/n}}$ con $Z\sim \mathcal{N}%
\left( 0,1\right) $, $S_{n}\sim \mathcal{\chi }^{2}\left( n\right) $, $%
Z\perp S_{n}$. Poich\'{e} $\frac{S_{n}}{n}=\bar{X}_{n}\rightarrow \mu =1$ q.
c. per la LGN applicata a $\left( Z_{n}^{2}\right) _{n\geq 1}$, che ha $%
\mathbf{E}\left( Z_{i}^{2}\right) =1$, per le propriet\`{a} della
convergenza quasi certa $\frac{1}{\sqrt{S_{n}/n}}\rightarrow 1$ q. c. e $%
\frac{Z}{\sqrt{S_{n}/n}}\rightarrow \frac{Z}{1}$ q. c. Poich%
\'{e} per\`{o} $Z$ \`{e} definita solo limitatamente alla legge e $V_{n}=%
\frac{Z}{\sqrt{S_{n}/n}}$ solo in legge, si pu\`{o} dedurre che $V_{n}=\frac{%
Z}{\sqrt{S_{n}/n}}\rightarrow ^{\tciLaplace }Z$.

\item[3] Sia $X_{n}\sim bin\left( n,p\right) $, $Y_{k}\sim b\left( p\right) $
iid. So che $X_{n}=^{D}Y_{1}+...+Y_{n}=S_{n}$: allora, applicando il TLC
alle $Y_{k}$ ($Y_{k}\in L^{2}$, $\mathbf{E}\left( Y_{k}\right) =p$, $%
var\left( Y_{k}\right) =p\left( 1-p\right) $ $\forall $ $k$), si ha che $%
\frac{S_{n}-np}{\sqrt{np\left( 1-p\right) }}\rightarrow ^{\tciLaplace }Z$,
cio\`{e} $S_{n}$ ha distribuzione approssimativamente $\mathcal{N}\left(
np,np\left( 1-p\right) \right) $ per $n$ grandi, e $\mathbf{P}\left(
X_{n}\leq x\right) \simeq \Phi \left( \frac{x-np}{\sqrt{np\left( 1-p\right) }%
}\right) $.
\end{description}

\subsection{Funzione di ripartizione empirica}

Suppongo di avere una v. a. $X$ con legge sconosciuta e di voler stimare la
funzione di ripartizione della sua legge: \`{e} un tipo di inferenza molto pi%
\`{u} complesso dell'inferenza parametrica, condotto sulla base di un
campione casuale estratto dalla legge di $X$.

\textbf{Def} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, $X:\Omega \rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ variabile aleatoria con legge $P^{X}$, $X_{1},...,X_{n}\sim iidP^{X}$, si
dice funzione di ripartizione empirica $F_{n}\left( t\right) =\frac{1}{n}%
\sum_{k=1}^{n}I_{(-\infty ,t]}\left( X_{k}\right) $.

La funzione di ripartizione empirica approssima $F_{X}\left( t\right) $ con
la frequenza relativa di variabili aleatorie del campione che stanno
effettivamente in $(-\infty ,t]$. $F_{n}$ non \`{e} una funzione
deterministica, ma stocastica, perch\'{e} dipende dal campione casuale: $%
F_{n}\left( t\right) =\frac{1}{n}\sum_{k=1}^{n}I_{(-\infty ,t]}\left(
X_{k}\left( \omega \right) \right) $.

Si noti che $F_{n}\left( t\right) $ \`{e} effettivamente una funzione di
ripartizione, di puro salto.

\begin{enumerate}
\item Sia $n=4$, $x_{1},x_{2},x_{3},x_{4}$ la realizzazione di 4 v. a.
estratte dalla legge di $X$, e siano $x_{4}=-1,x_{2}=1,x_{1}=2,x_{3}=4$. Con
questo campione posso costruire una realizzazione della fdr empirica: $%
F_{n}\left( t\right) =\left\{ 
\begin{array}{c}
0\text{ se }t<-1 \\ 
\frac{1}{4}\text{ se }t\in \lbrack -1,1) \\ 
\frac{1}{2}\text{ se }t\in \lbrack 1,2) \\ 
\frac{3}{4}\text{ se }t\in \lbrack 2,4) \\ 
1\text{ se }t\geq 4%
\end{array}%
\right. $.
\end{enumerate}

Fissato $t$, $\left( F_{n}\left( t\right) \right) _{n\geq 1}$ \`{e} una
successione di variabili aleatorie che mira a stimare $F_{X}\left( t\right) $%
. Definisco $V_{k}=I_{(-\infty ,t]}\left( X_{k}\right) $: $V_{k}\sim b\left(
p\right) $ con $p=\mathbf{P}\left( X_{k}\leq t\right) =F_{X_{k}}\left(
t\right) =F_{X}\left( t\right) $ perch\'{e} le v. a. sono identicamente
distribuite. Allora $F_{n}\left( t\right) =\frac{1}{n}\sum_{k=1}^{n}V_{k}=%
\bar{V}_{k}$: \`{e} una media campionaria di bernoulli. $F_{n}\left(
t\right) $ ha le seguenti propriet\`{a}:

\begin{description}
\item[P1] $\mathbf{E}\left( F_{n}\left( t\right) \right) =F_{X}\left(
t\right) $: fissato $t$, il valore atteso dello stimatore coincide con il
valore da stimare, quindi si dice che lo stimatore \`{e} corretto per $%
F_{X}\left( t\right) $ $\forall $ $t$.

\item[P2] $var\left( F_{n}\left( t\right) \right) =\frac{F_{X}\left(
t\right) \left( 1-F_{X}\left( t\right) \right) }{n}$: fissato $t$, $%
\lim_{n\rightarrow +\infty }var\left( F_{n}\left( t\right) \right) =0$,
quindi si dice che lo stimatore \`{e} consistente.

\item[P3] Per la LGN $F_{n}$ converge a $F_{X}\left( t\right) $ q. c. Per il
TCL $\frac{F_{n}\left( t\right) -F_{X}\left( t\right) }{var\left(
F_{n}\left( t\right) \right) }$ converge in legge a una normale standard.
\end{description}

Tutte queste propriet\`{a} per\`{o} valgono per $t$ fissato: non riguardano
la funzione globalmente. Ad esempio, la convergenza q. c. in P3 significa
che l'insieme $A=\left\{ \omega :\lim_{n\rightarrow +\infty }F_{n}\left(
t\right) =F_{X}\left( t\right) \right\} :\mathbf{P}\left( A\right) =1$
dipende da $t$, cio\`{e} $A=A\left( t\right) $. E' possibile che non si
riesca a trovare un insieme che sia di probabilit\`{a} $1$ $\forall $ $t$.
Il seguente teorema fornisce informazioni globali sulla funzione.

\textbf{Teorema di Glivenko-Cantelli}
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 1}\text{ successione di v.a. r. su }%
\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{ spazio di probabilit\`{a}%
, } \\
\left( X_{n}\right) _{n}\text{ iid, }F_{n}\left( t\right) =\frac{1}{n}%
\sum_{k=1}^{n}I_{(-\infty ,t]}\left( X_{k}\right) \\
\text{Ts: }\lim_{n\rightarrow +\infty }\sup_{t\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left\vert F_{n}\left( t\right) -F_{X}\left( t\right) \right\vert =0\text{
q. c. }
\end{gather*}

Il teorema afferma che l'insieme degli $\omega $ per cui $F_{n}\left(
t\right) $ converge uniformemente a $F_{X}\left( t\right) $ \`{e} un evento
di probabilit\`{a} $1$.

\section{Catene di Markov}

Data successione di v. a. $\left( X_{n}\right) _{n\geq 1}$, l'indice $n$ pu%
\`{o} essere interpretato come indice temporale, per cui la successione
modella l'evoluzione nel tempo di un fenomeno aleatorio. La convergenza di $%
\left( X_{n}\right) _{n\geq 1}$ \`{e} gi\`{a} stata studiata nel caso in cui
le $X_{n}$ siano iid: ora togliamo questa ipotesi.

\textbf{Def 27.1} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( E,\mathcal{E}\right) $ spazio misurabile
e una famiglia di variabili aleatorie $\left( X_{t}\right) _{t\in T}$ con $T=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{+}$ o $T=I$ intervallo, $\left( X_{t}\right) _{t\in T}$ si dice processo
stocastico (o aleatorio) se $\forall $ $t$ $X_{t}:\left( \Omega ,\mathcal{A},%
\mathbf{P}\right) \rightarrow \left( E,\mathcal{E}\right) $. In tal caso $E$ 
\`{e} detto spazio degli stati e ogni suo elemento \`{e} detto stato. Se in
particolare $T=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ e $E$ \`{e} discreto, il processo stocastico $\left( X_{n}\right) _{n\geq
0}$ \`{e} detto catena.

Il processo stocastico \`{e} una nozione generalizzata rispetto alle
successioni di v. a. gi\`{a} viste: infatti l'indice dell'insieme $t$ pu\`{o}
anche essere continuo, a differenza dell'indice delle successioni. Una
catena \`{e} quindi una successione di v. a. - indicizzata su $%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$ - definite su uno stesso spazio a valori in uno spazio discreto.

Fissato $\omega $, $\left( X_{t}\left( \omega \right) \right) _{t\in T}$ 
\`{e} una funzione da $T$ in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$. In tal caso il grafico di $\left( X_{t}\left( \omega \right) \right)
_{t\in T}$ come funzione di $t$ \`{e} detto traiettoria della catena.

\begin{enumerate}
\item Suppongo di lanciare una moneta infinite volte; sia $X_{n}\left(
\omega \right) $ una v. a. che vale $1$ se all'$n$-esimo lancio esce testa, $%
0$ altrimenti. Quindi $E=\left\{ 0,1\right\} $; uno spazio campionario
plausibile \`{e} $\Omega =\left\{ 0,1\right\} ^{%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
}$. $\left( X_{n}\right) _{n\geq 1}$ \`{e} una catena, ma le $X_{n}$ sono
ancora iid.

\item Sia $X_{n}$ il meteo in una certa localit\`{a} al giorno $n$. $%
E=\left\{ \text{sole, pioggia, nuvole}\right\} $, quindi $\left(
X_{n}\right) _{n\geq 1}$ \`{e} una catena. In questo caso le $X_{n}$ non
sono indipendenti, perch\'{e} il meteo in un certo giorno non \`{e}
indipendente dal meteo del giorno precedente.

\item Suppongo che un giocatore con un capitale iniziale $X_{0}=6$ punti
1\euro\ sull'uscita del 6 in un certo gioco. Sia $X_{n}$ la v. a. che
descrive il capitale del giocatore dopo l'$n$-esimo lancio; $E\subseteq 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, quindi $\left( X_{n}\right) _{n\geq 1}$ \`{e} una catena. La traiettoria
della catena dipende da $X_{0}$ e dal meccanismo del gioco: in particolare,
conoscendo $X_{n}$ \`{e} possibile fare previsioni su $X_{n+1}$.
\end{enumerate}

\textbf{Def 27.2} Dato un insieme $E:\left\vert E\right\vert <+\infty $ e $%
P\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( \left\vert E\right\vert ,\left\vert E\right\vert \right) $, $P$ si
dice matrice di transizione (o stocastica) se $p_{ij}\geq 0$ $\forall $ $%
i,j\in E$ e $\forall $ $i\in E$ vale $\sum_{j\in E}p_{ij}=1$. Se inoltre $%
\forall $ $j\in E$ $\sum_{i\in E}p_{ij}=1$, $P$ si dice bistocastica.

\begin{enumerate}
\item Se $P$ \`{e} stocastica, anche $P^{n}$ \`{e} stocastica $\forall $ $%
n>1 $. Infatti $\left( P^{2}\right) _{ij}=\left\langle
R_{i},C_{j}\right\rangle $, e $\sum_{j\in E}\left( P^{2}\right)
_{ij}=\left\langle R_{i},C_{1}+...+C_{\left\vert E\right\vert }\right\rangle
=\left\langle R_{i},\left( 1|...|1\right) ^{T}\right\rangle =\sum_{j\in
E}p_{ij}=1$. Di conseguenza il prodotto di due matrici stocastiche \`{e}
stocastico e $P^{n}$ \`{e} stocastica.

Se $P_{i}$ \`{e} stocastica $\forall $ $i=1,...,n$, $\sum_{i=1}^{n}P_{i}$
non \`{e} una matrice stocastica, ma lo \`{e} $\frac{1}{n}%
\sum_{i=1}^{n}P_{i} $.

\item Se $P$ \`{e} stocastica ed \`{e} simmetrica, allora \`{e} anche
bistocastica.
\end{enumerate}

C'\`{e} una relazione biunivoca tra $P$ e un grafo: una matrice di
transizione $P$ codifica le stesse informazioni di un grafo orientato avente 
$\left\vert E\right\vert $ nodi, numerati da $1$ a $\left\vert E\right\vert $%
, ciascuno collegato a se stesso e a tutti gli altri mediante archi
orientati in modo che sulla freccia che collega il nodo $i$ al nodo $j$ \`{e}
scritto il valore $p_{ij}$. Per ogni nodo la somma dei valori scritti su
tutti gli archi uscenti dal nodo deve essere $1$. Ogni arco assente \`{e}
equivalente a un arco di valore $0$; ogni arco senza scritte reca valore $1$%
. $P$ ha ovviamente un significato probabilistico.

\textbf{Def 27.3} Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $
spazio di probabilit\`{a}, $\left( E,\mathcal{E}\right) $ spazio misurabile
con $\left\vert E\right\vert <+\infty $ e $\mathcal{E}=2^{E}$, $v$ densit%
\`{a} discreta su $E$, $P$ matrice di transizione e $\left( X_{n}\right)
_{n\geq 1}$ processo stocastico con $X_{n}:\Omega \rightarrow E$ $\forall $ $%
n$, si dice che $\left( X_{n}\right) _{n\geq 0}$ \`{e} una catena di Markov
omogenea con legge iniziale $v$ e matrice di transizione $P$, e si scrive $%
\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $, se

\begin{description}
\item[M1] $\mathbf{P}\left( X_{0}=i\right) =v_{i}$ $\forall $ $%
i=1,...,\left\vert E\right\vert $

\item[M2] $\mathbf{P}\left(
X_{n+1}=j|X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i\right) =\mathbf{P}\left(
X_{n+1}=j|X_{n}=i\right) =p_{ij}$ $\forall $ $i_{0},i_{1},...,i,j\in E$, $%
\forall $ $n\geq 0$
\end{description}

$v$ densit\`{a} discreta su $E$ implica che $v$ possa essere scritta come
vettore in $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{\left\vert E\right\vert }$, avendo ordinato gli elementi di $E$ con
cardinalit\`{a} finita, per cui $v=\left( v_{1},...,v_{k}\right) $, $%
v_{i}\geq 0$ $\forall $ $i\in E$, $\sum_{i\in E}v_{i}=1$. La prima propriet%
\`{a} significa che $X_{0}\sim v$, cio\`{e} la legge di $X_{0}$ \`{e}
discreta con densit\`{a} $v$ (la definizione implica peraltro che tutte le $%
X_{n}$ sono discrete). La seconda, detta propriet\`{a} di Markov, significa
che la previsione dello stato al tempo $n+1$ dipende solo dallo stato al
tempo $n$ e non \`{e} influenzato da tutti gli stati precedenti: in questo
sta il significato modellistico delle catene di Markov, il quale le rende
adatte a descrivere fenomeni in cui "il passato non influenza il futuro". $%
p_{ij}$ esprime quindi la probabilit\`{a} di passare dallo stato $i$ allo
stato $j$ (in un passo).

La propriet\`{a} di Markov vale $\forall $ $n$, per cui $\mathbf{P}\left(
X_{n+1}=j|X_{n}=i\right) =\mathbf{P}\left( X_{1}=j|X_{0}=i\right) =p_{ij}$ $%
\forall $ $n$: la propriet\`{a} per cui probabilit\`{a} di transizione non
dipende da $n$ \`{e} detta omogeneit\`{a} nel tempo.

$v$ e $P$ sono sufficienti a descrivere il processo.

\begin{enumerate}
\item Dati $a,b\in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
$, Albus ha $a$ galeoni, Bellatrix ne ha $b$. Viene lanciata una moneta: se
esce testa (con probabilit\`{a} $p$) Albus riceve un galeone da Bellatrix,
altrimenti accade il contrario. Il gioco prosegue lanciando monete finch\'{e}
uno dei due non esaurisce i galeoni; per semplicit\`{a} si suppone che le
monete siano lanciate infinite volte, ma che il processo ci interessi fino
all'esaurimento dei galeoni (altrimenti il tempo di durata del gioco $T$
sarebbe aleatorio). Sia $X_{n}$ la v. a. che descrive il numero di galeoni
di Albus: $E=\left\{ 0,...,a+b\right\} $; $X_{0}=a$ q. c., quindi $X_{0}\sim
\delta _{a}=v$. $\mathbf{P}\left( X_{n+1}=j|X_{n}=i\right) =0$ se $j\neq
i+1,i-1$; $\mathbf{P}\left( X_{n+1}=i+1|X_{n}=i\right) =p$, mentre $\mathbf{P%
}\left( X_{n+1}=i-1|X_{n}=i\right) =1-p$, $\forall $ $i,j\neq 0$; nei casi
in cui il gioco finisce si ha invece $\mathbf{P}\left(
X_{n+1}=0|X_{n}=0\right) =1=\mathbf{P}\left( X_{n+1}=a+b|X_{n}=a+b\right) $.
Quindi la matrice di transizione \`{e} $P\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( a+b+1,a+b+1\right) $, $P=\left[ 
\begin{array}{ccccc}
1 & p & 0 & ... & 0 \\ 
1-p & 0 & p & ... & 0 \\ 
0 & 1-p & 0 & ... & 0 \\ 
... & ... & ... & ... & ... \\ 
0 & 0 & ... & 1-p & 1%
\end{array}%
\right] $, tridiagonale.

\item Considero un'urna con $N$ palline bianche e nere; a ogni istante pesco
una pallina e la sostituisco con una pallina dell'altro colore. Sia $X_{n}$
il numero di palline nere nell'urna dopo l'$n$-esima estrazione: $E=\left\{
0,...,N\right\} $. $X_{0}\sim v$? $P\left( X_{n+1}=j|X_{n}=i\right) =0$ se $%
j\neq i+1,i-1$; $\mathbf{P}\left( X_{n+1}=1|X_{n}=0\right) =1$ perch\'{e} le
palline sono tutte bianche, $\mathbf{P}\left( X_{n+1}=2|X_{n}=1\right) =%
\frac{N-1}{N}$,...., $\mathbf{P}\left( X_{n+1}=N|X_{n}=N-1\right) =\frac{1}{N%
}$, mentre viceversa $\mathbf{P}\left( X_{n+1}=0|X_{n}=1\right) =\frac{1}{N}$%
, $\mathbf{P}\left( X_{n+1}=1|X_{n}=2\right) =\frac{2}{N}$,...., $\mathbf{P}%
\left( X_{n+1}=N-1|X_{n}=N\right) =1$ perch\'{e} le palline sono tutte nere. 
$P\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( N+1,N+1\right) $, $P=\left[ 
\begin{array}{ccccc}
0 & 1 & 0 & ... & 0 \\ 
\frac{1}{N} & 0 & \frac{N-1}{N} & ... & 0 \\ 
... & ... & ... & ... & ... \\ 
0 & ... & \frac{N-1}{N} & 0 & \frac{1}{N} \\ 
0 & 0 & ... & 1 & 0%
\end{array}%
\right] $. Lo stesso processo descrive la situazione fisica di due
contenitori comunicanti, con molecole di gas all'interno, in cui a ogni
istante si sposta una molecola; $X_{n}$ descrive il numero di molecole nel
primo recipiente.

\item Considero una successione di v.a. iid $\left( X_{n}\right) _{n\geq 1}$
a valori in $E:\left\vert E\right\vert <+\infty $, con $P^{X_{n}}=v$ $%
\forall $ $n$; $X_{0}\sim v$ \`{e} la distribuzione iniziale. $\left(
X_{n}\right) _{n\geq 1}$ \`{e} una catena di Markov perch\'{e} $\mathbf{P}%
\left( X_{n+1}=j|X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i\right) =\frac{\mathbf{P}%
\left( X_{n+1}=j,X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i\right) }{\mathbf{P}%
\left( X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i\right) }=\mathbf{P}\left(
X_{n+1}=j\right) =\mathbf{P}\left( X_{n+1}=j|X_{n}=i\right) $ perch\'{e} la
probabilit\`{a} si fattorizza per v. a. indipendenti. $P=\left[ 
\begin{array}{ccc}
v\left( 1\right) & ... & v\left( \left\vert E\right\vert \right) \\ 
... & ... & ... \\ 
v\left( 1\right) & ... & v\left( \left\vert E\right\vert \right)%
\end{array}%
\right] $.
\end{enumerate}

\textbf{Teo 27.4 (legge congiunta dei primi }$n$ \textbf{elementi di una
catena)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \\
\text{Ts: }\mathbf{P}\left( X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i_{n}\right)
=v_{i_{0}}p_{i_{0}i_{1}}...p_{i_{n-1}i_{n}}
\end{gather*}

Quindi conoscere $v$ e $P$ \`{e} sufficiente per fare previsioni sui primi $%
n $ elementi di una catena: la legge congiunta $P^{\left(
X_{0},...,X_{n}\right) }\left( i_{0},...,i_{n}\right) $ dei primi $n$
elementi \`{e} caratterizzata dalla legge iniziale e dalla matrice di
transizione. Intuitivamente infatti \`{e} la probabilit\`{a} di essere nello
stato $i_{0}$, di passare da $i_{0}$ a $i_{1}$, ecc.

\textbf{Dim} Sia $\mathbf{P}\left(
X_{0}=i_{0},X_{1}=i_{1},...,X_{n-1}=i_{n-1}\right) >0$. Per la formula di
moltiplicazione $\mathbf{P}\left(
X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i_{n}\right) =$ $\mathbf{P}\left(
X_{n}=i_{n}|X_{0}=i_{0},...,X_{n-1}=i_{n-1}\right) \mathbf{P}\left(
X_{n-1}=i_{n-1}|X_{0}=i_{0},...,X_{n-2}=i_{n-2}\right) ...\mathbf{P}\left(
X_{1}=i_{1}|X_{0}=i_{0}\right) \mathbf{P}\left( X_{0}=i_{0}\right) $.
Questo, per la propriet\`{a} di Markov, \`{e} $\mathbf{P}\left(
X_{n}=i_{n}|X_{n-1}=i_{n-1}\right) \mathbf{P}\left(
X_{n-1}=i_{n-1}|X_{n-2}=i_{n-2}\right) ...\mathbf{P}\left(
X_{1}=i_{1}|X_{0}=i_{0}\right) \mathbf{P}\left( X_{0}=i_{0}\right) $ $%
=p_{i_{n-1}i_{n}}p_{i_{n-2}i_{n-1}}...p_{i_{0}i_{1}}v_{i_{0}}$.

Se invece $\mathbf{P}\left( X_{0}=i_{0},...,X_{n-1}=i_{n-1}\right) =0$, $%
\mathbf{P}\left( X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i_{n}\right) =0$. Se $%
\mathbf{P}\left( X_{0}=i_{0}\right) =0$, si ha la tesi perch\'{e} allora $%
\mathbf{P}\left( X_{1}=i_{1}|X_{0}=i_{0}\right) =0$. Se invece $\mathbf{P}%
\left( X_{0}=i_{0}\right) \neq 0$, $\mathbf{P}\left(
X_{0}=i_{0},X_{1}=i_{1},...,X_{n}=i_{n}\right) =\mathbf{P}\left(
X_{1}=i_{1},...,X_{n}=i_{n}|X_{0}=i_{0}\right) \mathbf{P}\left(
X_{0}=0\right) =0$ implica $\mathbf{P}\left(
X_{1}=i_{1},...,X_{n}=i_{n}|X_{0}=i_{0}\right) =\mathbf{P}\left(
X_{1}=i_{1}|X_{0}=i_{0}\right) =0$, cio\`{e} $p_{i_{0}i_{1}}=0$, da cui la
tesi.
$\blacksquare $

Da 27.4 \`{e} evidente che se $v$ cambia la legge congiunta cambia. Se $%
v=\delta _{i}$, la partenza \`{e} deterministica perch\'{e} $\mathbf{P}%
\left( X_{0}=i\right) =1$ e l'aleatoriet\`{a} \`{e} tutta governata da $P$
(questo accade e. g. se $X_{i}$ rappresenta il capitale al tempo $i$);
altrimenti, sia la partenza che l'evoluzione sono casuali.

Suppongo ora, data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $%
, di osservare la catena al tempo $n=0$: si verifica l'evento $X_{0}=i$, con 
$i\in E$. E' naturale che, se si calcolano probabilit\`{a} relative alla
catena tenendo conto di questa informazione, non ci sia alcuna differenza
rispetto alle probabilit\`{a} relative a un catena $\left( \tilde{X}%
_{n}\right) _{n\geq 0}\sim CM\left( \delta _{i},P\right) $. Si introduce una
notazione atta a descrivere questa situazione.

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
con $i\in E$ e $v_{i}=\mathbf{P}\left( X_{0}=i\right) >0$, si definisce $%
\mathbf{P}_{i}:\mathcal{A}\rightarrow \left[ 0,1\right] ,\mathbf{P}%
_{i}\left( A\right) :=\mathbf{P}\left( A|X_{0}=i\right) $ $\forall $ $A\in 
\mathcal{A}$.

\textbf{Corollario 28.1 (catena di Markov condizionata allo stato iniziale)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }v_{i}>0 \\
\text{Ts: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta _{i},P\right) 
\text{ su }\left( \Omega ,\mathcal{A},\mathbf{P}_{i}\right)
\end{gather*}

La tesi non \`{e} scontata, perch\'{e} in generale sostituendo $\mathbf{P}$
con una legge qualsiasi non si ha alcuna garanzia sul fatto che si ottenga
ancora una catena di Markov.

\textbf{Dim} Se si \`{e} venuti in possesso dell'informazione $X_{0}=i$,
effettivamente $P^{X_{0}}=\delta _{i}$. Dimostro che $\mathbf{P}_{i}\left(
X_{n+1}=j|X_{0}=i_{0},...,X_{n}=k\right) =\mathbf{P}_{i}\left(
X_{n+1}=j|X_{n}=k\right) =p_{kj}$. Infatti, poich\'{e} $\mathbf{P}\left(
\left( A|B\right) |C\right) =\mathbf{P}\left( A|\left( B\cap C\right)
\right) $, $\mathbf{P}_{i}\left( X_{n+1}=j|X_{0}=i_{0},...,X_{n}=k\right) =%
\mathbf{P}\left( X_{n+1}=j|X_{0}=i_{0},...,X_{n}=k,X_{0}=i\right) =\mathbf{P}%
\left( X_{n+1}=j|X_{0}=i,...,X_{n}=k\right) $, che per la propriet\`{a} di
Markov \`{e} $\mathbf{P}\left( X_{n+1}=j|X_{n}=k\right) =p_{kj}$: quindi $%
\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta _{i},P\right) $ anche su $%
\left( \Omega ,\mathcal{A},\mathbf{P}_{i}\right) $. $\blacksquare $

Se $\left\vert E\right\vert =k$, si indica la legge iniziale $v$ con il
vettore riga $\left( v_{1},...,v_{k}\right) $. Vale $\left( vP\right)
_{j}=\sum_{i\in E}v_{i}P_{ij}=\sum_{i\in E}\mathbf{P}\left( X_{0}=i\right) 
\mathbf{P}\left( X_{1}=j|X_{0}=i\right) $: questa \`{e} la formula delle
probabilit\`{a} totali per $\mathbf{P}\left( X_{1}=j\right) $, disintegrando 
$\left( X_{1}=j\right) $ con gli eventi $\left( X_{0}=i\right) $, al variare
di $i\in E$. Una formula analoga vale per $\mathbf{P}\left( X_{n}=j\right) $
con $n$ generico, come mostra 28.2 (1).

Per convenzione $P^{0}=Id$; $P^{1}=P$. Vale $P^{2}\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( k,k\right) $, $P_{ij}^{2}=\sum_{k\in E}p_{ik}p_{kj}$,..., $%
P_{ij}^{n}=\sum_{k_{1},...,k_{n-1}\in
E}p_{ik_{1}}p_{k_{1}k_{2}}...p_{k_{n-1}j}$. Si indica con $p_{ij}^{\left(
n\right) }$ il numero $\left( P^{\left( n\right) }\right) _{ij}$, con $%
v^{\left( n\right) }$ la legge della catena al tempo $n$ $P^{X_{n}}$.

\textbf{Teorema 28.2 (legge delle }$X_{n}$, \textbf{legge congiunta)} 
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, } \\
n,m\geq 0,n_{1},...,n_{l}>0,i_{1},...,i_{l}\in E \\
\text{Ts: (1) }v^{\left( n\right) }=v^{\left( 0\right) }P^{n} \\
\text{(2) }p_{ij}^{\left( n\right) }=\mathbf{P}\left(
X_{n+m}=j|X_{m}=i\right) =\mathbf{P}_{i}\left( X_{n}=j\right) \\
\text{(3) }\mathbf{P}\left( X_{n_{1}}=i_{1},...X_{n_{l}}=i_{l}\right)
=\sum_{i\in E}v_{i}^{\left( 0\right) }p_{ii_{1}}^{\left( n_{1}\right)
}p_{i_{1}i_{2}}^{\left( n_{2}-n_{1}\right) }...p_{i_{l-1}i_{l}}^{\left(
n_{l}-n_{l-1}\right) }
\end{gather*}

Il teorema \`{e} enunciato nell'ipotesi che le probabilit\`{a} condizionate
abbiano senso.

$v_{n}$ \`{e} la legge di $X_{n}$, che essendo definita su $E$ di cardinalit%
\`{a} finita pu\`{o} anche essere scritta come un vettore di $%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{\left\vert E\right\vert }$, che \`{e} il risultato del prodotto di $%
v^{\left( 0\right) }$, vettore della legge iniziale, e $P^{n}$. (1) \`{e},
per componenti, $\mathbf{P}\left( X_{n}=j\right) =\left( vP^{n}\right) _{j}$ 
$\forall $ $j\in E$.

(2) con $m=0$, cio\`{e} la seconda uguaglianza della tesi, deriva da (1)
vedendo la catena come $\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta
_{i},P\right) $, per cui $\mathbf{P}\left( X_{n}=j|X_{0}=i\right) =\delta
_{i}P^{n}$.

Mentre $P$ contiene le probabilit\`{a} che regolano il passaggio da un certo
stato in $X_{m}$ a un certo in $X_{m+1}$, le probabilit\`{a} sul passaggio
da uno stato in $X_{m}$ a un altro in $X_{m+n}$ sono contenute in $P^{n}$,
detta matrice di transizione a $n$ passi: $\left( P^{n}\right) _{ij}$ \`{e}
la probabilit\`{a} di passare da $i$ a $j$ in $n$ passi.

Il significato di (3) \`{e} calcolare la probabilit\`{a} congiunta di un
sottinsieme della successione (non necessariamente di elementi contigui)
come probabilit\`{a} di arrivare a $i_{1}$ in $n_{1}$ passi ($%
p_{i_{1}}^{\left( n_{1}\right) }$), a $i_{2}$ in $n_{2}-n_{1}$ passi,...
ecc., senza conoscere il valore di $X_{0}$ e quindi sommando su $%
v_{i}^{\left( 0\right) }$ al variare di $i\in E$.

\textbf{Dim} (1) Dimostro che $\forall $ $j\in E$ $\mathbf{P}\left(
X_{n}=j\right) =\sum_{i\in E}\mathbf{P}\left( X_{0}=i\right) P_{ij}^{n}$. E'
noto che ! $P_{ij}^{n}=\sum_{k_{1},...,k_{n-1}\in
E}p_{ik_{1}}p_{k_{1}k_{2}}...p_{k_{n-1}j}=\sum_{k_{1},...,k_{n-1}\in E}%
\mathbf{P}\left( X_{1}=k_{1}|X_{0}=i\right) \mathbf{P}\left(
X_{2}=k_{2}|X_{1}=k_{1}\right) ...\mathbf{P}\left(
X_{n}=j|X_{n-1}=k_{n-1}\right) $, dato che la propriet\`{a} di Markov vale $%
\forall $ $n$. Quindi la sommatoria iniziale \`{e} un'iterazione della
formula delle probabilit\`{a} totali: $\sum_{i\in E}\mathbf{P}\left(
X_{0}=i\right) P_{ij}^{n}=$ $\sum_{i,k_{1},...,k_{n-1}\in E}\mathbf{P}\left(
X_{0}=i\right) \mathbf{P}\left( X_{1}=k_{1}|X_{0}=i\right) \mathbf{P}\left(
X_{2}=k_{2}|X_{1}=k_{1}\right) ...\mathbf{P}\left(
X_{n}=j|X_{n-1}=k_{n-1}\right) $ $=\sum_{k_{n-1}\in E}...\sum_{k_{1}\in
E}\sum_{i\in E}\mathbf{P}\left( X_{0}=i\right) \mathbf{P}\left(
X_{1}=k_{1}|X_{0}=i\right) \mathbf{P}\left( X_{2}=k_{2}|X_{1}=k_{1}\right)
...\mathbf{P}\left( X_{n}=j|X_{n-1}=k_{n-1}\right) $. Ma $\sum_{i\in E}%
\mathbf{P}\left( X_{0}=i\right) \mathbf{P}\left( X_{1}=k_{1}|X_{0}=i\right) =%
\mathbf{P}\left( X_{1}=k_{1}\right) $ ecc., quindi la sommatoria scritta
coincide con $\sum_{k_{n-1}\in E}...\sum_{k_{1}\in E}\mathbf{P}\left(
X_{1}=k_{1}\right) \mathbf{P}\left( X_{2}=k_{2}|X_{1}=k_{1}\right) ...%
\mathbf{P}\left( X_{n}=j|X_{n-1}=k_{n-1}\right) $ $=\sum_{k_{n-1}\in
E}...\sum_{k_{2}\in E}\mathbf{P}\left( X_{2}=k_{2}\right) ...\mathbf{P}%
\left( X_{n}=j|X_{n-1}=k_{n-1}\right) =...=\mathbf{P}\left( X_{n}=j\right) $.

(3) In generale la strategia per calcolare una probabilit\`{a} congiunta
relativa a elementi di una catena di Markov \`{e} disintegrare rispetto a
tutti gli elementi della catena partendo da $X_{0}$, e riscrivere tutto
usando le probabilit\`{a} condizionate sfruttando la propriet\`{a} di
Markov. Per semplicit\`{a} si dimostra nel caso particolare di $%
n_{1}=1,n_{2}=3,n_{3}=6$. $\mathbf{P}\left(
X_{1}=i_{1},X_{3}=i_{3},X_{6}=i_{6}\right) =$ $\sum_{k_{0},k_{2},k_{4},k_{5}%
\in E}\mathbf{P}\left(
X_{0}=k_{0},X_{1}=i_{1},X_{2}=k_{2},X_{3}=i_{3},X_{4}=k_{4},X_{5}=k_{5},X_{6}=i_{6}\right) 
$ $=$ $\sum_{k_{0},k_{2},k_{4},k_{5}\in
E}v_{k_{0}}p_{k_{0}i_{1}}...p_{k_{5}i_{6}}=\sum_{k_{0}\in
E}v_{k_{0}}p_{k_{0}i_{1}}\sum_{k_{2}\in
E}p_{i_{1}k_{2}}p_{k_{2}i_{3}}\sum_{k_{4},k_{5}\in
E}p_{i_{3}k_{4}}p_{k_{4}k_{5}}p_{k_{5}i_{6}}$ \ $=\sum_{k_{0}\in
E}v_{k_{0}}p_{k_{0}i_{1}}p_{i_{1}i_{3}}^{\left( 2\right)
}p_{i_{3}i_{6}}^{\left( 3\right) }$.

(2) $\mathbf{P}\left( X_{n+m}=j|X_{m}=i\right) =\frac{\mathbf{P}\left(
X_{n+m}=j,X_{m}=i\right) }{\mathbf{P}\left( X_{m}=i\right) }$. Il numeratore 
\`{e} $\sum_{i_{0}\in E}v_{i_{0}}^{\left( 0\right) }p_{i_{0}i}^{\left(
m\right) }p_{ij}^{\left( n\right) }$, mentre il denominatore \`{e} $%
\sum_{i_{0}\in E}v_{i_{0}}^{\left( 0\right) }p_{i_{0}i}^{\left( n\right) }$:
operando la semplificazione si ottiene $\mathbf{P}\left(
X_{n+m}=j|X_{m}=i\right) =p_{ij}^{\left( n\right) }$. $\blacksquare $

$P^{n+m}=P^{n}P^{m}$, quindi $p_{ij}^{n+m}=\sum_{k\in E}p_{ik}^{n}p_{kj}^{m}$%
. Per 28.2 (2) $p_{ij}^{n+m}=\mathbf{P}\left( X_{n+m}=j|X_{0}=i\right) =%
\mathbf{P}_{i}\left( X_{n+m}=j\right) $, che \`{e} quindi uguale a $%
\sum_{k\in E}p_{ik}^{n}p_{kj}^{m}=\sum_{k\in E}\mathbf{P}\left(
X_{n}=k|X_{0}=i\right) \mathbf{P}\left( X_{m}=j|X_{0}=k\right) =\sum_{k\in E}%
\mathbf{P}_{i}\left( X_{n}=k\right) \mathbf{P}\left(
X_{n+m}=j|X_{n}=k\right) $. Vale quindi la

\textbf{Equazione di Chapman-Kolmogorov}%
\begin{equation*}
\mathbf{P}\left( X_{n+m}=j|X_{0}=i\right) =\sum_{k\in E}\mathbf{P}_{i}\left(
X_{n}=k\right) \mathbf{P}\left( X_{n+m}=j|X_{n}=k\right)
\end{equation*}

Il senso dell'uguaglianza \`{e} considerare tutte le possibili traiettorie
con cui, avendo $X_{0}=i$, pu\`{o} essere $X_{n+m}=j$: si sommano le
probabilit\`{a} di tutte le traiettorie al variare di $k\in E$, supponendo
che al tempo $n$ la catena sia in $k$.

\textbf{Dim} Per 28.2 (2) $\mathbf{P}\left( X_{n+m}=j|X_{0}=i\right)
=p_{ij}^{\left( n+m\right) }=\mathbf{P}_{i}\left( X_{n+m}=j\right) $. $%
P^{n+m}=P^{n}P^{m}$, quindi $p_{ij}^{\left( n+m\right) }=\sum_{k\in
E}p_{ik}^{\left( n\right) }p_{kj}^{\left( m\right) }=\sum_{k\in E}\mathbf{P}%
\left( X_{n}=k|X_{0}=i\right) \mathbf{P}\left( X_{n+m}=j|X_{n}=k\right)
=\sum_{k\in E}\mathbf{P}_{i}\left( X_{n}=k\right) \mathbf{P}\left(
X_{n+m}=j|X_{n}=k\right) $. $\blacksquare $

\subsection{Classificazione degli stati}

\textbf{Def 28.3 }Data\textbf{\ }$\left( X_{n}\right) _{n\geq 0}\sim
CM\left( v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}%
\right) $, $X_{n}:\Omega \rightarrow E$ $\forall $ $n\geq 0$, $j\in E$, si
dice istante di primo passaggio per $j$, e si indica con $S_{j}$, la
variabile aleatoria $S_{j}:\Omega \rightarrow 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\cup \left\{ +\infty \right\} $, $S_{j}\left( \omega \right) :=\left\{ 
\begin{array}{c}
\min \left\{ n\geq 0:X_{n}\left( \omega \right) =j\right\} \\ 
+\infty \text{ se }X_{n}\left( \omega \right) \neq j\text{ }\forall \text{ }%
n\geq 0%
\end{array}%
\right. $; si dice istante di primo arrivo per $j$, e si indica con $T_{j}$,
la variabile aleatoria $T_{j}:\Omega \rightarrow 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\cup \left\{ +\infty \right\} $, $T_{j}\left( \omega \right) :=\left\{ 
\begin{array}{c}
\min \left\{ n\geq 1:X_{n}\left( \omega \right) =j\right\} \\ 
+\infty \text{ se }X_{n}\left( \omega \right) \neq j\text{ }\forall \text{ }%
n\geq 1%
\end{array}%
\right. $.

Se $X_{0}=j$, $S_{j}=0$, mentre $T_{j}$ avr\`{a} sicuramente un valore
diverso: $T_{j}>0$. Se invece $X_{0}\neq j$, $S_{j}=T_{j}$. Se $\NEG%
{\exists}n\geq 1:X_{n}=j$, $T_{j}=+\infty $. Si pu\`{o} quindi scrivere $%
S_{j}=T_{j}I_{\left( X_{0}\neq j\right) }\left( \omega \right) $. !

\textbf{Prop 28.4 (istante di primo arrivo e passaggio sono v. a.)}%
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) 
\text{ definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E%
\text{ spazio degli stati} \\
\text{Ts}\text{: }S_{j},T_{j}\text{ sono variabili aleatorie}
\end{gather*}

\textbf{Dim} Mostro che $T_{j}$ \`{e} una v. a.: allora anche $S_{j}$ lo sar%
\`{a}, essendo $S_{j}=T_{j}I_{\left( X_{0}\neq j\right) }\left( \omega
\right) $. $\func{Im}T_{j}=%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\cup \left\{ +\infty \right\} $, quindi \`{e} sufficiente mostrare che $%
\left( T_{j}=n\right) ,\left( T_{j}=+\infty \right) \in \mathcal{A}$ $%
\forall $ $n$, perch\'{e} poi la controimmagine di ogni boreliano sar\`{a}
la controimmagine di un sottinsieme di $%
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\cup \left\{ +\infty \right\} $, che pu\`{o} essere scritto come unione di
eventi del tipo $\left( T_{j}=n\right) ,\left( T_{j}=+\infty \right) $. Ma $%
\left( T_{j}=n\right) =\left( X_{1}\neq j,...,X_{n-1}\neq j,X_{n}=j\right)
=\bigcap_{i=1}^{n-1}\left( X_{i}\neq j\right) \cap \left( X_{n}=j\right) \in 
\mathcal{A}$ perch\'{e} intersezione di eventi, dato che le $X_{n}$ sono v.
a. $\left( T_{j}=+\infty \right) =\bigcap_{n=1}^{+\infty }\left( X_{n}\neq
j\right) \in \mathcal{A}$ perch\'{e} intersezione di eventi, dato che le $%
X_{n}$ sono v. a. (oppure $\left( T_{j}=+\infty \right) =\left(
T_{j}<+\infty \right) ^{c}=\left( \bigcup_{l=1}^{+\infty }\left(
T_{j}=l\right) \right) ^{c}\in \mathcal{A}$ per quanto detto sopra su $%
\left( T_{j}=n\right) $). $\blacksquare $

La legge di $S_{j},T_{j}$ dipende solo da $v,P$.

\begin{enumerate}
\item Sia $E=\left\{ a,b\right\} $ con $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $: si passa certamente dallo stato A allo stato B, per cui
l'evoluzione \`{e} deterministica. $S_{a}\left( \omega \right) =0\cdot
I_{\left( X_{0}=a\right) }\left( \omega \right) +1\cdot I_{\left( X_{0}\neq
a\right) }\left( \omega \right) $, $S_{b}\left( \omega \right) =1\cdot
I_{\left( X_{0}=a\right) }\left( \omega \right) +0\cdot I_{\left( X_{0}\neq
a\right) }\left( \omega \right) $, $T_{a}\left( \omega \right) =1\cdot
I_{\left( X_{0}=b\right) }\left( \omega \right) +2\cdot I_{\left(
X_{0}=a\right) }\left( \omega \right) $, $T_{b}\left( \omega \right) =1\cdot
I_{\left( X_{0}=a\right) }\left( \omega \right) +2\cdot I_{\left(
X_{0}=b\right) }\left( \omega \right) $. Se $X_{0}\sim v$, $\mathbf{P}\left(
S_{a}=1\right) =\mathbf{P}\left( X_{0}=b\right) =v\left( b\right) $; $%
\mathbf{P}\left( S_{a}=0\right) =\mathbf{P}\left( X_{0}=a\right) =v\left(
a\right) $. $\mathbf{E}\left( S_{a}\right) =v\left( b\right) $. $\mathbf{P}%
\left( T_{a}=1\right) =\mathbf{P}\left( X_{0}=b\right) =v\left( b\right) $; $%
\mathbf{P}\left( T_{a}=2\right) =\mathbf{P}\left( X_{0}=a\right) =v\left(
a\right) $.

\item Sia $E=\left\{ a,b\right\} $ con $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
\alpha & 1-\alpha%
\end{array}%
\right] $ e $v=\delta _{a}=\left( 
\begin{array}{c}
1 \\ 
0%
\end{array}%
\right) $. $\mathbf{P}\left( X_{0}=a\right) =1$. La legge dell'istante di
primo passaggio \`{e} $P^{S_{a}}=\delta _{0}$ con $\mathbf{P}\left(
S_{a}=0\right) =\mathbf{P}_{a}\left( S_{a}=0\right) =1,\mathbf{P}\left(
S_{a}=1\right) =0$; la legge dell'istante di primo arrivo \`{e} $P^{T_{a}}$
con $\mathbf{P}\left( T_{a}=1\right) =0,\mathbf{P}\left( T_{a}=k\right) =%
\mathbf{P}_{a}\left( T_{a}=k\right) =\alpha \left( 1-\alpha \right) ^{k-2}$
se $k>1$. $\mathbf{P}\left( T_{a}<+\infty \right) =\sum_{k=1}^{+\infty }%
\mathbf{P}\left( T_{a}=k\right) =\sum_{k=2}^{+\infty }\alpha \left( 1-\alpha
\right) ^{k-2}=\frac{\alpha }{1-\left( 1-\alpha \right) }=1$. $\mathbf{E}%
\left( T_{a}\right) =\sum_{k=2}^{+\infty }k\alpha \left( 1-\alpha \right)
^{k-2}=\frac{\alpha }{1-\alpha }\sum_{k=2}^{+\infty }k\left( 1-\alpha
\right) ^{k-1}=\frac{1+\alpha }{\alpha }$.
\end{enumerate}

Se quindi $\mathbf{P}_{i}\left( S_{j}<+\infty \right) >0$, significa che lo
stato $j$ prima o poi viene visitato, dato che $X_{0}=i$. Se $i=j$ $\mathbf{P%
}_{i}\left( S_{j}<+\infty \right) =1$; se $i\neq j$ $\mathbf{P}_{i}\left(
S_{j}<+\infty \right) =\mathbf{P}_{i}\left( T_{j}<+\infty \right) $.

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$ spazio
degli stati, $i,j\in E$, si dice che $i$ conduce a $j$, e si scrive $%
i\rightarrow j$, se $\mathbf{P}_{i}\left( S_{j}<+\infty \right) >0$.!

Vale ovviamente $i\rightarrow i$.

\textbf{Prop 28.7 (condizioni equivalenti di conduzione)}%
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) 
\text{ definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, } \\
E\text{ spazio degli stati, }i,j\in E\text{, }i\neq j \\
\text{Ts}\text{: (i) }i\rightarrow j\Longleftrightarrow \exists \text{ }%
n\geq 0:p_{ij}^{\left( n\right) }>0 \\
\text{(ii) }i\rightarrow j\Longleftrightarrow \exists \text{ }%
j_{1},...,j_{n-1}:p_{ij_{1}}p_{j_{1}j_{2}}...p_{j_{n-1}j_{n}}>0
\end{gather*}

(i) \`{e} intuitivamente ovvia, dato che $p_{ij}^{\left( n\right) }=\mathbf{P%
}\left( X_{n}=j|X_{0}=i\right) $. (ii) significa che $i$ conduce a $j$ se e
solo se esiste un cammino, di probabilit\`{a} non nulla - cio\`{e} un
percorso di archi - che porta da $i$ a $j$.

\textbf{Dim} (i) Se $i\rightarrow j$, $\mathbf{P}_{i}\left( S_{j}<+\infty
\right) >0$. $\left( S_{j}<+\infty \right) =\bigcup_{n=0}^{+\infty }\left(
X_{n}=j\right) $, ma allora, per subadditivit\`{a} della probabilit\`{a}, $%
\mathbf{P}_{i}\left( \bigcup_{n=0}^{+\infty }\left( X_{n}=j\right) \right)
\leq \sum_{n=0}^{+\infty }\mathbf{P}_{i}\left( X_{n}=j\right) $: quindi $%
\sum_{n=0}^{+\infty }\mathbf{P}_{i}\left( X_{n}=j\right) >0$. Essendo la
serie a termini nonnegativi, deve esistere $\bar{n}:\mathbf{P}_{i}\left( X_{%
\bar{n}}=j\right) >0$, dunque $p_{ij}^{\left( \bar{n}\right) }>0$.

Se $\exists $ $\bar{n}:\mathbf{P}_{i}\left( X_{\bar{n}}=j\right)
=p_{ij}^{\left( \bar{n}\right) }>0$, allora $\mathbf{P}_{i}\left(
S_{j}<+\infty \right) >0$ perch\'{e} l'evento $\left( X_{\bar{n}}=j\right)
\subseteq \left( S_{j}<+\infty \right) $ (se l'istante di primo passaggio 
\`{e} $j$, allora esso \`{e} finito): per monotonia della probabilit\`{a}, $%
\mathbf{P}_{i}\left( S_{j}<+\infty \right) \geq \mathbf{P}_{i}\left( X_{\bar{%
n}}=j\right) >0$.

(ii) $\exists $ $n\geq 0:p_{ij}^{\left( n\right) }>0\Longleftrightarrow
\exists $ $j_{1},...,j_{n-1}:p_{ij_{1}}p_{j_{1}j_{2}}...p_{j_{n-1}j_{n}}>0$,
dato che $p_{ij}^{\left( n\right) }=\sum_{j_{1},...,j_{n}\in
E}p_{ij_{1}}...p_{j_{n}j}$. $\blacksquare $

\textbf{Corollario 28.8 (transitivit\`{a} della conduzione)}%
\begin{gather*}
\text{Hp}\text{: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) 
\text{ definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E%
\text{ } \\
\text{spazio degli stati, }i,j,k\in E\text{, }i\rightarrow j\text{ e }%
j\rightarrow k \\
\text{Ts: }i\rightarrow k
\end{gather*}

\textbf{Dim* }E' noto che $\exists $ $n\geq 0:p_{ij}^{\left( n\right) }>0$, $%
\exists $ $m\geq 0:p_{jk}^{\left( m\right) }>0$. $p_{ik}^{\left( n+m\right)
}=\sum_{h\in E}p_{ih}^{\left( n\right) }p_{hk}^{\left( m\right) }\geq
p_{ij}^{\left( n\right) }p_{jk}^{\left( m\right) }>0$ per ipotesi, quindi $%
\exists $ $n+m\geq 0:p_{ij}^{\left( n+m\right) }>0$ e $i\rightarrow k$. $%
\blacksquare $

\begin{enumerate}
\item Considero $\left( X_{n}\right) _{n\geq 0}$ con $P=\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
0 & \alpha & 1-\alpha \\ 
1-\beta & 0 & \beta%
\end{array}%
\right] $. $1\rightarrow 2$ perch\'{e} $p_{12}>0$, cio\`{e} esiste un
percorso di archi da $1$ a $2$; analogamente $2\rightarrow 3$, quindi anche $%
1\rightarrow 3$. In questo caso inoltre vale anche $3\rightarrow 1$: da ogni
stato \`{e} possibile raggiungere ogni altro stato.

\item Considero $\left( X_{n}\right) _{n\geq 0}$ con $P=\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
1 & 0 & 0 \\ 
0 & 0 & 1%
\end{array}%
\right] $. In questo caso $1\rightarrow 2,2\rightarrow 1$, ma lo stato $3$ 
\`{e} isolato.
\end{enumerate}

\textbf{Def 28.9} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left(
v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$
spazio degli stati, $i,j\in E$, si dice che $i$ comunica con $j$, e si
scrive $i\leftrightarrow j$, se $i\rightarrow j$ e $j\rightarrow i$.

In tal caso la relazione di conduzione gode della propriet\`{a} di
simmetria. Nel primo esempio sopra $i\leftrightarrow j$ $\forall $ $i,j\in E$%
. Nel secondo $1\leftrightarrow 2$, ma $1\not\leftrightarrow
3,2\not\leftrightarrow 3$.

\textbf{Def 29.1} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta
_{i},P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, 
$E$ spazio degli stati, $i\in E$, $i$ si dice stato ricorrente se $\mathbf{P}%
_{i}\left( T_{i}<+\infty \right) =1$; $i$ si dice transiente se $\mathbf{P}%
_{i}\left( T_{i}<+\infty \right) <1$.

Quindi $i$ \`{e} ricorrente se la catena parte da $i$ e prima o poi ci
ritorna quasi certamente (l'istante di primo arrivo - che di fatto \`{e}
primo ritorno - \`{e} finito q. c.); in caso contrario $i$ \`{e} transiente.
Ogni stato \`{e} quindi ricorrente o transiente, dato che $\mathbf{P}%
_{i}\left( T_{i}<+\infty \right) \leq 1$.

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$ spazio
degli stati, $i\in E$, $i$ si dice stato assorbente se $p_{ii}=1$.

\textbf{Teo 29.2 (stati ricorrenti e transienti)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta _{i},P\right) 
\text{ definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E%
\text{ spazio degli stati, }i,j\in E \\
\text{Ts: (1) }i\text{ \`{e} ricorrente }\Longleftrightarrow \mathbf{P}%
_{i}\left( X_{n}=i\text{ per infiniti }n\right) =1 \\
\text{(2) }i\text{ \`{e} transiente }\Longleftrightarrow \mathbf{P}%
_{i}\left( X_{n}=i\text{ per infiniti }n\right) =0 \\
\text{(3) }j\text{ \`{e} transiente }\Longrightarrow \lim_{n\rightarrow
+\infty }p_{ij}^{\left( n\right) }=0 \\
\text{(4) }i\text{ \`{e} assorbente }\Longrightarrow i\text{ \`{e} ricorrente%
} \\
\text{(5) }i\text{ \`{e} transiente }\Longleftrightarrow \exists \text{ }%
j:i\rightarrow j\text{ e }j\nrightarrow i \\
\text{(6) }i\text{ \`{e} ricorrente e }i\rightarrow j\Longrightarrow j\text{ 
\`{e} ricorrente} \\
\text{(7) }j\text{ \`{e} transiente e }i\rightarrow j\Longrightarrow i\text{ 
\`{e} transiente} \\
\text{(8) }i\leftrightarrow j\Longleftrightarrow i,j\text{ sono entrambi
ricorrenti o entrambi transienti} \\
\text{(9) }\exists \text{ }i\in E:i\text{ \`{e} ricorrente}
\end{gather*}

Per classificare uno stato si suppone che $X_{0}$ sia quello stato.

(1),(2) affermano che gli stati transienti caratterizzano il comportamento
della catena solo all'inizio; poi l'evoluzione \`{e} determinata dagli stati
ricorrenti. (3) sottolinea questo aspetto: pi\`{u} passa il tempo, pi\`{u} 
\`{e} improbabile che la catena arrivi in $j$ se $j$ \`{e} transiente.

Le catene di Markov hanno inoltre la propriet\`{a} particolare che $\mathbf{P%
}_{i}\left( X_{n}=i\text{ per infiniti }n\right) $ possa valere solo $0$ o $%
1 $: questo \`{e} dovuto alla legge zero-uno di Kolmogorov, secondo cui ogni
evento nella $\sigma $-algebra di coda ha probabilit\`{a} $0$ o $1$ (p. 72
ProbEss).

(4) \`{e} giustificata dal fatto che se $i$ \`{e} assorbente la catena parte
da $i$ e rimane in $i$ per ogni $n$, per cui $T_{i}=1$. (5) esprime il fatto
che, trovandosi la catena in uno stato transiente, \`{e} possibile che ne
esca senza poterci tornare. (8) \`{e} una conseguenza di (6), (7). Non vale
il viceversa in (6): se $i\rightarrow j$ e $j$ \`{e} ricorrente, non \`{e}
vero che allora $i$ \`{e} ricorrente; analogamente in (7).

In (5) e (9) l'implicazione da destra a sinistra vale perch\'{e} $\left\vert
E\right\vert <+\infty $.

\begin{enumerate}
\item Se in $P$ $\exists $ $j:p_{ij}=0$ $\forall $ $i\neq j$ e $\exists $ $%
k:p_{jk}\neq 0$, allora $j$ \`{e} uno stato transiente, perch\'{e} non \`{e}
possibile arrivare in $j$ senza partire da $j$: $\exists $ $i:j\rightarrow i$
e $i\nrightarrow j$.

\item Considero una catena con la matrice di transizione $\left[ 
\begin{array}{ccccc}
0 & 1 & 0 & 0 & 0 \\ 
1 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & \alpha & 0 & 1-\alpha \\ 
0 & 0 & 0 & 0 & 1%
\end{array}%
\right] $. Classifico gli stati. Lo stato 5 \`{e} assorbente, quindi \`{e}
ricorrente (4); 4 \`{e} transiente perch\'{e} conduce a 5, ma 5 non conduce
a 4 (5). Poich\'{e} 4 comunica con 3, questo implica che anche 3 \`{e}
transiente (8). 1 e 2 sono entrambi ricorrenti perch\'{e} non sono
transienti (5). Nel fatto che 4 non \`{e} ricorrente, ma 5 lo \`{e}, si vede
un esempio del fatto che non vale il viceversa in (6) n\'{e} in (7).
\end{enumerate}

\textbf{Def 29.3} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta
_{i},P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, 
$E$ spazio degli stati, $i\in E$, si dice periodo dello stato $i$, e si
indica con $d\left( i\right) $, $\left\{ 
\begin{array}{c}
MCD\left\{ n\geq 1:p_{ii}^{\left( n\right) }>0\right\} \\ 
+\infty \text{ se }p_{ii}^{\left( n\right) }=0\text{ }\forall \text{ }n\geq 1%
\end{array}%
\right. \in 
%TCIMACRO{\U{2115} }%
%BeginExpansion
\mathbb{N}
%EndExpansion
\cup \left\{ +\infty \right\} $. Se tutti gli stati hanno lo stesso periodo,
la catena si dice aperiodica.

$d\left( i\right) =+\infty $ significa che, una volta passata in $i$, la
catena non ci torna pi\`{u}. $d$ esprime le periodicit\`{a} nell'evoluzione
della catena.

\textbf{Def 29.4} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( \delta
_{i},P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, 
$E$ spazio degli stati, $i\in E$, $i$ si dice aperiodico se $d\left(
i\right) =1$, altrimenti si dice che ha periodo $d\left( i\right) =d\geq 2$.

Ogni stato tale che $p_{ii}>0$ ha periodo 1, quindi in particolare ogni
stato assorbente \`{e} aperiodico.

\begin{enumerate}
\item Sia $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $. Considero $i=1$: $p_{11}^{\left( n\right) }=0$ se $n$ \`{e}
dispari, $p_{11}^{\left( n\right) }=1$ se $n$ \`{e} pari, quindi $d\left(
1\right) =2=d\left( 2\right) $. Infatti $P^{2}=\left[ 
\begin{array}{cc}
1 & 0 \\ 
0 & 1%
\end{array}%
\right] =P^{n}$ $\forall $ $n$ pari, per cui e. g. $P^{n}=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $ $\forall $ $n$ dispari (verifica), e si applica 28.2 (2).

\item Sia $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1/2 & 1/2%
\end{array}%
\right] $. Considero $i=2$: $d\left( 2\right) =MCD\left\{ 1,2\right\} =1$. $%
p_{11}^{\left( 2\right) }=1\cdot \frac{1}{2}>0$, ma anche $p_{11}^{\left(
n\right) }>0$ $\forall $ $n>2$, quindi $d\left( 1\right) =MCD\left\{
2,3,4,...\right\} =1$.
\end{enumerate}

\textbf{Teo 29.5 (equivalenza tra comunicanza e medesimo periodo)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati, }i,j\in E \\
\text{Ts: }i\leftrightarrow j\Longleftrightarrow d\left( i\right) =d\left(
j\right)
\end{gather*}

\textbf{Def 29.6} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left(
v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$
spazio degli stati, $C\subseteq E$ si dice classe chiusa se $i\in
C,i\rightarrow j\Longrightarrow j\in C$.

Una classe \`{e} quindi chiusa se "non se ne pu\`{o} uscire".

\begin{enumerate}
\item Data la $P=\left[ 
\begin{array}{ccccc}
0 & 1 & 0 & 0 & 0 \\ 
1 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 1 & 0 \\ 
0 & 0 & \alpha & 0 & 1-\alpha \\ 
0 & 0 & 0 & 0 & 1%
\end{array}%
\right] $ di prima, $\left\{ 1,2\right\} ,\left\{ 5\right\} ,\left\{
3,4,5\right\} ,\left\{ 1,2,5\right\} $ sono classi chiuse.
\end{enumerate}

\textbf{Def 29.7} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left(
v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$
spazio degli stati, $C\subseteq E$ si dice classe irriducibile se \`{e}
chiusa e $\forall $ $i,j\in C$ $i\leftrightarrow j$.

E' quindi irriducibile una classe chiusa in cui tutti gli stati comunicano.
Poich\'{e} due stati comunicanti sono entrambi ricorrenti o entrambi
transienti, tutti gli stati di una classe chiusa hanno il medesimo
carattere: si vedr\`{a} che sono tutti ricorrenti.

\begin{enumerate}
\item Nell'esempio precedente, le classi $\left\{ 1,2\right\} ,\left\{
5\right\} $ sono anche irriducibili.
\end{enumerate}

\textbf{Def 29.7} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left(
v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$
spazio degli stati, $\left( X_{n}\right) _{n\geq 0}$, o equivalentemente $P$%
, si dice irriducibile se $E$ \`{e} una classe irriducibile.

\begin{enumerate}
\item Nell'esempio precedente, se $\mathbf{P}\left( X_{0}\in \left\{
1,2\right\} \right) =1$, allora $\mathbf{P}\left( X_{n}\in \left\{
1,2\right\} \right) =1$ $\forall $ $n$, perch\'{e} $\left\{ 1,2\right\} $ 
\`{e} una classe chiusa. In tal caso tutte le informazioni sull'evoluzione
di una catena sono codificate da $P^{\prime }=P|_{C}=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $, che peraltro \`{e} irriducibile: la catena pu\`{o} essere
studiata su $E^{\prime }=\left\{ 1,2\right\} $.

Se $\mathbf{P}\left( X_{0}\in \left\{ 3,4,5\right\} \right) =1$, allora $%
\mathbf{P}\left( X_{n}\in \left\{ 3,4,5\right\} \right) =1$ $\forall $ $n$,
perch\'{e} $\left\{ 3,4,5\right\} $ \`{e} una classe chiusa. In tal caso
tutte le informazioni sull'evoluzione di una catena sono codificate da $%
P^{\prime }=P|_{C}=\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
\alpha & 0 & 1-\alpha \\ 
0 & 0 & 1%
\end{array}%
\right] $, che non \`{e} irriducibile, dato che la classe non lo \`{e}.
\end{enumerate}

\textbf{Teo 29.9 (classi irriducibili)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli } \\
\text{stati, }E_{T}\text{ \`{e} insieme degli stati transienti} \\
\text{Ts: (1) se }C\subseteq E\text{ \`{e} una classe irriducibile, tutti
gli stati sono } \\
\text{ricorrenti \textit{con lo stesso periodo}} \\
\text{(2) se }E\text{ \`{e} una classe irriducibile, tutti gli stati di }E%
\text{ sono ricorrenti} \\
\text{(3) }\exists \text{ }C_{1},...,C_{k}\text{ classi disgiunte e
irriducibili di }E: \\
E=E_{T}\cup C_{1}\cup ...\cup C_{k}\text{ e la decomposizione \`{e} unica;}
\\
\text{se }\exists \text{ }l=1,...,k:X_{0}\in C_{l}\text{ q. c., }X_{n}\in
C_{l}\text{ q. c. }\forall \text{ }n\geq 1\text{;} \\
\text{se }X_{0}\in E_{T}\text{ q. c., }\exists \text{ }\bar{n}\geq 1,\exists 
\text{ }k:X_{n}\in C_{k}\text{ }\forall \text{ }n\geq \bar{n}
\end{gather*}

$C_{1}\cup ...\cup C_{k}$ \`{e} l'insieme degli stati ricorrenti, indicato
con $E_{R}$, ed \`{e} una classe chiusa perch\'{e} unione di classi chiuse.

Con lo stesso periodo la G l'ha detto solo nel riassuntino.

\textbf{Dim} (1) Dato $i\in C$, $i$ \`{e} transiente $\Longleftrightarrow
\exists $ $j:i\rightarrow j$ e $j\nrightarrow i$. Questo \`{e} assurdo per
definizione di classe irriducibile: tutti gli stati comunicano, per cui $i$ 
\`{e} ricorrente $\forall $ $i\in E$. Il fatto che abbiano lo stesso periodo
segue da 29.5.

(2) Caso particolare di 1. $\blacksquare $

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$ spazio
degli stati, $C\subseteq E$ classe chiusa, si dice istante di primo
passaggio nella classe (o tempo di assorbimento nella classe) e si indica
con $S_{C}$, $\left\{ 
\begin{array}{c}
\min \left\{ n\geq 0:X_{n}\in C\right\} \\ 
+\infty \text{ se }X_{n}\not\in C\text{ }\forall ~n\geq 0%
\end{array}%
\right. $; si dice istante di primo arrivo nella classe, e si indica con $%
T_{C}$, $\left\{ 
\begin{array}{c}
\min \left\{ n\geq 1:X_{n}\in C\right\} \\ 
+\infty \text{ se }X_{n}\not\in C\text{ }\forall ~n\geq 1%
\end{array}%
\right. $. Si dice tempo medio di assorbimento in $C$, e si indica con $\tau
_{i}^{C}$, $\mathbf{E}_{i}\left( T_{C}\right) $.

$S_{C}\leq T_{C}$ sempre. Se $X_{0}\in C$, $S_{C}=0$ e $T_{C}=1$ perch\'{e} $%
C$ \`{e} chiusa; se $X_{0}\not\in C$, $S_{C}=T_{C}$. Si noti inoltre che
vale $\mathbf{P}_{i}\left( T_{C}<+\infty \right) =\mathbf{P}_{i}\left(
S_{C}<+\infty \right) $, perch\'{e} se $X_{0}\in C$ $S_{C},T_{C}$ sono
entrambe certamente finite e si ha $1=1$, mentre se $X_{0}\not\in C$ $%
S_{C}=T_{C}$ e quindi $\left( T_{C}<+\infty \right) =\left( S_{C}<+\infty
\right) $.

\begin{enumerate}
\item Considero il gioco di Albus e Bellatrix, che hanno $a,b$ galeoni
rispettivamente: $X_{n}$ \`{e} il numero di galeoni di Albus, $P=\left[ 
\begin{array}{ccccc}
1 & p & 0 & ... & 0 \\ 
1-p & 0 & p & ... & 0 \\ 
0 & 1-p & 0 & ... & 0 \\ 
... & ... & ... & ... & ... \\ 
0 & 0 & ... & 1-p & 1%
\end{array}%
\right] $. $0$ e $a+b$ sono stati assorbenti e quindi ricorrenti e
aperiodici ($\left\{ 0\right\} ,\left\{ a+b\right\} $ sono classi
irriducibili); tutti gli altri stati sono transienti (???) di periodo 2
(direi invece: $1$ e $a+b-1$ sono transienti, gli altri sono ricorrenti). Se
il grafo \`{e} della catena $Y_{n}$ con $Y_{n}$ capitale di B e mi interessa
la rovina di B, \`{e} naturale considerare la classe $C=\left\{ 0\right\} $
e voler calcolare la probabilit\`{a} che B vada in rovina $\mathbf{P}%
_{b}\left( T_{C}<+\infty \right) $ e il numero medio di passi affinch\'{e} ci%
\`{o} accada $\mathbf{E}_{i}\left( T_{C}\right) $. Se voglio sapere quando
finisce il gioco, considero la classe $C^{\prime }=\left\{ 0,a+b\right\} $
(che \`{e} chiusa, ma non irriducibile) e calcolo $T_{C^{\prime }}$.
\end{enumerate}

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $i\in E$ spazio
degli stati, $C\subseteq E$ classe chiusa, si dice probabilit\`{a} di
assorbimento nella classe $C$ partendo da $i$, e si indica con $\lambda
_{i}^{C}$, $\mathbf{P}_{i}\left( T_{C}<+\infty \right) $.

$\lambda _{i}^{C}=\mathbf{P}_{i}\left( S_{C}<+\infty \right) $. Ricordo che $%
E=E_{T}\cup C_{1}\cup ...\cup C_{k}$. Se $i\in C$, $\lambda _{i}^{C}=1$ perch%
\'{e} $T_{C}=0$; se $i\in \tilde{C}$ classe chiusa disgiunta da $C$ (quindi
in particolare se $\tilde{C}$ \`{e} irriducibile), $T_{C}=+\infty $ e $%
\lambda _{1}^{C}=0$, perch\'{e} partendo da una classe chiusa non \`{e}
possibile uscirne. Il valore $\lambda _{i}^{C}$ \`{e} quindi interessante
quando $i\in E_{T}\backslash C=:D$, che \`{e} una classe non irriducibile. Si noti che una classe chiusa pu\`{o} non essere
irriducibile e contenere stati transienti.

\textbf{Prop 29.10 (la probabilit\`{a} di assorbimento risolve un'equazione
lineare)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio } \\
\text{degli stati, }C\subseteq E\text{ classe chiusa, }D=E_{T}\backslash C%
\text{, }i\in D \\
\text{Ts: }\lambda _{i}^{C}\text{ \`{e} tale che }\lambda
_{i}^{C}=\sum_{k\in C}p_{ik}+\sum_{j\in D}p_{ij}\lambda _{j}^{C}
\end{gather*}

Il significato dell'equazione \`{e} controllare cosa accade al passo
immediatamente successivo a $i$: la probabilit\`{a} di essere assorbiti in $%
C $ partendo da $i$ \`{e} la probabilit\`{a} di essere assorbiti in $C$ al
passo immediatamente successivo pi\`{u} la probabilit\`{a} di andare - al
passo immediatamente successivo - in uno stato $j$ in $E_{T}\backslash C$
(non si considerano tutte le altri classi irriducibili, perch\'{e} in tal
caso $\lambda _{j}^{C}=0$) ed essere assorbiti in $C$ in un tempo
successivo. Se si scrive l'equazione della tesi $\forall $ $i\in E$, si
ottiene un sistema lineare quadrato di dimensione $\left\vert E\right\vert
\times \left\vert E\right\vert $ nelle incognite $\lambda
_{1}^{C},...,\lambda _{\left\vert E\right\vert }^{C}$.

\textbf{Dim} E' noto che $\lambda _{i}^{C}=\mathbf{P}_{i}\left(
T_{C}<+\infty \right) =\sum_{k\in E}\mathbf{P}_{i}\left( T_{C}<+\infty
|X_{1}=k\right) \mathbf{P}\left( X_{1}=k\right) $ per le probabilit\`{a}
totali, con $\Omega $ disintegrato con i possibili valori di $X_{1}$. Quanto
scritto coincide con $\sum_{k\in C}\mathbf{P}_{i}\left( T_{C}<+\infty
|X_{1}=k\right) \mathbf{P}_{i}\left( X_{1}=k\right) +\sum_{k\in
E_{T}\backslash C}\mathbf{P}_{i}\left( T_{C}<+\infty |X_{1}=k\right) \mathbf{%
P}_{i}\left( X_{1}=k\right) $. Non si somma con $k$ nelle classi di stati
ricorrenti, perch\'{e} in tal caso $\mathbf{P}_{i}\left( T_{C}<+\infty
|X_{1}=k\right) =0$, dato che $X_{0}$ \`{e} uno stato transitorio non in $C$
e $X_{1}$ \`{e} uno stato ricorrente facente parte di una classe chiusa: la
catena non uscir\`{a} mai da quella classe e quindi non arriver\`{a} in $C$.
Vale $\mathbf{P}_{i}\left( T_{C}<+\infty |X_{1}=k\right) =\mathbf{P}\left(
T_{C}<+\infty |X_{0}=i,X_{1}=k\right) $ (per quanto dimostrato a suo tempo
sulle probabilit\`{a} condizionate): ci\`{o} \`{e} uguale a $\mathbf{P}%
\left( S_{C}<+\infty |X_{0}=k\right) =\mathbf{P}\left( T_{C}<+\infty
|X_{0}=k\right) =\lambda _{k}^{C}$, per la propriet\`{a} di Markov (non ben
giustificato). Si ottiene quindi $\sum_{k\in C}\lambda _{k}^{C}\mathbf{P}%
_{i}\left( X_{1}=k\right) +\sum_{k\in E_{T}\backslash C}\lambda _{k}^{C}%
\mathbf{P}_{i}\left( X_{1}=k\right) $: ma se $k\in C$, $\lambda _{k}^{C}=1$,
quindi si ha $\sum_{k\in C}p_{ik}+\sum_{k\in E_{T}\backslash C}\lambda
_{k}^{C}p_{ik}$. $\blacksquare $

\begin{enumerate}
\item Si considera ancora il gioco di A e B, con $Y_{n}$ che descrive il
capitale di Bellatrix; $C=\left\{ 0\right\} $ \`{e} la classe che descrive
lo stato rovina di B. La probabilit\`{a} che B vada in rovina, sapendo che $%
X_{0}=b$, \`{e} $\mathbf{P}_{b}\left( T_{C}<+\infty \right) =\lambda
_{b}^{C} $. Per trovarlo scrivo il sistema $\left\{ 
\begin{array}{c}
\lambda _{1}^{C}=p+\left( 1-p\right) \lambda _{2}^{C} \\ 
... \\ 
\lambda _{a+b-1}^{C}=p\lambda _{a+b-2}^{C}%
\end{array}%
\right. $. Vale ovviamente $\lambda _{0}^{C}=1$, $\lambda _{a+b}^{C}=0$. Se $%
p=q$ vale $\lambda _{i}^{C}=\frac{a+b-i}{a+b}$ $\forall $ $i=1,...,a+b-1$,
quindi in particolare $\lambda _{b}^{C}=\frac{a}{a+b}$, che \`{e} la
percentuale di capitale iniziale posseduta da A.

Se $p\neq q$ con $q>p$, posto $\alpha :=\frac{p}{1-p}$
\end{enumerate}

Si ricorda che $\tau _{i}^{C}=\mathbf{E}_{i}\left( T_{C}\right) $. Se $i\in
C=E_{R}$ insieme degli stati ricorrenti, $T_{C}<+\infty $ q. c. e $\mathbf{E}_{i}\left( T_{C}\right) <+\infty $; se $i$ \`{e}
ricorrente e $i\not\in C$, $\mathbf{E}_{i}\left( T_{C}\right) =+\infty $. Se 
$i$ \`{e} transiente, $\tau _{i}^{C}=1$.

\textbf{Prop 29.11 (il tempo medio di assorbimento risolve un'equazione
lineare)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, } \\
E\text{ spazio degli stati, }i\in E_{T} \\
\text{Ts: (1) }\tau _{i}^{E_{R}}<+\infty \\
\text{(2) }\tau _{i}^{E_{R}}\text{ \`{e} tale che }\tau
_{i}^{E_{R}}=1+\sum_{j\in E^{T}}p_{ij}\tau _{j}^{E_{R}}
\end{gather*}

Il senso di (1) \`{e} che partendo da uno stato transiente il numero medio
di passi per finire in uno stato ricorrente \`{e} finito. (2) \`{e} analoga
a 29.10: o si finisce subito in uno stato ricorrente o ci si finisce
partendo da uno stato transiente $j$.

\textbf{Def} \textbf{30.1} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left(
v,P\right) $ definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $,
dato $E$ spazio degli stati finito, una misura di probabilit\`{a} $\pi $ su $%
\left( E,2^{E}\right) $ si dice invariante per $P$ se $\pi P=\pi $.

Si ricorda che, essendo $E$ finito, ogni densit\`{a} discreta su $E$ pu\`{o}
essere scritta come un vettore con $\left\vert E\right\vert $ componenti: la
definizione significa quindi che $\pi $ \`{e} un autovettore sinistro per $P$%
, relativo all'autovalore $1$ (che $P$ ammette, dato che la somma degli
elementi su ogni riga \`{e} $1$). Se $\pi $ \`{e} invariante per $P$ e $%
v=\pi $, $vP^{n}=\pi P^{n}=\pi $ $\forall $ $n$, cio\`{e} se la catena ha
come distribuzione iniziale una distribuzione invariante, ogni $X_{n}$ ha $%
\pi $ come legge: $X_{n}\sim \pi $ $\forall $ $n\geq 0$.

\begin{enumerate}
\item Se $P$ \`{e} inoltre bistocastica, la distribuzione uniforme $\pi
=\left( \frac{1}{E}|...|\frac{1}{E}\right) $ \`{e} invariante per $P$.
Infatti $\left( \frac{1}{E}|...|\frac{1}{E}\right) P=\left( \frac{1}{E}%
\sum_{i\in E}p_{ij}|...|\frac{1}{E}\sum_{i\in E}p_{ij}\right) =\left( \frac{1%
}{E}|...|\frac{1}{E}\right) $.

\item Se le $X_{n}$ sono iid, per cui $X_{n}\sim CM\left( v,\left[ 
\begin{array}{ccc}
v\left( 1\right) & ... & v\left( \left\vert E\right\vert \right) \\ 
... & ... & ... \\ 
v\left( 1\right) & ... & v\left( \left\vert E\right\vert \right)%
\end{array}%
\right] \right) $, $v$ \`{e} invariante per $P$.
\end{enumerate}

\textbf{Teo 30.2 (Markov-Kakutani)}%
\begin{gather*}
\text{Hp}\text{: }\left\vert E\right\vert <+\infty \text{, }P\in M_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}\left( \left\vert E\right\vert ,\left\vert E\right\vert \right) \text{
matrice stocastica} \\
\text{Ts}\text{: }\exists \text{ }\pi \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{\left\vert E\right\vert }:\pi P=\pi \text{, con }\pi \text{ densit\`{a} di
probabilit\`{a}}
\end{gather*}

La tesi \`{e} che ogni matrice stocastica ammette almeno un autovettore
sinistro relativo all'autovalore $1$; in generale non vale l'unicit\`{a}. In
particolare, se non \`{e} unica, ce ne sono infinite: se esistono $\pi
_{1},\pi _{2}$ invarianti per $\pi $, allora $\forall $ $\alpha \in \left(
0,1\right) $ $\alpha \pi _{1}+\left( 1-\alpha \right) \pi _{2}$ \`{e}
invariante per $\pi $, per la propriet\`{a} distributiva del prodotto
matriciale; la combinazione dev'essere convessa affinch\'{e} $\alpha \pi
_{1}+\left( 1-\alpha \right) \pi _{2}$ sia una distribuzione di probabilit%
\`{a}.

Il teorema ha qualche analogia con il teorema delle contrazioni: si afferma
l'esistenza di un punto fisso per l'applicazione lineare $\mathbf{x}P$.

\textbf{Dim*} (riempi buchi) Sia $N=\left\vert E\right\vert $ e $v$ una
densit\`{a} di probabilit\`{a} qualsiasi su $\left( E,2^{E}\right) $.
Definisco per ricorrenza la successione di vettori $v_{n}=\frac{1}{n}%
\sum_{k=0}^{n-1}vP^{k}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{N}$. Ogni $v_{n}$ \`{e} una densit\`{a} di probabilit\`{a} su $\left(
E,2^{E}\right) $, perch\'{e} $\frac{1}{n}\sum_{k=0}^{n-1}vP^{k}=v%
\sum_{k=0}^{n-1}\frac{1}{n}P^{k}$, il secondo fattore \`{e} una matrice
stocastica $S$ per quanto visto all'inizio, quindi la somma degli elementi
di $v_{n}$ \`{e} $\left\langle v,C_{1}\left( S\right) +...+C_{N}\left(
S\right) \right\rangle =1$. L'immagine della successione \`{e} contenuta in $%
S=\left\{ \mathbf{w}\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{N}:w_{i}\geq 0\text{ }\forall \text{ }i=1,...,N\text{ e }%
\sum_{j=1}^{N}w_{j}=1\right\} $, che \`{e} chiuso e limitato e quindi
compatto. Allora, per definizione di compatto, $v_{n}$ ammette una
sottosuccessione convergente a un elemento di $S$, cio\`{e} $\exists $ $%
\left( n_{k}\right) _{k\geq 1},\exists $ $\pi \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
^{N}:\lim_{k\rightarrow +\infty }v_{n_{k}}=\pi $; quindi, essendo $P$
un'applicazione lineare e dunque continua, $\pi -\pi P=\lim_{k\rightarrow
+\infty }v_{n_{k}}-\left( \lim_{k\rightarrow +\infty }v_{n_{k}}\right)
P=\lim_{k\rightarrow +\infty }v_{n_{k}}-\left( \lim_{k\rightarrow +\infty
}v_{n_{k}}P\right) =\lim_{k\rightarrow +\infty }\left(
v_{n_{k}}-v_{n_{k}}P\right) $. Questa \`{e} una somma telescopica, perch\'{e}
$v_{n_{k}}-v_{n_{k}}P=\frac{1}{n_{k}}\sum_{k=0}^{n_{k}-1}vP^{k}-\frac{1}{%
n_{k}}\sum_{k=0}^{n_{k-1}}vP^{k}P=\frac{1}{n_{k}}\left(
\sum_{k=0}^{n_{k}-1}vP^{k}-\frac{1}{n_{k}}\sum_{k=0}^{n_{k}-1}vP^{k+1}%
\right) =\frac{1}{n_{k}}\left( v-vP^{n_{k}}\right) $.

$\lim_{k\rightarrow +\infty }\frac{1}{n_{k}}\left( v-vP^{n_{k}}\right) =0$
perch\'{e} $P^{n_{k}}$ \`{e} un'applicazione limitata per la condizione di
stocasticit\`{a}: allora $\pi =\pi P$. $\blacksquare $

\textbf{Prop 30. 1 (relazione tra probabilit\`{a} invarianti e propriet\`{a}
di }$E$)%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati,} \\
\pi \text{ \`{e} una distribuzione di probabilit\`{a} invariante per }P\text{%
, }j\in E \\
\text{Ts: (1) se }j\text{ \`{e} transiente, }\pi _{j}=0 \\
\text{(2) se }E\text{ \`{e} irriducibile, }\exists \text{ }!\text{
distribuzione invariante per }P \\
\text{(3) se }E\text{ \`{e} irriducibile, }\pi _{i}>0\text{ }\forall \text{ }%
i\in E
\end{gather*}

In (1) $\pi _{j}$ \`{e} la componente $j$-esima di $\pi $. Acquisir\`{a} senso quando si vedr\`{a} che $\pi $ descrive
il comportamento sul lungo periodo della catena, per cui non c'\`{e}
probabilit\`{a} sugli stati transienti. (3) significa che $\pi $ \`{e}
positiva su tutti gli stati, che sono tutti ricorrenti.

\textbf{Dim} (1) Se $j$ \`{e} transiente, $\lim_{n\rightarrow +\infty
}p_{ij}^{\left( n\right) }=0$. Ma poich\'{e} $\pi $ \`{e} invariante per $P$%
, $\pi _{j}=\left( \pi P^{n}\right) _{j}=\sum_{i\in E}\pi _{i}p_{ij}^{n}$:
tutti gli addendi della somma finita tendono a $0$ per $n\rightarrow +\infty 
$, quindi $\lim_{n\rightarrow +\infty }\sum_{i\in E}\pi _{i}p_{ij}^{\left(
n\right) }=0=\pi _{j}$.

(3) Essendo $\pi $ una distribuzione di probabilit\`{a}, $\exists $ $\bar{k}%
:\pi _{\bar{k}}>0$. Poich\'{e} $E$ \`{e} irriducibile, $\forall $ $j\in E$ $%
\bar{k}\leftrightarrow j$ e quindi $\exists $ $n:p_{\bar{k}j}^{\left(
n\right) }>0$. Ma $\pi _{j}=\left( \pi P^{n}\right) _{j}=\sum_{i\in E}\pi
_{i}p_{ij}^{\left( n\right) }>\pi _{\bar{k}}p_{\bar{k}j}^{\left( n\right)
}>0 $, da cui la tesi. $\blacksquare $

Se invece $E$ non \`{e} irriducibile, esistono infinite distribuzione
invarianti, che potrebbero valere $0$ anche su stati ricorrenti.

Sono solo gli stati ricorrenti a determinare la distribuzione invariante.

\textbf{Def} Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $
definita su $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $, $E$ spazio
degli stati finito, $\pi $ densit\`{a} di probabilit\`{a} su $\left(
E,2^{E}\right) $, $\pi $ si dice reversibile se $\pi _{i}p_{ij}=\pi
_{j}p_{ji}$ $\forall $ $i,j\in E$.

Significa che gli indici possono essere scambiati. L'equazione nella
definizione \`{e} detta equazione di bilancio dettagliato. Se $P$ \`{e}
simmetrica, \`{e} necessario e sufficiente che $\pi $ abbia tutte le
componenti uguali per essere reversibile: infatti $P$ \`{e} bistocastica.

\textbf{Prop 30.5 (una probabilit\`{a} reversibile \`{e} invariante)}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati,} \\
\pi \text{ \`{e} una distribuzione di probabilit\`{a} reversibile} \\
\text{Ts: }\pi \text{ \`{e} invariante per }P
\end{gather*}

\textbf{Dim}* Voglio mostrare che $\left( \pi P\right) _{j}=\sum_{i\in E}\pi
_{i}p_{ij}=\pi _{j}$. Ma poich\'{e} $\pi $ \`{e} reversibile, $\sum_{i\in
E}\pi _{i}p_{ij}=\sum_{i\in E}\pi _{j}p_{ji}=\pi _{j}\cdot 1=\pi _{j}$ perch%
\'{e} si sta sommando su una riga. $\blacksquare $

\begin{enumerate}
\item Considero il modello di Ehrenfest con $N=2$ particelle; se $X_{n}$
descrive il numero di particelle nel primo contenitore, $\left( X_{n}\right)
_{n\geq 0}\sim CM\left( v,P\right) $ con $P=\left[ 
\begin{array}{ccc}
0 & 1 & 0 \\ 
\frac{1}{2} & 0 & \frac{1}{2} \\ 
0 & 1 & 0%
\end{array}%
\right] $. $E$ \`{e} quindi irriducibile e tutti gli stati sono ricorrenti
con periodo $d=2$. Come calcolo l'unica distribuzione invariante $\pi $? $%
\pi =\left( \pi _{0},\pi _{1},\pi _{2}\right) $ soddisfa $\left\{ 
\begin{array}{c}
\frac{1}{2}\pi _{1}=\pi _{0} \\ 
\pi _{0}+\pi _{2}=\pi _{1} \\ 
\frac{1}{2}\pi _{1}=\pi _{2}%
\end{array}%
\right. $ ed \`{e} tale che $\pi _{k}\geq 0$ $\forall $ $k$ e $\pi _{0}+\pi
_{1}+\pi _{2}=0$. Risolvendo il sistema lineare si ottiene $\pi =\left( 
\frac{1}{4},\frac{1}{2},\frac{1}{4}\right) $: $\pi _{0}=\frac{1}{2^{N}}$ e
in generale $\pi =bin\left( N,\frac{1}{2}\right) $. $\pi $ \`{e}
irreversibile e quindi invariante.
\end{enumerate}

\subsection{Comportamento asintotico di catene}

\begin{enumerate}
\item Dato $\left( \Omega ,\mathcal{A},\mathbf{P}\right) $ spazio di
probabilit\`{a}, se $\left( X_{n}\right) _{n\geq 1}$ \`{e} una successione
di variabili aleatorie, con $X_{n}:\Omega \rightarrow E$ $\forall $ $n$ e $%
\left\vert E\right\vert <+\infty $, la relazioni tra i vari tipi di
convergenza diventano pi\`{u} semplici. La convergenza quasi certa implica
la convergenza in $L^{p}$ perch\'{e}, se $X_{n}\rightarrow X$ q. c. e le $%
X_{n},X$ stanno tutte in $L^{p}$, $\left\vert X_{n}-X\right\vert ^{p}$ \`{e}
una v. a. semplice e $\mathbf{E}\left( \left\vert X_{n}-X\right\vert
^{p}\right) =\sum_{i\in E}x_{i}\mathbf{P}\left( \left\vert
X_{n}-X\right\vert ^{p}=x_{i}\right) $. $\lim_{n\rightarrow +\infty }\mathbf{%
P}\left( \left\vert X_{n}-X\right\vert ^{p}\right) =0$ perch\'{e} $%
\left\vert X_{n}-X\right\vert ^{p}\rightarrow ^{\mathbf{P}}0$, quindi $%
X_{n}\rightarrow ^{L^{p}}X$.
\end{enumerate}

Data $\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $, se $v=\pi $
invariante per $P$, $P^{X_{n}}=\pi $ $\forall $ $n$, quindi $%
X_{n}\rightarrow ^{\tciLaplace }X\sim \pi $ (la successione delle leggi \`{e}
una successione costante).

\begin{enumerate}
\item Sia $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $ con $v=\left( 
\begin{array}{c}
\alpha \\ 
1-\alpha%
\end{array}%
\right) $, $\alpha \in \left( 0,1\right) $. Se $n$ \`{e} pari, $P^{n}=Id$,
altrimenti $P^{n}=P$: quindi $v^{\left( n\right) }=vP^{n}=\left\{ 
\begin{array}{c}
v\text{ se }n\text{ \`{e} pari} \\ 
vP\text{ se }n\text{ \`{e} dispari}%
\end{array}%
\right. =\left\{ 
\begin{array}{c}
\left( \alpha ,1-\alpha \right) \text{ se }n\text{ \`{e} pari} \\ 
\left( 1-\alpha ,\alpha \right) \text{ se }n\text{ \`{e} dispari}%
\end{array}%
\right. $: quindi la successione delle leggi non converge, a meno che $%
\alpha =\frac{1}{2}$, nel qual caso converge a $\left( 
\begin{array}{c}
1/2 \\ 
1/2%
\end{array}%
\right) $.
\end{enumerate}

\textbf{Teo 30.6}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati } \\
\text{irriducibile, }\pi \text{ \`{e} l'unica distribuzione invariante per }P
\\
\text{Ts: (1) }\pi _{i}=\frac{1}{\mathbf{E}_{i}\left( T_{i}\right) }\text{ }%
\forall \text{ }i\in E \\
\text{(2) }\frac{1}{n+1}\sum_{k=0}^{n}h\left( X_{k}\right) \rightarrow
\sum_{i\in E}h\left( i\right) \pi _{i}\text{ q. c. }\forall \text{ }%
h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\text{ misurabile}
\end{gather*}

Il senso di (1) \`{e} che $\pi _{i}$ rappresenta una frequenza. $%
\sum_{k=0}^{n}h\left( X_{k}\right) $ \`{e} una successione di variabili
aleatorie detta somma ergodica. Essendo $E$ finito, 
$h:E\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ \`{e} sempre continua (perch\'{e} $E$ non ha punti di accumulazione) e
limitata. (2) \`{e} un generalizzazione della legge dei grandi numeri:
afferma che la media campionaria delle $h\left( X_{k}\right) $ converge q.
c. al valore atteso di $h\left( X_{k}\right) $, calcolato - secondo la
regola del valore atteso, e sfruttando il fatto che $E$ \`{e} finito, per
cui $h\left( X_{k}\right) $ \`{e} semplice - nello spazio $\left(
E,2^{E},\pi \right) $ come $\mathbf{E}_{\pi }\left( h\right) $: il
significato \`{e} che $\pi $ \`{e}, asintoticamente, la legge di $h\left(
X_{k}\right) $.

Ci sono due casi particolari di applicazione del teorema. Se infatti $%
h\left( i\right) =i$ $\forall $ $i\in E$, si ottiene il

\textbf{Teorema ergodico}%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati } \\
\text{irriducibile, }\pi \text{ \`{e} l'unica distribuzione invariante per }P
\\
\text{Ts: }\frac{1}{n+1}\sum_{k=0}^{n}X_{k}\rightarrow \sum_{i\in E}i\pi _{i}%
\text{ q. c.}
\end{gather*}

La tesi afferma quindi che la successione delle medie campionarie converge
quasi certamente alla media $\sum_{i\in E}i\pi _{i}$: una probabilit\`{a}
invariante descrive il comportamento in media di una catena di Markov per $%
n\rightarrow +\infty $. Infatti, se in particolare le $X_{n}$ sono iid con
distribuzione iniziale $v$, la tesi afferma che $\frac{1}{n+1}%
\sum_{k=0}^{n}X_{k}\rightarrow \sum_{i\in E}iv_{i}$, che \`{e} proprio la
LGN.

Se invece $h\left( X_{k}\right) =I_{\left\{ j\right\} }\left( X_{k}\right) $%
, cio\`{e} si ottiene 
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati } \\
\text{irriducibile, }\pi \text{ \`{e} l'unica distribuzione invariante per }P
\\
\text{Ts: }\frac{1}{n+1}\sum_{k=0}^{n}I_{\left\{ j\right\} }\left(
X_{k}\right) \rightarrow \pi _{j}\text{ q. c.}
\end{gather*}

$\frac{1}{n+1}\sum_{k=0}^{n}I_{\left\{ j\right\} }X_{k}$, al variare di $n$,
descrive la frequenza relativa di elementi della catena che passano in $j$,
e pu\`{o} quindi essere vista come approssimazione di $\mathbf{P}\left(
X_{n}=j\right) $, la frazione di tempo che la catena passa in $i$.

\begin{enumerate}
\item Nel modello di Ehrenfest, la frazione di tempo in cui il contenitore 
\`{e} privo di particelle \`{e} $\frac{1}{2^{N}}=\pi _{0}$.
\end{enumerate}

Nell'esempio sopra si \`{e} visto che anche per una catena a due stati non
valeva alcun tipo di convergenza per la catena: la ragione \`{e} che il
periodo di ogni stato non \`{e} $1$.%
\begin{gather*}
\text{Hp: }\left( X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) \text{
definita su }\left( \Omega ,\mathcal{A},\mathbf{P}\right) \text{, }E\text{
spazio degli stati irriducibile,} \\
P\text{ aperiodica, }\pi \text{ \`{e} l'unica distribuzione invariante per }P
\\
\text{Ts: (3) }\lim_{n\rightarrow +\infty }p_{ij}^{\left( n\right) }=\pi _{j}%
\text{ }\forall \text{ }i,j\in E\text{ se }v=\delta _{i} \\
\text{(4) }\lim_{n\rightarrow +\infty }v^{\left( n\right) }=\pi \text{ }%
\forall \text{ }v
\end{gather*}

In (3), poich\'{e} $%
p_{ij}^{\left( n\right) }=\mathbf{P}_{i}\left( X_{n}=j\right) $, si sta
affermando che la legge asintotica della catena, sapendo che $X_{0}=i$, \`{e}
descritta da $\pi $. Il limite in (4) \`{e} inteso componente per
componente. (4) \`{e} detta convergenza all'equilibrio: la legge della
catena si avvicina a $\pi $, legge asintotica della catena, con il passare
del tempo, cio\`{e} per $n$ grande $\mathbf{P}\left( X_{n}=j\right) \simeq
\pi _{j}$: \`{e} equivalente a dire che $X_{n}\rightarrow ^{\tciLaplace }\pi 
$. Questa \`{e} un'informazione pi\`{u} forte di quella fornita dal teorema
ergodico (come il TCL d\`{a} pi\`{u} informazioni della LGN).

Si pu\`{o} usare il teorema ergodico anche per calcolare il numero reale $%
\int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) d\mu \left( x\right) =c$, introducendo $\left(
X_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $, con $E=%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$, tale che $\mu $ sia una distribuzione invariante per $P$. Allora $\frac{1%
}{n+1}\sum_{k=0}^{n}h\left( X_{k}\right) \rightarrow \int_{%
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
}h\left( x\right) d\mu \left( x\right) =c$, cio\`{e} il valore
dell'integrale pu\`{o} essere stimato simulando l'evoluzione della catena e
calcolando il lato sinistro.

\begin{enumerate}
\item Presi gli stati $a,b\in E$ e $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
1 & 0%
\end{array}%
\right] $, $P$ \`{e} bistocastica, quindi la distribuzione uniforme $\pi
=\left( 
\begin{array}{c}
1/2 \\ 
1/2%
\end{array}%
\right) $ \`{e} invariante per $P$, che \`{e} anche irriducibile. Allora,
per il teorema ergodico, $\frac{1}{n+1}\sum_{k=0}^{n}I_{\left\{ a\right\}
}X_{k}\rightarrow \frac{1}{2}$ q. c. Se $v=\delta _{a}$, $v^{\left( n\right)
}=\left\{ 
\begin{array}{c}
\delta _{a}\text{ se }n\text{ \`{e} pari} \\ 
\delta _{b}\text{ se }n\text{ \`{e} dispari}%
\end{array}%
\right. $ per quanto gi\`{a} visto su $b$: in questo caso non c'\`{e}
convergenza all'equilibrio, cio\`{e} non vale (4) $\lim_{n\rightarrow
+\infty }v^{\left( n\right) }=\pi =\frac{1}{2}$, per cui $P$ non \`{e}
aperiodica (infatti ogni stato ha periodo $2$) (analogamente, per il modello
di Ehrenfest, non si pu\`{o} applicare 4). Vale per\`{o} che $\mathbf{E}%
_{a}\left( T_{a}\right) =\frac{1}{\pi _{1}}=2=\mathbf{E}_{b}\left(
T_{b}\right) $. Ma se introduco la sottocatena $Y_{n}=X_{2\bar{n}}$, allora $%
\left( Y_{n}\right) _{n\geq 0}\sim CM\left( v,P\right) $ con $v^{\left(
n\right) }=\delta _{a}$. 

\item Presi gli stati $1,2\in E$, $P=\left[ 
\begin{array}{cc}
0 & 1 \\ 
\alpha & 1-\alpha%
\end{array}%
\right] $, si \`{e} gi\`{a} calcolato che $\mathbf{E}_{a}\left( T_{a}\right)
=\frac{1}{\pi _{a}}=\frac{1+\alpha }{\alpha }$; $\pi $ \`{e} unica perch\'{e}
$E$ \`{e} irriducibile. $\pi _{a}+\pi _{b}=1$, quindi si deduce che $\pi
_{b}=\frac{1}{\alpha +1}$ e $\mathbf{E}_{b}\left( T_{b}\right) =\alpha +1$.
\end{enumerate}

\end{document}
